 > Using CUDA:  True
 > Number of GPUs:  4
 > `speakers.json` is saved to /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf/speakers.json.
 > `speakers_file` is updated in the config.json.
 > Restoring from model_file.pth.tar ...
 > Restoring Model...
 > Partial model initialization...
 | > Layer missing in the model definition: encoder.convolutions.0.convolution1d.weight
 | > Layer missing in the model definition: encoder.convolutions.0.convolution1d.bias
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.weight
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.bias
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.running_mean
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.running_var
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: encoder.convolutions.1.convolution1d.weight
 | > Layer missing in the model definition: encoder.convolutions.1.convolution1d.bias
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.weight
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.bias
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.running_mean
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.running_var
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: encoder.convolutions.2.convolution1d.weight
 | > Layer missing in the model definition: encoder.convolutions.2.convolution1d.bias
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.weight
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.bias
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.running_mean
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.running_var
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: encoder.lstm.weight_ih_l0
 | > Layer missing in the model definition: encoder.lstm.weight_hh_l0
 | > Layer missing in the model definition: encoder.lstm.bias_ih_l0
 | > Layer missing in the model definition: encoder.lstm.bias_hh_l0
 | > Layer missing in the model definition: encoder.lstm.weight_ih_l0_reverse
 | > Layer missing in the model definition: encoder.lstm.weight_hh_l0_reverse
 | > Layer missing in the model definition: encoder.lstm.bias_ih_l0_reverse
 | > Layer missing in the model definition: encoder.lstm.bias_hh_l0_reverse
 | > Layer missing in the model definition: decoder.attention.prior
 | > Layer missing in the model definition: decoder.attention.query_layer.weight
 | > Layer missing in the model definition: decoder.attention.query_layer.bias
 | > Layer missing in the model definition: decoder.attention.key_layer.weight
 | > Layer missing in the model definition: decoder.attention.static_filter_conv.weight
 | > Layer missing in the model definition: decoder.attention.static_filter_layer.weight
 | > Layer missing in the model definition: decoder.attention.dynamic_filter_layer.weight
 | > Layer missing in the model definition: decoder.attention.dynamic_filter_layer.bias
 | > Layer missing in the model definition: decoder.attention.v.weight
 | > Layer missing in the model definition: decoder.decoder_rnn.weight_ih
 | > Layer missing in the model definition: decoder.decoder_rnn.weight_hh
 | > Layer missing in the model definition: decoder.decoder_rnn.bias_ih
 | > Layer missing in the model definition: decoder.decoder_rnn.bias_hh
 | > Layer missing in the model definition: decoder.linear_projection.linear_layer.weight
 | > Layer missing in the model definition: decoder.linear_projection.linear_layer.bias
 | > Layer missing in the model definition: decoder.stopnet.1.linear_layer.weight
 | > Layer missing in the model definition: decoder.stopnet.1.linear_layer.bias
 | > Layer missing in the model definition: postnet.convolutions.0.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.0.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.1.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.1.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.2.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.2.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.3.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.3.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.4.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.4.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.num_batches_tracked
 | > 1 / 281 layers are restored.
 > Model restored from step 270000

 > Model has 9749029 parameters
 > Restoring best loss from  ...
 > Starting with loaded last best loss 0.09947767853736877.

[4m[1m > EPOCH: 0/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 09:38:16) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 270000[0m
     | > decoder_loss: 35.01127  (35.01127)
     | > postnet_loss: 21.75618  (21.75618)
     | > stopnet_loss: 1.35702  (1.35702)
     | > decoder_coarse_loss: 35.13684  (35.13684)
     | > decoder_ddc_loss: 0.00035  (0.00035)
     | > ga_loss: 0.00221  (0.00221)
     | > decoder_diff_spec_loss: 0.40748  (0.40748)
     | > postnet_diff_spec_loss: 0.82418  (0.82418)
     | > decoder_ssim_loss: 0.54467  (0.54467)
     | > postnet_ssim_loss: 0.54462  (0.54462)
     | > loss: 24.92445  (24.92445)
     | > align_error: 0.99479  (0.99479)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.82248  (1.82248)
     | > current_lr: 2.5000000000000002e-08 
     | > step_time: 2.70560  (2.70558)
     | > loader_time: 12.33180  (12.33177)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 270025[0m
     | > decoder_loss: 32.91222  (32.97549)
     | > postnet_loss: 18.74924  (19.53537)
     | > stopnet_loss: 1.80415  (1.86529)
     | > decoder_coarse_loss: 33.04670  (33.09028)
     | > decoder_ddc_loss: 0.00061  (0.00051)
     | > ga_loss: 0.00247  (0.00263)
     | > decoder_diff_spec_loss: 0.41874  (0.43447)
     | > postnet_diff_spec_loss: 0.84458  (0.86606)
     | > decoder_ssim_loss: 0.40671  (0.40306)
     | > postnet_ssim_loss: 0.40668  (0.40302)
     | > loss: 23.51288  (23.80549)
     | > align_error: 0.99402  (0.99458)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.88067  (1.80166)
     | > current_lr: 6.5e-07 
     | > step_time: 3.65370  (3.97904)
     | > loader_time: 0.01890  (0.03250)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 270050[0m
     | > decoder_loss: 33.14086  (33.46827)
     | > postnet_loss: 20.21301  (19.96420)
     | > stopnet_loss: 2.35059  (1.91591)
     | > decoder_coarse_loss: 33.30551  (33.58521)
     | > decoder_ddc_loss: 0.00045  (0.00052)
     | > ga_loss: 0.00204  (0.00258)
     | > decoder_diff_spec_loss: 0.45112  (0.43857)
     | > postnet_diff_spec_loss: 0.89831  (0.86956)
     | > decoder_ssim_loss: 0.30377  (0.39525)
     | > postnet_ssim_loss: 0.30375  (0.39522)
     | > loss: 24.51498  (24.20803)
     | > align_error: 0.99552  (0.99464)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.79593  (1.80967)
     | > current_lr: 1.275e-06 
     | > step_time: 4.75690  (3.94432)
     | > loader_time: 0.02730  (0.03026)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 270075[0m
     | > decoder_loss: 33.28966  (33.46149)
     | > postnet_loss: 20.20178  (19.90664)
     | > stopnet_loss: 1.73732  (1.92464)
     | > decoder_coarse_loss: 33.42768  (33.57946)
     | > decoder_ddc_loss: 0.00068  (0.00052)
     | > ga_loss: 0.00356  (0.00261)
     | > decoder_diff_spec_loss: 0.40421  (0.43745)
     | > postnet_diff_spec_loss: 0.83882  (0.86822)
     | > decoder_ssim_loss: 0.43132  (0.39500)
     | > postnet_ssim_loss: 0.43126  (0.39496)
     | > loss: 24.01145  (24.19865)
     | > align_error: 0.99278  (0.99457)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.72940  (1.80397)
     | > current_lr: 1.9e-06 
     | > step_time: 3.22440  (3.91836)
     | > loader_time: 0.02280  (0.03106)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time: 5.41574 [0m(+0.00000)
     | > avg_decoder_loss: 31.63254 [0m(+0.00000)
     | > avg_postnet_loss: 20.24841 [0m(+0.00000)
     | > avg_stopnet_loss: 1.84633 [0m(+0.00000)
     | > avg_decoder_coarse_loss: 31.70675 [0m(+0.00000)
     | > avg_decoder_ddc_loss: 0.00030 [0m(+0.00000)
     | > avg_ga_loss: 0.00274 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss: 0.46843 [0m(+0.00000)
     | > avg_postnet_diff_spec_loss: 0.90074 [0m(+0.00000)
     | > avg_decoder_ssim_loss: 0.38603 [0m(+0.00000)
     | > avg_postnet_ssim_loss: 0.38599 [0m(+0.00000)
     | > avg_loss: 23.29233 [0m(+0.00000)
     | > avg_align_error: 0.99506 [0m(+0.00000)


[4m[1m > EPOCH: 1/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 09:46:10) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 270100[0m
     | > decoder_loss: 31.07539  (32.82369)
     | > postnet_loss: 17.74138  (19.42146)
     | > stopnet_loss: 1.59597  (1.82161)
     | > decoder_coarse_loss: 31.19990  (32.93554)
     | > decoder_ddc_loss: 0.00060  (0.00046)
     | > ga_loss: 0.00289  (0.00249)
     | > decoder_diff_spec_loss: 0.44383  (0.43216)
     | > postnet_diff_spec_loss: 0.87120  (0.86410)
     | > decoder_ssim_loss: 0.46318  (0.41622)
     | > postnet_ssim_loss: 0.46315  (0.41618)
     | > loss: 22.17509  (23.66152)
     | > align_error: 0.99434  (0.99485)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.68595  (1.81574)
     | > current_lr: 2.525e-06 
     | > step_time: 2.68030  (4.43032)
     | > loader_time: 0.01580  (0.03471)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 270125[0m
     | > decoder_loss: 33.66753  (33.30301)
     | > postnet_loss: 20.83769  (19.94908)
     | > stopnet_loss: 2.31222  (1.90697)
     | > decoder_coarse_loss: 33.75340  (33.41538)
     | > decoder_ddc_loss: 0.00052  (0.00050)
     | > ga_loss: 0.00270  (0.00263)
     | > decoder_diff_spec_loss: 0.42572  (0.43614)
     | > postnet_diff_spec_loss: 0.85076  (0.86630)
     | > decoder_ssim_loss: 0.31771  (0.39692)
     | > postnet_ssim_loss: 0.31767  (0.39689)
     | > loss: 24.86844  (24.11116)
     | > align_error: 0.99534  (0.99464)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.82185  (1.81567)
     | > current_lr: 3.1500000000000003e-06 
     | > step_time: 3.70640  (3.95797)
     | > loader_time: 0.02070  (0.03276)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 270150[0m
     | > decoder_loss: 38.32879  (33.24789)
     | > postnet_loss: 23.04899  (19.81426)
     | > stopnet_loss: 1.80897  (1.93099)
     | > decoder_coarse_loss: 38.45086  (33.35898)
     | > decoder_ddc_loss: 0.00072  (0.00051)
     | > ga_loss: 0.00291  (0.00262)
     | > decoder_diff_spec_loss: 0.43271  (0.43635)
     | > postnet_diff_spec_loss: 0.84977  (0.86720)
     | > decoder_ssim_loss: 0.39514  (0.39551)
     | > postnet_ssim_loss: 0.39512  (0.39548)
     | > loss: 27.29906  (24.07312)
     | > align_error: 0.99324  (0.99459)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.86770  (1.81770)
     | > current_lr: 3.7750000000000003e-06 
     | > step_time: 3.81640  (3.96348)
     | > loader_time: 0.01880  (0.03544)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 270175[0m
     | > decoder_loss: 32.16924  (33.39011)
     | > postnet_loss: 21.15750  (19.89584)
     | > stopnet_loss: 1.34112  (1.92445)
     | > decoder_coarse_loss: 32.17535  (33.50114)
     | > decoder_ddc_loss: 0.00202  (0.00052)
     | > ga_loss: 0.00988  (0.00271)
     | > decoder_diff_spec_loss: 0.45516  (0.43741)
     | > postnet_diff_spec_loss: 0.97309  (0.86903)
     | > decoder_ssim_loss: 0.65678  (0.39795)
     | > postnet_ssim_loss: 0.65665  (0.39792)
     | > loss: 23.45196  (24.16047)
     | > align_error: 0.97471  (0.99436)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.64884  (1.83054)
     | > current_lr: 4.4e-06 
     | > step_time: 0.45090  (3.78711)
     | > loader_time: 0.00890  (0.03368)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.48713 [0m(+0.07139)
     | > avg_decoder_loss:[92m 31.53632 [0m(-0.09622)
     | > avg_postnet_loss:[92m 20.19428 [0m(-0.05413)
     | > avg_stopnet_loss:[92m 1.84349 [0m(-0.00284)
     | > avg_decoder_coarse_loss:[92m 31.49833 [0m(-0.20841)
     | > avg_decoder_ddc_loss:[92m 0.00028 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00274 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.46876 [0m(+0.00034)
     | > avg_postnet_diff_spec_loss:[92m 0.90064 [0m(-0.00010)
     | > avg_decoder_ssim_loss:[92m 0.38602 [0m(-0.00001)
     | > avg_postnet_ssim_loss:[92m 0.38598 [0m(-0.00000)
     | > avg_loss:[92m 23.19983 [0m(-0.09250)
     | > avg_align_error:[91m 0.99506 [0m(+0.00001)


[4m[1m > EPOCH: 2/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 09:53:52) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 270200[0m
     | > decoder_loss: 32.29855  (32.74904)
     | > postnet_loss: 20.20214  (19.46982)
     | > stopnet_loss: 1.78276  (1.87705)
     | > decoder_coarse_loss: 32.41938  (32.85308)
     | > decoder_ddc_loss: 0.00053  (0.00046)
     | > ga_loss: 0.00327  (0.00263)
     | > decoder_diff_spec_loss: 0.46604  (0.43720)
     | > postnet_diff_spec_loss: 0.90016  (0.86683)
     | > decoder_ssim_loss: 0.42947  (0.40289)
     | > postnet_ssim_loss: 0.42944  (0.40286)
     | > loss: 23.58556  (23.68574)
     | > align_error: 0.99319  (0.99464)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.02080  (1.96146)
     | > current_lr: 0.00001 
     | > step_time: 2.88260  (3.81154)
     | > loader_time: 0.02100  (0.03367)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 270225[0m
     | > decoder_loss: 32.80231  (33.18895)
     | > postnet_loss: 18.90728  (19.83794)
     | > stopnet_loss: 2.53577  (1.91731)
     | > decoder_coarse_loss: 32.93629  (33.29933)
     | > decoder_ddc_loss: 0.00044  (0.00046)
     | > ga_loss: 0.00229  (0.00259)
     | > decoder_diff_spec_loss: 0.47809  (0.44226)
     | > postnet_diff_spec_loss: 0.89415  (0.86866)
     | > decoder_ssim_loss: 0.28520  (0.39710)
     | > postnet_ssim_loss: 0.28519  (0.39707)
     | > loss: 24.19444  (24.03821)
     | > align_error: 0.99545  (0.99466)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.33859  (2.06130)
     | > current_lr: 0.00001 
     | > step_time: 5.74380  (3.83131)
     | > loader_time: 0.02580  (0.03186)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 270250[0m
     | > decoder_loss: 30.64979  (33.10899)
     | > postnet_loss: 17.60573  (19.75658)
     | > stopnet_loss: 2.46462  (1.93781)
     | > decoder_coarse_loss: 30.85189  (33.22580)
     | > decoder_ddc_loss: 0.00040  (0.00045)
     | > ga_loss: 0.00257  (0.00260)
     | > decoder_diff_spec_loss: 0.44845  (0.44445)
     | > postnet_diff_spec_loss: 0.85508  (0.86824)
     | > decoder_ssim_loss: 0.30629  (0.39448)
     | > postnet_ssim_loss: 0.30632  (0.39446)
     | > loss: 22.73347  (23.99915)
     | > align_error: 0.99570  (0.99464)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.83194  (2.17545)
     | > current_lr: 0.00001 
     | > step_time: 3.70080  (3.76907)
     | > loader_time: 0.02520  (0.03586)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.96244 [0m(+0.47530)
     | > avg_decoder_loss:[92m 31.25146 [0m(-0.28486)
     | > avg_postnet_loss:[92m 20.07780 [0m(-0.11648)
     | > avg_stopnet_loss:[91m 1.85427 [0m(+0.01078)
     | > avg_decoder_coarse_loss:[92m 30.97684 [0m(-0.52150)
     | > avg_decoder_ddc_loss:[92m 0.00025 [0m(-0.00003)
     | > avg_ga_loss:[92m 0.00274 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47628 [0m(+0.00751)
     | > avg_postnet_diff_spec_loss:[92m 0.90016 [0m(-0.00048)
     | > avg_decoder_ssim_loss:[92m 0.38599 [0m(-0.00003)
     | > avg_postnet_ssim_loss:[92m 0.38598 [0m(-0.00001)
     | > avg_loss:[92m 22.98164 [0m(-0.21820)
     | > avg_align_error:[91m 0.99507 [0m(+0.00001)


[4m[1m > EPOCH: 3/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:01:25) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 270275[0m
     | > decoder_loss: 35.78188  (32.20903)
     | > postnet_loss: 21.86103  (19.31443)
     | > stopnet_loss: 2.17383  (1.85160)
     | > decoder_coarse_loss: 35.92200  (32.35701)
     | > decoder_ddc_loss: 0.00030  (0.00034)
     | > ga_loss: 0.00225  (0.00245)
     | > decoder_diff_spec_loss: 0.44344  (0.45808)
     | > postnet_diff_spec_loss: 0.84187  (0.86283)
     | > decoder_ssim_loss: 0.34240  (0.41185)
     | > postnet_ssim_loss: 0.34244  (0.41189)
     | > loss: 26.06893  (23.37019)
     | > align_error: 0.99548  (0.99498)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 3.28216  (3.05592)
     | > current_lr: 0.00001 
     | > step_time: 5.06480  (4.14968)
     | > loader_time: 0.02260  (0.03110)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 270300[0m
     | > decoder_loss: 32.82770  (32.31500)
     | > postnet_loss: 19.71411  (19.61265)
     | > stopnet_loss: 1.82696  (1.90615)
     | > decoder_coarse_loss: 33.06717  (32.50016)
     | > decoder_ddc_loss: 0.00034  (0.00038)
     | > ga_loss: 0.00231  (0.00261)
     | > decoder_diff_spec_loss: 0.48313  (0.47676)
     | > postnet_diff_spec_loss: 0.84176  (0.86598)
     | > decoder_ssim_loss: 0.40420  (0.39900)
     | > postnet_ssim_loss: 0.40434  (0.39906)
     | > loss: 23.77419  (23.56146)
     | > align_error: 0.99567  (0.99471)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 4.25003  (3.41740)
     | > current_lr: 0.00001 
     | > step_time: 4.20990  (3.73623)
     | > loader_time: 0.01670  (0.03120)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 270325[0m
     | > decoder_loss: 28.69915  (31.92829)
     | > postnet_loss: 17.27624  (19.40041)
     | > stopnet_loss: 1.30647  (1.94376)
     | > decoder_coarse_loss: 28.79386  (32.15155)
     | > decoder_ddc_loss: 0.00046  (0.00037)
     | > ga_loss: 0.00329  (0.00260)
     | > decoder_diff_spec_loss: 0.51839  (0.49650)
     | > postnet_diff_spec_loss: 0.88045  (0.86672)
     | > decoder_ssim_loss: 0.57903  (0.39534)
     | > postnet_ssim_loss: 0.57944  (0.39545)
     | > loss: 20.65466  (23.36541)
     | > align_error: 0.99189  (0.99470)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 4.41408  (3.91262)
     | > current_lr: 0.00001 
     | > step_time: 2.31350  (3.74186)
     | > loader_time: 0.04380  (0.03237)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 270350[0m
     | > decoder_loss: 28.56796  (31.79006)
     | > postnet_loss: 18.69326  (19.46302)
     | > stopnet_loss: 1.82618  (1.94230)
     | > decoder_coarse_loss: 29.03952  (32.07882)
     | > decoder_ddc_loss: 0.00027  (0.00037)
     | > ga_loss: 0.00202  (0.00261)
     | > decoder_diff_spec_loss: 0.63501  (0.52901)
     | > postnet_diff_spec_loss: 0.83989  (0.86702)
     | > decoder_ssim_loss: 0.39585  (0.39466)
     | > postnet_ssim_loss: 0.39641  (0.39488)
     | > loss: 21.47830  (23.33479)
     | > align_error: 0.99574  (0.99468)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 7.18961  (4.58428)
     | > current_lr: 0.00001 
     | > step_time: 3.10720  (3.66417)
     | > loader_time: 0.02180  (0.03069)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.97696 [0m(-0.98548)
     | > avg_decoder_loss:[92m 29.83659 [0m(-1.41487)
     | > avg_postnet_loss:[92m 20.04988 [0m(-0.02792)
     | > avg_stopnet_loss:[92m 1.85256 [0m(-0.00171)
     | > avg_decoder_coarse_loss:[92m 29.17138 [0m(-1.80546)
     | > avg_decoder_ddc_loss:[92m 0.00024 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00272 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.54209 [0m(+0.06581)
     | > avg_postnet_diff_spec_loss:[92m 0.89924 [0m(-0.00092)
     | > avg_decoder_ssim_loss:[92m 0.38575 [0m(-0.00024)
     | > avg_postnet_ssim_loss:[91m 0.38598 [0m(+0.00001)
     | > avg_loss:[92m 22.18396 [0m(-0.79767)
     | > avg_align_error:[92m 0.99505 [0m(-0.00002)


[4m[1m > EPOCH: 4/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:09:00) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 270375[0m
     | > decoder_loss: 27.89497  (29.12337)
     | > postnet_loss: 18.63927  (18.76868)
     | > stopnet_loss: 1.93741  (1.86735)
     | > decoder_coarse_loss: 28.51168  (29.73192)
     | > decoder_ddc_loss: 0.00037  (0.00034)
     | > ga_loss: 0.00209  (0.00257)
     | > decoder_diff_spec_loss: 0.77116  (0.72051)
     | > postnet_diff_spec_loss: 0.88742  (0.86449)
     | > decoder_ssim_loss: 0.37696  (0.40068)
     | > postnet_ssim_loss: 0.37783  (0.40164)
     | > loss: 21.31279  (21.88310)
     | > align_error: 0.99503  (0.99477)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 8.85229  (8.00119)
     | > current_lr: 0.00001 
     | > step_time: 3.78310  (3.93526)
     | > loader_time: 0.02290  (0.03996)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 270400[0m
     | > decoder_loss: 24.54606  (28.84951)
     | > postnet_loss: 16.62659  (19.10678)
     | > stopnet_loss: 2.51642  (1.87269)
     | > decoder_coarse_loss: 25.52481  (29.56844)
     | > decoder_ddc_loss: 0.00036  (0.00037)
     | > ga_loss: 0.00209  (0.00256)
     | > decoder_diff_spec_loss: 1.02292  (0.80043)
     | > postnet_diff_spec_loss: 0.85777  (0.86725)
     | > decoder_ssim_loss: 0.28386  (0.39799)
     | > postnet_ssim_loss: 0.28603  (0.39933)
     | > loss: 19.81395  (21.88300)
     | > align_error: 0.99616  (0.99469)
     | > amp_scaler: 32768.00000  (53248.00000)
     | > grad_norm: 11.17786  (8.60196)
     | > current_lr: 0.00001 
     | > step_time: 4.23200  (3.79098)
     | > loader_time: 0.01570  (0.03427)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 270425[0m
     | > decoder_loss: 26.19257  (28.04700)
     | > postnet_loss: 19.59962  (18.95132)
     | > stopnet_loss: 2.11707  (1.87791)
     | > decoder_coarse_loss: 27.41607  (28.86262)
     | > decoder_ddc_loss: 0.00042  (0.00040)
     | > ga_loss: 0.00214  (0.00255)
     | > decoder_diff_spec_loss: 1.23588  (0.88463)
     | > postnet_diff_spec_loss: 0.86805  (0.86757)
     | > decoder_ssim_loss: 0.31808  (0.39381)
     | > postnet_ssim_loss: 0.32103  (0.39559)
     | > loss: 21.11569  (21.49139)
     | > align_error: 0.99560  (0.99464)
     | > amp_scaler: 32768.00000  (46234.30137)
     | > grad_norm: 11.32390  (9.25241)
     | > current_lr: 0.00001 
     | > step_time: 4.21020  (3.79739)
     | > loader_time: 0.06010  (0.03446)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.58403 [0m(+0.60707)
     | > avg_decoder_loss:[92m 25.24052 [0m(-4.59607)
     | > avg_postnet_loss:[92m 19.63447 [0m(-0.41541)
     | > avg_stopnet_loss:[92m 1.71627 [0m(-0.13630)
     | > avg_decoder_coarse_loss:[92m 24.69866 [0m(-4.47273)
     | > avg_decoder_ddc_loss:[91m 0.00032 [0m(+0.00008)
     | > avg_ga_loss:[92m 0.00268 [0m(-0.00004)
     | > avg_decoder_diff_spec_loss:[91m 0.85384 [0m(+0.31175)
     | > avg_postnet_diff_spec_loss:[92m 0.89911 [0m(-0.00014)
     | > avg_decoder_ssim_loss:[92m 0.38379 [0m(-0.00196)
     | > avg_postnet_ssim_loss:[92m 0.38596 [0m(-0.00002)
     | > avg_loss:[92m 19.75382 [0m(-2.43014)
     | > avg_align_error:[92m 0.99496 [0m(-0.00009)


[4m[1m > EPOCH: 5/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:16:27) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 270450[0m
     | > decoder_loss: 23.56640  (23.10460)
     | > postnet_loss: 17.65337  (17.83040)
     | > stopnet_loss: 1.20761  (1.60945)
     | > decoder_coarse_loss: 24.65114  (24.25302)
     | > decoder_ddc_loss: 0.00072  (0.00048)
     | > ga_loss: 0.00254  (0.00238)
     | > decoder_diff_spec_loss: 1.23250  (1.27617)
     | > postnet_diff_spec_loss: 0.88378  (0.86418)
     | > decoder_ssim_loss: 0.50672  (0.41324)
     | > postnet_ssim_loss: 0.51216  (0.41868)
     | > loss: 18.47200  (18.66156)
     | > align_error: 0.99345  (0.99472)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 10.52285  (11.01057)
     | > current_lr: 0.00001 
     | > step_time: 3.24950  (4.23686)
     | > loader_time: 0.01770  (0.04623)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 270475[0m
     | > decoder_loss: 21.03635  (22.30762)
     | > postnet_loss: 17.99889  (18.13537)
     | > stopnet_loss: 1.85684  (1.66430)
     | > decoder_coarse_loss: 22.44969  (23.52817)
     | > decoder_ddc_loss: 0.00057  (0.00056)
     | > ga_loss: 0.00288  (0.00252)
     | > decoder_diff_spec_loss: 1.56570  (1.38652)
     | > postnet_diff_spec_loss: 0.84296  (0.86607)
     | > decoder_ssim_loss: 0.33746  (0.39240)
     | > postnet_ssim_loss: 0.34597  (0.39872)
     | > loss: 18.01565  (18.43078)
     | > align_error: 0.99466  (0.99442)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.78087  (9.91876)
     | > current_lr: 0.00001 
     | > step_time: 3.30640  (3.77607)
     | > loader_time: 0.05470  (0.03912)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 270500[0m
     | > decoder_loss: 12.66028  (20.80902)
     | > postnet_loss: 12.28439  (17.69918)
     | > stopnet_loss: 2.62237  (1.68071)
     | > decoder_coarse_loss: 13.77947  (22.03959)
     | > decoder_ddc_loss: 0.00049  (0.00060)
     | > ga_loss: 0.00223  (0.00248)
     | > decoder_diff_spec_loss: 1.67222  (1.46344)
     | > postnet_diff_spec_loss: 0.85024  (0.86584)
     | > decoder_ssim_loss: 0.24228  (0.38448)
     | > postnet_ssim_loss: 0.25146  (0.39214)
     | > loss: 13.06871  (17.60669)
     | > align_error: 0.99517  (0.99439)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.12001  (8.68928)
     | > current_lr: 0.00001 
     | > step_time: 4.74300  (3.86411)
     | > loader_time: 0.01780  (0.04025)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 270525[0m
     | > decoder_loss: 13.69209  (19.30218)
     | > postnet_loss: 16.74428  (17.36822)
     | > stopnet_loss: 2.34489  (1.66224)
     | > decoder_coarse_loss: 14.81035  (20.52522)
     | > decoder_ddc_loss: 0.00065  (0.00065)
     | > ga_loss: 0.00236  (0.00250)
     | > decoder_diff_spec_loss: 1.62757  (1.50701)
     | > postnet_diff_spec_loss: 0.84488  (0.86672)
     | > decoder_ssim_loss: 0.26893  (0.38473)
     | > postnet_ssim_loss: 0.28111  (0.39449)
     | > loss: 14.42415  (16.76203)
     | > align_error: 0.99413  (0.99420)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.58347  (8.09142)
     | > current_lr: 0.00001 
     | > step_time: 3.05710  (3.70247)
     | > loader_time: 0.01900  (0.03692)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.42604 [0m(-0.15799)
     | > avg_decoder_loss:[92m 16.42171 [0m(-8.81881)
     | > avg_postnet_loss:[92m 17.46236 [0m(-2.17211)
     | > avg_stopnet_loss:[92m 1.52487 [0m(-0.19140)
     | > avg_decoder_coarse_loss:[92m 15.79589 [0m(-8.90276)
     | > avg_decoder_ddc_loss:[91m 0.00057 [0m(+0.00025)
     | > avg_ga_loss:[92m 0.00266 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 1.04416 [0m(+0.19032)
     | > avg_postnet_diff_spec_loss:[91m 0.89916 [0m(+0.00005)
     | > avg_decoder_ssim_loss:[92m 0.37523 [0m(-0.00856)
     | > avg_postnet_ssim_loss:[92m 0.38563 [0m(-0.00033)
     | > avg_loss:[92m 14.63437 [0m(-5.11945)
     | > avg_align_error:[92m 0.99471 [0m(-0.00025)


[4m[1m > EPOCH: 6/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:23:56) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 270550[0m
     | > decoder_loss: 9.99355  (11.69902)
     | > postnet_loss: 12.55110  (14.91530)
     | > stopnet_loss: 1.48300  (1.60653)
     | > decoder_coarse_loss: 11.09300  (12.82212)
     | > decoder_ddc_loss: 0.00057  (0.00072)
     | > ga_loss: 0.00196  (0.00244)
     | > decoder_diff_spec_loss: 1.45333  (1.52279)
     | > postnet_diff_spec_loss: 0.84794  (0.86330)
     | > decoder_ssim_loss: 0.38837  (0.38197)
     | > postnet_ssim_loss: 0.41151  (0.40162)
     | > loss: 10.67764  (12.27044)
     | > align_error: 0.99474  (0.99381)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.43774  (7.24722)
     | > current_lr: 0.00001 
     | > step_time: 3.65780  (3.88937)
     | > loader_time: 0.02050  (0.03938)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 270575[0m
     | > decoder_loss: 8.91360  (10.74968)
     | > postnet_loss: 15.12596  (14.83691)
     | > stopnet_loss: 1.12370  (1.61732)
     | > decoder_coarse_loss: 9.94932  (11.85686)
     | > decoder_ddc_loss: 0.00122  (0.00076)
     | > ga_loss: 0.00290  (0.00242)
     | > decoder_diff_spec_loss: 1.24388  (1.44423)
     | > postnet_diff_spec_loss: 0.84409  (0.86732)
     | > decoder_ssim_loss: 0.49924  (0.37901)
     | > postnet_ssim_loss: 0.53391  (0.40042)
     | > loss: 10.41599  (11.76323)
     | > align_error: 0.99140  (0.99357)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.67345  (7.05993)
     | > current_lr: 0.00001 
     | > step_time: 1.67030  (3.76296)
     | > loader_time: 0.01540  (0.03661)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 270600[0m
     | > decoder_loss: 6.93814  (9.60610)
     | > postnet_loss: 14.45211  (14.27108)
     | > stopnet_loss: 2.11998  (1.67001)
     | > decoder_coarse_loss: 7.99079  (10.68504)
     | > decoder_ddc_loss: 0.00108  (0.00079)
     | > ga_loss: 0.00289  (0.00241)
     | > decoder_diff_spec_loss: 1.04460  (1.34770)
     | > postnet_diff_spec_loss: 0.84717  (0.86737)
     | > decoder_ssim_loss: 0.30845  (0.37213)
     | > postnet_ssim_loss: 0.33392  (0.39506)
     | > loss: 10.11350  (11.06838)
     | > align_error: 0.99198  (0.99344)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.88506  (6.54664)
     | > current_lr: 0.00002 
     | > step_time: 4.04760  (3.77169)
     | > loader_time: 0.02280  (0.03594)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.11666 [0m(-0.30938)
     | > avg_decoder_loss:[92m 9.13414 [0m(-7.28757)
     | > avg_postnet_loss:[92m 13.64368 [0m(-3.81869)
     | > avg_stopnet_loss:[92m 1.52459 [0m(-0.00028)
     | > avg_decoder_coarse_loss:[92m 8.69413 [0m(-7.10176)
     | > avg_decoder_ddc_loss:[91m 0.00102 [0m(+0.00046)
     | > avg_ga_loss:[91m 0.00268 [0m(+0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.72762 [0m(-0.31654)
     | > avg_postnet_diff_spec_loss:[92m 0.89911 [0m(-0.00004)
     | > avg_decoder_ssim_loss:[92m 0.36324 [0m(-0.01199)
     | > avg_postnet_ssim_loss:[92m 0.38396 [0m(-0.00166)
     | > avg_loss:[92m 9.99973 [0m(-4.63464)
     | > avg_align_error:[92m 0.99366 [0m(-0.00105)


[4m[1m > EPOCH: 7/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:31:22) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 270625[0m
     | > decoder_loss: 5.42432  (5.14401)
     | > postnet_loss: 11.95429  (11.87430)
     | > stopnet_loss: 1.51039  (1.62831)
     | > decoder_coarse_loss: 6.29495  (6.02450)
     | > decoder_ddc_loss: 0.00115  (0.00086)
     | > ga_loss: 0.00259  (0.00225)
     | > decoder_diff_spec_loss: 0.83379  (0.87191)
     | > postnet_diff_spec_loss: 0.86109  (0.86187)
     | > decoder_ssim_loss: 0.42808  (0.37315)
     | > postnet_ssim_loss: 0.46755  (0.40539)
     | > loss: 8.08963  (8.02856)
     | > align_error: 0.99164  (0.99328)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.96465  (5.08145)
     | > current_lr: 0.00002 
     | > step_time: 3.00460  (4.31541)
     | > loader_time: 0.05590  (0.04527)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 270650[0m
     | > decoder_loss: 3.97982  (4.80246)
     | > postnet_loss: 10.85992  (11.86825)
     | > stopnet_loss: 2.17293  (1.70498)
     | > decoder_coarse_loss: 4.67947  (5.60464)
     | > decoder_ddc_loss: 0.00109  (0.00092)
     | > ga_loss: 0.00224  (0.00240)
     | > decoder_diff_spec_loss: 0.69326  (0.78286)
     | > postnet_diff_spec_loss: 0.91132  (0.86657)
     | > decoder_ssim_loss: 0.29359  (0.36418)
     | > postnet_ssim_loss: 0.32439  (0.39713)
     | > loss: 7.61983  (7.88871)
     | > align_error: 0.99232  (0.99276)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.80879  (4.29866)
     | > current_lr: 0.00002 
     | > step_time: 2.99290  (3.75111)
     | > loader_time: 0.01660  (0.03213)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 270675[0m
     | > decoder_loss: 3.52431  (4.46526)
     | > postnet_loss: 10.41592  (11.48977)
     | > stopnet_loss: 1.28763  (1.75701)
     | > decoder_coarse_loss: 4.03201  (5.18397)
     | > decoder_ddc_loss: 0.00111  (0.00095)
     | > ga_loss: 0.00253  (0.00238)
     | > decoder_diff_spec_loss: 0.51763  (0.70718)
     | > postnet_diff_spec_loss: 0.82891  (0.86587)
     | > decoder_ssim_loss: 0.45550  (0.35735)
     | > postnet_ssim_loss: 0.50308  (0.39120)
     | > loss: 6.36991  (7.63430)
     | > align_error: 0.99088  (0.99274)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.82420  (4.07962)
     | > current_lr: 0.00002 
     | > step_time: 2.47730  (3.81199)
     | > loader_time: 0.02500  (0.03388)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 270700[0m
     | > decoder_loss: 2.93443  (4.23102)
     | > postnet_loss: 9.04210  (11.16025)
     | > stopnet_loss: 1.56180  (1.76487)
     | > decoder_coarse_loss: 3.28091  (4.86492)
     | > decoder_ddc_loss: 0.00118  (0.00098)
     | > ga_loss: 0.00281  (0.00241)
     | > decoder_diff_spec_loss: 0.46875  (0.64961)
     | > postnet_diff_spec_loss: 0.84121  (0.86674)
     | > decoder_ssim_loss: 0.36525  (0.35695)
     | > postnet_ssim_loss: 0.40773  (0.39227)
     | > loss: 5.91126  (7.40758)
     | > align_error: 0.99178  (0.99257)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.29687  (4.11756)
     | > current_lr: 0.00002 
     | > step_time: 2.10330  (3.69566)
     | > loader_time: 0.01440  (0.03361)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.68212 [0m(+0.56546)
     | > avg_decoder_loss:[92m 5.80729 [0m(-3.32685)
     | > avg_postnet_loss:[92m 10.99842 [0m(-2.64526)
     | > avg_stopnet_loss:[91m 1.53113 [0m(+0.00655)
     | > avg_decoder_coarse_loss:[92m 5.45330 [0m(-3.24083)
     | > avg_decoder_ddc_loss:[91m 0.00152 [0m(+0.00050)
     | > avg_ga_loss:[91m 0.00271 [0m(+0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.51297 [0m(-0.21465)
     | > avg_postnet_diff_spec_loss:[91m 0.89931 [0m(+0.00019)
     | > avg_decoder_ssim_loss:[92m 0.35318 [0m(-0.01006)
     | > avg_postnet_ssim_loss:[92m 0.38227 [0m(-0.00169)
     | > avg_loss:[92m 7.64673 [0m(-2.35299)
     | > avg_align_error:[92m 0.99262 [0m(-0.00104)


[4m[1m > EPOCH: 8/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:38:55) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 270725[0m
     | > decoder_loss: 3.37711  (3.36099)
     | > postnet_loss: 8.98793  (9.67422)
     | > stopnet_loss: 2.08859  (1.73327)
     | > decoder_coarse_loss: 3.59662  (3.63952)
     | > decoder_ddc_loss: 0.00093  (0.00102)
     | > ga_loss: 0.00226  (0.00242)
     | > decoder_diff_spec_loss: 0.44794  (0.45810)
     | > postnet_diff_spec_loss: 0.88689  (0.86342)
     | > decoder_ssim_loss: 0.28889  (0.35617)
     | > postnet_ssim_loss: 0.32396  (0.39710)
     | > loss: 6.57747  (6.43302)
     | > align_error: 0.99354  (0.99237)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.10396  (3.37078)
     | > current_lr: 0.00002 
     | > step_time: 4.26660  (3.78872)
     | > loader_time: 0.01880  (0.03622)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 270750[0m
     | > decoder_loss: 4.30511  (3.39665)
     | > postnet_loss: 11.58183  (9.62946)
     | > stopnet_loss: 1.75534  (1.75138)
     | > decoder_coarse_loss: 4.49480  (3.63012)
     | > decoder_ddc_loss: 0.00103  (0.00106)
     | > ga_loss: 0.00187  (0.00238)
     | > decoder_diff_spec_loss: 0.50949  (0.44874)
     | > postnet_diff_spec_loss: 0.95638  (0.86729)
     | > decoder_ssim_loss: 0.33726  (0.35217)
     | > postnet_ssim_loss: 0.37478  (0.39358)
     | > loss: 7.40488  (6.44302)
     | > align_error: 0.99251  (0.99235)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.34801  (3.15592)
     | > current_lr: 0.00002 
     | > step_time: 4.91820  (3.81052)
     | > loader_time: 0.09800  (0.03469)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 270775[0m
     | > decoder_loss: 3.21430  (3.37147)
     | > postnet_loss: 7.58862  (9.31946)
     | > stopnet_loss: 1.44522  (1.78159)
     | > decoder_coarse_loss: 3.29923  (3.56477)
     | > decoder_ddc_loss: 0.00125  (0.00108)
     | > ga_loss: 0.00217  (0.00237)
     | > decoder_diff_spec_loss: 0.43234  (0.43975)
     | > postnet_diff_spec_loss: 0.89468  (0.86721)
     | > decoder_ssim_loss: 0.38412  (0.35041)
     | > postnet_ssim_loss: 0.42962  (0.39204)
     | > loss: 5.51709  (6.37001)
     | > align_error: 0.99220  (0.99229)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.07307  (3.10416)
     | > current_lr: 0.00002 
     | > step_time: 3.85750  (3.85366)
     | > loader_time: 0.03420  (0.03356)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.65668 [0m(-1.02544)
     | > avg_decoder_loss:[92m 4.97199 [0m(-0.83530)
     | > avg_postnet_loss:[92m 9.29128 [0m(-1.70714)
     | > avg_stopnet_loss:[91m 1.53468 [0m(+0.00354)
     | > avg_decoder_coarse_loss:[92m 4.59253 [0m(-0.86077)
     | > avg_decoder_ddc_loss:[91m 0.00168 [0m(+0.00015)
     | > avg_ga_loss:[92m 0.00269 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.47774 [0m(-0.03523)
     | > avg_postnet_diff_spec_loss:[92m 0.89929 [0m(-0.00002)
     | > avg_decoder_ssim_loss:[92m 0.34865 [0m(-0.00453)
     | > avg_postnet_ssim_loss:[92m 0.38086 [0m(-0.00141)
     | > avg_loss:[92m 6.78912 [0m(-0.85761)
     | > avg_align_error:[92m 0.99225 [0m(-0.00036)


[4m[1m > EPOCH: 9/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:46:15) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 270800[0m
     | > decoder_loss: 3.36732  (3.21149)
     | > postnet_loss: 7.85223  (8.09472)
     | > stopnet_loss: 1.66660  (1.67275)
     | > decoder_coarse_loss: 3.39248  (3.26758)
     | > decoder_ddc_loss: 0.00091  (0.00099)
     | > ga_loss: 0.00292  (0.00219)
     | > decoder_diff_spec_loss: 0.43711  (0.40920)
     | > postnet_diff_spec_loss: 0.89001  (0.86140)
     | > decoder_ssim_loss: 0.36066  (0.35090)
     | > postnet_ssim_loss: 0.40394  (0.39434)
     | > loss: 5.85736  (5.83133)
     | > align_error: 0.99113  (0.99292)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.61156  (3.06188)
     | > current_lr: 0.00002 
     | > step_time: 1.87080  (4.39052)
     | > loader_time: 0.01670  (0.03368)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 270825[0m
     | > decoder_loss: 3.79161  (3.24954)
     | > postnet_loss: 7.52596  (8.17481)
     | > stopnet_loss: 1.32275  (1.74338)
     | > decoder_coarse_loss: 3.84259  (3.29825)
     | > decoder_ddc_loss: 0.00139  (0.00108)
     | > ga_loss: 0.00291  (0.00240)
     | > decoder_diff_spec_loss: 0.41782  (0.41468)
     | > postnet_diff_spec_loss: 0.88335  (0.86484)
     | > decoder_ssim_loss: 0.45729  (0.35213)
     | > postnet_ssim_loss: 0.51275  (0.39597)
     | > loss: 5.69549  (5.94321)
     | > align_error: 0.98935  (0.99228)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.96325  (3.00908)
     | > current_lr: 0.00002 
     | > step_time: 2.79640  (3.86771)
     | > loader_time: 0.01660  (0.03050)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 270850[0m
     | > decoder_loss: 3.56409  (3.25515)
     | > postnet_loss: 8.49439  (7.94796)
     | > stopnet_loss: 1.93290  (1.81038)
     | > decoder_coarse_loss: 3.59618  (3.29662)
     | > decoder_ddc_loss: 0.00124  (0.00109)
     | > ga_loss: 0.00312  (0.00239)
     | > decoder_diff_spec_loss: 0.40216  (0.41410)
     | > postnet_diff_spec_loss: 0.83509  (0.86615)
     | > decoder_ssim_loss: 0.34841  (0.34326)
     | > postnet_ssim_loss: 0.39206  (0.38608)
     | > loss: 6.35690  (5.94994)
     | > align_error: 0.99235  (0.99239)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.35384  (3.17567)
     | > current_lr: 0.00002 
     | > step_time: 3.26850  (3.86968)
     | > loader_time: 0.02540  (0.03110)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 270875[0m
     | > decoder_loss: 3.26757  (3.26914)
     | > postnet_loss: 6.93778  (7.76738)
     | > stopnet_loss: 1.58872  (1.80224)
     | > decoder_coarse_loss: 3.28360  (3.30509)
     | > decoder_ddc_loss: 0.00098  (0.00110)
     | > ga_loss: 0.00272  (0.00240)
     | > decoder_diff_spec_loss: 0.42817  (0.41386)
     | > postnet_diff_spec_loss: 0.86358  (0.86668)
     | > decoder_ssim_loss: 0.40544  (0.34590)
     | > postnet_ssim_loss: 0.45447  (0.38895)
     | > loss: 5.51273  (5.90378)
     | > align_error: 0.99245  (0.99229)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.42620  (3.36270)
     | > current_lr: 0.00002 
     | > step_time: 1.75180  (3.77449)
     | > loader_time: 0.01490  (0.03069)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.62822 [0m(+0.97155)
     | > avg_decoder_loss:[91m 6.64345 [0m(+1.67146)
     | > avg_postnet_loss:[92m 8.20879 [0m(-1.08250)
     | > avg_stopnet_loss:[92m 1.52692 [0m(-0.00776)
     | > avg_decoder_coarse_loss:[91m 5.73104 [0m(+1.13850)
     | > avg_decoder_ddc_loss:[91m 0.00196 [0m(+0.00029)
     | > avg_ga_loss:[91m 0.00281 [0m(+0.00012)
     | > avg_decoder_diff_spec_loss:[91m 0.49312 [0m(+0.01537)
     | > avg_postnet_diff_spec_loss:[91m 0.90024 [0m(+0.00095)
     | > avg_decoder_ssim_loss:[91m 0.35269 [0m(+0.00404)
     | > avg_postnet_ssim_loss:[92m 0.38050 [0m(-0.00036)
     | > avg_loss:[91m 7.21889 [0m(+0.42977)
     | > avg_align_error:[91m 0.99402 [0m(+0.00177)


[4m[1m > EPOCH: 10/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:53:52) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 270900[0m
     | > decoder_loss: 2.96502  (3.17283)
     | > postnet_loss: 6.83701  (6.90606)
     | > stopnet_loss: 2.17231  (1.75695)
     | > decoder_coarse_loss: 2.97968  (3.18638)
     | > decoder_ddc_loss: 0.00142  (0.00105)
     | > ga_loss: 0.00277  (0.00243)
     | > decoder_diff_spec_loss: 0.40235  (0.40877)
     | > postnet_diff_spec_loss: 0.85838  (0.86202)
     | > decoder_ssim_loss: 0.28935  (0.35401)
     | > postnet_ssim_loss: 0.32638  (0.39798)
     | > loss: 5.85105  (5.59137)
     | > align_error: 0.99151  (0.99234)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.37478  (3.17751)
     | > current_lr: 0.00002 
     | > step_time: 3.72580  (3.88963)
     | > loader_time: 0.02310  (0.03586)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 270925[0m
     | > decoder_loss: 3.37172  (3.22266)
     | > postnet_loss: 6.59207  (6.83956)
     | > stopnet_loss: 1.45153  (1.76858)
     | > decoder_coarse_loss: 3.38956  (3.23687)
     | > decoder_ddc_loss: 0.00084  (0.00105)
     | > ga_loss: 0.00191  (0.00239)
     | > decoder_diff_spec_loss: 0.38478  (0.41069)
     | > postnet_diff_spec_loss: 0.85641  (0.86508)
     | > decoder_ssim_loss: 0.38336  (0.34823)
     | > postnet_ssim_loss: 0.42849  (0.39135)
     | > loss: 5.31291  (5.60941)
     | > align_error: 0.99430  (0.99238)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.28879  (3.01776)
     | > current_lr: 0.00002 
     | > step_time: 4.39680  (3.87151)
     | > loader_time: 0.05990  (0.03574)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 270950[0m
     | > decoder_loss: 3.63906  (3.24447)
     | > postnet_loss: 6.93586  (6.69159)
     | > stopnet_loss: 1.41600  (1.79458)
     | > decoder_coarse_loss: 3.66173  (3.25932)
     | > decoder_ddc_loss: 0.00133  (0.00105)
     | > ga_loss: 0.00236  (0.00238)
     | > decoder_diff_spec_loss: 0.41952  (0.41163)
     | > postnet_diff_spec_loss: 0.87073  (0.86655)
     | > decoder_ssim_loss: 0.43562  (0.34629)
     | > postnet_ssim_loss: 0.48509  (0.38895)
     | > loss: 5.54004  (5.60893)
     | > align_error: 0.98957  (0.99235)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.63831  (3.01455)
     | > current_lr: 0.00002 
     | > step_time: 3.31580  (3.88748)
     | > loader_time: 0.01900  (0.03336)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.55966 [0m(-0.06856)
     | > avg_decoder_loss:[92m 5.04238 [0m(-1.60107)
     | > avg_postnet_loss:[92m 6.99224 [0m(-1.21654)
     | > avg_stopnet_loss:[91m 1.52910 [0m(+0.00218)
     | > avg_decoder_coarse_loss:[92m 4.54921 [0m(-1.18183)
     | > avg_decoder_ddc_loss:[92m 0.00177 [0m(-0.00020)
     | > avg_ga_loss:[92m 0.00277 [0m(-0.00004)
     | > avg_decoder_diff_spec_loss:[92m 0.47727 [0m(-0.01585)
     | > avg_postnet_diff_spec_loss:[92m 0.89936 [0m(-0.00088)
     | > avg_decoder_ssim_loss:[92m 0.34823 [0m(-0.00446)
     | > avg_postnet_ssim_loss:[92m 0.37870 [0m(-0.00181)
     | > avg_loss:[92m 6.21522 [0m(-1.00367)
     | > avg_align_error:[92m 0.99272 [0m(-0.00130)


[4m[1m > EPOCH: 11/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:01:32) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 270975[0m
     | > decoder_loss: 3.47899  (3.13204)
     | > postnet_loss: 6.20290  (5.91879)
     | > stopnet_loss: 1.35793  (1.70367)
     | > decoder_coarse_loss: 3.50385  (3.15043)
     | > decoder_ddc_loss: 0.00103  (0.00092)
     | > ga_loss: 0.00173  (0.00211)
     | > decoder_diff_spec_loss: 0.44293  (0.39993)
     | > postnet_diff_spec_loss: 0.91014  (0.85712)
     | > decoder_ssim_loss: 0.39795  (0.34818)
     | > postnet_ssim_loss: 0.44389  (0.39083)
     | > loss: 5.21199  (5.26377)
     | > align_error: 0.99209  (0.99339)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.11654  (3.67722)
     | > current_lr: 0.00002 
     | > step_time: 4.13490  (4.63676)
     | > loader_time: 0.01930  (0.05356)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 271000[0m
     | > decoder_loss: 3.04999  (3.16658)
     | > postnet_loss: 6.48906  (5.98403)
     | > stopnet_loss: 2.13549  (1.77569)
     | > decoder_coarse_loss: 3.06598  (3.18025)
     | > decoder_ddc_loss: 0.00069  (0.00096)
     | > ga_loss: 0.00219  (0.00238)
     | > decoder_diff_spec_loss: 0.40031  (0.41031)
     | > postnet_diff_spec_loss: 0.84470  (0.86406)
     | > decoder_ssim_loss: 0.28095  (0.34775)
     | > postnet_ssim_loss: 0.31691  (0.39010)
     | > loss: 5.75860  (5.37363)
     | > align_error: 0.99463  (0.99258)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.24676  (3.42845)
     | > current_lr: 0.00002 
     | > step_time: 4.22090  (3.85495)
     | > loader_time: 0.01700  (0.03862)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 271025[0m
     | > decoder_loss: 3.56135  (3.18867)
     | > postnet_loss: 6.35567  (5.81345)
     | > stopnet_loss: 1.68999  (1.82287)
     | > decoder_coarse_loss: 3.58676  (3.20417)
     | > decoder_ddc_loss: 0.00132  (0.00096)
     | > ga_loss: 0.00279  (0.00239)
     | > decoder_diff_spec_loss: 0.43005  (0.41066)
     | > postnet_diff_spec_loss: 0.88498  (0.86650)
     | > decoder_ssim_loss: 0.32867  (0.34226)
     | > postnet_ssim_loss: 0.36531  (0.38383)
     | > loss: 5.58247  (5.38745)
     | > align_error: 0.98952  (0.99261)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.75970  (3.21790)
     | > current_lr: 0.00003 
     | > step_time: 3.30280  (3.93104)
     | > loader_time: 0.01960  (0.03848)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 271050[0m
     | > decoder_loss: 3.19841  (3.20746)
     | > postnet_loss: 5.16081  (5.71773)
     | > stopnet_loss: 1.51518  (1.81816)
     | > decoder_coarse_loss: 3.21055  (3.22514)
     | > decoder_ddc_loss: 0.00050  (0.00097)
     | > ga_loss: 0.00190  (0.00241)
     | > decoder_diff_spec_loss: 0.40131  (0.41049)
     | > postnet_diff_spec_loss: 0.86646  (0.86654)
     | > decoder_ssim_loss: 0.39108  (0.34435)
     | > postnet_ssim_loss: 0.43858  (0.38604)
     | > loss: 4.94163  (5.36990)
     | > align_error: 0.99613  (0.99253)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.27522  (3.49460)
     | > current_lr: 0.00003 
     | > step_time: 3.21050  (3.81783)
     | > loader_time: 0.01350  (0.03678)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.12317 [0m(-0.43649)
     | > avg_decoder_loss:[92m 4.67978 [0m(-0.36260)
     | > avg_postnet_loss:[92m 6.20071 [0m(-0.79153)
     | > avg_stopnet_loss:[91m 1.53243 [0m(+0.00333)
     | > avg_decoder_coarse_loss:[92m 4.27103 [0m(-0.27817)
     | > avg_decoder_ddc_loss:[92m 0.00172 [0m(-0.00004)
     | > avg_ga_loss:[92m 0.00274 [0m(-0.00003)
     | > avg_decoder_diff_spec_loss:[92m 0.47328 [0m(-0.00399)
     | > avg_postnet_diff_spec_loss:[92m 0.89920 [0m(-0.00016)
     | > avg_decoder_ssim_loss:[92m 0.34709 [0m(-0.00115)
     | > avg_postnet_ssim_loss:[92m 0.37767 [0m(-0.00102)
     | > avg_loss:[92m 5.85874 [0m(-0.35648)
     | > avg_align_error:[92m 0.99254 [0m(-0.00018)


[4m[1m > EPOCH: 12/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:09:05) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 271075[0m
     | > decoder_loss: 3.22870  (3.11549)
     | > postnet_loss: 5.55698  (5.20553)
     | > stopnet_loss: 1.51587  (1.72949)
     | > decoder_coarse_loss: 3.26075  (3.13982)
     | > decoder_ddc_loss: 0.00083  (0.00096)
     | > ga_loss: 0.00236  (0.00240)
     | > decoder_diff_spec_loss: 0.42268  (0.40749)
     | > postnet_diff_spec_loss: 0.87566  (0.86205)
     | > decoder_ssim_loss: 0.38324  (0.35687)
     | > postnet_ssim_loss: 0.43014  (0.39978)
     | > loss: 5.06744  (5.11350)
     | > align_error: 0.99326  (0.99272)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.66022  (3.77439)
     | > current_lr: 0.00003 
     | > step_time: 2.73530  (3.81566)
     | > loader_time: 0.01740  (0.03515)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 271100[0m
     | > decoder_loss: 2.64318  (3.14829)
     | > postnet_loss: 4.16335  (5.15982)
     | > stopnet_loss: 2.25508  (1.76531)
     | > decoder_coarse_loss: 2.66315  (3.17660)
     | > decoder_ddc_loss: 0.00066  (0.00095)
     | > ga_loss: 0.00213  (0.00241)
     | > decoder_diff_spec_loss: 0.40034  (0.40983)
     | > postnet_diff_spec_loss: 0.84942  (0.86509)
     | > decoder_ssim_loss: 0.25764  (0.34688)
     | > postnet_ssim_loss: 0.29017  (0.38863)
     | > loss: 5.08270  (5.15137)
     | > align_error: 0.99503  (0.99268)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.58789  (3.29605)
     | > current_lr: 0.00003 
     | > step_time: 4.41900  (3.82800)
     | > loader_time: 0.02190  (0.03289)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 271125[0m
     | > decoder_loss: 3.17965  (3.16347)
     | > postnet_loss: 4.97483  (5.07191)
     | > stopnet_loss: 2.13510  (1.79973)
     | > decoder_coarse_loss: 3.21876  (3.19816)
     | > decoder_ddc_loss: 0.00068  (0.00096)
     | > ga_loss: 0.00197  (0.00238)
     | > decoder_diff_spec_loss: 0.43116  (0.41038)
     | > postnet_diff_spec_loss: 0.89195  (0.86632)
     | > decoder_ssim_loss: 0.27879  (0.34446)
     | > postnet_ssim_loss: 0.31025  (0.38575)
     | > loss: 5.46649  (5.17200)
     | > align_error: 0.99533  (0.99274)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.83461  (3.27194)
     | > current_lr: 0.00003 
     | > step_time: 5.08400  (3.88043)
     | > loader_time: 0.06760  (0.03240)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.53045 [0m(+0.40728)
     | > avg_decoder_loss:[91m 5.63569 [0m(+0.95592)
     | > avg_postnet_loss:[92m 5.68837 [0m(-0.51235)
     | > avg_stopnet_loss:[92m 1.52758 [0m(-0.00485)
     | > avg_decoder_coarse_loss:[91m 4.88769 [0m(+0.61665)
     | > avg_decoder_ddc_loss:[91m 0.00256 [0m(+0.00084)
     | > avg_ga_loss:[91m 0.00281 [0m(+0.00007)
     | > avg_decoder_diff_spec_loss:[91m 0.48706 [0m(+0.01378)
     | > avg_postnet_diff_spec_loss:[91m 0.90010 [0m(+0.00090)
     | > avg_decoder_ssim_loss:[91m 0.35002 [0m(+0.00294)
     | > avg_postnet_ssim_loss:[91m 0.37771 [0m(+0.00004)
     | > avg_loss:[91m 6.12394 [0m(+0.26519)
     | > avg_align_error:[91m 0.99324 [0m(+0.00070)


[4m[1m > EPOCH: 13/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:16:33) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 271150[0m
     | > decoder_loss: 2.86462  (2.98860)
     | > postnet_loss: 4.46671  (4.57947)
     | > stopnet_loss: 1.89649  (1.73427)
     | > decoder_coarse_loss: 2.95785  (3.04939)
     | > decoder_ddc_loss: 0.00079  (0.00080)
     | > ga_loss: 0.00174  (0.00218)
     | > decoder_diff_spec_loss: 0.37187  (0.39346)
     | > postnet_diff_spec_loss: 0.82515  (0.84844)
     | > decoder_ssim_loss: 0.31443  (0.33929)
     | > postnet_ssim_loss: 0.35401  (0.38042)
     | > loss: 4.94405  (4.89016)
     | > align_error: 0.99497  (0.99397)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.77903  (3.01683)
     | > current_lr: 0.00003 
     | > step_time: 5.03910  (4.45809)
     | > loader_time: 0.01650  (0.05047)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 271175[0m
     | > decoder_loss: 2.93211  (3.06749)
     | > postnet_loss: 4.89704  (4.67333)
     | > stopnet_loss: 1.65455  (1.72593)
     | > decoder_coarse_loss: 3.00464  (3.12966)
     | > decoder_ddc_loss: 0.00079  (0.00093)
     | > ga_loss: 0.00242  (0.00241)
     | > decoder_diff_spec_loss: 0.40747  (0.41152)
     | > postnet_diff_spec_loss: 0.84113  (0.86464)
     | > decoder_ssim_loss: 0.38612  (0.34927)
     | > postnet_ssim_loss: 0.43061  (0.39084)
     | > loss: 4.89164  (4.95992)
     | > align_error: 0.99345  (0.99299)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.60690  (3.24921)
     | > current_lr: 0.00003 
     | > step_time: 3.28600  (3.79509)
     | > loader_time: 0.03650  (0.03255)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 271200[0m
     | > decoder_loss: 3.06325  (3.07001)
     | > postnet_loss: 4.45478  (4.56893)
     | > stopnet_loss: 1.29275  (1.79801)
     | > decoder_coarse_loss: 3.17336  (3.14142)
     | > decoder_ddc_loss: 0.00089  (0.00093)
     | > ga_loss: 0.00193  (0.00238)
     | > decoder_diff_spec_loss: 0.41485  (0.41178)
     | > postnet_diff_spec_loss: 0.86381  (0.86610)
     | > decoder_ssim_loss: 0.41895  (0.34184)
     | > postnet_ssim_loss: 0.46806  (0.38261)
     | > loss: 4.51691  (5.00584)
     | > align_error: 0.99455  (0.99309)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.46420  (3.23790)
     | > current_lr: 0.00003 
     | > step_time: 4.11660  (3.80841)
     | > loader_time: 0.02200  (0.03374)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 271225[0m
     | > decoder_loss: 3.05969  (3.08142)
     | > postnet_loss: 4.18501  (4.53523)
     | > stopnet_loss: 2.01455  (1.79381)
     | > decoder_coarse_loss: 3.14741  (3.16404)
     | > decoder_ddc_loss: 0.00139  (0.00098)
     | > ga_loss: 0.00440  (0.00243)
     | > decoder_diff_spec_loss: 0.41255  (0.41279)
     | > postnet_diff_spec_loss: 0.87546  (0.86646)
     | > decoder_ssim_loss: 0.36903  (0.34303)
     | > postnet_ssim_loss: 0.41369  (0.38386)
     | > loss: 5.15261  (5.00291)
     | > align_error: 0.98830  (0.99286)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 18.56945  (3.42766)
     | > current_lr: 0.00003 
     | > step_time: 1.08390  (3.70534)
     | > loader_time: 0.01020  (0.03214)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.54706 [0m(+0.01661)
     | > avg_decoder_loss:[91m 5.90368 [0m(+0.26799)
     | > avg_postnet_loss:[92m 5.29562 [0m(-0.39275)
     | > avg_stopnet_loss:[91m 1.52918 [0m(+0.00160)
     | > avg_decoder_coarse_loss:[91m 5.00580 [0m(+0.11812)
     | > avg_decoder_ddc_loss:[91m 0.00280 [0m(+0.00024)
     | > avg_ga_loss:[91m 0.00287 [0m(+0.00006)
     | > avg_decoder_diff_spec_loss:[91m 0.49666 [0m(+0.00960)
     | > avg_postnet_diff_spec_loss:[91m 0.90077 [0m(+0.00067)
     | > avg_decoder_ssim_loss:[91m 0.35091 [0m(+0.00089)
     | > avg_postnet_ssim_loss:[92m 0.37741 [0m(-0.00030)
     | > avg_loss:[91m 6.12694 [0m(+0.00300)
     | > avg_align_error:[92m 0.99319 [0m(-0.00006)


[4m[1m > EPOCH: 14/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:24:00) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 271250[0m
     | > decoder_loss: 3.11526  (2.93276)
     | > postnet_loss: 4.61672  (4.26069)
     | > stopnet_loss: 2.06410  (1.71586)
     | > decoder_coarse_loss: 3.19825  (3.05183)
     | > decoder_ddc_loss: 0.00089  (0.00111)
     | > ga_loss: 0.00254  (0.00248)
     | > decoder_diff_spec_loss: 0.45206  (0.41298)
     | > postnet_diff_spec_loss: 0.89801  (0.86124)
     | > decoder_ssim_loss: 0.31720  (0.35461)
     | > postnet_ssim_loss: 0.35544  (0.39667)
     | > loss: 5.31524  (4.79624)
     | > align_error: 0.99364  (0.99282)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.53478  (3.64498)
     | > current_lr: 0.00003 
     | > step_time: 2.99940  (4.06913)
     | > loader_time: 0.01930  (0.03089)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 271275[0m
     | > decoder_loss: 3.18905  (2.96509)
     | > postnet_loss: 4.07366  (4.24998)
     | > stopnet_loss: 1.47071  (1.76195)
     | > decoder_coarse_loss: 3.37078  (3.10141)
     | > decoder_ddc_loss: 0.00238  (0.00129)
     | > ga_loss: 0.00283  (0.00250)
     | > decoder_diff_spec_loss: 0.42378  (0.41918)
     | > postnet_diff_spec_loss: 0.86292  (0.86544)
     | > decoder_ssim_loss: 0.43042  (0.34817)
     | > postnet_ssim_loss: 0.48057  (0.38952)
     | > loss: 4.69326  (4.85948)
     | > align_error: 0.98837  (0.99246)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.76650  (3.06270)
     | > current_lr: 0.00003 
     | > step_time: 2.16440  (3.84325)
     | > loader_time: 0.01750  (0.02832)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 271300[0m
     | > decoder_loss: 3.39929  (2.93708)
     | > postnet_loss: 4.73731  (4.18888)
     | > stopnet_loss: 1.86817  (1.80366)
     | > decoder_coarse_loss: 3.61606  (3.09458)
     | > decoder_ddc_loss: 0.00179  (0.00150)
     | > ga_loss: 0.00259  (0.00250)
     | > decoder_diff_spec_loss: 0.46217  (0.42395)
     | > postnet_diff_spec_loss: 0.90305  (0.86594)
     | > decoder_ssim_loss: 0.32152  (0.34454)
     | > postnet_ssim_loss: 0.36096  (0.38550)
     | > loss: 5.33166  (4.87666)
     | > align_error: 0.98994  (0.99214)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.88151  (3.04302)
     | > current_lr: 0.00003 
     | > step_time: 2.90170  (3.91424)
     | > loader_time: 0.02300  (0.02940)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 8.07261 [0m(+2.52555)
     | > avg_decoder_loss:[92m 4.01998 [0m(-1.88370)
     | > avg_postnet_loss:[92m 5.06589 [0m(-0.22973)
     | > avg_stopnet_loss:[91m 1.55273 [0m(+0.02355)
     | > avg_decoder_coarse_loss:[92m 3.81052 [0m(-1.19528)
     | > avg_decoder_ddc_loss:[92m 0.00198 [0m(-0.00082)
     | > avg_ga_loss:[91m 0.00316 [0m(+0.00029)
     | > avg_decoder_diff_spec_loss:[91m 0.51455 [0m(+0.01789)
     | > avg_postnet_diff_spec_loss:[91m 0.90078 [0m(+0.00000)
     | > avg_decoder_ssim_loss:[92m 0.34510 [0m(-0.00582)
     | > avg_postnet_ssim_loss:[92m 0.37601 [0m(-0.00141)
     | > avg_loss:[92m 5.32723 [0m(-0.79970)
     | > avg_align_error:[92m 0.99098 [0m(-0.00220)


[4m[1m > EPOCH: 15/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:31:42) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 271325[0m
     | > decoder_loss: 2.79799  (2.74816)
     | > postnet_loss: 4.10629  (3.89975)
     | > stopnet_loss: 1.62317  (1.76334)
     | > decoder_coarse_loss: 2.94945  (2.91968)
     | > decoder_ddc_loss: 0.00094  (0.00130)
     | > ga_loss: 0.00205  (0.00240)
     | > decoder_diff_spec_loss: 0.44451  (0.43087)
     | > postnet_diff_spec_loss: 0.86867  (0.85293)
     | > decoder_ssim_loss: 0.35536  (0.34293)
     | > postnet_ssim_loss: 0.39881  (0.38433)
     | > loss: 4.61394  (4.67033)
     | > align_error: 0.99377  (0.99219)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.05230  (2.61440)
     | > current_lr: 0.00003 
     | > step_time: 3.65490  (4.92198)
     | > loader_time: 0.05240  (0.03941)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 271350[0m
     | > decoder_loss: 2.93723  (2.77187)
     | > postnet_loss: 3.84536  (3.95751)
     | > stopnet_loss: 1.92578  (1.75064)
     | > decoder_coarse_loss: 3.05957  (2.90961)
     | > decoder_ddc_loss: 0.00157  (0.00147)
     | > ga_loss: 0.00261  (0.00259)
     | > decoder_diff_spec_loss: 0.46246  (0.44464)
     | > postnet_diff_spec_loss: 0.90332  (0.86518)
     | > decoder_ssim_loss: 0.30205  (0.34688)
     | > postnet_ssim_loss: 0.33828  (0.38789)
     | > loss: 4.90130  (4.68484)
     | > align_error: 0.99146  (0.99119)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.61096  (3.38936)
     | > current_lr: 0.00003 
     | > step_time: 5.02290  (3.90868)
     | > loader_time: 0.02450  (0.03368)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 271375[0m
     | > decoder_loss: 2.53506  (2.76819)
     | > postnet_loss: 3.25491  (3.88968)
     | > stopnet_loss: 1.43085  (1.81120)
     | > decoder_coarse_loss: 2.63200  (2.89472)
     | > decoder_ddc_loss: 0.00216  (0.00154)
     | > ga_loss: 0.00296  (0.00255)
     | > decoder_diff_spec_loss: 0.41400  (0.44381)
     | > postnet_diff_spec_loss: 0.83415  (0.86567)
     | > decoder_ssim_loss: 0.42391  (0.33928)
     | > postnet_ssim_loss: 0.47201  (0.37924)
     | > loss: 4.08770  (4.71948)
     | > align_error: 0.98913  (0.99128)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.08233  (3.15012)
     | > current_lr: 0.00003 
     | > step_time: 2.59330  (3.81948)
     | > loader_time: 0.05140  (0.03181)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 271400[0m
     | > decoder_loss: 2.64893  (2.76721)
     | > postnet_loss: 3.64567  (3.86636)
     | > stopnet_loss: 1.65551  (1.80653)
     | > decoder_coarse_loss: 2.74472  (2.88575)
     | > decoder_ddc_loss: 0.00188  (0.00165)
     | > ga_loss: 0.00234  (0.00257)
     | > decoder_diff_spec_loss: 0.41044  (0.44504)
     | > postnet_diff_spec_loss: 0.82208  (0.86527)
     | > decoder_ssim_loss: 0.33618  (0.34134)
     | > postnet_ssim_loss: 0.37516  (0.38100)
     | > loss: 4.41348  (4.70779)
     | > align_error: 0.99086  (0.99106)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.11226  (3.18005)
     | > current_lr: 0.00003 
     | > step_time: 3.22300  (3.78828)
     | > loader_time: 0.01660  (0.03177)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.69470 [0m(-2.37791)
     | > avg_decoder_loss:[92m 3.17709 [0m(-0.84289)
     | > avg_postnet_loss:[92m 4.63488 [0m(-0.43101)
     | > avg_stopnet_loss:[92m 1.54837 [0m(-0.00436)
     | > avg_decoder_coarse_loss:[92m 3.29213 [0m(-0.51839)
     | > avg_decoder_ddc_loss:[91m 0.00200 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00302 [0m(-0.00015)
     | > avg_decoder_diff_spec_loss:[91m 0.52123 [0m(+0.00668)
     | > avg_postnet_diff_spec_loss:[92m 0.89487 [0m(-0.00591)
     | > avg_decoder_ssim_loss:[92m 0.34108 [0m(-0.00401)
     | > avg_postnet_ssim_loss:[92m 0.37043 [0m(-0.00558)
     | > avg_loss:[92m 4.87187 [0m(-0.45536)
     | > avg_align_error:[92m 0.99021 [0m(-0.00077)


[4m[1m > EPOCH: 16/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:39:11) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 271425[0m
     | > decoder_loss: 2.79159  (2.66455)
     | > postnet_loss: 3.70862  (3.62178)
     | > stopnet_loss: 1.98718  (1.70685)
     | > decoder_coarse_loss: 2.84477  (2.70713)
     | > decoder_ddc_loss: 0.00159  (0.00191)
     | > ga_loss: 0.00207  (0.00263)
     | > decoder_diff_spec_loss: 0.41618  (0.43865)
     | > postnet_diff_spec_loss: 0.82545  (0.85476)
     | > decoder_ssim_loss: 0.29884  (0.35558)
     | > postnet_ssim_loss: 0.33184  (0.39319)
     | > loss: 4.80227  (4.47937)
     | > align_error: 0.99304  (0.99075)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.45767  (3.38457)
     | > current_lr: 0.00004 
     | > step_time: 5.34460  (3.88888)
     | > loader_time: 0.05760  (0.03165)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 271450[0m
     | > decoder_loss: 2.49587  (2.71355)
     | > postnet_loss: 2.94488  (3.61331)
     | > stopnet_loss: 1.58112  (1.76698)
     | > decoder_coarse_loss: 2.50925  (2.74919)
     | > decoder_ddc_loss: 0.00226  (0.00192)
     | > ga_loss: 0.00291  (0.00261)
     | > decoder_diff_spec_loss: 0.43804  (0.44465)
     | > postnet_diff_spec_loss: 0.85947  (0.86093)
     | > decoder_ssim_loss: 0.39488  (0.34502)
     | > postnet_ssim_loss: 0.43580  (0.38095)
     | > loss: 4.11577  (4.55739)
     | > align_error: 0.98864  (0.99069)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.34169  (3.34521)
     | > current_lr: 0.00004 
     | > step_time: 2.53670  (3.77701)
     | > loader_time: 0.01920  (0.03078)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 271475[0m
     | > decoder_loss: 2.74500  (2.70327)
     | > postnet_loss: 3.23361  (3.53962)
     | > stopnet_loss: 1.71831  (1.79210)
     | > decoder_coarse_loss: 2.77469  (2.73485)
     | > decoder_ddc_loss: 0.00143  (0.00190)
     | > ga_loss: 0.00213  (0.00258)
     | > decoder_diff_spec_loss: 0.49011  (0.44509)
     | > postnet_diff_spec_loss: 0.89260  (0.85987)
     | > decoder_ssim_loss: 0.32823  (0.34361)
     | > postnet_ssim_loss: 0.35697  (0.37852)
     | > loss: 4.43463  (4.55668)
     | > align_error: 0.99244  (0.99063)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.11087  (3.21201)
     | > current_lr: 0.00004 
     | > step_time: 4.72750  (3.83378)
     | > loader_time: 0.02810  (0.02997)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.11098 [0m(-0.58371)
     | > avg_decoder_loss:[91m 3.21667 [0m(+0.03958)
     | > avg_postnet_loss:[92m 4.26514 [0m(-0.36973)
     | > avg_stopnet_loss:[92m 1.53106 [0m(-0.01731)
     | > avg_decoder_coarse_loss:[91m 3.43434 [0m(+0.14221)
     | > avg_decoder_ddc_loss:[91m 0.00230 [0m(+0.00031)
     | > avg_ga_loss:[92m 0.00299 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.50872 [0m(-0.01251)
     | > avg_postnet_diff_spec_loss:[92m 0.88651 [0m(-0.00836)
     | > avg_decoder_ssim_loss:[91m 0.34119 [0m(+0.00011)
     | > avg_postnet_ssim_loss:[92m 0.36375 [0m(-0.00668)
     | > avg_loss:[92m 4.80069 [0m(-0.07119)
     | > avg_align_error:[91m 0.99029 [0m(+0.00008)


[4m[1m > EPOCH: 17/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:46:52) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 271500[0m
     | > decoder_loss: 2.95649  (2.61480)
     | > postnet_loss: 3.94794  (3.25592)
     | > stopnet_loss: 1.42958  (1.78604)
     | > decoder_coarse_loss: 2.93688  (2.62303)
     | > decoder_ddc_loss: 0.00238  (0.00182)
     | > ga_loss: 0.00286  (0.00253)
     | > decoder_diff_spec_loss: 0.44357  (0.43093)
     | > postnet_diff_spec_loss: 0.85980  (0.84070)
     | > decoder_ssim_loss: 0.38987  (0.33825)
     | > postnet_ssim_loss: 0.42912  (0.36915)
     | > loss: 4.43538  (4.41731)
     | > align_error: 0.98870  (0.99098)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.17675  (3.02849)
     | > current_lr: 0.00004 
     | > step_time: 3.38550  (4.93345)
     | > loader_time: 0.02390  (0.07374)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 271525[0m
     | > decoder_loss: 3.43866  (2.66588)
     | > postnet_loss: 4.89373  (3.30507)
     | > stopnet_loss: 1.37298  (1.75573)
     | > decoder_coarse_loss: 3.37240  (2.65025)
     | > decoder_ddc_loss: 0.00176  (0.00201)
     | > ga_loss: 0.00197  (0.00258)
     | > decoder_diff_spec_loss: 0.48124  (0.44670)
     | > postnet_diff_spec_loss: 0.85444  (0.85382)
     | > decoder_ssim_loss: 0.39187  (0.34736)
     | > postnet_ssim_loss: 0.42696  (0.37738)
     | > loss: 4.84810  (4.43072)
     | > align_error: 0.99186  (0.99036)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.64264  (3.82688)
     | > current_lr: 0.00004 
     | > step_time: 3.84480  (3.98897)
     | > loader_time: 0.02430  (0.03670)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 271550[0m
     | > decoder_loss: 2.55691  (2.67674)
     | > postnet_loss: 2.99770  (3.25220)
     | > stopnet_loss: 2.97018  (1.83510)
     | > decoder_coarse_loss: 2.59707  (2.65828)
     | > decoder_ddc_loss: 0.00166  (0.00198)
     | > ga_loss: 0.00275  (0.00254)
     | > decoder_diff_spec_loss: 0.47064  (0.44898)
     | > postnet_diff_spec_loss: 0.85770  (0.85627)
     | > decoder_ssim_loss: 0.21349  (0.33676)
     | > postnet_ssim_loss: 0.22818  (0.36570)
     | > loss: 5.46475  (4.49701)
     | > align_error: 0.99081  (0.99046)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.26322  (3.55206)
     | > current_lr: 0.00004 
     | > step_time: 4.18650  (3.96092)
     | > loader_time: 0.02130  (0.03539)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 271575[0m
     | > decoder_loss: 3.09747  (2.67910)
     | > postnet_loss: 3.84675  (3.22059)
     | > stopnet_loss: 1.36252  (1.81387)
     | > decoder_coarse_loss: 3.04991  (2.65732)
     | > decoder_ddc_loss: 0.00247  (0.00206)
     | > ga_loss: 0.00230  (0.00256)
     | > decoder_diff_spec_loss: 0.48629  (0.44988)
     | > postnet_diff_spec_loss: 0.87548  (0.85576)
     | > decoder_ssim_loss: 0.43016  (0.34039)
     | > postnet_ssim_loss: 0.46395  (0.36899)
     | > loss: 4.43713  (4.47018)
     | > align_error: 0.98923  (0.99024)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.27418  (3.54378)
     | > current_lr: 0.00004 
     | > step_time: 2.95480  (3.86746)
     | > loader_time: 0.01790  (0.03555)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.99563 [0m(-0.11536)
     | > avg_decoder_loss:[92m 2.98984 [0m(-0.22684)
     | > avg_postnet_loss:[92m 4.08588 [0m(-0.17926)
     | > avg_stopnet_loss:[92m 1.52570 [0m(-0.00536)
     | > avg_decoder_coarse_loss:[92m 3.40772 [0m(-0.02662)
     | > avg_decoder_ddc_loss:[91m 0.00267 [0m(+0.00037)
     | > avg_ga_loss:[92m 0.00287 [0m(-0.00012)
     | > avg_decoder_diff_spec_loss:[91m 0.52630 [0m(+0.01758)
     | > avg_postnet_diff_spec_loss:[92m 0.88078 [0m(-0.00573)
     | > avg_decoder_ssim_loss:[92m 0.33925 [0m(-0.00194)
     | > avg_postnet_ssim_loss:[92m 0.35499 [0m(-0.00876)
     | > avg_loss:[92m 4.68692 [0m(-0.11376)
     | > avg_align_error:[92m 0.98982 [0m(-0.00047)


[4m[1m > EPOCH: 18/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:54:33) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 271600[0m
     | > decoder_loss: 2.41822  (2.58975)
     | > postnet_loss: 2.79784  (3.02271)
     | > stopnet_loss: 1.35817  (1.67914)
     | > decoder_coarse_loss: 2.46842  (2.56650)
     | > decoder_ddc_loss: 0.00295  (0.00217)
     | > ga_loss: 0.00319  (0.00263)
     | > decoder_diff_spec_loss: 0.43089  (0.44671)
     | > postnet_diff_spec_loss: 0.83565  (0.84612)
     | > decoder_ssim_loss: 0.44484  (0.35780)
     | > postnet_ssim_loss: 0.48718  (0.38390)
     | > loss: 3.84563  (4.24620)
     | > align_error: 0.98772  (0.98992)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.42794  (4.18248)
     | > current_lr: 0.00004 
     | > step_time: 2.24150  (3.85258)
     | > loader_time: 0.05070  (0.04041)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 271625[0m
     | > decoder_loss: 2.84746  (2.64493)
     | > postnet_loss: 2.99083  (3.04534)
     | > stopnet_loss: 1.41873  (1.75382)
     | > decoder_coarse_loss: 2.83797  (2.61720)
     | > decoder_ddc_loss: 0.00274  (0.00210)
     | > ga_loss: 0.00249  (0.00256)
     | > decoder_diff_spec_loss: 0.49809  (0.45038)
     | > postnet_diff_spec_loss: 0.89380  (0.85064)
     | > decoder_ssim_loss: 0.38855  (0.34260)
     | > postnet_ssim_loss: 0.41239  (0.36768)
     | > loss: 4.14915  (4.34684)
     | > align_error: 0.98811  (0.99010)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.25928  (3.70366)
     | > current_lr: 0.00004 
     | > step_time: 3.27380  (3.84273)
     | > loader_time: 0.02100  (0.03474)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 271650[0m
     | > decoder_loss: 2.75140  (2.62633)
     | > postnet_loss: 3.08996  (2.98416)
     | > stopnet_loss: 1.82885  (1.76937)
     | > decoder_coarse_loss: 2.73909  (2.60321)
     | > decoder_ddc_loss: 0.00140  (0.00208)
     | > ga_loss: 0.00226  (0.00255)
     | > decoder_diff_spec_loss: 0.48433  (0.44998)
     | > postnet_diff_spec_loss: 0.86050  (0.84914)
     | > decoder_ssim_loss: 0.31662  (0.34289)
     | > postnet_ssim_loss: 0.33345  (0.36742)
     | > loss: 4.48433  (4.33843)
     | > align_error: 0.99232  (0.98999)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.08569  (3.69877)
     | > current_lr: 0.00004 
     | > step_time: 3.89280  (3.87842)
     | > loader_time: 0.06160  (0.03363)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.20787 [0m(+0.21224)
     | > avg_decoder_loss:[91m 3.06974 [0m(+0.07990)
     | > avg_postnet_loss:[92m 3.47491 [0m(-0.61097)
     | > avg_stopnet_loss:[92m 1.51760 [0m(-0.00810)
     | > avg_decoder_coarse_loss:[91m 3.50274 [0m(+0.09501)
     | > avg_decoder_ddc_loss:[92m 0.00241 [0m(-0.00026)
     | > avg_ga_loss:[92m 0.00283 [0m(-0.00004)
     | > avg_decoder_diff_spec_loss:[92m 0.51314 [0m(-0.01316)
     | > avg_postnet_diff_spec_loss:[92m 0.87452 [0m(-0.00626)
     | > avg_decoder_ssim_loss:[91m 0.34005 [0m(+0.00080)
     | > avg_postnet_ssim_loss:[92m 0.35297 [0m(-0.00202)
     | > avg_loss:[92m 4.56437 [0m(-0.12256)
     | > avg_align_error:[91m 0.99015 [0m(+0.00033)


[4m[1m > EPOCH: 19/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:02:27) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 271675[0m
     | > decoder_loss: 2.51519  (2.45180)
     | > postnet_loss: 2.88407  (2.61541)
     | > stopnet_loss: 1.60861  (1.83458)
     | > decoder_coarse_loss: 2.51281  (2.43284)
     | > decoder_ddc_loss: 0.00202  (0.00173)
     | > ga_loss: 0.00241  (0.00238)
     | > decoder_diff_spec_loss: 0.42175  (0.42770)
     | > postnet_diff_spec_loss: 0.82044  (0.82469)
     | > decoder_ssim_loss: 0.36042  (0.32107)
     | > postnet_ssim_loss: 0.38355  (0.34081)
     | > loss: 4.09571  (4.20049)
     | > align_error: 0.99011  (0.99137)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.32762  (3.26139)
     | > current_lr: 0.00004 
     | > step_time: 4.03540  (5.53124)
     | > loader_time: 0.04990  (0.06014)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 271700[0m
     | > decoder_loss: 2.75139  (2.55938)
     | > postnet_loss: 2.96305  (2.81054)
     | > stopnet_loss: 1.35729  (1.74033)
     | > decoder_coarse_loss: 2.70272  (2.53238)
     | > decoder_ddc_loss: 0.00281  (0.00206)
     | > ga_loss: 0.00296  (0.00258)
     | > decoder_diff_spec_loss: 0.48114  (0.44932)
     | > postnet_diff_spec_loss: 0.87107  (0.84467)
     | > decoder_ssim_loss: 0.40926  (0.34492)
     | > postnet_ssim_loss: 0.43177  (0.36597)
     | > loss: 4.02539  (4.23056)
     | > align_error: 0.98724  (0.98992)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.50946  (4.54592)
     | > current_lr: 0.00004 
     | > step_time: 3.22480  (3.77597)
     | > loader_time: 0.01490  (0.02841)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 271725[0m
     | > decoder_loss: 2.50707  (2.59693)
     | > postnet_loss: 2.72901  (2.82518)
     | > stopnet_loss: 1.91153  (1.78291)
     | > decoder_coarse_loss: 2.46464  (2.57303)
     | > decoder_ddc_loss: 0.00168  (0.00197)
     | > ga_loss: 0.00251  (0.00252)
     | > decoder_diff_spec_loss: 0.44325  (0.45355)
     | > postnet_diff_spec_loss: 0.82537  (0.84721)
     | > decoder_ssim_loss: 0.28926  (0.33836)
     | > postnet_ssim_loss: 0.30493  (0.35914)
     | > loss: 4.31541  (4.29433)
     | > align_error: 0.99116  (0.99007)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.61080  (3.97928)
     | > current_lr: 0.00004 
     | > step_time: 3.45720  (3.88746)
     | > loader_time: 0.02330  (0.02665)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 271750[0m
     | > decoder_loss: 2.43336  (2.59287)
     | > postnet_loss: 2.67934  (2.79473)
     | > stopnet_loss: 1.41012  (1.79472)
     | > decoder_coarse_loss: 2.35255  (2.57071)
     | > decoder_ddc_loss: 0.00165  (0.00200)
     | > ga_loss: 0.00190  (0.00254)
     | > decoder_diff_spec_loss: 0.41800  (0.45374)
     | > postnet_diff_spec_loss: 0.81224  (0.84659)
     | > decoder_ssim_loss: 0.36464  (0.33859)
     | > postnet_ssim_loss: 0.38753  (0.35882)
     | > loss: 3.78193  (4.29695)
     | > align_error: 0.99144  (0.98992)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.90255  (3.84455)
     | > current_lr: 0.00004 
     | > step_time: 3.79330  (3.83642)
     | > loader_time: 0.02240  (0.02862)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.16137 [0m(-0.04649)
     | > avg_decoder_loss:[92m 2.93132 [0m(-0.13842)
     | > avg_postnet_loss:[92m 3.36666 [0m(-0.10825)
     | > avg_stopnet_loss:[91m 1.52657 [0m(+0.00897)
     | > avg_decoder_coarse_loss:[92m 3.44871 [0m(-0.05402)
     | > avg_decoder_ddc_loss:[92m 0.00228 [0m(-0.00013)
     | > avg_ga_loss:[92m 0.00275 [0m(-0.00008)
     | > avg_decoder_diff_spec_loss:[92m 0.51239 [0m(-0.00075)
     | > avg_postnet_diff_spec_loss:[92m 0.86743 [0m(-0.00709)
     | > avg_decoder_ssim_loss:[92m 0.33878 [0m(-0.00128)
     | > avg_postnet_ssim_loss:[92m 0.34780 [0m(-0.00517)
     | > avg_loss:[92m 4.49417 [0m(-0.07019)
     | > avg_align_error:[91m 0.99022 [0m(+0.00007)


[4m[1m > EPOCH: 20/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:10:06) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 271775[0m
     | > decoder_loss: 2.49733  (2.52973)
     | > postnet_loss: 2.87934  (2.69984)
     | > stopnet_loss: 2.17673  (1.70375)
     | > decoder_coarse_loss: 2.42845  (2.50477)
     | > decoder_ddc_loss: 0.00239  (0.00191)
     | > ga_loss: 0.00274  (0.00255)
     | > decoder_diff_spec_loss: 0.44367  (0.45042)
     | > postnet_diff_spec_loss: 0.82525  (0.83887)
     | > decoder_ssim_loss: 0.28659  (0.35140)
     | > postnet_ssim_loss: 0.30452  (0.36876)
     | > loss: 4.60729  (4.15294)
     | > align_error: 0.98881  (0.98987)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.75287  (3.53151)
     | > current_lr: 0.00004 
     | > step_time: 3.97420  (3.97587)
     | > loader_time: 0.02770  (0.03488)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 271800[0m
     | > decoder_loss: 2.53775  (2.56069)
     | > postnet_loss: 2.87694  (2.70287)
     | > stopnet_loss: 1.56596  (1.75834)
     | > decoder_coarse_loss: 2.55382  (2.53231)
     | > decoder_ddc_loss: 0.00190  (0.00185)
     | > ga_loss: 0.00245  (0.00254)
     | > decoder_diff_spec_loss: 0.46157  (0.45365)
     | > postnet_diff_spec_loss: 0.85085  (0.84232)
     | > decoder_ssim_loss: 0.35865  (0.34090)
     | > postnet_ssim_loss: 0.37761  (0.35889)
     | > loss: 4.08299  (4.21939)
     | > align_error: 0.98956  (0.98993)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.99947  (3.78830)
     | > current_lr: 0.00004 
     | > step_time: 3.41910  (3.81115)
     | > loader_time: 0.05500  (0.03579)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 271825[0m
     | > decoder_loss: 2.51520  (2.54662)
     | > postnet_loss: 2.60405  (2.65255)
     | > stopnet_loss: 1.21099  (1.76245)
     | > decoder_coarse_loss: 2.52080  (2.52514)
     | > decoder_ddc_loss: 0.00216  (0.00186)
     | > ga_loss: 0.00248  (0.00253)
     | > decoder_diff_spec_loss: 0.47946  (0.45376)
     | > postnet_diff_spec_loss: 0.83732  (0.84200)
     | > decoder_ssim_loss: 0.43852  (0.34251)
     | > postnet_ssim_loss: 0.45812  (0.36035)
     | > loss: 3.68731  (4.20630)
     | > align_error: 0.98848  (0.98975)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.22405  (3.57205)
     | > current_lr: 0.00005 
     | > step_time: 3.51780  (3.81396)
     | > loader_time: 0.05300  (0.03655)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.26129 [0m(+0.09991)
     | > avg_decoder_loss:[91m 3.09186 [0m(+0.16055)
     | > avg_postnet_loss:[92m 3.31758 [0m(-0.04908)
     | > avg_stopnet_loss:[92m 1.52324 [0m(-0.00333)
     | > avg_decoder_coarse_loss:[91m 3.81273 [0m(+0.36402)
     | > avg_decoder_ddc_loss:[92m 0.00221 [0m(-0.00006)
     | > avg_ga_loss:[92m 0.00274 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.52018 [0m(+0.00779)
     | > avg_postnet_diff_spec_loss:[92m 0.86553 [0m(-0.00190)
     | > avg_decoder_ssim_loss:[91m 0.33949 [0m(+0.00071)
     | > avg_postnet_ssim_loss:[92m 0.34433 [0m(-0.00347)
     | > avg_loss:[91m 4.61041 [0m(+0.11624)
     | > avg_align_error:[91m 0.99031 [0m(+0.00009)


[4m[1m > EPOCH: 21/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:17:39) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 271850[0m
     | > decoder_loss: 2.49929  (2.36661)
     | > postnet_loss: 2.42195  (2.24605)
     | > stopnet_loss: 1.84703  (1.97550)
     | > decoder_coarse_loss: 2.48605  (2.36577)
     | > decoder_ddc_loss: 0.00161  (0.00139)
     | > ga_loss: 0.00239  (0.00236)
     | > decoder_diff_spec_loss: 0.44563  (0.43611)
     | > postnet_diff_spec_loss: 0.82386  (0.82071)
     | > decoder_ssim_loss: 0.33166  (0.30078)
     | > postnet_ssim_loss: 0.34695  (0.31404)
     | > loss: 4.19825  (4.20018)
     | > align_error: 0.99084  (0.99200)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.79598  (2.18230)
     | > current_lr: 0.00005 
     | > step_time: 5.41530  (6.59598)
     | > loader_time: 0.02630  (0.07455)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 271875[0m
     | > decoder_loss: 2.45981  (2.50133)
     | > postnet_loss: 2.44172  (2.53592)
     | > stopnet_loss: 2.23415  (1.76013)
     | > decoder_coarse_loss: 2.39431  (2.47095)
     | > decoder_ddc_loss: 0.00189  (0.00175)
     | > ga_loss: 0.00294  (0.00253)
     | > decoder_diff_spec_loss: 0.41993  (0.45225)
     | > postnet_diff_spec_loss: 0.80332  (0.83855)
     | > decoder_ssim_loss: 0.28052  (0.34200)
     | > postnet_ssim_loss: 0.29788  (0.35738)
     | > loss: 4.52370  (4.14781)
     | > align_error: 0.98935  (0.98995)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.78186  (4.04585)
     | > current_lr: 0.00005 
     | > step_time: 3.39960  (3.87446)
     | > loader_time: 0.06710  (0.04217)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 271900[0m
     | > decoder_loss: 2.28011  (2.53910)
     | > postnet_loss: 2.21065  (2.56355)
     | > stopnet_loss: 1.57258  (1.77666)
     | > decoder_coarse_loss: 2.23993  (2.50622)
     | > decoder_ddc_loss: 0.00136  (0.00171)
     | > ga_loss: 0.00208  (0.00248)
     | > decoder_diff_spec_loss: 0.41156  (0.45762)
     | > postnet_diff_spec_loss: 0.81284  (0.84234)
     | > decoder_ssim_loss: 0.33493  (0.33874)
     | > postnet_ssim_loss: 0.35325  (0.35407)
     | > loss: 3.74412  (4.18989)
     | > align_error: 0.99142  (0.99002)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.95163  (3.79961)
     | > current_lr: 0.00005 
     | > step_time: 4.79680  (3.88609)
     | > loader_time: 0.02670  (0.03826)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 271925[0m
     | > decoder_loss: 2.88751  (2.53845)
     | > postnet_loss: 2.72317  (2.54204)
     | > stopnet_loss: 2.13650  (1.79562)
     | > decoder_coarse_loss: 2.76186  (2.50126)
     | > decoder_ddc_loss: 0.00174  (0.00173)
     | > ga_loss: 0.00314  (0.00252)
     | > decoder_diff_spec_loss: 0.53382  (0.45867)
     | > postnet_diff_spec_loss: 0.91757  (0.84198)
     | > decoder_ssim_loss: 0.26919  (0.33771)
     | > postnet_ssim_loss: 0.27868  (0.35248)
     | > loss: 4.74559  (4.20179)
     | > align_error: 0.98990  (0.98988)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.86427  (3.62148)
     | > current_lr: 0.00005 
     | > step_time: 3.41330  (3.79611)
     | > loader_time: 0.02310  (0.03693)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.36677 [0m(+0.10548)
     | > avg_decoder_loss:[91m 3.15648 [0m(+0.06461)
     | > avg_postnet_loss:[91m 3.35316 [0m(+0.03558)
     | > avg_stopnet_loss:[91m 1.52625 [0m(+0.00301)
     | > avg_decoder_coarse_loss:[91m 4.01994 [0m(+0.20720)
     | > avg_decoder_ddc_loss:[91m 0.00226 [0m(+0.00005)
     | > avg_ga_loss:[92m 0.00274 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.51475 [0m(-0.00543)
     | > avg_postnet_diff_spec_loss:[91m 0.86586 [0m(+0.00032)
     | > avg_decoder_ssim_loss:[92m 0.33919 [0m(-0.00030)
     | > avg_postnet_ssim_loss:[91m 0.34548 [0m(+0.00115)
     | > avg_loss:[91m 4.68921 [0m(+0.07880)
     | > avg_align_error:[91m 0.99047 [0m(+0.00016)


[4m[1m > EPOCH: 22/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:25:26) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 271950[0m
     | > decoder_loss: 2.44739  (2.47900)
     | > postnet_loss: 2.23291  (2.48352)
     | > stopnet_loss: 1.85175  (1.65710)
     | > decoder_coarse_loss: 2.43245  (2.44581)
     | > decoder_ddc_loss: 0.00209  (0.00169)
     | > ga_loss: 0.00384  (0.00254)
     | > decoder_diff_spec_loss: 0.44330  (0.45663)
     | > postnet_diff_spec_loss: 0.82963  (0.83590)
     | > decoder_ssim_loss: 0.34023  (0.35525)
     | > postnet_ssim_loss: 0.34792  (0.36837)
     | > loss: 4.13994  (4.02633)
     | > align_error: 0.98707  (0.99006)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 9.19139  (3.44558)
     | > current_lr: 0.00005 
     | > step_time: 2.74000  (3.94420)
     | > loader_time: 0.01810  (0.03798)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 271975[0m
     | > decoder_loss: 2.92423  (2.51356)
     | > postnet_loss: 2.77867  (2.48813)
     | > stopnet_loss: 1.64032  (1.76625)
     | > decoder_coarse_loss: 2.83815  (2.47049)
     | > decoder_ddc_loss: 0.00181  (0.00169)
     | > ga_loss: 0.00245  (0.00252)
     | > decoder_diff_spec_loss: 0.48357  (0.45829)
     | > postnet_diff_spec_loss: 0.85675  (0.83765)
     | > decoder_ssim_loss: 0.36260  (0.33971)
     | > postnet_ssim_loss: 0.37408  (0.35320)
     | > loss: 4.30754  (4.14452)
     | > align_error: 0.98949  (0.99002)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.14114  (4.09662)
     | > current_lr: 0.00005 
     | > step_time: 3.51060  (3.89341)
     | > loader_time: 0.02590  (0.03489)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 272000[0m
     | > decoder_loss: 2.38763  (2.50187)
     | > postnet_loss: 2.23722  (2.45238)
     | > stopnet_loss: 2.04935  (1.77218)
     | > decoder_coarse_loss: 2.38543  (2.46195)
     | > decoder_ddc_loss: 0.00202  (0.00168)
     | > ga_loss: 0.00276  (0.00251)
     | > decoder_diff_spec_loss: 0.43459  (0.45802)
     | > postnet_diff_spec_loss: 0.82083  (0.83782)
     | > decoder_ssim_loss: 0.30472  (0.34046)
     | > postnet_ssim_loss: 0.31513  (0.35395)
     | > loss: 4.28507  (4.13676)
     | > align_error: 0.98683  (0.98984)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 7.57538  (3.80220)
     | > current_lr: 0.00005 
     | > step_time: 3.71390  (3.91673)
     | > loader_time: 0.02010  (0.03318)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.92445 [0m(+0.55769)
     | > avg_decoder_loss:[92m 2.96184 [0m(-0.19464)
     | > avg_postnet_loss:[92m 3.29949 [0m(-0.05366)
     | > avg_stopnet_loss:[91m 1.52705 [0m(+0.00080)
     | > avg_decoder_coarse_loss:[92m 3.79131 [0m(-0.22862)
     | > avg_decoder_ddc_loss:[92m 0.00212 [0m(-0.00014)
     | > avg_ga_loss:[92m 0.00269 [0m(-0.00004)
     | > avg_decoder_diff_spec_loss:[91m 0.51611 [0m(+0.00136)
     | > avg_postnet_diff_spec_loss:[92m 0.86256 [0m(-0.00330)
     | > avg_decoder_ssim_loss:[92m 0.33756 [0m(-0.00163)
     | > avg_postnet_ssim_loss:[92m 0.34135 [0m(-0.00413)
     | > avg_loss:[92m 4.56861 [0m(-0.12060)
     | > avg_align_error:[92m 0.99037 [0m(-0.00010)


[4m[1m > EPOCH: 23/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:33:13) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 272025[0m
     | > decoder_loss: 2.17007  (2.17007)
     | > postnet_loss: 1.94249  (1.94249)
     | > stopnet_loss: 2.10488  (2.10488)
     | > decoder_coarse_loss: 2.17446  (2.17446)
     | > decoder_ddc_loss: 0.00107  (0.00107)
     | > ga_loss: 0.00231  (0.00231)
     | > decoder_diff_spec_loss: 0.43393  (0.43393)
     | > postnet_diff_spec_loss: 0.81177  (0.81177)
     | > decoder_ssim_loss: 0.26760  (0.26760)
     | > postnet_ssim_loss: 0.27590  (0.27590)
     | > loss: 4.13577  (4.13577)
     | > align_error: 0.99316  (0.99316)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.37614  (2.37614)
     | > current_lr: 0.00005 
     | > step_time: 7.25370  (7.25369)
     | > loader_time: 0.04440  (0.04436)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 272050[0m
     | > decoder_loss: 2.53686  (2.45057)
     | > postnet_loss: 2.20769  (2.37286)
     | > stopnet_loss: 2.02742  (1.73362)
     | > decoder_coarse_loss: 2.43549  (2.40293)
     | > decoder_ddc_loss: 0.00117  (0.00159)
     | > ga_loss: 0.00225  (0.00251)
     | > decoder_diff_spec_loss: 0.47114  (0.45893)
     | > postnet_diff_spec_loss: 0.84868  (0.83563)
     | > decoder_ssim_loss: 0.27756  (0.34326)
     | > postnet_ssim_loss: 0.28570  (0.35504)
     | > loss: 4.30473  (4.05138)
     | > align_error: 0.99253  (0.99005)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.98464  (3.80116)
     | > current_lr: 0.00005 
     | > step_time: 5.22080  (3.89563)
     | > loader_time: 0.02290  (0.04244)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 272075[0m
     | > decoder_loss: 2.50473  (2.49155)
     | > postnet_loss: 2.29760  (2.39677)
     | > stopnet_loss: 2.16201  (1.78738)
     | > decoder_coarse_loss: 2.44791  (2.44435)
     | > decoder_ddc_loss: 0.00122  (0.00158)
     | > ga_loss: 0.00250  (0.00248)
     | > decoder_diff_spec_loss: 0.45477  (0.46399)
     | > postnet_diff_spec_loss: 0.85685  (0.83898)
     | > decoder_ssim_loss: 0.26438  (0.33781)
     | > postnet_ssim_loss: 0.27152  (0.34959)
     | > loss: 4.44924  (4.13093)
     | > align_error: 0.99065  (0.99005)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.53946  (3.74070)
     | > current_lr: 0.00005 
     | > step_time: 3.26050  (3.86622)
     | > loader_time: 0.01950  (0.03402)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 272100[0m
     | > decoder_loss: 2.41552  (2.48069)
     | > postnet_loss: 2.29186  (2.37351)
     | > stopnet_loss: 2.38221  (1.79459)
     | > decoder_coarse_loss: 2.34419  (2.43297)
     | > decoder_ddc_loss: 0.00115  (0.00160)
     | > ga_loss: 0.00230  (0.00250)
     | > decoder_diff_spec_loss: 0.44788  (0.46281)
     | > postnet_diff_spec_loss: 0.83987  (0.83702)
     | > decoder_ssim_loss: 0.24305  (0.33754)
     | > postnet_ssim_loss: 0.24907  (0.34904)
     | > loss: 4.60185  (4.12591)
     | > align_error: 0.99281  (0.98993)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.57759  (3.67833)
     | > current_lr: 0.00005 
     | > step_time: 4.68470  (3.81807)
     | > loader_time: 0.02580  (0.03568)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.35266 [0m(-0.57179)
     | > avg_decoder_loss:[91m 2.99412 [0m(+0.03228)
     | > avg_postnet_loss:[92m 3.29486 [0m(-0.00463)
     | > avg_stopnet_loss:[92m 1.52481 [0m(-0.00225)
     | > avg_decoder_coarse_loss:[91m 3.92376 [0m(+0.13245)
     | > avg_decoder_ddc_loss:[92m 0.00209 [0m(-0.00003)
     | > avg_ga_loss:[92m 0.00269 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.52000 [0m(+0.00389)
     | > avg_postnet_diff_spec_loss:[91m 0.86368 [0m(+0.00113)
     | > avg_decoder_ssim_loss:[92m 0.33702 [0m(-0.00054)
     | > avg_postnet_ssim_loss:[91m 0.34157 [0m(+0.00023)
     | > avg_loss:[91m 4.60751 [0m(+0.03890)
     | > avg_align_error:[91m 0.99042 [0m(+0.00004)


[4m[1m > EPOCH: 24/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:40:52) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 272125[0m
     | > decoder_loss: 2.37475  (2.43249)
     | > postnet_loss: 2.25418  (2.35014)
     | > stopnet_loss: 1.84913  (1.63598)
     | > decoder_coarse_loss: 2.41071  (2.39325)
     | > decoder_ddc_loss: 0.00159  (0.00151)
     | > ga_loss: 0.00271  (0.00241)
     | > decoder_diff_spec_loss: 0.49608  (0.46257)
     | > postnet_diff_spec_loss: 0.84677  (0.83202)
     | > decoder_ssim_loss: 0.32972  (0.35561)
     | > postnet_ssim_loss: 0.33557  (0.36553)
     | > loss: 4.12499  (3.94631)
     | > align_error: 0.98932  (0.99027)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.28092  (4.02227)
     | > current_lr: 0.00005 
     | > step_time: 3.32330  (4.23468)
     | > loader_time: 0.06350  (0.02787)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 272150[0m
     | > decoder_loss: 2.34659  (2.44973)
     | > postnet_loss: 2.04193  (2.33417)
     | > stopnet_loss: 2.10841  (1.76195)
     | > decoder_coarse_loss: 2.32091  (2.39916)
     | > decoder_ddc_loss: 0.00138  (0.00157)
     | > ga_loss: 0.00239  (0.00250)
     | > decoder_diff_spec_loss: 0.44964  (0.46215)
     | > postnet_diff_spec_loss: 0.82460  (0.83350)
     | > decoder_ssim_loss: 0.26419  (0.33815)
     | > postnet_ssim_loss: 0.27376  (0.34882)
     | > loss: 4.25110  (4.06627)
     | > align_error: 0.99015  (0.99007)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.85494  (4.19025)
     | > current_lr: 0.00005 
     | > step_time: 4.50890  (3.87860)
     | > loader_time: 0.03760  (0.02795)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 272175[0m
     | > decoder_loss: 2.26369  (2.45061)
     | > postnet_loss: 2.17672  (2.31441)
     | > stopnet_loss: 1.22171  (1.76656)
     | > decoder_coarse_loss: 2.23708  (2.39937)
     | > decoder_ddc_loss: 0.00150  (0.00158)
     | > ga_loss: 0.00230  (0.00249)
     | > decoder_diff_spec_loss: 0.44120  (0.46354)
     | > postnet_diff_spec_loss: 0.83668  (0.83449)
     | > decoder_ssim_loss: 0.40965  (0.33996)
     | > postnet_ssim_loss: 0.42462  (0.35077)
     | > loss: 3.43100  (4.06771)
     | > align_error: 0.99030  (0.98992)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.76647  (3.82601)
     | > current_lr: 0.00005 
     | > step_time: 3.83880  (3.86818)
     | > loader_time: 0.02490  (0.03212)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.39892 [0m(+1.04626)
     | > avg_decoder_loss:[92m 2.99310 [0m(-0.00101)
     | > avg_postnet_loss:[92m 3.18447 [0m(-0.11039)
     | > avg_stopnet_loss:[91m 1.53138 [0m(+0.00657)
     | > avg_decoder_coarse_loss:[91m 4.02980 [0m(+0.10604)
     | > avg_decoder_ddc_loss:[92m 0.00202 [0m(-0.00007)
     | > avg_ga_loss:[92m 0.00267 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.52704 [0m(+0.00704)
     | > avg_postnet_diff_spec_loss:[92m 0.86298 [0m(-0.00070)
     | > avg_decoder_ssim_loss:[92m 0.33611 [0m(-0.00091)
     | > avg_postnet_ssim_loss:[92m 0.34092 [0m(-0.00065)
     | > avg_loss:[91m 4.61383 [0m(+0.00632)
     | > avg_align_error:[91m 0.99047 [0m(+0.00005)


[4m[1m > EPOCH: 25/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:48:28) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 272200[0m
     | > decoder_loss: 2.16071  (2.16071)
     | > postnet_loss: 2.05865  (2.05865)
     | > stopnet_loss: 1.13059  (1.13059)
     | > decoder_coarse_loss: 2.12846  (2.12846)
     | > decoder_ddc_loss: 0.00174  (0.00174)
     | > ga_loss: 0.00216  (0.00216)
     | > decoder_diff_spec_loss: 0.44203  (0.44203)
     | > postnet_diff_spec_loss: 0.80125  (0.80125)
     | > decoder_ssim_loss: 0.46205  (0.46205)
     | > postnet_ssim_loss: 0.48341  (0.48341)
     | > loss: 3.27596  (3.27596)
     | > align_error: 0.99026  (0.99026)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.82421  (4.82421)
     | > current_lr: 0.00005 
     | > step_time: 5.68500  (5.68504)
     | > loader_time: 11.14270  (11.14270)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 272225[0m
     | > decoder_loss: 2.18357  (2.38899)
     | > postnet_loss: 1.91955  (2.24321)
     | > stopnet_loss: 1.65634  (1.71565)
     | > decoder_coarse_loss: 2.12738  (2.34377)
     | > decoder_ddc_loss: 0.00163  (0.00157)
     | > ga_loss: 0.00240  (0.00251)
     | > decoder_diff_spec_loss: 0.43671  (0.46414)
     | > postnet_diff_spec_loss: 0.81114  (0.83114)
     | > decoder_ssim_loss: 0.34670  (0.34446)
     | > postnet_ssim_loss: 0.35888  (0.35382)
     | > loss: 3.71471  (3.97097)
     | > align_error: 0.98907  (0.98995)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.39895  (4.17074)
     | > current_lr: 0.00006 
     | > step_time: 3.60290  (3.81416)
     | > loader_time: 0.01700  (0.03531)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 272250[0m
     | > decoder_loss: 2.52073  (2.43159)
     | > postnet_loss: 2.25263  (2.26444)
     | > stopnet_loss: 2.16785  (1.76138)
     | > decoder_coarse_loss: 2.48978  (2.37829)
     | > decoder_ddc_loss: 0.00122  (0.00156)
     | > ga_loss: 0.00197  (0.00247)
     | > decoder_diff_spec_loss: 0.48413  (0.47109)
     | > postnet_diff_spec_loss: 0.86384  (0.83447)
     | > decoder_ssim_loss: 0.26043  (0.33787)
     | > postnet_ssim_loss: 0.26766  (0.34741)
     | > loss: 4.46280  (4.04042)
     | > align_error: 0.99188  (0.99007)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.95373  (3.96849)
     | > current_lr: 0.00006 
     | > step_time: 4.75380  (3.81651)
     | > loader_time: 0.06230  (0.03520)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 272275[0m
     | > decoder_loss: 2.34971  (2.41783)
     | > postnet_loss: 2.30860  (2.24004)
     | > stopnet_loss: 1.56121  (1.76482)
     | > decoder_coarse_loss: 2.30082  (2.36795)
     | > decoder_ddc_loss: 0.00214  (0.00158)
     | > ga_loss: 0.00340  (0.00250)
     | > decoder_diff_spec_loss: 0.43175  (0.47024)
     | > postnet_diff_spec_loss: 0.80752  (0.83270)
     | > decoder_ssim_loss: 0.36255  (0.33736)
     | > postnet_ssim_loss: 0.37285  (0.34659)
     | > loss: 3.81221  (4.03089)
     | > align_error: 0.98672  (0.98993)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.42526  (3.75469)
     | > current_lr: 0.00006 
     | > step_time: 3.03250  (3.84140)
     | > loader_time: 0.03980  (0.03577)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.59198 [0m(-0.80695)
     | > avg_decoder_loss:[92m 2.79035 [0m(-0.20275)
     | > avg_postnet_loss:[92m 3.12414 [0m(-0.06033)
     | > avg_stopnet_loss:[91m 1.53555 [0m(+0.00417)
     | > avg_decoder_coarse_loss:[92m 3.75466 [0m(-0.27514)
     | > avg_decoder_ddc_loss:[92m 0.00188 [0m(-0.00014)
     | > avg_ga_loss:[92m 0.00265 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.52596 [0m(-0.00107)
     | > avg_postnet_diff_spec_loss:[92m 0.86116 [0m(-0.00182)
     | > avg_decoder_ssim_loss:[92m 0.33396 [0m(-0.00215)
     | > avg_postnet_ssim_loss:[92m 0.33977 [0m(-0.00115)
     | > avg_loss:[92m 4.48180 [0m(-0.13204)
     | > avg_align_error:[91m 0.99058 [0m(+0.00011)


[4m[1m > EPOCH: 26/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:56:05) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 272300[0m
     | > decoder_loss: 2.33265  (2.36004)
     | > postnet_loss: 2.02334  (2.20597)
     | > stopnet_loss: 1.41573  (1.61090)
     | > decoder_coarse_loss: 2.34702  (2.32613)
     | > decoder_ddc_loss: 0.00161  (0.00148)
     | > ga_loss: 0.00273  (0.00239)
     | > decoder_diff_spec_loss: 0.47303  (0.46700)
     | > postnet_diff_spec_loss: 0.82655  (0.82627)
     | > decoder_ssim_loss: 0.39289  (0.35564)
     | > postnet_ssim_loss: 0.39721  (0.36362)
     | > loss: 3.62794  (3.84938)
     | > align_error: 0.98961  (0.99046)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.70485  (3.24605)
     | > current_lr: 0.00006 
     | > step_time: 2.99560  (4.27026)
     | > loader_time: 0.01930  (0.03527)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 272325[0m
     | > decoder_loss: 2.38334  (2.37360)
     | > postnet_loss: 2.23336  (2.19334)
     | > stopnet_loss: 2.19281  (1.73519)
     | > decoder_coarse_loss: 2.32624  (2.33014)
     | > decoder_ddc_loss: 0.00129  (0.00155)
     | > ga_loss: 0.00254  (0.00251)
     | > decoder_diff_spec_loss: 0.46659  (0.47168)
     | > postnet_diff_spec_loss: 0.81369  (0.82888)
     | > decoder_ssim_loss: 0.26996  (0.33802)
     | > postnet_ssim_loss: 0.27676  (0.34646)
     | > loss: 4.39831  (3.96863)
     | > align_error: 0.99157  (0.99016)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.27461  (4.65312)
     | > current_lr: 0.00006 
     | > step_time: 4.50290  (3.89375)
     | > loader_time: 0.02990  (0.03436)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 272350[0m
     | > decoder_loss: 2.52119  (2.37258)
     | > postnet_loss: 2.23070  (2.17100)
     | > stopnet_loss: 1.81457  (1.75789)
     | > decoder_coarse_loss: 2.46783  (2.33248)
     | > decoder_ddc_loss: 0.00214  (0.00156)
     | > ga_loss: 0.00279  (0.00250)
     | > decoder_diff_spec_loss: 0.46912  (0.47375)
     | > postnet_diff_spec_loss: 0.80866  (0.82969)
     | > decoder_ssim_loss: 0.33308  (0.33678)
     | > postnet_ssim_loss: 0.34091  (0.34521)
     | > loss: 4.12194  (3.98614)
     | > align_error: 0.98703  (0.99002)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.70820  (4.27817)
     | > current_lr: 0.00006 
     | > step_time: 4.20410  (3.88440)
     | > loader_time: 0.05080  (0.03667)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 272375[0m
     | > decoder_loss: 2.49605  (2.37455)
     | > postnet_loss: 2.59428  (2.16818)
     | > stopnet_loss: 1.51807  (1.76506)
     | > decoder_coarse_loss: 2.58518  (2.33937)
     | > decoder_ddc_loss: 0.00981  (0.00167)
     | > ga_loss: 0.00904  (0.00258)
     | > decoder_diff_spec_loss: 0.50197  (0.47589)
     | > postnet_diff_spec_loss: 0.91684  (0.83082)
     | > decoder_ssim_loss: 0.53194  (0.33834)
     | > postnet_ssim_loss: 0.53569  (0.34649)
     | > loss: 4.10620  (3.99680)
     | > align_error: 0.95862  (0.98965)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 31.99080  (4.54683)
     | > current_lr: 0.00006 
     | > step_time: 0.50100  (3.72784)
     | > loader_time: 0.00910  (0.03358)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.19726 [0m(-0.39472)
     | > avg_decoder_loss:[91m 2.82389 [0m(+0.03353)
     | > avg_postnet_loss:[92m 3.12329 [0m(-0.00085)
     | > avg_stopnet_loss:[91m 1.53846 [0m(+0.00291)
     | > avg_decoder_coarse_loss:[92m 3.74391 [0m(-0.01075)
     | > avg_decoder_ddc_loss:[91m 0.00191 [0m(+0.00003)
     | > avg_ga_loss:[91m 0.00266 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.53448 [0m(+0.00851)
     | > avg_postnet_diff_spec_loss:[92m 0.85773 [0m(-0.00343)
     | > avg_decoder_ssim_loss:[92m 0.33253 [0m(-0.00143)
     | > avg_postnet_ssim_loss:[92m 0.33907 [0m(-0.00070)
     | > avg_loss:[91m 4.49097 [0m(+0.00917)
     | > avg_align_error:[91m 0.99059 [0m(+0.00001)


[4m[1m > EPOCH: 27/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:03:44) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 272400[0m
     | > decoder_loss: 2.32436  (2.30478)
     | > postnet_loss: 2.30028  (2.11352)
     | > stopnet_loss: 1.64158  (1.71904)
     | > decoder_coarse_loss: 2.34341  (2.28677)
     | > decoder_ddc_loss: 0.00201  (0.00161)
     | > ga_loss: 0.00310  (0.00252)
     | > decoder_diff_spec_loss: 0.50827  (0.47429)
     | > postnet_diff_spec_loss: 0.85623  (0.82781)
     | > decoder_ssim_loss: 0.36349  (0.34170)
     | > postnet_ssim_loss: 0.37072  (0.34967)
     | > loss: 3.92428  (3.90666)
     | > align_error: 0.98705  (0.99009)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.84093  (4.38110)
     | > current_lr: 0.00006 
     | > step_time: 3.62240  (3.87741)
     | > loader_time: 0.05640  (0.03424)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 272425[0m
     | > decoder_loss: 2.33184  (2.33236)
     | > postnet_loss: 1.87349  (2.12046)
     | > stopnet_loss: 2.41330  (1.74111)
     | > decoder_coarse_loss: 2.29335  (2.31266)
     | > decoder_ddc_loss: 0.00113  (0.00158)
     | > ga_loss: 0.00217  (0.00248)
     | > decoder_diff_spec_loss: 0.51851  (0.48157)
     | > postnet_diff_spec_loss: 0.85058  (0.82954)
     | > decoder_ssim_loss: 0.24251  (0.33684)
     | > postnet_ssim_loss: 0.24493  (0.34464)
     | > loss: 4.51323  (3.94340)
     | > align_error: 0.99174  (0.99011)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.99248  (4.19848)
     | > current_lr: 0.00006 
     | > step_time: 5.82100  (3.92307)
     | > loader_time: 0.02630  (0.03020)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 272450[0m
     | > decoder_loss: 2.06283  (2.31954)
     | > postnet_loss: 1.71599  (2.09589)
     | > stopnet_loss: 2.23587  (1.76085)
     | > decoder_coarse_loss: 2.09487  (2.30690)
     | > decoder_ddc_loss: 0.00117  (0.00158)
     | > ga_loss: 0.00248  (0.00248)
     | > decoder_diff_spec_loss: 0.46172  (0.48152)
     | > postnet_diff_spec_loss: 0.81652  (0.82883)
     | > decoder_ssim_loss: 0.25838  (0.33425)
     | > postnet_ssim_loss: 0.26330  (0.34188)
     | > loss: 4.16696  (3.95085)
     | > align_error: 0.99243  (0.99005)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.31583  (3.86609)
     | > current_lr: 0.00006 
     | > step_time: 3.88330  (3.88810)
     | > loader_time: 0.03300  (0.03405)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.79124 [0m(+0.59398)
     | > avg_decoder_loss:[92m 2.80564 [0m(-0.01824)
     | > avg_postnet_loss:[91m 3.21055 [0m(+0.08726)
     | > avg_stopnet_loss:[92m 1.53760 [0m(-0.00086)
     | > avg_decoder_coarse_loss:[91m 3.74584 [0m(+0.00193)
     | > avg_decoder_ddc_loss:[92m 0.00183 [0m(-0.00008)
     | > avg_ga_loss:[92m 0.00265 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.53997 [0m(+0.00549)
     | > avg_postnet_diff_spec_loss:[92m 0.85732 [0m(-0.00041)
     | > avg_decoder_ssim_loss:[92m 0.33030 [0m(-0.00222)
     | > avg_postnet_ssim_loss:[92m 0.33886 [0m(-0.00021)
     | > avg_loss:[91m 4.50843 [0m(+0.01746)
     | > avg_align_error:[91m 0.99063 [0m(+0.00004)


[4m[1m > EPOCH: 28/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:11:28) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 272475[0m
     | > decoder_loss: 2.21073  (2.25033)
     | > postnet_loss: 2.31784  (2.09335)
     | > stopnet_loss: 1.89328  (1.63945)
     | > decoder_coarse_loss: 2.21894  (2.26476)
     | > decoder_ddc_loss: 0.00128  (0.00149)
     | > ga_loss: 0.00219  (0.00236)
     | > decoder_diff_spec_loss: 0.46247  (0.47862)
     | > postnet_diff_spec_loss: 0.81001  (0.82250)
     | > decoder_ssim_loss: 0.29230  (0.34895)
     | > postnet_ssim_loss: 0.30012  (0.35628)
     | > loss: 4.05766  (3.80529)
     | > align_error: 0.99164  (0.99049)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.04052  (2.98771)
     | > current_lr: 0.00006 
     | > step_time: 4.91430  (4.50842)
     | > loader_time: 0.02100  (0.03912)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 272500[0m
     | > decoder_loss: 2.21514  (2.26090)
     | > postnet_loss: 1.90436  (2.05983)
     | > stopnet_loss: 1.51916  (1.72208)
     | > decoder_coarse_loss: 2.25954  (2.27049)
     | > decoder_ddc_loss: 0.00125  (0.00157)
     | > ga_loss: 0.00221  (0.00250)
     | > decoder_diff_spec_loss: 0.47246  (0.48226)
     | > postnet_diff_spec_loss: 0.80311  (0.82531)
     | > decoder_ssim_loss: 0.34122  (0.33661)
     | > postnet_ssim_loss: 0.35078  (0.34436)
     | > loss: 3.61716  (3.87994)
     | > align_error: 0.99171  (0.99012)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.33339  (3.95515)
     | > current_lr: 0.00006 
     | > step_time: 4.21330  (3.95157)
     | > loader_time: 0.02240  (0.03643)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 272525[0m
     | > decoder_loss: 2.11986  (2.25761)
     | > postnet_loss: 1.96416  (2.04311)
     | > stopnet_loss: 1.10729  (1.76765)
     | > decoder_coarse_loss: 2.17541  (2.27042)
     | > decoder_ddc_loss: 0.00270  (0.00155)
     | > ga_loss: 0.00315  (0.00249)
     | > decoder_diff_spec_loss: 0.50112  (0.48421)
     | > postnet_diff_spec_loss: 0.83798  (0.82628)
     | > decoder_ssim_loss: 0.48912  (0.33359)
     | > postnet_ssim_loss: 0.49998  (0.34135)
     | > loss: 3.27062  (3.91964)
     | > align_error: 0.98484  (0.99008)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.60094  (3.91207)
     | > current_lr: 0.00006 
     | > step_time: 2.22760  (3.88243)
     | > loader_time: 0.01780  (0.03413)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 272550[0m
     | > decoder_loss: 2.13253  (2.26107)
     | > postnet_loss: 2.10481  (2.03931)
     | > stopnet_loss: 1.57657  (1.76791)
     | > decoder_coarse_loss: 2.15146  (2.27495)
     | > decoder_ddc_loss: 0.00121  (0.00155)
     | > ga_loss: 0.00195  (0.00250)
     | > decoder_diff_spec_loss: 0.47764  (0.48603)
     | > postnet_diff_spec_loss: 0.79807  (0.82616)
     | > decoder_ssim_loss: 0.33511  (0.33275)
     | > postnet_ssim_loss: 0.34178  (0.34044)
     | > loss: 3.67196  (3.92098)
     | > align_error: 0.99186  (0.99006)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.96046  (3.95630)
     | > current_lr: 0.00006 
     | > step_time: 3.41630  (3.72834)
     | > loader_time: 0.02480  (0.03186)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.29095 [0m(-0.50029)
     | > avg_decoder_loss:[91m 2.93597 [0m(+0.13032)
     | > avg_postnet_loss:[91m 3.35904 [0m(+0.14849)
     | > avg_stopnet_loss:[92m 1.52523 [0m(-0.01237)
     | > avg_decoder_coarse_loss:[91m 3.86302 [0m(+0.11719)
     | > avg_decoder_ddc_loss:[92m 0.00169 [0m(-0.00014)
     | > avg_ga_loss:[91m 0.00267 [0m(+0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.54418 [0m(+0.00420)
     | > avg_postnet_diff_spec_loss:[92m 0.85620 [0m(-0.00112)
     | > avg_decoder_ssim_loss:[92m 0.32912 [0m(-0.00118)
     | > avg_postnet_ssim_loss:[92m 0.33861 [0m(-0.00025)
     | > avg_loss:[91m 4.59553 [0m(+0.08710)
     | > avg_align_error:[91m 0.99094 [0m(+0.00031)


[4m[1m > EPOCH: 29/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:19:06) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 272575[0m
     | > decoder_loss: 2.27048  (2.19868)
     | > postnet_loss: 1.97018  (1.99923)
     | > stopnet_loss: 1.75232  (1.70072)
     | > decoder_coarse_loss: 2.26528  (2.22863)
     | > decoder_ddc_loss: 0.00137  (0.00151)
     | > ga_loss: 0.00206  (0.00247)
     | > decoder_diff_spec_loss: 0.50234  (0.48449)
     | > postnet_diff_spec_loss: 0.84207  (0.82234)
     | > decoder_ssim_loss: 0.31747  (0.33736)
     | > postnet_ssim_loss: 0.32542  (0.34510)
     | > loss: 3.88626  (3.81743)
     | > align_error: 0.99083  (0.99029)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 8.69015  (4.39970)
     | > current_lr: 0.00006 
     | > step_time: 4.45990  (3.80242)
     | > loader_time: 0.05060  (0.03917)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 272600[0m
     | > decoder_loss: 2.08545  (2.22902)
     | > postnet_loss: 1.75762  (2.02096)
     | > stopnet_loss: 2.41285  (1.71734)
     | > decoder_coarse_loss: 2.15611  (2.26226)
     | > decoder_ddc_loss: 0.00105  (0.00154)
     | > ga_loss: 0.00205  (0.00248)
     | > decoder_diff_spec_loss: 0.46828  (0.49107)
     | > postnet_diff_spec_loss: 0.81444  (0.82515)
     | > decoder_ssim_loss: 0.24164  (0.33562)
     | > postnet_ssim_loss: 0.24333  (0.34358)
     | > loss: 4.36507  (3.85702)
     | > align_error: 0.99313  (0.99011)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.98059  (4.34552)
     | > current_lr: 0.00006 
     | > step_time: 4.70710  (3.78728)
     | > loader_time: 0.02070  (0.03850)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 272625[0m
     | > decoder_loss: 2.29204  (2.22340)
     | > postnet_loss: 1.96246  (1.99993)
     | > stopnet_loss: 2.08678  (1.74465)
     | > decoder_coarse_loss: 2.30174  (2.25526)
     | > decoder_ddc_loss: 0.00115  (0.00155)
     | > ga_loss: 0.00211  (0.00247)
     | > decoder_diff_spec_loss: 0.51440  (0.49116)
     | > postnet_diff_spec_loss: 0.82427  (0.82530)
     | > decoder_ssim_loss: 0.27046  (0.33218)
     | > postnet_ssim_loss: 0.27446  (0.33996)
     | > loss: 4.20756  (3.87419)
     | > align_error: 0.99215  (0.99004)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.84115  (3.98670)
     | > current_lr: 0.00007 
     | > step_time: 4.54350  (3.82781)
     | > loader_time: 0.07780  (0.03720)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.53664 [0m(+0.24569)
     | > avg_decoder_loss:[92m 2.85139 [0m(-0.08458)
     | > avg_postnet_loss:[92m 2.94740 [0m(-0.41164)
     | > avg_stopnet_loss:[92m 1.51184 [0m(-0.01340)
     | > avg_decoder_coarse_loss:[92m 3.61951 [0m(-0.24351)
     | > avg_decoder_ddc_loss:[92m 0.00163 [0m(-0.00005)
     | > avg_ga_loss:[92m 0.00264 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.54002 [0m(-0.00415)
     | > avg_postnet_diff_spec_loss:[92m 0.85228 [0m(-0.00392)
     | > avg_decoder_ssim_loss:[92m 0.32720 [0m(-0.00192)
     | > avg_postnet_ssim_loss:[92m 0.33548 [0m(-0.00313)
     | > avg_loss:[92m 4.39379 [0m(-0.20175)
     | > avg_align_error:[91m 0.99098 [0m(+0.00004)


[4m[1m > EPOCH: 30/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:26:45) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 272650[0m
     | > decoder_loss: 2.25467  (2.17656)
     | > postnet_loss: 1.88469  (1.98330)
     | > stopnet_loss: 1.13707  (1.60842)
     | > decoder_coarse_loss: 2.31418  (2.21942)
     | > decoder_ddc_loss: 0.00192  (0.00146)
     | > ga_loss: 0.00244  (0.00236)
     | > decoder_diff_spec_loss: 0.51493  (0.49066)
     | > postnet_diff_spec_loss: 0.83450  (0.82045)
     | > decoder_ssim_loss: 0.43305  (0.35165)
     | > postnet_ssim_loss: 0.43518  (0.35887)
     | > loss: 3.31754  (3.72079)
     | > align_error: 0.98761  (0.99038)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.63951  (3.82651)
     | > current_lr: 0.00007 
     | > step_time: 3.43810  (4.19469)
     | > loader_time: 0.02100  (0.05094)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 272675[0m
     | > decoder_loss: 2.14015  (2.18193)
     | > postnet_loss: 1.82367  (1.98937)
     | > stopnet_loss: 2.03232  (1.71984)
     | > decoder_coarse_loss: 2.20091  (2.21221)
     | > decoder_ddc_loss: 0.00144  (0.00152)
     | > ga_loss: 0.00280  (0.00250)
     | > decoder_diff_spec_loss: 0.46057  (0.49018)
     | > postnet_diff_spec_loss: 0.80360  (0.82265)
     | > decoder_ssim_loss: 0.28695  (0.33365)
     | > postnet_ssim_loss: 0.29729  (0.34170)
     | > loss: 4.04998  (3.82564)
     | > align_error: 0.99019  (0.99010)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.04753  (4.67356)
     | > current_lr: 0.00007 
     | > step_time: 3.70360  (3.81995)
     | > loader_time: 0.01650  (0.03186)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 272700[0m
     | > decoder_loss: 1.94783  (2.18176)
     | > postnet_loss: 1.93963  (1.96858)
     | > stopnet_loss: 2.70351  (1.76651)
     | > decoder_coarse_loss: 1.99433  (2.21104)
     | > decoder_ddc_loss: 0.00104  (0.00148)
     | > ga_loss: 0.00227  (0.00247)
     | > decoder_diff_spec_loss: 0.44786  (0.49088)
     | > postnet_diff_spec_loss: 0.81276  (0.82263)
     | > decoder_ssim_loss: 0.20996  (0.32834)
     | > postnet_ssim_loss: 0.21449  (0.33619)
     | > loss: 4.60686  (3.86408)
     | > align_error: 0.99214  (0.99019)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.88905  (4.52169)
     | > current_lr: 0.00007 
     | > step_time: 4.36260  (3.85672)
     | > loader_time: 0.02450  (0.03510)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 272725[0m
     | > decoder_loss: 2.27633  (2.18652)
     | > postnet_loss: 2.41505  (1.96361)
     | > stopnet_loss: 2.64562  (1.76175)
     | > decoder_coarse_loss: 2.28701  (2.21626)
     | > decoder_ddc_loss: 0.00131  (0.00151)
     | > ga_loss: 0.00233  (0.00250)
     | > decoder_diff_spec_loss: 0.49354  (0.49275)
     | > postnet_diff_spec_loss: 0.80053  (0.82314)
     | > decoder_ssim_loss: 0.23656  (0.33017)
     | > postnet_ssim_loss: 0.24356  (0.33792)
     | > loss: 4.84577  (3.86222)
     | > align_error: 0.99036  (0.99004)
     | > amp_scaler: 32768.00000  (20817.31765)
     | > grad_norm: 5.45705  (4.39047)
     | > current_lr: 0.00007 
     | > step_time: 3.63930  (3.75188)
     | > loader_time: 0.01730  (0.03453)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.01546 [0m(+0.47882)
     | > avg_decoder_loss:[92m 2.70353 [0m(-0.14786)
     | > avg_postnet_loss:[92m 2.90207 [0m(-0.04533)
     | > avg_stopnet_loss:[92m 1.50993 [0m(-0.00191)
     | > avg_decoder_coarse_loss:[92m 3.52811 [0m(-0.09140)
     | > avg_decoder_ddc_loss:[92m 0.00161 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00264 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.54295 [0m(+0.00292)
     | > avg_postnet_diff_spec_loss:[92m 0.85152 [0m(-0.00076)
     | > avg_decoder_ssim_loss:[92m 0.32505 [0m(-0.00214)
     | > avg_postnet_ssim_loss:[92m 0.33473 [0m(-0.00075)
     | > avg_loss:[92m 4.32053 [0m(-0.07326)
     | > avg_align_error:[92m 0.99088 [0m(-0.00010)


[4m[1m > EPOCH: 31/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:34:20) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 272750[0m
     | > decoder_loss: 1.96970  (2.12794)
     | > postnet_loss: 1.71312  (1.92915)
     | > stopnet_loss: 1.60170  (1.69298)
     | > decoder_coarse_loss: 1.94966  (2.16603)
     | > decoder_ddc_loss: 0.00119  (0.00146)
     | > ga_loss: 0.00200  (0.00248)
     | > decoder_diff_spec_loss: 0.45514  (0.48836)
     | > postnet_diff_spec_loss: 0.80562  (0.81798)
     | > decoder_ssim_loss: 0.34569  (0.33580)
     | > postnet_ssim_loss: 0.35167  (0.34352)
     | > loss: 3.50963  (3.75796)
     | > align_error: 0.99156  (0.99021)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 8.94651  (4.35304)
     | > current_lr: 0.00007 
     | > step_time: 4.19120  (3.90602)
     | > loader_time: 0.01970  (0.03979)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 272775[0m
     | > decoder_loss: 2.14951  (2.16354)
     | > postnet_loss: 2.02170  (1.95311)
     | > stopnet_loss: 1.24484  (1.70149)
     | > decoder_coarse_loss: 2.24079  (2.19821)
     | > decoder_ddc_loss: 0.00203  (0.00148)
     | > ga_loss: 0.00293  (0.00247)
     | > decoder_diff_spec_loss: 0.49313  (0.49588)
     | > postnet_diff_spec_loss: 0.80309  (0.82217)
     | > decoder_ssim_loss: 0.44456  (0.33509)
     | > postnet_ssim_loss: 0.46131  (0.34318)
     | > loss: 3.41351  (3.79202)
     | > align_error: 0.98755  (0.99003)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.35858  (4.28640)
     | > current_lr: 0.00007 
     | > step_time: 2.42120  (3.75437)
     | > loader_time: 0.05780  (0.03724)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 272800[0m
     | > decoder_loss: 2.07565  (2.15571)
     | > postnet_loss: 1.84073  (1.93001)
     | > stopnet_loss: 2.02134  (1.73787)
     | > decoder_coarse_loss: 2.09499  (2.19054)
     | > decoder_ddc_loss: 0.00189  (0.00148)
     | > ga_loss: 0.00301  (0.00247)
     | > decoder_diff_spec_loss: 0.47907  (0.49494)
     | > postnet_diff_spec_loss: 0.80721  (0.82237)
     | > decoder_ssim_loss: 0.27803  (0.33057)
     | > postnet_ssim_loss: 0.28424  (0.33853)
     | > loss: 4.00185  (3.81624)
     | > align_error: 0.98834  (0.99000)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.87899  (3.94364)
     | > current_lr: 0.00007 
     | > step_time: 3.77810  (3.77990)
     | > loader_time: 0.01920  (0.03616)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.47745 [0m(-0.53801)
     | > avg_decoder_loss:[91m 2.79165 [0m(+0.08811)
     | > avg_postnet_loss:[91m 2.97970 [0m(+0.07763)
     | > avg_stopnet_loss:[92m 1.50738 [0m(-0.00255)
     | > avg_decoder_coarse_loss:[91m 3.53490 [0m(+0.00679)
     | > avg_decoder_ddc_loss:[92m 0.00158 [0m(-0.00003)
     | > avg_ga_loss:[92m 0.00263 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.54258 [0m(-0.00037)
     | > avg_postnet_diff_spec_loss:[91m 0.85228 [0m(+0.00076)
     | > avg_decoder_ssim_loss:[92m 0.32442 [0m(-0.00063)
     | > avg_postnet_ssim_loss:[91m 0.33571 [0m(+0.00098)
     | > avg_loss:[91m 4.36124 [0m(+0.04071)
     | > avg_align_error:[91m 0.99097 [0m(+0.00009)


[4m[1m > EPOCH: 32/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:42:04) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 272825[0m
     | > decoder_loss: 2.26570  (2.11247)
     | > postnet_loss: 1.89401  (1.93216)
     | > stopnet_loss: 1.41525  (1.64052)
     | > decoder_coarse_loss: 2.25902  (2.13133)
     | > decoder_ddc_loss: 0.00161  (0.00135)
     | > ga_loss: 0.00275  (0.00232)
     | > decoder_diff_spec_loss: 0.49109  (0.48911)
     | > postnet_diff_spec_loss: 0.81315  (0.81679)
     | > decoder_ssim_loss: 0.39199  (0.34035)
     | > postnet_ssim_loss: 0.39875  (0.34826)
     | > loss: 3.55781  (3.69509)
     | > align_error: 0.98866  (0.99059)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.73524  (3.46608)
     | > current_lr: 0.00007 
     | > step_time: 2.95980  (4.32142)
     | > loader_time: 0.02050  (0.03867)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 272850[0m
     | > decoder_loss: 2.08635  (2.13193)
     | > postnet_loss: 1.83636  (1.93057)
     | > stopnet_loss: 2.10350  (1.68814)
     | > decoder_coarse_loss: 2.07346  (2.13665)
     | > decoder_ddc_loss: 0.00145  (0.00145)
     | > ga_loss: 0.00230  (0.00247)
     | > decoder_diff_spec_loss: 0.52571  (0.49402)
     | > postnet_diff_spec_loss: 0.85645  (0.82076)
     | > decoder_ssim_loss: 0.27117  (0.33294)
     | > postnet_ssim_loss: 0.26898  (0.34077)
     | > loss: 4.09496  (3.74776)
     | > align_error: 0.98950  (0.99002)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 8.43378  (4.43994)
     | > current_lr: 0.00007 
     | > step_time: 3.29710  (3.81791)
     | > loader_time: 0.01910  (0.03254)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 272875[0m
     | > decoder_loss: 1.96026  (2.13447)
     | > postnet_loss: 1.89614  (1.91377)
     | > stopnet_loss: 1.20044  (1.72946)
     | > decoder_coarse_loss: 1.98549  (2.14227)
     | > decoder_ddc_loss: 0.00177  (0.00142)
     | > ga_loss: 0.00274  (0.00245)
     | > decoder_diff_spec_loss: 0.46186  (0.49509)
     | > postnet_diff_spec_loss: 0.79069  (0.82066)
     | > decoder_ssim_loss: 0.41819  (0.32819)
     | > postnet_ssim_loss: 0.43901  (0.33635)
     | > loss: 3.20247  (3.78479)
     | > align_error: 0.98860  (0.99009)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.38276  (4.21887)
     | > current_lr: 0.00007 
     | > step_time: 3.70570  (3.82554)
     | > loader_time: 0.01820  (0.03156)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 272900[0m
     | > decoder_loss: 1.92729  (2.13587)
     | > postnet_loss: 1.71942  (1.90297)
     | > stopnet_loss: 1.65807  (1.72632)
     | > decoder_coarse_loss: 1.90415  (2.14220)
     | > decoder_ddc_loss: 0.00150  (0.00143)
     | > ga_loss: 0.00285  (0.00248)
     | > decoder_diff_spec_loss: 0.46572  (0.49576)
     | > postnet_diff_spec_loss: 0.80248  (0.82135)
     | > decoder_ssim_loss: 0.34114  (0.32914)
     | > postnet_ssim_loss: 0.34943  (0.33715)
     | > loss: 3.55009  (3.78018)
     | > align_error: 0.98938  (0.98998)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.63372  (4.17548)
     | > current_lr: 0.00007 
     | > step_time: 2.16200  (3.72814)
     | > loader_time: 0.01570  (0.03355)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.99173 [0m(-0.48572)
     | > avg_decoder_loss:[91m 2.91560 [0m(+0.12395)
     | > avg_postnet_loss:[92m 2.97530 [0m(-0.00439)
     | > avg_stopnet_loss:[91m 1.50909 [0m(+0.00171)
     | > avg_decoder_coarse_loss:[91m 3.83021 [0m(+0.29531)
     | > avg_decoder_ddc_loss:[92m 0.00149 [0m(-0.00009)
     | > avg_ga_loss:[92m 0.00263 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.54508 [0m(+0.00250)
     | > avg_postnet_diff_spec_loss:[92m 0.85061 [0m(-0.00167)
     | > avg_decoder_ssim_loss:[92m 0.32382 [0m(-0.00060)
     | > avg_postnet_ssim_loss:[92m 0.33536 [0m(-0.00035)
     | > avg_loss:[91m 4.46660 [0m(+0.10535)
     | > avg_align_error:[91m 0.99117 [0m(+0.00020)


[4m[1m > EPOCH: 33/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:49:43) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 272925[0m
     | > decoder_loss: 2.19938  (2.09666)
     | > postnet_loss: 1.88590  (1.89581)
     | > stopnet_loss: 2.00021  (1.67679)
     | > decoder_coarse_loss: 2.20037  (2.10038)
     | > decoder_ddc_loss: 0.00111  (0.00137)
     | > ga_loss: 0.00232  (0.00249)
     | > decoder_diff_spec_loss: 0.49294  (0.49290)
     | > postnet_diff_spec_loss: 0.83485  (0.81688)
     | > decoder_ssim_loss: 0.27211  (0.33341)
     | > postnet_ssim_loss: 0.27647  (0.34164)
     | > loss: 4.05261  (3.70902)
     | > align_error: 0.99162  (0.99012)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.55904  (3.80392)
     | > current_lr: 0.00007 
     | > step_time: 4.04960  (3.85280)
     | > loader_time: 0.02250  (0.03252)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 272950[0m
     | > decoder_loss: 2.60957  (2.12452)
     | > postnet_loss: 2.48678  (1.90821)
     | > stopnet_loss: 1.65917  (1.69700)
     | > decoder_coarse_loss: 2.64976  (2.11750)
     | > decoder_ddc_loss: 0.00126  (0.00138)
     | > ga_loss: 0.00195  (0.00245)
     | > decoder_diff_spec_loss: 0.59561  (0.49884)
     | > postnet_diff_spec_loss: 0.89814  (0.82097)
     | > decoder_ssim_loss: 0.31691  (0.33090)
     | > postnet_ssim_loss: 0.32594  (0.33911)
     | > loss: 4.13992  (3.74459)
     | > align_error: 0.99021  (0.99004)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.31993  (4.06135)
     | > current_lr: 0.00007 
     | > step_time: 4.70420  (3.84211)
     | > loader_time: 0.06480  (0.03140)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 272975[0m
     | > decoder_loss: 2.11622  (2.11897)
     | > postnet_loss: 1.84815  (1.89048)
     | > stopnet_loss: 1.41636  (1.71903)
     | > decoder_coarse_loss: 2.08090  (2.11107)
     | > decoder_ddc_loss: 0.00136  (0.00138)
     | > ga_loss: 0.00221  (0.00244)
     | > decoder_diff_spec_loss: 0.51840  (0.49826)
     | > postnet_diff_spec_loss: 0.83819  (0.82087)
     | > decoder_ssim_loss: 0.36325  (0.32963)
     | > postnet_ssim_loss: 0.36269  (0.33777)
     | > loss: 3.45967  (3.75835)
     | > align_error: 0.99000  (0.98996)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.05482  (3.87472)
     | > current_lr: 0.00007 
     | > step_time: 3.98180  (3.87756)
     | > loader_time: 0.01940  (0.03176)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.35755 [0m(+0.36582)
     | > avg_decoder_loss:[92m 2.82175 [0m(-0.09385)
     | > avg_postnet_loss:[92m 2.93789 [0m(-0.03742)
     | > avg_stopnet_loss:[92m 1.50782 [0m(-0.00127)
     | > avg_decoder_coarse_loss:[92m 3.66486 [0m(-0.16535)
     | > avg_decoder_ddc_loss:[92m 0.00140 [0m(-0.00008)
     | > avg_ga_loss:[92m 0.00262 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.53936 [0m(-0.00572)
     | > avg_postnet_diff_spec_loss:[92m 0.84958 [0m(-0.00103)
     | > avg_decoder_ssim_loss:[92m 0.32258 [0m(-0.00124)
     | > avg_postnet_ssim_loss:[91m 0.33542 [0m(+0.00005)
     | > avg_loss:[92m 4.38913 [0m(-0.07747)
     | > avg_align_error:[91m 0.99126 [0m(+0.00009)


[4m[1m > EPOCH: 34/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:57:21) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 273000[0m
     | > decoder_loss: 2.12013  (2.05141)
     | > postnet_loss: 2.24577  (1.89482)
     | > stopnet_loss: 1.73551  (1.63006)
     | > decoder_coarse_loss: 2.10618  (2.04096)
     | > decoder_ddc_loss: 0.00160  (0.00122)
     | > ga_loss: 0.00295  (0.00227)
     | > decoder_diff_spec_loss: 0.50702  (0.49060)
     | > postnet_diff_spec_loss: 0.83981  (0.81520)
     | > decoder_ssim_loss: 0.33914  (0.33182)
     | > postnet_ssim_loss: 0.34996  (0.34072)
     | > loss: 3.87765  (3.63311)
     | > align_error: 0.98853  (0.99083)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 8.46069  (3.68089)
     | > current_lr: 0.00007 
     | > step_time: 2.33880  (4.53589)
     | > loader_time: 0.07050  (0.03845)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 273025[0m
     | > decoder_loss: 2.08538  (2.08920)
     | > postnet_loss: 1.98562  (1.89076)
     | > stopnet_loss: 1.18494  (1.67046)
     | > decoder_coarse_loss: 2.03084  (2.06916)
     | > decoder_ddc_loss: 0.00184  (0.00136)
     | > ga_loss: 0.00288  (0.00246)
     | > decoder_diff_spec_loss: 0.49695  (0.49535)
     | > postnet_diff_spec_loss: 0.83503  (0.81803)
     | > decoder_ssim_loss: 0.43223  (0.33311)
     | > postnet_ssim_loss: 0.44411  (0.34176)
     | > loss: 3.27734  (3.69245)
     | > align_error: 0.98708  (0.98997)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.20602  (4.16175)
     | > current_lr: 0.00008 
     | > step_time: 3.18720  (3.84519)
     | > loader_time: 0.02110  (0.03330)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 273050[0m
     | > decoder_loss: 2.14673  (2.09692)
     | > postnet_loss: 1.94963  (1.87593)
     | > stopnet_loss: 1.66450  (1.73736)
     | > decoder_coarse_loss: 2.05477  (2.07418)
     | > decoder_ddc_loss: 0.00142  (0.00131)
     | > ga_loss: 0.00294  (0.00243)
     | > decoder_diff_spec_loss: 0.49152  (0.49738)
     | > postnet_diff_spec_loss: 0.79204  (0.81976)
     | > decoder_ssim_loss: 0.32816  (0.32491)
     | > postnet_ssim_loss: 0.34020  (0.33351)
     | > loss: 3.70531  (3.75550)
     | > align_error: 0.98921  (0.99005)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.79142  (4.22409)
     | > current_lr: 0.00008 
     | > step_time: 2.80570  (3.81988)
     | > loader_time: 0.02110  (0.03235)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 273075[0m
     | > decoder_loss: 2.11950  (2.09812)
     | > postnet_loss: 1.68770  (1.86936)
     | > stopnet_loss: 1.47775  (1.73387)
     | > decoder_coarse_loss: 2.02245  (2.07531)
     | > decoder_ddc_loss: 0.00139  (0.00132)
     | > ga_loss: 0.00285  (0.00246)
     | > decoder_diff_spec_loss: 0.50925  (0.49763)
     | > postnet_diff_spec_loss: 0.81464  (0.82010)
     | > decoder_ssim_loss: 0.38169  (0.32723)
     | > postnet_ssim_loss: 0.38876  (0.33594)
     | > loss: 3.47335  (3.75242)
     | > align_error: 0.98948  (0.98993)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.67702  (4.23602)
     | > current_lr: 0.00008 
     | > step_time: 2.51220  (3.73502)
     | > loader_time: 0.02050  (0.03288)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.26376 [0m(-0.09380)
     | > avg_decoder_loss:[91m 2.89927 [0m(+0.07752)
     | > avg_postnet_loss:[91m 3.04479 [0m(+0.10690)
     | > avg_stopnet_loss:[91m 1.51083 [0m(+0.00301)
     | > avg_decoder_coarse_loss:[91m 3.70873 [0m(+0.04387)
     | > avg_decoder_ddc_loss:[92m 0.00133 [0m(-0.00007)
     | > avg_ga_loss:[91m 0.00263 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.53980 [0m(+0.00044)
     | > avg_postnet_diff_spec_loss:[92m 0.84932 [0m(-0.00026)
     | > avg_decoder_ssim_loss:[92m 0.32199 [0m(-0.00060)
     | > avg_postnet_ssim_loss:[92m 0.33521 [0m(-0.00020)
     | > avg_loss:[91m 4.44907 [0m(+0.05995)
     | > avg_align_error:[91m 0.99139 [0m(+0.00013)


[4m[1m > EPOCH: 35/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:05:02) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 273100[0m
     | > decoder_loss: 2.00537  (2.04768)
     | > postnet_loss: 1.83863  (1.85132)
     | > stopnet_loss: 2.13622  (1.66968)
     | > decoder_coarse_loss: 1.98794  (2.02474)
     | > decoder_ddc_loss: 0.00149  (0.00130)
     | > ga_loss: 0.00287  (0.00249)
     | > decoder_diff_spec_loss: 0.47958  (0.49534)
     | > postnet_diff_spec_loss: 0.81824  (0.81468)
     | > decoder_ssim_loss: 0.27301  (0.33476)
     | > postnet_ssim_loss: 0.28321  (0.34340)
     | > loss: 4.07243  (3.66042)
     | > align_error: 0.98872  (0.98992)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.19732  (4.08908)
     | > current_lr: 0.00008 
     | > step_time: 3.67890  (3.85051)
     | > loader_time: 0.01680  (0.03512)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 273125[0m
     | > decoder_loss: 1.98399  (2.07156)
     | > postnet_loss: 1.84441  (1.85775)
     | > stopnet_loss: 1.37058  (1.69426)
     | > decoder_coarse_loss: 1.96947  (2.04182)
     | > decoder_ddc_loss: 0.00092  (0.00129)
     | > ga_loss: 0.00194  (0.00244)
     | > decoder_diff_spec_loss: 0.47824  (0.49801)
     | > postnet_diff_spec_loss: 0.80843  (0.81789)
     | > decoder_ssim_loss: 0.36172  (0.32942)
     | > postnet_ssim_loss: 0.37310  (0.33814)
     | > loss: 3.33534  (3.69545)
     | > align_error: 0.99234  (0.98995)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 9.76877  (4.55407)
     | > current_lr: 0.00008 
     | > step_time: 4.99600  (3.76145)
     | > loader_time: 0.02050  (0.03273)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 273150[0m
     | > decoder_loss: 2.19203  (2.07802)
     | > postnet_loss: 1.98434  (1.85596)
     | > stopnet_loss: 1.19480  (1.71015)
     | > decoder_coarse_loss: 2.09495  (2.05066)
     | > decoder_ddc_loss: 0.00166  (0.00128)
     | > ga_loss: 0.00252  (0.00243)
     | > decoder_diff_spec_loss: 0.50964  (0.49913)
     | > postnet_diff_spec_loss: 0.82133  (0.81932)
     | > decoder_ssim_loss: 0.40797  (0.32732)
     | > postnet_ssim_loss: 0.41806  (0.33628)
     | > loss: 3.31488  (3.71430)
     | > align_error: 0.98696  (0.98990)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.72658  (4.26999)
     | > current_lr: 0.00008 
     | > step_time: 2.75850  (3.81208)
     | > loader_time: 0.02460  (0.03482)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.00209 [0m(+0.73833)
     | > avg_decoder_loss:[92m 2.71110 [0m(-0.18817)
     | > avg_postnet_loss:[92m 2.87756 [0m(-0.16723)
     | > avg_stopnet_loss:[91m 1.51114 [0m(+0.00031)
     | > avg_decoder_coarse_loss:[92m 3.47881 [0m(-0.22992)
     | > avg_decoder_ddc_loss:[91m 0.00135 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00260 [0m(-0.00003)
     | > avg_decoder_diff_spec_loss:[92m 0.53418 [0m(-0.00561)
     | > avg_postnet_diff_spec_loss:[92m 0.84796 [0m(-0.00136)
     | > avg_decoder_ssim_loss:[92m 0.32023 [0m(-0.00176)
     | > avg_postnet_ssim_loss:[92m 0.33384 [0m(-0.00137)
     | > avg_loss:[92m 4.30039 [0m(-0.14868)
     | > avg_align_error:[92m 0.99102 [0m(-0.00037)


[4m[1m > EPOCH: 36/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:12:41) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 273175[0m
     | > decoder_loss: 2.21132  (2.01727)
     | > postnet_loss: 1.84319  (1.81136)
     | > stopnet_loss: 1.28930  (1.61477)
     | > decoder_coarse_loss: 2.19406  (1.97073)
     | > decoder_ddc_loss: 0.00123  (0.00108)
     | > ga_loss: 0.00185  (0.00216)
     | > decoder_diff_spec_loss: 0.55286  (0.48838)
     | > postnet_diff_spec_loss: 0.85592  (0.81089)
     | > decoder_ssim_loss: 0.37745  (0.32978)
     | > postnet_ssim_loss: 0.38096  (0.33847)
     | > loss: 3.40279  (3.56758)
     | > align_error: 0.99006  (0.99116)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.53348  (3.01908)
     | > current_lr: 0.00008 
     | > step_time: 4.16590  (4.71842)
     | > loader_time: 0.02270  (0.05040)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 273200[0m
     | > decoder_loss: 2.05042  (2.06165)
     | > postnet_loss: 1.86569  (1.85518)
     | > stopnet_loss: 1.94901  (1.67165)
     | > decoder_coarse_loss: 1.99537  (2.01596)
     | > decoder_ddc_loss: 0.00098  (0.00126)
     | > ga_loss: 0.00224  (0.00245)
     | > decoder_diff_spec_loss: 0.48743  (0.49585)
     | > postnet_diff_spec_loss: 0.79672  (0.81604)
     | > decoder_ssim_loss: 0.26518  (0.32838)
     | > postnet_ssim_loss: 0.27384  (0.33722)
     | > loss: 3.89412  (3.66178)
     | > align_error: 0.99236  (0.99011)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.48737  (4.72976)
     | > current_lr: 0.00008 
     | > step_time: 3.98670  (3.77243)
     | > loader_time: 0.04970  (0.03452)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 273225[0m
     | > decoder_loss: 2.14633  (2.06589)
     | > postnet_loss: 1.89815  (1.84014)
     | > stopnet_loss: 1.82123  (1.72897)
     | > decoder_coarse_loss: 2.08676  (2.02163)
     | > decoder_ddc_loss: 0.00168  (0.00124)
     | > ga_loss: 0.00284  (0.00243)
     | > decoder_diff_spec_loss: 0.51933  (0.49819)
     | > postnet_diff_spec_loss: 0.82788  (0.81855)
     | > decoder_ssim_loss: 0.30720  (0.32327)
     | > postnet_ssim_loss: 0.31481  (0.33204)
     | > loss: 3.86097  (3.71633)
     | > align_error: 0.98625  (0.99010)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.10312  (4.57304)
     | > current_lr: 0.00008 
     | > step_time: 3.46930  (3.84235)
     | > loader_time: 0.02280  (0.03574)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 273250[0m
     | > decoder_loss: 2.09942  (2.06958)
     | > postnet_loss: 1.85301  (1.83929)
     | > stopnet_loss: 1.39608  (1.72953)
     | > decoder_coarse_loss: 2.00601  (2.02348)
     | > decoder_ddc_loss: 0.00071  (0.00125)
     | > ga_loss: 0.00187  (0.00246)
     | > decoder_diff_spec_loss: 0.48199  (0.49785)
     | > postnet_diff_spec_loss: 0.82157  (0.81876)
     | > decoder_ssim_loss: 0.37233  (0.32509)
     | > postnet_ssim_loss: 0.38280  (0.33403)
     | > loss: 3.40989  (3.71914)
     | > align_error: 0.99440  (0.98996)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.74245  (4.42715)
     | > current_lr: 0.00008 
     | > step_time: 2.73190  (3.76475)
     | > loader_time: 0.01440  (0.03369)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.64260 [0m(-0.35949)
     | > avg_decoder_loss:[92m 2.66691 [0m(-0.04418)
     | > avg_postnet_loss:[92m 2.67852 [0m(-0.19904)
     | > avg_stopnet_loss:[91m 1.51435 [0m(+0.00320)
     | > avg_decoder_coarse_loss:[92m 3.36172 [0m(-0.11709)
     | > avg_decoder_ddc_loss:[92m 0.00133 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00261 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.53752 [0m(+0.00334)
     | > avg_postnet_diff_spec_loss:[92m 0.84541 [0m(-0.00255)
     | > avg_decoder_ssim_loss:[92m 0.31886 [0m(-0.00137)
     | > avg_postnet_ssim_loss:[92m 0.33110 [0m(-0.00275)
     | > avg_loss:[92m 4.21272 [0m(-0.08767)
     | > avg_align_error:[92m 0.99088 [0m(-0.00014)


[4m[1m > EPOCH: 37/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:20:19) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 273275[0m
     | > decoder_loss: 2.06416  (2.01953)
     | > postnet_loss: 1.84659  (1.82276)
     | > stopnet_loss: 1.37670  (1.62592)
     | > decoder_coarse_loss: 2.01102  (1.98257)
     | > decoder_ddc_loss: 0.00113  (0.00123)
     | > ga_loss: 0.00230  (0.00246)
     | > decoder_diff_spec_loss: 0.52202  (0.49436)
     | > postnet_diff_spec_loss: 0.82092  (0.81313)
     | > decoder_ssim_loss: 0.36006  (0.33635)
     | > postnet_ssim_loss: 0.36534  (0.34549)
     | > loss: 3.38602  (3.59205)
     | > align_error: 0.99059  (0.99004)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.64480  (4.15174)
     | > current_lr: 0.00008 
     | > step_time: 3.55950  (3.98443)
     | > loader_time: 0.01600  (0.03518)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 273300[0m
     | > decoder_loss: 1.85926  (2.04389)
     | > postnet_loss: 1.59495  (1.82618)
     | > stopnet_loss: 2.12757  (1.68354)
     | > decoder_coarse_loss: 1.84917  (2.00109)
     | > decoder_ddc_loss: 0.00078  (0.00125)
     | > ga_loss: 0.00215  (0.00244)
     | > decoder_diff_spec_loss: 0.47475  (0.49794)
     | > postnet_diff_spec_loss: 0.80203  (0.81692)
     | > decoder_ssim_loss: 0.24427  (0.32721)
     | > postnet_ssim_loss: 0.25152  (0.33632)
     | > loss: 3.90750  (3.65846)
     | > align_error: 0.99278  (0.98991)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.13645  (4.63154)
     | > current_lr: 0.00008 
     | > step_time: 4.47930  (3.81683)
     | > loader_time: 0.01770  (0.03397)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 273325[0m
     | > decoder_loss: 2.13593  (2.05041)
     | > postnet_loss: 1.81371  (1.82315)
     | > stopnet_loss: 2.10472  (1.72243)
     | > decoder_coarse_loss: 2.09176  (2.00801)
     | > decoder_ddc_loss: 0.00082  (0.00123)
     | > ga_loss: 0.00199  (0.00242)
     | > decoder_diff_spec_loss: 0.53602  (0.49924)
     | > postnet_diff_spec_loss: 0.83610  (0.81825)
     | > decoder_ssim_loss: 0.26525  (0.32474)
     | > postnet_ssim_loss: 0.26520  (0.33411)
     | > loss: 4.10086  (3.69932)
     | > align_error: 0.99310  (0.98995)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.81203  (4.45216)
     | > current_lr: 0.00008 
     | > step_time: 5.10650  (3.86945)
     | > loader_time: 0.02980  (0.03276)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.52718 [0m(-0.11541)
     | > avg_decoder_loss:[91m 2.70931 [0m(+0.04240)
     | > avg_postnet_loss:[91m 2.75904 [0m(+0.08052)
     | > avg_stopnet_loss:[92m 1.51358 [0m(-0.00077)
     | > avg_decoder_coarse_loss:[92m 3.18379 [0m(-0.17793)
     | > avg_decoder_ddc_loss:[92m 0.00122 [0m(-0.00011)
     | > avg_ga_loss:[92m 0.00261 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.53374 [0m(-0.00378)
     | > avg_postnet_diff_spec_loss:[91m 0.84571 [0m(+0.00030)
     | > avg_decoder_ssim_loss:[92m 0.31863 [0m(-0.00023)
     | > avg_postnet_ssim_loss:[91m 0.33281 [0m(+0.00171)
     | > avg_loss:[92m 4.19767 [0m(-0.01505)
     | > avg_align_error:[91m 0.99125 [0m(+0.00037)


[4m[1m > EPOCH: 38/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:27:52) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 273350[0m
     | > decoder_loss: 1.73956  (1.95041)
     | > postnet_loss: 1.75580  (1.77464)
     | > stopnet_loss: 1.82023  (1.69594)
     | > decoder_coarse_loss: 1.69615  (1.90167)
     | > decoder_ddc_loss: 0.00082  (0.00106)
     | > ga_loss: 0.00173  (0.00220)
     | > decoder_diff_spec_loss: 0.45024  (0.47986)
     | > postnet_diff_spec_loss: 0.78568  (0.80252)
     | > decoder_ssim_loss: 0.29373  (0.31914)
     | > postnet_ssim_loss: 0.31097  (0.33054)
     | > loss: 3.58711  (3.59690)
     | > align_error: 0.99273  (0.99127)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.10596  (2.32013)
     | > current_lr: 0.00008 
     | > step_time: 4.71660  (5.04440)
     | > loader_time: 0.03100  (0.03886)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 273375[0m
     | > decoder_loss: 1.95654  (2.02676)
     | > postnet_loss: 1.87445  (1.82002)
     | > stopnet_loss: 1.42195  (1.67634)
     | > decoder_coarse_loss: 1.89985  (1.98113)
     | > decoder_ddc_loss: 0.00131  (0.00125)
     | > ga_loss: 0.00252  (0.00244)
     | > decoder_diff_spec_loss: 0.49807  (0.49817)
     | > postnet_diff_spec_loss: 0.79728  (0.81592)
     | > decoder_ssim_loss: 0.36310  (0.32896)
     | > postnet_ssim_loss: 0.37464  (0.33842)
     | > loss: 3.37589  (3.64117)
     | > align_error: 0.99000  (0.98995)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.52897  (3.97764)
     | > current_lr: 0.00008 
     | > step_time: 2.77800  (3.93037)
     | > loader_time: 0.04890  (0.03415)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 273400[0m
     | > decoder_loss: 2.10254  (2.03456)
     | > postnet_loss: 1.75683  (1.81055)
     | > stopnet_loss: 1.19587  (1.72773)
     | > decoder_coarse_loss: 2.03303  (1.98524)
     | > decoder_ddc_loss: 0.00093  (0.00122)
     | > ga_loss: 0.00188  (0.00240)
     | > decoder_diff_spec_loss: 0.50508  (0.49876)
     | > postnet_diff_spec_loss: 0.81218  (0.81777)
     | > decoder_ssim_loss: 0.39345  (0.32219)
     | > postnet_ssim_loss: 0.40476  (0.33170)
     | > loss: 3.20750  (3.69024)
     | > align_error: 0.99232  (0.99006)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 8.88215  (4.25293)
     | > current_lr: 0.00008 
     | > step_time: 4.46250  (3.95401)
     | > loader_time: 0.01950  (0.03319)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 273425[0m
     | > decoder_loss: 2.13736  (2.03884)
     | > postnet_loss: 1.86704  (1.80968)
     | > stopnet_loss: 1.74519  (1.73097)
     | > decoder_coarse_loss: 2.04070  (1.98858)
     | > decoder_ddc_loss: 0.00226  (0.00126)
     | > ga_loss: 0.00446  (0.00245)
     | > decoder_diff_spec_loss: 0.48180  (0.49913)
     | > postnet_diff_spec_loss: 0.82337  (0.81805)
     | > decoder_ssim_loss: 0.34658  (0.32307)
     | > postnet_ssim_loss: 0.35902  (0.33272)
     | > loss: 3.78204  (3.69603)
     | > align_error: 0.98356  (0.98979)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 12.36602  (4.19022)
     | > current_lr: 0.00009 
     | > step_time: 1.25730  (3.80492)
     | > loader_time: 0.01360  (0.03552)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.55959 [0m(+0.03241)
     | > avg_decoder_loss:[91m 2.77847 [0m(+0.06916)
     | > avg_postnet_loss:[92m 2.63114 [0m(-0.12791)
     | > avg_stopnet_loss:[91m 1.51418 [0m(+0.00060)
     | > avg_decoder_coarse_loss:[91m 3.26216 [0m(+0.07837)
     | > avg_decoder_ddc_loss:[91m 0.00124 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00260 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.53344 [0m(-0.00029)
     | > avg_postnet_diff_spec_loss:[92m 0.84543 [0m(-0.00028)
     | > avg_decoder_ssim_loss:[92m 0.31838 [0m(-0.00025)
     | > avg_postnet_ssim_loss:[92m 0.33243 [0m(-0.00038)
     | > avg_loss:[91m 4.20285 [0m(+0.00518)
     | > avg_align_error:[92m 0.99123 [0m(-0.00002)


[4m[1m > EPOCH: 39/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:35:22) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 273450[0m
     | > decoder_loss: 2.20415  (2.00062)
     | > postnet_loss: 1.77502  (1.78762)
     | > stopnet_loss: 1.88169  (1.62673)
     | > decoder_coarse_loss: 2.10572  (1.93985)
     | > decoder_ddc_loss: 0.00115  (0.00126)
     | > ga_loss: 0.00247  (0.00244)
     | > decoder_diff_spec_loss: 0.52613  (0.49346)
     | > postnet_diff_spec_loss: 0.83737  (0.81216)
     | > decoder_ssim_loss: 0.29894  (0.33386)
     | > postnet_ssim_loss: 0.30447  (0.34395)
     | > loss: 3.90726  (3.56715)
     | > align_error: 0.99070  (0.98996)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.80037  (3.93690)
     | > current_lr: 0.00009 
     | > step_time: 3.09950  (3.73812)
     | > loader_time: 0.02090  (0.03319)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 273475[0m
     | > decoder_loss: 2.13296  (2.03261)
     | > postnet_loss: 1.77990  (1.79954)
     | > stopnet_loss: 1.25758  (1.65948)
     | > decoder_coarse_loss: 2.04822  (1.96611)
     | > decoder_ddc_loss: 0.00189  (0.00128)
     | > ga_loss: 0.00275  (0.00244)
     | > decoder_diff_spec_loss: 0.50374  (0.49832)
     | > postnet_diff_spec_loss: 0.81362  (0.81647)
     | > decoder_ssim_loss: 0.40306  (0.32812)
     | > postnet_ssim_loss: 0.41585  (0.33774)
     | > loss: 3.29615  (3.61673)
     | > align_error: 0.98611  (0.98982)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.65215  (4.19293)
     | > current_lr: 0.00009 
     | > step_time: 3.46970  (3.68397)
     | > loader_time: 0.01410  (0.03148)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 273500[0m
     | > decoder_loss: 2.35166  (2.03143)
     | > postnet_loss: 1.99749  (1.79590)
     | > stopnet_loss: 1.74872  (1.69038)
     | > decoder_coarse_loss: 2.27284  (1.96743)
     | > decoder_ddc_loss: 0.00150  (0.00125)
     | > ga_loss: 0.00256  (0.00242)
     | > decoder_diff_spec_loss: 0.54070  (0.49872)
     | > postnet_diff_spec_loss: 0.84810  (0.81699)
     | > decoder_ssim_loss: 0.30160  (0.32458)
     | > postnet_ssim_loss: 0.31274  (0.33451)
     | > loss: 3.91817  (3.64517)
     | > align_error: 0.98781  (0.98985)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.14900  (4.00831)
     | > current_lr: 0.00009 
     | > step_time: 3.74760  (3.72756)
     | > loader_time: 0.02110  (0.03219)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.24704 [0m(+0.68745)
     | > avg_decoder_loss:[91m 2.93958 [0m(+0.16111)
     | > avg_postnet_loss:[91m 2.74238 [0m(+0.11125)
     | > avg_stopnet_loss:[92m 1.51351 [0m(-0.00066)
     | > avg_decoder_coarse_loss:[91m 3.36974 [0m(+0.10758)
     | > avg_decoder_ddc_loss:[92m 0.00117 [0m(-0.00007)
     | > avg_ga_loss:[91m 0.00261 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.53599 [0m(+0.00255)
     | > avg_postnet_diff_spec_loss:[92m 0.84513 [0m(-0.00030)
     | > avg_decoder_ssim_loss:[91m 0.31840 [0m(+0.00003)
     | > avg_postnet_ssim_loss:[91m 0.33245 [0m(+0.00002)
     | > avg_loss:[91m 4.29777 [0m(+0.09492)
     | > avg_align_error:[91m 0.99153 [0m(+0.00030)


[4m[1m > EPOCH: 40/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:42:44) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 273525[0m
     | > decoder_loss: 2.01309  (1.98094)
     | > postnet_loss: 1.77449  (1.75091)
     | > stopnet_loss: 1.51885  (1.61665)
     | > decoder_coarse_loss: 1.94810  (1.91150)
     | > decoder_ddc_loss: 0.00087  (0.00110)
     | > ga_loss: 0.00199  (0.00230)
     | > decoder_diff_spec_loss: 0.49773  (0.48551)
     | > postnet_diff_spec_loss: 0.81706  (0.80563)
     | > decoder_ssim_loss: 0.33493  (0.32358)
     | > postnet_ssim_loss: 0.34651  (0.33365)
     | > loss: 3.46202  (3.52637)
     | > align_error: 0.99274  (0.99098)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.50048  (2.40696)
     | > current_lr: 0.00009 
     | > step_time: 3.70160  (4.53759)
     | > loader_time: 0.06390  (0.05680)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 273550[0m
     | > decoder_loss: 2.19202  (2.01678)
     | > postnet_loss: 1.84179  (1.78799)
     | > stopnet_loss: 1.81560  (1.64969)
     | > decoder_coarse_loss: 2.15554  (1.95271)
     | > decoder_ddc_loss: 0.00126  (0.00124)
     | > ga_loss: 0.00245  (0.00241)
     | > decoder_diff_spec_loss: 0.52930  (0.49840)
     | > postnet_diff_spec_loss: 0.84875  (0.81593)
     | > decoder_ssim_loss: 0.28700  (0.32683)
     | > postnet_ssim_loss: 0.29298  (0.33685)
     | > loss: 3.86501  (3.59591)
     | > align_error: 0.98998  (0.98989)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.27422  (4.45942)
     | > current_lr: 0.00009 
     | > step_time: 3.87230  (3.72480)
     | > loader_time: 0.02160  (0.03679)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 273575[0m
     | > decoder_loss: 1.88841  (2.01464)
     | > postnet_loss: 1.63104  (1.77801)
     | > stopnet_loss: 1.29040  (1.71861)
     | > decoder_coarse_loss: 1.79670  (1.95265)
     | > decoder_ddc_loss: 0.00138  (0.00119)
     | > ga_loss: 0.00277  (0.00239)
     | > decoder_diff_spec_loss: 0.44766  (0.49901)
     | > postnet_diff_spec_loss: 0.79722  (0.81711)
     | > decoder_ssim_loss: 0.39977  (0.31982)
     | > postnet_ssim_loss: 0.41849  (0.32983)
     | > loss: 3.14940  (3.65864)
     | > align_error: 0.98842  (0.99000)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.06560  (4.68425)
     | > current_lr: 0.00009 
     | > step_time: 2.59100  (3.72295)
     | > loader_time: 0.02320  (0.03889)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 273600[0m
     | > decoder_loss: 1.92127  (2.01870)
     | > postnet_loss: 1.60547  (1.77585)
     | > stopnet_loss: 1.68394  (1.71645)
     | > decoder_coarse_loss: 1.84316  (1.95888)
     | > decoder_ddc_loss: 0.00113  (0.00122)
     | > ga_loss: 0.00218  (0.00240)
     | > decoder_diff_spec_loss: 0.46469  (0.49949)
     | > postnet_diff_spec_loss: 0.78366  (0.81718)
     | > decoder_ssim_loss: 0.31961  (0.32172)
     | > postnet_ssim_loss: 0.33305  (0.33196)
     | > loss: 3.51286  (3.65971)
     | > align_error: 0.98983  (0.98985)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.17372  (4.38128)
     | > current_lr: 0.00009 
     | > step_time: 3.24730  (3.70528)
     | > loader_time: 0.02500  (0.03643)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.11829 [0m(-1.12875)
     | > avg_decoder_loss:[92m 2.72735 [0m(-0.21223)
     | > avg_postnet_loss:[92m 2.58078 [0m(-0.16161)
     | > avg_stopnet_loss:[91m 1.51740 [0m(+0.00389)
     | > avg_decoder_coarse_loss:[92m 3.11670 [0m(-0.25304)
     | > avg_decoder_ddc_loss:[91m 0.00123 [0m(+0.00006)
     | > avg_ga_loss:[92m 0.00259 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.53201 [0m(-0.00398)
     | > avg_postnet_diff_spec_loss:[92m 0.84463 [0m(-0.00050)
     | > avg_decoder_ssim_loss:[92m 0.31652 [0m(-0.00188)
     | > avg_postnet_ssim_loss:[91m 0.33277 [0m(+0.00031)
     | > avg_loss:[92m 4.14334 [0m(-0.15444)
     | > avg_align_error:[92m 0.99110 [0m(-0.00043)


[4m[1m > EPOCH: 41/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:49:58) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 273625[0m
     | > decoder_loss: 1.99426  (1.97006)
     | > postnet_loss: 1.64061  (1.74809)
     | > stopnet_loss: 1.78202  (1.61918)
     | > decoder_coarse_loss: 1.95305  (1.89667)
     | > decoder_ddc_loss: 0.00095  (0.00124)
     | > ga_loss: 0.00191  (0.00243)
     | > decoder_diff_spec_loss: 0.47409  (0.49047)
     | > postnet_diff_spec_loss: 0.78422  (0.80923)
     | > decoder_ssim_loss: 0.28301  (0.33455)
     | > postnet_ssim_loss: 0.29381  (0.34508)
     | > loss: 3.64756  (3.53017)
     | > align_error: 0.99199  (0.98982)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.75665  (3.96476)
     | > current_lr: 0.00009 
     | > step_time: 5.40340  (4.03751)
     | > loader_time: 0.02350  (0.03759)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 273650[0m
     | > decoder_loss: 1.94860  (2.00721)
     | > postnet_loss: 1.74481  (1.75961)
     | > stopnet_loss: 1.39879  (1.67941)
     | > decoder_coarse_loss: 1.88147  (1.93691)
     | > decoder_ddc_loss: 0.00149  (0.00123)
     | > ga_loss: 0.00266  (0.00242)
     | > decoder_diff_spec_loss: 0.48488  (0.49859)
     | > postnet_diff_spec_loss: 0.81688  (0.81554)
     | > decoder_ssim_loss: 0.37323  (0.32493)
     | > postnet_ssim_loss: 0.38605  (0.33502)
     | > loss: 3.32147  (3.61125)
     | > align_error: 0.98796  (0.98980)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.17577  (4.41046)
     | > current_lr: 0.00009 
     | > step_time: 3.69430  (3.78492)
     | > loader_time: 0.01720  (0.03464)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 273675[0m
     | > decoder_loss: 2.04558  (2.00617)
     | > postnet_loss: 1.67145  (1.75207)
     | > stopnet_loss: 1.65743  (1.69513)
     | > decoder_coarse_loss: 2.01647  (1.93704)
     | > decoder_ddc_loss: 0.00093  (0.00121)
     | > ga_loss: 0.00202  (0.00240)
     | > decoder_diff_spec_loss: 0.53676  (0.49845)
     | > postnet_diff_spec_loss: 0.84898  (0.81562)
     | > decoder_ssim_loss: 0.30977  (0.32375)
     | > postnet_ssim_loss: 0.31837  (0.33394)
     | > loss: 3.60460  (3.62417)
     | > align_error: 0.99207  (0.98979)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.62226  (4.33535)
     | > current_lr: 0.00009 
     | > step_time: 3.97450  (3.82427)
     | > loader_time: 0.02190  (0.03235)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.41976 [0m(+0.30146)
     | > avg_decoder_loss:[91m 2.86067 [0m(+0.13332)
     | > avg_postnet_loss:[91m 2.75219 [0m(+0.17141)
     | > avg_stopnet_loss:[92m 1.51567 [0m(-0.00174)
     | > avg_decoder_coarse_loss:[91m 3.22272 [0m(+0.10603)
     | > avg_decoder_ddc_loss:[92m 0.00114 [0m(-0.00009)
     | > avg_ga_loss:[91m 0.00259 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.53210 [0m(+0.00009)
     | > avg_postnet_diff_spec_loss:[92m 0.84369 [0m(-0.00095)
     | > avg_decoder_ssim_loss:[91m 0.31666 [0m(+0.00013)
     | > avg_postnet_ssim_loss:[92m 0.33110 [0m(-0.00167)
     | > avg_loss:[91m 4.24367 [0m(+0.10033)
     | > avg_align_error:[91m 0.99142 [0m(+0.00033)


[4m[1m > EPOCH: 42/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:57:32) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 273700[0m
     | > decoder_loss: 2.10787  (1.95145)
     | > postnet_loss: 1.92775  (1.69737)
     | > stopnet_loss: 1.42188  (1.66035)
     | > decoder_coarse_loss: 2.01036  (1.87333)
     | > decoder_ddc_loss: 0.00147  (0.00114)
     | > ga_loss: 0.00258  (0.00233)
     | > decoder_diff_spec_loss: 0.50077  (0.48076)
     | > postnet_diff_spec_loss: 0.82103  (0.80023)
     | > decoder_ssim_loss: 0.36924  (0.31975)
     | > postnet_ssim_loss: 0.38345  (0.32964)
     | > loss: 3.46525  (3.53542)
     | > align_error: 0.98763  (0.99035)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.06524  (2.32334)
     | > current_lr: 0.00009 
     | > step_time: 3.67730  (5.18761)
     | > loader_time: 0.02120  (0.04016)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 273725[0m
     | > decoder_loss: 2.41462  (1.99134)
     | > postnet_loss: 2.27459  (1.73695)
     | > stopnet_loss: 1.29558  (1.63972)
     | > decoder_coarse_loss: 2.32754  (1.92215)
     | > decoder_ddc_loss: 0.00109  (0.00123)
     | > ga_loss: 0.00183  (0.00239)
     | > decoder_diff_spec_loss: 0.56221  (0.49540)
     | > postnet_diff_spec_loss: 0.81379  (0.81366)
     | > decoder_ssim_loss: 0.36792  (0.32692)
     | > postnet_ssim_loss: 0.38557  (0.33712)
     | > loss: 3.59155  (3.55787)
     | > align_error: 0.99101  (0.98978)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.57408  (3.78601)
     | > current_lr: 0.00009 
     | > step_time: 3.35650  (3.85850)
     | > loader_time: 0.02160  (0.03112)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 273750[0m
     | > decoder_loss: 1.95775  (1.99967)
     | > postnet_loss: 1.75575  (1.73554)
     | > stopnet_loss: 2.68107  (1.72121)
     | > decoder_coarse_loss: 1.88867  (1.93037)
     | > decoder_ddc_loss: 0.00094  (0.00118)
     | > ga_loss: 0.00261  (0.00236)
     | > decoder_diff_spec_loss: 0.51218  (0.49931)
     | > postnet_diff_spec_loss: 0.81949  (0.81648)
     | > decoder_ssim_loss: 0.20084  (0.31716)
     | > postnet_ssim_loss: 0.20699  (0.32720)
     | > loss: 4.52979  (3.63975)
     | > align_error: 0.99063  (0.98995)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.51295  (4.27198)
     | > current_lr: 0.00009 
     | > step_time: 4.65010  (3.89863)
     | > loader_time: 0.02410  (0.03415)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 273775[0m
     | > decoder_loss: 2.28568  (2.00226)
     | > postnet_loss: 2.01582  (1.73412)
     | > stopnet_loss: 1.24427  (1.70506)
     | > decoder_coarse_loss: 2.14820  (1.93374)
     | > decoder_ddc_loss: 0.00136  (0.00120)
     | > ga_loss: 0.00215  (0.00238)
     | > decoder_diff_spec_loss: 0.55961  (0.49939)
     | > postnet_diff_spec_loss: 0.83814  (0.81651)
     | > decoder_ssim_loss: 0.40761  (0.32054)
     | > postnet_ssim_loss: 0.42316  (0.33089)
     | > loss: 3.42493  (3.62664)
     | > align_error: 0.98883  (0.98980)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.53119  (4.16218)
     | > current_lr: 0.00009 
     | > step_time: 3.38690  (3.81915)
     | > loader_time: 0.02090  (0.03258)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.11750 [0m(+0.69775)
     | > avg_decoder_loss:[92m 2.66937 [0m(-0.19130)
     | > avg_postnet_loss:[92m 2.60694 [0m(-0.14525)
     | > avg_stopnet_loss:[91m 1.52268 [0m(+0.00701)
     | > avg_decoder_coarse_loss:[92m 2.92748 [0m(-0.29524)
     | > avg_decoder_ddc_loss:[91m 0.00116 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00257 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.52720 [0m(-0.00490)
     | > avg_postnet_diff_spec_loss:[91m 0.84629 [0m(+0.00261)
     | > avg_decoder_ssim_loss:[92m 0.31472 [0m(-0.00194)
     | > avg_postnet_ssim_loss:[91m 0.33316 [0m(+0.00206)
     | > avg_loss:[92m 4.09211 [0m(-0.15156)
     | > avg_align_error:[92m 0.99105 [0m(-0.00037)


[4m[1m > EPOCH: 43/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:05:23) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 273800[0m
     | > decoder_loss: 1.79429  (1.94037)
     | > postnet_loss: 1.53430  (1.70900)
     | > stopnet_loss: 1.25431  (1.57947)
     | > decoder_coarse_loss: 1.71685  (1.87699)
     | > decoder_ddc_loss: 0.00162  (0.00125)
     | > ga_loss: 0.00300  (0.00246)
     | > decoder_diff_spec_loss: 0.47159  (0.49325)
     | > postnet_diff_spec_loss: 0.80495  (0.81049)
     | > decoder_ssim_loss: 0.41955  (0.33609)
     | > postnet_ssim_loss: 0.44498  (0.34773)
     | > loss: 3.06635  (3.47054)
     | > align_error: 0.98771  (0.98973)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.92733  (3.18679)
     | > current_lr: 0.00009 
     | > step_time: 2.34980  (4.05630)
     | > loader_time: 0.01760  (0.04717)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 273825[0m
     | > decoder_loss: 2.19727  (1.98664)
     | > postnet_loss: 1.84349  (1.72464)
     | > stopnet_loss: 1.38859  (1.65672)
     | > decoder_coarse_loss: 2.15851  (1.91638)
     | > decoder_ddc_loss: 0.00153  (0.00120)
     | > ga_loss: 0.00236  (0.00240)
     | > decoder_diff_spec_loss: 0.55113  (0.49976)
     | > postnet_diff_spec_loss: 0.85320  (0.81474)
     | > decoder_ssim_loss: 0.36631  (0.32245)
     | > postnet_ssim_loss: 0.37320  (0.33327)
     | > loss: 3.48656  (3.56851)
     | > align_error: 0.98772  (0.98987)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 7.39266  (4.01412)
     | > current_lr: 0.00010 
     | > step_time: 3.46360  (3.86558)
     | > loader_time: 0.09030  (0.04213)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 273850[0m
     | > decoder_loss: 2.12575  (1.98322)
     | > postnet_loss: 1.73727  (1.72137)
     | > stopnet_loss: 1.72573  (1.67467)
     | > decoder_coarse_loss: 2.06328  (1.91230)
     | > decoder_ddc_loss: 0.00087  (0.00119)
     | > ga_loss: 0.00211  (0.00240)
     | > decoder_diff_spec_loss: 0.52452  (0.49883)
     | > postnet_diff_spec_loss: 0.82493  (0.81450)
     | > decoder_ssim_loss: 0.29677  (0.32254)
     | > postnet_ssim_loss: 0.30295  (0.33361)
     | > loss: 3.70535  (3.58355)
     | > align_error: 0.99233  (0.98979)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.68591  (4.14749)
     | > current_lr: 0.00010 
     | > step_time: 4.23690  (3.84537)
     | > loader_time: 0.02170  (0.04119)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.78851 [0m(+0.67100)
     | > avg_decoder_loss:[91m 2.77590 [0m(+0.10653)
     | > avg_postnet_loss:[91m 2.68800 [0m(+0.08106)
     | > avg_stopnet_loss:[91m 1.52272 [0m(+0.00003)
     | > avg_decoder_coarse_loss:[91m 3.03140 [0m(+0.10392)
     | > avg_decoder_ddc_loss:[92m 0.00112 [0m(-0.00004)
     | > avg_ga_loss:[91m 0.00259 [0m(+0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.53084 [0m(+0.00364)
     | > avg_postnet_diff_spec_loss:[92m 0.84477 [0m(-0.00152)
     | > avg_decoder_ssim_loss:[91m 0.31487 [0m(+0.00015)
     | > avg_postnet_ssim_loss:[92m 0.33292 [0m(-0.00024)
     | > avg_loss:[91m 4.16560 [0m(+0.07349)
     | > avg_align_error:[91m 0.99137 [0m(+0.00032)


[4m[1m > EPOCH: 44/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:13:10) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 273875[0m
     | > decoder_loss: 1.93714  (1.89185)
     | > postnet_loss: 1.66480  (1.58723)
     | > stopnet_loss: 1.48562  (1.69533)
     | > decoder_coarse_loss: 1.86906  (1.82736)
     | > decoder_ddc_loss: 0.00123  (0.00103)
     | > ga_loss: 0.00224  (0.00225)
     | > decoder_diff_spec_loss: 0.48389  (0.48054)
     | > postnet_diff_spec_loss: 0.79073  (0.79434)
     | > decoder_ssim_loss: 0.34087  (0.30235)
     | > postnet_ssim_loss: 0.35015  (0.31126)
     | > loss: 3.35630  (3.50559)
     | > align_error: 0.98996  (0.99131)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.75090  (2.59681)
     | > current_lr: 0.00010 
     | > step_time: 5.99920  (5.80929)
     | > loader_time: 0.02560  (0.06020)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 273900[0m
     | > decoder_loss: 2.07707  (1.95688)
     | > postnet_loss: 1.69078  (1.68458)
     | > stopnet_loss: 1.25300  (1.62811)
     | > decoder_coarse_loss: 2.01587  (1.89119)
     | > decoder_ddc_loss: 0.00163  (0.00122)
     | > ga_loss: 0.00278  (0.00241)
     | > decoder_diff_spec_loss: 0.53663  (0.49451)
     | > postnet_diff_spec_loss: 0.83220  (0.81267)
     | > decoder_ssim_loss: 0.38602  (0.32435)
     | > postnet_ssim_loss: 0.39612  (0.33481)
     | > loss: 3.25096  (3.51521)
     | > align_error: 0.98677  (0.98975)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.72060  (3.95942)
     | > current_lr: 0.00010 
     | > step_time: 3.18840  (3.79040)
     | > loader_time: 0.01510  (0.03869)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 273925[0m
     | > decoder_loss: 1.94852  (1.98299)
     | > postnet_loss: 1.58510  (1.70577)
     | > stopnet_loss: 1.94584  (1.68022)
     | > decoder_coarse_loss: 1.90940  (1.91348)
     | > decoder_ddc_loss: 0.00093  (0.00119)
     | > ga_loss: 0.00239  (0.00235)
     | > decoder_diff_spec_loss: 0.49868  (0.49974)
     | > postnet_diff_spec_loss: 0.79863  (0.81557)
     | > decoder_ssim_loss: 0.27213  (0.31835)
     | > postnet_ssim_loss: 0.28256  (0.32888)
     | > loss: 3.78180  (3.58348)
     | > align_error: 0.99109  (0.98990)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.80496  (4.23645)
     | > current_lr: 0.00010 
     | > step_time: 3.42090  (3.77231)
     | > loader_time: 0.04130  (0.03996)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 273950[0m
     | > decoder_loss: 1.76172  (1.98190)
     | > postnet_loss: 1.61666  (1.70424)
     | > stopnet_loss: 1.40627  (1.69580)
     | > decoder_coarse_loss: 1.73083  (1.91347)
     | > decoder_ddc_loss: 0.00110  (0.00120)
     | > ga_loss: 0.00175  (0.00238)
     | > decoder_diff_spec_loss: 0.44857  (0.49943)
     | > postnet_diff_spec_loss: 0.78744  (0.81563)
     | > decoder_ssim_loss: 0.34163  (0.31844)
     | > postnet_ssim_loss: 0.36067  (0.32914)
     | > loss: 3.17719  (3.59857)
     | > align_error: 0.99106  (0.98976)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.60132  (4.17200)
     | > current_lr: 0.00010 
     | > step_time: 3.41310  (3.68151)
     | > loader_time: 0.02440  (0.03854)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.63953 [0m(-2.14898)
     | > avg_decoder_loss:[91m 2.82942 [0m(+0.05351)
     | > avg_postnet_loss:[92m 2.66394 [0m(-0.02406)
     | > avg_stopnet_loss:[92m 1.52207 [0m(-0.00064)
     | > avg_decoder_coarse_loss:[92m 2.89670 [0m(-0.13470)
     | > avg_decoder_ddc_loss:[92m 0.00110 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00257 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.53018 [0m(-0.00066)
     | > avg_postnet_diff_spec_loss:[92m 0.84471 [0m(-0.00006)
     | > avg_decoder_ssim_loss:[92m 0.31428 [0m(-0.00059)
     | > avg_postnet_ssim_loss:[92m 0.33230 [0m(-0.00063)
     | > avg_loss:[92m 4.13810 [0m(-0.02751)
     | > avg_align_error:[91m 0.99144 [0m(+0.00007)


[4m[1m > EPOCH: 45/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:20:20) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 273975[0m
     | > decoder_loss: 1.87471  (1.93130)
     | > postnet_loss: 1.72452  (1.67651)
     | > stopnet_loss: 2.02774  (1.58465)
     | > decoder_coarse_loss: 1.80560  (1.86687)
     | > decoder_ddc_loss: 0.00141  (0.00124)
     | > ga_loss: 0.00245  (0.00238)
     | > decoder_diff_spec_loss: 0.46073  (0.49388)
     | > postnet_diff_spec_loss: 0.79945  (0.81009)
     | > decoder_ssim_loss: 0.26874  (0.32941)
     | > postnet_ssim_loss: 0.28359  (0.34046)
     | > loss: 3.84465  (3.45899)
     | > align_error: 0.98850  (0.98973)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.61525  (3.40727)
     | > current_lr: 0.00010 
     | > step_time: 4.12490  (3.94771)
     | > loader_time: 0.02610  (0.03628)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 274000[0m
     | > decoder_loss: 1.98107  (1.95959)
     | > postnet_loss: 1.73218  (1.68119)
     | > stopnet_loss: 1.52186  (1.65464)
     | > decoder_coarse_loss: 1.92995  (1.89135)
     | > decoder_ddc_loss: 0.00121  (0.00120)
     | > ga_loss: 0.00236  (0.00238)
     | > decoder_diff_spec_loss: 0.50788  (0.49784)
     | > postnet_diff_spec_loss: 0.82344  (0.81313)
     | > decoder_ssim_loss: 0.33829  (0.32034)
     | > postnet_ssim_loss: 0.35557  (0.33126)
     | > loss: 3.45104  (3.54051)
     | > align_error: 0.98952  (0.98983)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.02668  (3.70319)
     | > current_lr: 0.00010 
     | > step_time: 3.66150  (3.79457)
     | > loader_time: 0.01970  (0.03312)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 274025[0m
     | > decoder_loss: 1.97023  (1.95957)
     | > postnet_loss: 1.68932  (1.68389)
     | > stopnet_loss: 1.19345  (1.66799)
     | > decoder_coarse_loss: 1.91342  (1.88917)
     | > decoder_ddc_loss: 0.00140  (0.00121)
     | > ga_loss: 0.00231  (0.00238)
     | > decoder_diff_spec_loss: 0.50286  (0.49774)
     | > postnet_diff_spec_loss: 0.80717  (0.81373)
     | > decoder_ssim_loss: 0.41205  (0.32187)
     | > postnet_ssim_loss: 0.42245  (0.33325)
     | > loss: 3.13471  (3.55498)
     | > align_error: 0.98831  (0.98964)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.61963  (3.84730)
     | > current_lr: 0.00010 
     | > step_time: 3.84090  (3.81816)
     | > loader_time: 0.01740  (0.03600)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.09444 [0m(+1.45490)
     | > avg_decoder_loss:[92m 2.60141 [0m(-0.22800)
     | > avg_postnet_loss:[92m 2.51828 [0m(-0.14567)
     | > avg_stopnet_loss:[91m 1.52507 [0m(+0.00300)
     | > avg_decoder_coarse_loss:[92m 2.76907 [0m(-0.12763)
     | > avg_decoder_ddc_loss:[91m 0.00113 [0m(+0.00003)
     | > avg_ga_loss:[92m 0.00255 [0m(-0.00003)
     | > avg_decoder_diff_spec_loss:[92m 0.52536 [0m(-0.00482)
     | > avg_postnet_diff_spec_loss:[92m 0.84288 [0m(-0.00183)
     | > avg_decoder_ssim_loss:[92m 0.31273 [0m(-0.00155)
     | > avg_postnet_ssim_loss:[92m 0.33089 [0m(-0.00141)
     | > avg_loss:[92m 4.01325 [0m(-0.12485)
     | > avg_align_error:[92m 0.99098 [0m(-0.00046)


[4m[1m > EPOCH: 46/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:28:03) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 274050[0m
     | > decoder_loss: 1.92593  (1.83669)
     | > postnet_loss: 1.58633  (1.52869)
     | > stopnet_loss: 1.60374  (1.82741)
     | > decoder_coarse_loss: 1.88981  (1.81071)
     | > decoder_ddc_loss: 0.00114  (0.00097)
     | > ga_loss: 0.00231  (0.00226)
     | > decoder_diff_spec_loss: 0.49744  (0.48175)
     | > postnet_diff_spec_loss: 0.79490  (0.79464)
     | > decoder_ssim_loss: 0.31044  (0.28156)
     | > postnet_ssim_loss: 0.31967  (0.29033)
     | > loss: 3.44673  (3.59504)
     | > align_error: 0.99070  (0.99185)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.01641  (2.26311)
     | > current_lr: 0.00010 
     | > step_time: 5.56760  (6.24707)
     | > loader_time: 0.11000  (0.11082)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 274075[0m
     | > decoder_loss: 1.80243  (1.92897)
     | > postnet_loss: 1.49827  (1.64945)
     | > stopnet_loss: 2.01596  (1.62983)
     | > decoder_coarse_loss: 1.75291  (1.86858)
     | > decoder_ddc_loss: 0.00143  (0.00121)
     | > ga_loss: 0.00274  (0.00238)
     | > decoder_diff_spec_loss: 0.45641  (0.49283)
     | > postnet_diff_spec_loss: 0.77841  (0.81081)
     | > decoder_ssim_loss: 0.26156  (0.32051)
     | > postnet_ssim_loss: 0.27764  (0.33123)
     | > loss: 3.73695  (3.49265)
     | > align_error: 0.98934  (0.98979)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.87014  (4.70971)
     | > current_lr: 0.00010 
     | > step_time: 4.17290  (3.97848)
     | > loader_time: 0.10540  (0.04782)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 274100[0m
     | > decoder_loss: 1.74874  (1.95943)
     | > postnet_loss: 1.59368  (1.67697)
     | > stopnet_loss: 1.56866  (1.67642)
     | > decoder_coarse_loss: 1.73956  (1.89594)
     | > decoder_ddc_loss: 0.00096  (0.00119)
     | > ga_loss: 0.00199  (0.00234)
     | > decoder_diff_spec_loss: 0.44587  (0.49947)
     | > postnet_diff_spec_loss: 0.79755  (0.81489)
     | > decoder_ssim_loss: 0.31616  (0.31776)
     | > postnet_ssim_loss: 0.33040  (0.32875)
     | > loss: 3.32183  (3.56174)
     | > align_error: 0.99135  (0.98983)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.22217  (4.73080)
     | > current_lr: 0.00010 
     | > step_time: 4.09860  (3.92249)
     | > loader_time: 0.02400  (0.03919)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 274125[0m
     | > decoder_loss: 2.21260  (1.95957)
     | > postnet_loss: 1.81427  (1.67122)
     | > stopnet_loss: 2.12243  (1.69491)
     | > decoder_coarse_loss: 2.13308  (1.89782)
     | > decoder_ddc_loss: 0.00126  (0.00120)
     | > ga_loss: 0.00297  (0.00238)
     | > decoder_diff_spec_loss: 0.58023  (0.49995)
     | > postnet_diff_spec_loss: 0.88485  (0.81490)
     | > decoder_ssim_loss: 0.25163  (0.31671)
     | > postnet_ssim_loss: 0.25959  (0.32777)
     | > loss: 4.17165  (3.57909)
     | > align_error: 0.98949  (0.98967)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.93635  (4.37872)
     | > current_lr: 0.00010 
     | > step_time: 2.87880  (3.81706)
     | > loader_time: 0.01850  (0.03822)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 8.76595 [0m(+2.67152)
     | > avg_decoder_loss:[91m 2.61457 [0m(+0.01316)
     | > avg_postnet_loss:[92m 2.48476 [0m(-0.03352)
     | > avg_stopnet_loss:[91m 1.52704 [0m(+0.00197)
     | > avg_decoder_coarse_loss:[92m 2.74971 [0m(-0.01936)
     | > avg_decoder_ddc_loss:[92m 0.00108 [0m(-0.00004)
     | > avg_ga_loss:[91m 0.00255 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.52208 [0m(-0.00327)
     | > avg_postnet_diff_spec_loss:[92m 0.84056 [0m(-0.00232)
     | > avg_decoder_ssim_loss:[92m 0.31220 [0m(-0.00053)
     | > avg_postnet_ssim_loss:[92m 0.32892 [0m(-0.00197)
     | > avg_loss:[92m 4.00326 [0m(-0.00999)
     | > avg_align_error:[91m 0.99108 [0m(+0.00010)


[4m[1m > EPOCH: 47/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:35:28) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 274150[0m
     | > decoder_loss: 1.86595  (1.92436)
     | > postnet_loss: 1.62864  (1.63824)
     | > stopnet_loss: 1.67840  (1.54641)
     | > decoder_coarse_loss: 1.81870  (1.86074)
     | > decoder_ddc_loss: 0.00159  (0.00122)
     | > ga_loss: 0.00350  (0.00237)
     | > decoder_diff_spec_loss: 0.47023  (0.49593)
     | > postnet_diff_spec_loss: 0.80415  (0.80928)
     | > decoder_ssim_loss: 0.31747  (0.33305)
     | > postnet_ssim_loss: 0.32697  (0.34320)
     | > loss: 3.50429  (3.40975)
     | > align_error: 0.98705  (0.98971)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.12063  (3.30612)
     | > current_lr: 0.00010 
     | > step_time: 2.94600  (3.93521)
     | > loader_time: 0.02900  (0.03269)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 274175[0m
     | > decoder_loss: 2.08129  (1.94364)
     | > postnet_loss: 1.74012  (1.65044)
     | > stopnet_loss: 1.39979  (1.64907)
     | > decoder_coarse_loss: 1.99963  (1.87188)
     | > decoder_ddc_loss: 0.00133  (0.00119)
     | > ga_loss: 0.00227  (0.00237)
     | > decoder_diff_spec_loss: 0.51459  (0.49703)
     | > postnet_diff_spec_loss: 0.83262  (0.81160)
     | > decoder_ssim_loss: 0.33985  (0.31867)
     | > postnet_ssim_loss: 0.35229  (0.32951)
     | > loss: 3.37660  (3.51693)
     | > align_error: 0.98934  (0.98977)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.31211  (4.23883)
     | > current_lr: 0.00010 
     | > step_time: 3.57460  (3.84377)
     | > loader_time: 0.01970  (0.03071)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 274200[0m
     | > decoder_loss: 1.83362  (1.94372)
     | > postnet_loss: 1.54209  (1.65569)
     | > stopnet_loss: 1.87295  (1.67167)
     | > decoder_coarse_loss: 1.75453  (1.87347)
     | > decoder_ddc_loss: 0.00141  (0.00119)
     | > ga_loss: 0.00261  (0.00237)
     | > decoder_diff_spec_loss: 0.46978  (0.49685)
     | > postnet_diff_spec_loss: 0.79499  (0.81262)
     | > decoder_ssim_loss: 0.28434  (0.31927)
     | > postnet_ssim_loss: 0.29423  (0.33081)
     | > loss: 3.62976  (3.54192)
     | > align_error: 0.98698  (0.98963)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.13537  (4.30908)
     | > current_lr: 0.00010 
     | > step_time: 3.77960  (3.83774)
     | > loader_time: 0.01860  (0.03224)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 6.14489 [0m(-2.62106)
     | > avg_decoder_loss:[91m 2.67524 [0m(+0.06067)
     | > avg_postnet_loss:[91m 2.60568 [0m(+0.12092)
     | > avg_stopnet_loss:[91m 1.52866 [0m(+0.00162)
     | > avg_decoder_coarse_loss:[92m 2.69896 [0m(-0.05075)
     | > avg_decoder_ddc_loss:[92m 0.00103 [0m(-0.00005)
     | > avg_ga_loss:[92m 0.00255 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.52456 [0m(+0.00248)
     | > avg_postnet_diff_spec_loss:[92m 0.84050 [0m(-0.00007)
     | > avg_decoder_ssim_loss:[92m 0.31183 [0m(-0.00037)
     | > avg_postnet_ssim_loss:[91m 0.32922 [0m(+0.00030)
     | > avg_loss:[91m 4.03816 [0m(+0.03489)
     | > avg_align_error:[91m 0.99123 [0m(+0.00015)


[4m[1m > EPOCH: 48/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:43:09) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 274225[0m
     | > decoder_loss: 1.74120  (1.74120)
     | > postnet_loss: 1.45501  (1.45501)
     | > stopnet_loss: 2.09412  (2.09412)
     | > decoder_coarse_loss: 1.69910  (1.69910)
     | > decoder_ddc_loss: 0.00076  (0.00076)
     | > ga_loss: 0.00219  (0.00219)
     | > decoder_diff_spec_loss: 0.46268  (0.46268)
     | > postnet_diff_spec_loss: 0.79159  (0.79159)
     | > decoder_ssim_loss: 0.25241  (0.25241)
     | > postnet_ssim_loss: 0.26167  (0.26167)
     | > loss: 3.77118  (3.77118)
     | > align_error: 0.99306  (0.99306)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.21242  (2.21242)
     | > current_lr: 0.00010 
     | > step_time: 7.06360  (7.06357)
     | > loader_time: 0.09540  (0.09540)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 274250[0m
     | > decoder_loss: 1.96756  (1.91786)
     | > postnet_loss: 1.62435  (1.62706)
     | > stopnet_loss: 2.01522  (1.62432)
     | > decoder_coarse_loss: 1.91898  (1.84702)
     | > decoder_ddc_loss: 0.00090  (0.00119)
     | > ga_loss: 0.00210  (0.00236)
     | > decoder_diff_spec_loss: 0.51320  (0.49499)
     | > postnet_diff_spec_loss: 0.82878  (0.81189)
     | > decoder_ssim_loss: 0.26295  (0.32161)
     | > postnet_ssim_loss: 0.26736  (0.33284)
     | > loss: 3.87172  (3.47472)
     | > align_error: 0.99236  (0.98978)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.75363  (3.90509)
     | > current_lr: 0.00010 
     | > step_time: 4.53530  (3.83873)
     | > loader_time: 0.02120  (0.04422)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 274275[0m
     | > decoder_loss: 1.94511  (1.95146)
     | > postnet_loss: 1.73265  (1.65591)
     | > stopnet_loss: 2.12217  (1.67909)
     | > decoder_coarse_loss: 1.86609  (1.87615)
     | > decoder_ddc_loss: 0.00099  (0.00117)
     | > ga_loss: 0.00237  (0.00234)
     | > decoder_diff_spec_loss: 0.49113  (0.49998)
     | > postnet_diff_spec_loss: 0.83478  (0.81489)
     | > decoder_ssim_loss: 0.24640  (0.31679)
     | > postnet_ssim_loss: 0.25536  (0.32815)
     | > loss: 3.97713  (3.55189)
     | > align_error: 0.99056  (0.98978)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 7.13470  (4.29649)
     | > current_lr: 0.00010 
     | > step_time: 3.91990  (3.80321)
     | > loader_time: 0.07490  (0.03968)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 274300[0m
     | > decoder_loss: 1.92628  (1.94710)
     | > postnet_loss: 1.67560  (1.64934)
     | > stopnet_loss: 2.37630  (1.68792)
     | > decoder_coarse_loss: 1.84599  (1.87123)
     | > decoder_ddc_loss: 0.00075  (0.00118)
     | > ga_loss: 0.00219  (0.00235)
     | > decoder_diff_spec_loss: 0.47169  (0.49822)
     | > postnet_diff_spec_loss: 0.81633  (0.81359)
     | > decoder_ssim_loss: 0.22696  (0.31667)
     | > postnet_ssim_loss: 0.23557  (0.32806)
     | > loss: 4.18704  (3.55602)
     | > align_error: 0.99254  (0.98966)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.67008  (4.08395)
     | > current_lr: 0.00010 
     | > step_time: 4.88810  (3.84185)
     | > loader_time: 0.01930  (0.03717)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.67486 [0m(-0.47003)
     | > avg_decoder_loss:[91m 2.72763 [0m(+0.05240)
     | > avg_postnet_loss:[92m 2.60152 [0m(-0.00416)
     | > avg_stopnet_loss:[91m 1.52983 [0m(+0.00117)
     | > avg_decoder_coarse_loss:[92m 2.68071 [0m(-0.01825)
     | > avg_decoder_ddc_loss:[91m 0.00109 [0m(+0.00005)
     | > avg_ga_loss:[92m 0.00254 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.52122 [0m(-0.00334)
     | > avg_postnet_diff_spec_loss:[91m 0.84192 [0m(+0.00142)
     | > avg_decoder_ssim_loss:[92m 0.31145 [0m(-0.00039)
     | > avg_postnet_ssim_loss:[91m 0.33040 [0m(+0.00118)
     | > avg_loss:[91m 4.04649 [0m(+0.00833)
     | > avg_align_error:[92m 0.99111 [0m(-0.00012)


[4m[1m > EPOCH: 49/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:50:38) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 274325[0m
     | > decoder_loss: 1.91492  (1.91231)
     | > postnet_loss: 1.55515  (1.62268)
     | > stopnet_loss: 1.65764  (1.51468)
     | > decoder_coarse_loss: 1.85183  (1.83766)
     | > decoder_ddc_loss: 0.00130  (0.00119)
     | > ga_loss: 0.00253  (0.00226)
     | > decoder_diff_spec_loss: 0.52348  (0.49658)
     | > postnet_diff_spec_loss: 0.82037  (0.80939)
     | > decoder_ssim_loss: 0.30829  (0.33312)
     | > postnet_ssim_loss: 0.31499  (0.34373)
     | > loss: 3.49289  (3.36513)
     | > align_error: 0.98909  (0.98983)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.77138  (3.50257)
     | > current_lr: 0.00010 
     | > step_time: 3.07820  (4.08688)
     | > loader_time: 0.01650  (0.03624)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 274350[0m
     | > decoder_loss: 1.85808  (1.92364)
     | > postnet_loss: 1.52911  (1.62599)
     | > stopnet_loss: 2.10396  (1.65025)
     | > decoder_coarse_loss: 1.79269  (1.84843)
     | > decoder_ddc_loss: 0.00103  (0.00120)
     | > ga_loss: 0.00232  (0.00235)
     | > decoder_diff_spec_loss: 0.49118  (0.49532)
     | > postnet_diff_spec_loss: 0.80156  (0.81052)
     | > decoder_ssim_loss: 0.24969  (0.31699)
     | > postnet_ssim_loss: 0.25728  (0.32841)
     | > loss: 3.86070  (3.49963)
     | > align_error: 0.98978  (0.98967)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.28398  (4.43728)
     | > current_lr: 0.00010 
     | > step_time: 5.93670  (3.81617)
     | > loader_time: 0.02790  (0.02902)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 274375[0m
     | > decoder_loss: 1.81498  (1.92693)
     | > postnet_loss: 1.60243  (1.63113)
     | > stopnet_loss: 1.20261  (1.65675)
     | > decoder_coarse_loss: 1.82184  (1.85854)
     | > decoder_ddc_loss: 0.00110  (0.00119)
     | > ga_loss: 0.00218  (0.00234)
     | > decoder_diff_spec_loss: 0.46435  (0.49634)
     | > postnet_diff_spec_loss: 0.81900  (0.81214)
     | > decoder_ssim_loss: 0.38294  (0.31862)
     | > postnet_ssim_loss: 0.40401  (0.33070)
     | > loss: 3.04116  (3.51237)
     | > align_error: 0.99003  (0.98958)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.11263  (4.39968)
     | > current_lr: 0.00010 
     | > step_time: 3.85950  (3.83795)
     | > loader_time: 0.02280  (0.03285)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.58544 [0m(-0.08942)
     | > avg_decoder_loss:[92m 2.60295 [0m(-0.12468)
     | > avg_postnet_loss:[92m 2.39743 [0m(-0.20409)
     | > avg_stopnet_loss:[91m 1.53148 [0m(+0.00166)
     | > avg_decoder_coarse_loss:[92m 2.54391 [0m(-0.13680)
     | > avg_decoder_ddc_loss:[92m 0.00102 [0m(-0.00006)
     | > avg_ga_loss:[92m 0.00253 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.51859 [0m(-0.00264)
     | > avg_postnet_diff_spec_loss:[92m 0.83919 [0m(-0.00273)
     | > avg_decoder_ssim_loss:[92m 0.31033 [0m(-0.00111)
     | > avg_postnet_ssim_loss:[92m 0.32825 [0m(-0.00215)
     | > avg_loss:[92m 3.92956 [0m(-0.11693)
     | > avg_align_error:[91m 0.99114 [0m(+0.00003)


[4m[1m > EPOCH: 50/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:58:32) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 274400[0m
     | > decoder_loss: 1.68009  (1.68009)
     | > postnet_loss: 1.48264  (1.48264)
     | > stopnet_loss: 1.04396  (1.04396)
     | > decoder_coarse_loss: 1.63024  (1.63024)
     | > decoder_ddc_loss: 0.00119  (0.00119)
     | > ga_loss: 0.00199  (0.00199)
     | > decoder_diff_spec_loss: 0.46244  (0.46244)
     | > postnet_diff_spec_loss: 0.78079  (0.78079)
     | > decoder_ssim_loss: 0.43353  (0.43353)
     | > postnet_ssim_loss: 0.45861  (0.45861)
     | > loss: 2.78631  (2.78631)
     | > align_error: 0.98980  (0.98980)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.33698  (5.33698)
     | > current_lr: 0.00010 
     | > step_time: 5.42890  (5.42894)
     | > loader_time: 11.10360  (11.10359)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 274425[0m
     | > decoder_loss: 1.76392  (1.89575)
     | > postnet_loss: 1.44639  (1.59622)
     | > stopnet_loss: 1.49199  (1.57548)
     | > decoder_coarse_loss: 1.71837  (1.83146)
     | > decoder_ddc_loss: 0.00132  (0.00120)
     | > ga_loss: 0.00220  (0.00234)
     | > decoder_diff_spec_loss: 0.47000  (0.49248)
     | > postnet_diff_spec_loss: 0.79279  (0.81002)
     | > decoder_ssim_loss: 0.32705  (0.32303)
     | > postnet_ssim_loss: 0.33724  (0.33446)
     | > loss: 3.21728  (3.40835)
     | > align_error: 0.98882  (0.98960)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.03114  (4.18900)
     | > current_lr: 0.00010 
     | > step_time: 4.10310  (3.94237)
     | > loader_time: 0.01700  (0.04003)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 274450[0m
     | > decoder_loss: 2.04398  (1.93252)
     | > postnet_loss: 1.80427  (1.62021)
     | > stopnet_loss: 2.15852  (1.64795)
     | > decoder_coarse_loss: 1.97043  (1.85939)
     | > decoder_ddc_loss: 0.00094  (0.00119)
     | > ga_loss: 0.00188  (0.00231)
     | > decoder_diff_spec_loss: 0.52393  (0.49933)
     | > postnet_diff_spec_loss: 0.84194  (0.81324)
     | > decoder_ssim_loss: 0.24388  (0.31724)
     | > postnet_ssim_loss: 0.25298  (0.32863)
     | > loss: 4.08852  (3.50245)
     | > align_error: 0.99108  (0.98963)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.82667  (4.45238)
     | > current_lr: 0.00009 
     | > step_time: 4.52860  (3.90458)
     | > loader_time: 0.04270  (0.03626)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 274475[0m
     | > decoder_loss: 1.87569  (1.92779)
     | > postnet_loss: 1.61585  (1.61722)
     | > stopnet_loss: 1.54408  (1.66214)
     | > decoder_coarse_loss: 1.78314  (1.85782)
     | > decoder_ddc_loss: 0.00167  (0.00120)
     | > ga_loss: 0.00322  (0.00233)
     | > decoder_diff_spec_loss: 0.45296  (0.49723)
     | > postnet_diff_spec_loss: 0.79002  (0.81237)
     | > decoder_ssim_loss: 0.33878  (0.31674)
     | > postnet_ssim_loss: 0.35353  (0.32829)
     | > loss: 3.36308  (3.51347)
     | > align_error: 0.98617  (0.98950)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.58904  (4.13073)
     | > current_lr: 0.00009 
     | > step_time: 2.82120  (3.86099)
     | > loader_time: 0.01710  (0.03437)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.56496 [0m(-0.02048)
     | > avg_decoder_loss:[92m 2.51767 [0m(-0.08529)
     | > avg_postnet_loss:[92m 2.28378 [0m(-0.11365)
     | > avg_stopnet_loss:[91m 1.53319 [0m(+0.00171)
     | > avg_decoder_coarse_loss:[91m 2.55027 [0m(+0.00636)
     | > avg_decoder_ddc_loss:[91m 0.00107 [0m(+0.00004)
     | > avg_ga_loss:[92m 0.00252 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.51824 [0m(-0.00035)
     | > avg_postnet_diff_spec_loss:[92m 0.83882 [0m(-0.00038)
     | > avg_decoder_ssim_loss:[92m 0.30944 [0m(-0.00089)
     | > avg_postnet_ssim_loss:[92m 0.32741 [0m(-0.00084)
     | > avg_loss:[92m 3.88246 [0m(-0.04709)
     | > avg_align_error:[92m 0.99097 [0m(-0.00017)


[4m[1m > EPOCH: 51/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:06:15) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 274500[0m
     | > decoder_loss: 1.95295  (1.89824)
     | > postnet_loss: 1.59884  (1.59106)
     | > stopnet_loss: 1.26929  (1.50341)
     | > decoder_coarse_loss: 1.87463  (1.82791)
     | > decoder_ddc_loss: 0.00135  (0.00120)
     | > ga_loss: 0.00247  (0.00222)
     | > decoder_diff_spec_loss: 0.49975  (0.49382)
     | > postnet_diff_spec_loss: 0.80867  (0.80699)
     | > decoder_ssim_loss: 0.36955  (0.33328)
     | > postnet_ssim_loss: 0.37850  (0.34519)
     | > loss: 3.15267  (3.33893)
     | > align_error: 0.98904  (0.98987)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.86701  (2.83378)
     | > current_lr: 0.00009 
     | > step_time: 3.08580  (4.12701)
     | > loader_time: 0.02160  (0.03519)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 274525[0m
     | > decoder_loss: 1.88729  (1.91710)
     | > postnet_loss: 1.51364  (1.59892)
     | > stopnet_loss: 2.08174  (1.63087)
     | > decoder_coarse_loss: 1.77943  (1.83746)
     | > decoder_ddc_loss: 0.00093  (0.00121)
     | > ga_loss: 0.00231  (0.00234)
     | > decoder_diff_spec_loss: 0.48912  (0.49579)
     | > postnet_diff_spec_loss: 0.79388  (0.80981)
     | > decoder_ssim_loss: 0.25407  (0.31762)
     | > postnet_ssim_loss: 0.26286  (0.32937)
     | > loss: 3.83862  (3.46937)
     | > align_error: 0.99100  (0.98960)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.28819  (3.81454)
     | > current_lr: 0.00009 
     | > step_time: 4.10960  (3.84100)
     | > loader_time: 0.02160  (0.03322)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 274550[0m
     | > decoder_loss: 2.02630  (1.91820)
     | > postnet_loss: 1.63367  (1.60299)
     | > stopnet_loss: 1.65152  (1.66330)
     | > decoder_coarse_loss: 1.93444  (1.84173)
     | > decoder_ddc_loss: 0.00167  (0.00122)
     | > ga_loss: 0.00253  (0.00232)
     | > decoder_diff_spec_loss: 0.49615  (0.49654)
     | > postnet_diff_spec_loss: 0.79441  (0.81117)
     | > decoder_ssim_loss: 0.31404  (0.31653)
     | > postnet_ssim_loss: 0.32427  (0.32863)
     | > loss: 3.54539  (3.50418)
     | > align_error: 0.98611  (0.98947)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.92419  (3.87809)
     | > current_lr: 0.00009 
     | > step_time: 3.46180  (3.89598)
     | > loader_time: 0.02300  (0.03444)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 274575[0m
     | > decoder_loss: 1.98714  (1.92237)
     | > postnet_loss: 2.01394  (1.60960)
     | > stopnet_loss: 1.31698  (1.66056)
     | > decoder_coarse_loss: 2.04058  (1.84734)
     | > decoder_ddc_loss: 0.00646  (0.00127)
     | > ga_loss: 0.00830  (0.00240)
     | > decoder_diff_spec_loss: 0.50485  (0.49671)
     | > postnet_diff_spec_loss: 0.89291  (0.81261)
     | > decoder_ssim_loss: 0.49191  (0.31786)
     | > postnet_ssim_loss: 0.50800  (0.33001)
     | > loss: 3.46991  (3.50700)
     | > align_error: 0.95566  (0.98911)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 36.00043  (4.22847)
     | > current_lr: 0.00009 
     | > step_time: 0.43740  (3.68465)
     | > loader_time: 0.00810  (0.03299)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.17171 [0m(-0.39325)
     | > avg_decoder_loss:[91m 2.57704 [0m(+0.05937)
     | > avg_postnet_loss:[91m 2.36549 [0m(+0.08171)
     | > avg_stopnet_loss:[91m 1.53394 [0m(+0.00075)
     | > avg_decoder_coarse_loss:[91m 2.61782 [0m(+0.06754)
     | > avg_decoder_ddc_loss:[92m 0.00103 [0m(-0.00003)
     | > avg_ga_loss:[92m 0.00250 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.51923 [0m(+0.00099)
     | > avg_postnet_diff_spec_loss:[92m 0.83768 [0m(-0.00113)
     | > avg_decoder_ssim_loss:[92m 0.30907 [0m(-0.00037)
     | > avg_postnet_ssim_loss:[92m 0.32706 [0m(-0.00034)
     | > avg_loss:[91m 3.93507 [0m(+0.05260)
     | > avg_align_error:[91m 0.99114 [0m(+0.00017)


[4m[1m > EPOCH: 52/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:13:43) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 274600[0m
     | > decoder_loss: 2.01679  (1.88541)
     | > postnet_loss: 1.71843  (1.57775)
     | > stopnet_loss: 1.44912  (1.60213)
     | > decoder_coarse_loss: 1.94666  (1.81661)
     | > decoder_ddc_loss: 0.00162  (0.00122)
     | > ga_loss: 0.00298  (0.00234)
     | > decoder_diff_spec_loss: 0.52876  (0.49301)
     | > postnet_diff_spec_loss: 0.84157  (0.80976)
     | > decoder_ssim_loss: 0.34396  (0.32167)
     | > postnet_ssim_loss: 0.35508  (0.33340)
     | > loss: 3.40223  (3.42352)
     | > align_error: 0.98662  (0.98959)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.65171  (4.02781)
     | > current_lr: 0.00009 
     | > step_time: 2.87300  (3.80719)
     | > loader_time: 0.01830  (0.03346)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 274625[0m
     | > decoder_loss: 1.97261  (1.91020)
     | > postnet_loss: 1.55900  (1.59342)
     | > stopnet_loss: 2.22687  (1.64296)
     | > decoder_coarse_loss: 1.92591  (1.84151)
     | > decoder_ddc_loss: 0.00093  (0.00120)
     | > ga_loss: 0.00210  (0.00230)
     | > decoder_diff_spec_loss: 0.52830  (0.49771)
     | > postnet_diff_spec_loss: 0.83509  (0.81166)
     | > decoder_ssim_loss: 0.22899  (0.31751)
     | > postnet_ssim_loss: 0.23525  (0.32932)
     | > loss: 4.05891  (3.48010)
     | > align_error: 0.99118  (0.98956)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.24929  (4.26667)
     | > current_lr: 0.00009 
     | > step_time: 5.37830  (3.76061)
     | > loader_time: 0.02560  (0.02912)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 274650[0m
     | > decoder_loss: 1.79201  (1.91093)
     | > postnet_loss: 1.47511  (1.59315)
     | > stopnet_loss: 2.08367  (1.66098)
     | > decoder_coarse_loss: 1.70266  (1.83835)
     | > decoder_ddc_loss: 0.00091  (0.00121)
     | > ga_loss: 0.00226  (0.00230)
     | > decoder_diff_spec_loss: 0.47122  (0.49718)
     | > postnet_diff_spec_loss: 0.80237  (0.81167)
     | > decoder_ssim_loss: 0.24657  (0.31531)
     | > postnet_ssim_loss: 0.25176  (0.32713)
     | > loss: 3.78061  (3.49621)
     | > align_error: 0.99212  (0.98949)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.10411  (4.08048)
     | > current_lr: 0.00009 
     | > step_time: 5.06330  (3.74804)
     | > loader_time: 0.10130  (0.03013)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.38380 [0m(-0.78791)
     | > avg_decoder_loss:[92m 2.50720 [0m(-0.06983)
     | > avg_postnet_loss:[91m 2.38166 [0m(+0.01617)
     | > avg_stopnet_loss:[91m 1.53799 [0m(+0.00405)
     | > avg_decoder_coarse_loss:[92m 2.50061 [0m(-0.11720)
     | > avg_decoder_ddc_loss:[92m 0.00103 [0m(-0.00001)
     | > avg_ga_loss:[91m 0.00250 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.51544 [0m(-0.00379)
     | > avg_postnet_diff_spec_loss:[91m 0.83896 [0m(+0.00128)
     | > avg_decoder_ssim_loss:[92m 0.30810 [0m(-0.00097)
     | > avg_postnet_ssim_loss:[91m 0.32799 [0m(+0.00093)
     | > avg_loss:[92m 3.89576 [0m(-0.03931)
     | > avg_align_error:[92m 0.99094 [0m(-0.00020)


[4m[1m > EPOCH: 53/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:20:56) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 274675[0m
     | > decoder_loss: 1.73940  (1.86947)
     | > postnet_loss: 1.54024  (1.56955)
     | > stopnet_loss: 1.78143  (1.51215)
     | > decoder_coarse_loss: 1.70359  (1.80460)
     | > decoder_ddc_loss: 0.00103  (0.00112)
     | > ga_loss: 0.00205  (0.00220)
     | > decoder_diff_spec_loss: 0.46024  (0.49077)
     | > postnet_diff_spec_loss: 0.79361  (0.80638)
     | > decoder_ssim_loss: 0.27463  (0.32905)
     | > postnet_ssim_loss: 0.28950  (0.34128)
     | > loss: 3.49224  (3.32620)
     | > align_error: 0.99133  (0.99006)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.40926  (2.94034)
     | > current_lr: 0.00009 
     | > step_time: 4.33310  (4.12302)
     | > loader_time: 0.06700  (0.04298)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 274700[0m
     | > decoder_loss: 1.86739  (1.89406)
     | > postnet_loss: 1.49394  (1.58328)
     | > stopnet_loss: 1.50980  (1.60326)
     | > decoder_coarse_loss: 1.80609  (1.82164)
     | > decoder_ddc_loss: 0.00091  (0.00117)
     | > ga_loss: 0.00204  (0.00233)
     | > decoder_diff_spec_loss: 0.47934  (0.49511)
     | > postnet_diff_spec_loss: 0.78894  (0.80964)
     | > decoder_ssim_loss: 0.32398  (0.31835)
     | > postnet_ssim_loss: 0.33573  (0.33055)
     | > loss: 3.29407  (3.42838)
     | > align_error: 0.99117  (0.98962)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.53368  (3.81308)
     | > current_lr: 0.00009 
     | > step_time: 4.84990  (3.76083)
     | > loader_time: 0.02060  (0.03195)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 274725[0m
     | > decoder_loss: 1.84704  (1.89839)
     | > postnet_loss: 1.67269  (1.58851)
     | > stopnet_loss: 0.99582  (1.64401)
     | > decoder_coarse_loss: 1.73606  (1.82481)
     | > decoder_ddc_loss: 0.00196  (0.00117)
     | > ga_loss: 0.00283  (0.00232)
     | > decoder_diff_spec_loss: 0.51069  (0.49617)
     | > postnet_diff_spec_loss: 0.82511  (0.81075)
     | > decoder_ssim_loss: 0.46462  (0.31565)
     | > postnet_ssim_loss: 0.47901  (0.32795)
     | > loss: 2.89428  (3.47144)
     | > align_error: 0.98388  (0.98955)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.78332  (4.17660)
     | > current_lr: 0.00009 
     | > step_time: 2.73890  (3.75044)
     | > loader_time: 0.03860  (0.03151)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 274750[0m
     | > decoder_loss: 1.79774  (1.90738)
     | > postnet_loss: 1.46473  (1.58917)
     | > stopnet_loss: 1.46138  (1.64920)
     | > decoder_coarse_loss: 1.70782  (1.83015)
     | > decoder_ddc_loss: 0.00092  (0.00118)
     | > ga_loss: 0.00185  (0.00232)
     | > decoder_diff_spec_loss: 0.47917  (0.49580)
     | > postnet_diff_spec_loss: 0.78245  (0.81091)
     | > decoder_ssim_loss: 0.31507  (0.31501)
     | > postnet_ssim_loss: 0.32856  (0.32733)
     | > loss: 3.18976  (3.48005)
     | > align_error: 0.99158  (0.98951)
     | > amp_scaler: 32768.00000  (20956.27907)
     | > grad_norm: 6.32019  (4.28368)
     | > current_lr: 0.00009 
     | > step_time: 3.06450  (3.58667)
     | > loader_time: 0.02120  (0.03138)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.46415 [0m(+0.08035)
     | > avg_decoder_loss:[91m 2.51539 [0m(+0.00818)
     | > avg_postnet_loss:[92m 2.17810 [0m(-0.20356)
     | > avg_stopnet_loss:[92m 1.53777 [0m(-0.00022)
     | > avg_decoder_coarse_loss:[92m 2.45738 [0m(-0.04323)
     | > avg_decoder_ddc_loss:[92m 0.00101 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00251 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.51362 [0m(-0.00182)
     | > avg_postnet_diff_spec_loss:[92m 0.83557 [0m(-0.00340)
     | > avg_decoder_ssim_loss:[92m 0.30769 [0m(-0.00041)
     | > avg_postnet_ssim_loss:[92m 0.32430 [0m(-0.00369)
     | > avg_loss:[92m 3.83358 [0m(-0.06218)
     | > avg_align_error:[91m 0.99110 [0m(+0.00016)


[4m[1m > EPOCH: 54/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:28:04) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 274775[0m
     | > decoder_loss: 1.97535  (1.86385)
     | > postnet_loss: 1.60976  (1.55212)
     | > stopnet_loss: 1.64946  (1.59922)
     | > decoder_coarse_loss: 1.90042  (1.79842)
     | > decoder_ddc_loss: 0.00100  (0.00117)
     | > ga_loss: 0.00193  (0.00230)
     | > decoder_diff_spec_loss: 0.51296  (0.49085)
     | > postnet_diff_spec_loss: 0.82736  (0.80713)
     | > decoder_ssim_loss: 0.30094  (0.31918)
     | > postnet_ssim_loss: 0.31240  (0.33174)
     | > loss: 3.51915  (3.40186)
     | > align_error: 0.99032  (0.98968)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.31934  (3.95026)
     | > current_lr: 0.00009 
     | > step_time: 4.62760  (3.85648)
     | > loader_time: 0.07830  (0.04015)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 274800[0m
     | > decoder_loss: 1.84405  (1.89502)
     | > postnet_loss: 1.55482  (1.57018)
     | > stopnet_loss: 2.28931  (1.60939)
     | > decoder_coarse_loss: 1.77370  (1.82305)
     | > decoder_ddc_loss: 0.00083  (0.00119)
     | > ga_loss: 0.00191  (0.00231)
     | > decoder_diff_spec_loss: 0.47722  (0.49773)
     | > postnet_diff_spec_loss: 0.80418  (0.81021)
     | > decoder_ssim_loss: 0.23143  (0.31813)
     | > postnet_ssim_loss: 0.23575  (0.33048)
     | > loss: 4.02937  (3.43242)
     | > align_error: 0.99279  (0.98956)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.02244  (3.98578)
     | > current_lr: 0.00009 
     | > step_time: 3.98100  (3.69798)
     | > loader_time: 0.02300  (0.03452)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 274825[0m
     | > decoder_loss: 1.98785  (1.89888)
     | > postnet_loss: 1.57883  (1.57502)
     | > stopnet_loss: 1.88686  (1.63462)
     | > decoder_coarse_loss: 1.93845  (1.82552)
     | > decoder_ddc_loss: 0.00083  (0.00117)
     | > ga_loss: 0.00197  (0.00230)
     | > decoder_diff_spec_loss: 0.52609  (0.49717)
     | > postnet_diff_spec_loss: 0.81086  (0.81095)
     | > decoder_ssim_loss: 0.25846  (0.31523)
     | > postnet_ssim_loss: 0.26296  (0.32745)
     | > loss: 3.73777  (3.45898)
     | > align_error: 0.99168  (0.98952)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.95845  (3.84129)
     | > current_lr: 0.00009 
     | > step_time: 4.32020  (3.69376)
     | > loader_time: 0.06180  (0.03286)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.91948 [0m(+0.45533)
     | > avg_decoder_loss:[92m 2.50812 [0m(-0.00727)
     | > avg_postnet_loss:[91m 2.23285 [0m(+0.05475)
     | > avg_stopnet_loss:[92m 1.53723 [0m(-0.00054)
     | > avg_decoder_coarse_loss:[92m 2.44749 [0m(-0.00989)
     | > avg_decoder_ddc_loss:[92m 0.00099 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00251 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.51480 [0m(+0.00117)
     | > avg_postnet_diff_spec_loss:[91m 0.83692 [0m(+0.00135)
     | > avg_decoder_ssim_loss:[92m 0.30715 [0m(-0.00053)
     | > avg_postnet_ssim_loss:[91m 0.32560 [0m(+0.00130)
     | > avg_loss:[91m 3.84327 [0m(+0.00969)
     | > avg_align_error:[91m 0.99124 [0m(+0.00014)


[4m[1m > EPOCH: 55/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:35:12) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 274850[0m
     | > decoder_loss: 1.97288  (1.86441)
     | > postnet_loss: 1.61620  (1.54949)
     | > stopnet_loss: 1.14139  (1.49592)
     | > decoder_coarse_loss: 1.89362  (1.80121)
     | > decoder_ddc_loss: 0.00145  (0.00116)
     | > ga_loss: 0.00232  (0.00221)
     | > decoder_diff_spec_loss: 0.52172  (0.49625)
     | > postnet_diff_spec_loss: 0.82159  (0.80610)
     | > decoder_ssim_loss: 0.41410  (0.33314)
     | > postnet_ssim_loss: 0.42149  (0.34608)
     | > loss: 3.06874  (3.30644)
     | > align_error: 0.98725  (0.98982)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.76307  (2.76991)
     | > current_lr: 0.00009 
     | > step_time: 3.55230  (4.04257)
     | > loader_time: 0.02310  (0.04082)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 274875[0m
     | > decoder_loss: 1.89667  (1.88185)
     | > postnet_loss: 1.59895  (1.56256)
     | > stopnet_loss: 1.89962  (1.61119)
     | > decoder_coarse_loss: 1.81250  (1.81224)
     | > decoder_ddc_loss: 0.00107  (0.00122)
     | > ga_loss: 0.00262  (0.00233)
     | > decoder_diff_spec_loss: 0.45993  (0.49442)
     | > postnet_diff_spec_loss: 0.79311  (0.80907)
     | > decoder_ssim_loss: 0.27329  (0.31735)
     | > postnet_ssim_loss: 0.28665  (0.32982)
     | > loss: 3.69328  (3.42498)
     | > align_error: 0.98963  (0.98946)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.74142  (3.57754)
     | > current_lr: 0.00009 
     | > step_time: 3.27980  (3.63819)
     | > loader_time: 0.06550  (0.03213)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 274900[0m
     | > decoder_loss: 1.73875  (1.88611)
     | > postnet_loss: 1.54695  (1.56700)
     | > stopnet_loss: 2.68125  (1.65253)
     | > decoder_coarse_loss: 1.61878  (1.81314)
     | > decoder_ddc_loss: 0.00080  (0.00117)
     | > ga_loss: 0.00211  (0.00230)
     | > decoder_diff_spec_loss: 0.45655  (0.49496)
     | > postnet_diff_spec_loss: 0.79866  (0.80962)
     | > decoder_ssim_loss: 0.19849  (0.31221)
     | > postnet_ssim_loss: 0.21035  (0.32495)
     | > loss: 4.33413  (3.46634)
     | > align_error: 0.99173  (0.98960)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.67281  (3.60437)
     | > current_lr: 0.00009 
     | > step_time: 4.47330  (3.73762)
     | > loader_time: 0.01750  (0.02961)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 274925[0m
     | > decoder_loss: 1.94849  (1.89443)
     | > postnet_loss: 1.60778  (1.57292)
     | > stopnet_loss: 2.29946  (1.64989)
     | > decoder_coarse_loss: 1.79270  (1.82019)
     | > decoder_ddc_loss: 0.00103  (0.00119)
     | > ga_loss: 0.00219  (0.00232)
     | > decoder_diff_spec_loss: 0.49065  (0.49570)
     | > postnet_diff_spec_loss: 0.78602  (0.81042)
     | > decoder_ssim_loss: 0.22448  (0.31405)
     | > postnet_ssim_loss: 0.23506  (0.32678)
     | > loss: 4.08196  (3.47043)
     | > align_error: 0.98970  (0.98945)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.33219  (3.76739)
     | > current_lr: 0.00009 
     | > step_time: 2.66660  (3.56517)
     | > loader_time: 0.01560  (0.02910)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.55664 [0m(-0.36284)
     | > avg_decoder_loss:[92m 2.50064 [0m(-0.00747)
     | > avg_postnet_loss:[92m 2.17639 [0m(-0.05646)
     | > avg_stopnet_loss:[91m 1.54065 [0m(+0.00342)
     | > avg_decoder_coarse_loss:[92m 2.41953 [0m(-0.02797)
     | > avg_decoder_ddc_loss:[91m 0.00101 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00250 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.51014 [0m(-0.00465)
     | > avg_postnet_diff_spec_loss:[92m 0.83582 [0m(-0.00110)
     | > avg_decoder_ssim_loss:[92m 0.30681 [0m(-0.00034)
     | > avg_postnet_ssim_loss:[92m 0.32538 [0m(-0.00022)
     | > avg_loss:[92m 3.82207 [0m(-0.02120)
     | > avg_align_error:[92m 0.99117 [0m(-0.00007)


[4m[1m > EPOCH: 56/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:42:23) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 274950[0m
     | > decoder_loss: 1.70605  (1.84414)
     | > postnet_loss: 1.46670  (1.53514)
     | > stopnet_loss: 1.52232  (1.60353)
     | > decoder_coarse_loss: 1.65895  (1.78078)
     | > decoder_ddc_loss: 0.00098  (0.00120)
     | > ga_loss: 0.00184  (0.00229)
     | > decoder_diff_spec_loss: 0.45696  (0.48800)
     | > postnet_diff_spec_loss: 0.79627  (0.80591)
     | > decoder_ssim_loss: 0.32860  (0.31924)
     | > postnet_ssim_loss: 0.34132  (0.33246)
     | > loss: 3.22046  (3.39168)
     | > align_error: 0.99097  (0.98956)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.28788  (3.52717)
     | > current_lr: 0.00009 
     | > step_time: 3.82940  (3.88102)
     | > loader_time: 0.02010  (0.03629)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 274975[0m
     | > decoder_loss: 1.85755  (1.88267)
     | > postnet_loss: 1.49625  (1.56054)
     | > stopnet_loss: 1.16287  (1.60113)
     | > decoder_coarse_loss: 1.81386  (1.81245)
     | > decoder_ddc_loss: 0.00152  (0.00121)
     | > ga_loss: 0.00272  (0.00229)
     | > decoder_diff_spec_loss: 0.49056  (0.49587)
     | > postnet_diff_spec_loss: 0.78988  (0.80995)
     | > decoder_ssim_loss: 0.42502  (0.31918)
     | > postnet_ssim_loss: 0.44536  (0.33214)
     | > loss: 3.00646  (3.41608)
     | > align_error: 0.98690  (0.98936)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.10367  (3.58163)
     | > current_lr: 0.00009 
     | > step_time: 2.10840  (3.67089)
     | > loader_time: 0.05320  (0.03773)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 275000[0m
     | > decoder_loss: 1.83083  (1.88367)
     | > postnet_loss: 1.60971  (1.56479)
     | > stopnet_loss: 1.86874  (1.63842)
     | > decoder_coarse_loss: 1.76074  (1.81291)
     | > decoder_ddc_loss: 0.00137  (0.00119)
     | > ga_loss: 0.00281  (0.00229)
     | > decoder_diff_spec_loss: 0.47707  (0.49531)
     | > postnet_diff_spec_loss: 0.79743  (0.81045)
     | > decoder_ssim_loss: 0.26533  (0.31503)
     | > postnet_ssim_loss: 0.27707  (0.32800)
     | > loss: 3.63768  (3.45270)
     | > align_error: 0.98781  (0.98937)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.13382  (3.74234)
     | > current_lr: 0.00009 
     | > step_time: 3.56320  (3.68660)
     | > loader_time: 0.01710  (0.03408)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.45840 [0m(-0.09824)
     | > avg_decoder_loss:[91m 2.50412 [0m(+0.00348)
     | > avg_postnet_loss:[91m 2.21382 [0m(+0.03743)
     | > avg_stopnet_loss:[91m 1.54077 [0m(+0.00012)
     | > avg_decoder_coarse_loss:[92m 2.34958 [0m(-0.06995)
     | > avg_decoder_ddc_loss:[92m 0.00100 [0m(-0.00000)
     | > avg_ga_loss:[91m 0.00250 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.51111 [0m(+0.00097)
     | > avg_postnet_diff_spec_loss:[92m 0.83464 [0m(-0.00118)
     | > avg_decoder_ssim_loss:[92m 0.30609 [0m(-0.00072)
     | > avg_postnet_ssim_loss:[92m 0.32435 [0m(-0.00102)
     | > avg_loss:[92m 3.81446 [0m(-0.00761)
     | > avg_align_error:[91m 0.99119 [0m(+0.00002)


[4m[1m > EPOCH: 57/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:49:35) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 275025[0m
     | > decoder_loss: 1.97604  (1.84528)
     | > postnet_loss: 1.60890  (1.53761)
     | > stopnet_loss: 1.30625  (1.53356)
     | > decoder_coarse_loss: 1.85592  (1.78308)
     | > decoder_ddc_loss: 0.00139  (0.00112)
     | > ga_loss: 0.00254  (0.00217)
     | > decoder_diff_spec_loss: 0.49270  (0.48970)
     | > postnet_diff_spec_loss: 0.80199  (0.80446)
     | > decoder_ssim_loss: 0.37180  (0.32345)
     | > postnet_ssim_loss: 0.38689  (0.33757)
     | > loss: 3.19284  (3.32498)
     | > align_error: 0.98833  (0.99012)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.16594  (3.28945)
     | > current_lr: 0.00009 
     | > step_time: 3.35170  (4.09119)
     | > loader_time: 0.04680  (0.03490)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 275050[0m
     | > decoder_loss: 1.89075  (1.87079)
     | > postnet_loss: 1.62766  (1.55667)
     | > stopnet_loss: 2.09154  (1.60332)
     | > decoder_coarse_loss: 1.77154  (1.79559)
     | > decoder_ddc_loss: 0.00112  (0.00120)
     | > ga_loss: 0.00219  (0.00231)
     | > decoder_diff_spec_loss: 0.52439  (0.49452)
     | > postnet_diff_spec_loss: 0.84492  (0.80899)
     | > decoder_ssim_loss: 0.25932  (0.31774)
     | > postnet_ssim_loss: 0.26191  (0.33046)
     | > loss: 3.89791  (3.40886)
     | > align_error: 0.98896  (0.98946)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.62994  (3.71710)
     | > current_lr: 0.00009 
     | > step_time: 3.52340  (3.60584)
     | > loader_time: 0.01780  (0.03369)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 275075[0m
     | > decoder_loss: 1.72253  (1.87935)
     | > postnet_loss: 1.43598  (1.56051)
     | > stopnet_loss: 1.11206  (1.63899)
     | > decoder_coarse_loss: 1.68554  (1.80744)
     | > decoder_ddc_loss: 0.00144  (0.00118)
     | > ga_loss: 0.00253  (0.00229)
     | > decoder_diff_spec_loss: 0.46578  (0.49495)
     | > postnet_diff_spec_loss: 0.78081  (0.80900)
     | > decoder_ssim_loss: 0.39991  (0.31321)
     | > postnet_ssim_loss: 0.42370  (0.32623)
     | > loss: 2.85361  (3.44841)
     | > align_error: 0.98800  (0.98953)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 8.37103  (4.13563)
     | > current_lr: 0.00009 
     | > step_time: 2.68160  (3.62713)
     | > loader_time: 0.01880  (0.03084)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 275100[0m
     | > decoder_loss: 1.68733  (1.88251)
     | > postnet_loss: 1.49855  (1.56343)
     | > stopnet_loss: 1.52188  (1.63949)
     | > decoder_coarse_loss: 1.62940  (1.81045)
     | > decoder_ddc_loss: 0.00137  (0.00119)
     | > ga_loss: 0.00265  (0.00231)
     | > decoder_diff_spec_loss: 0.46502  (0.49479)
     | > postnet_diff_spec_loss: 0.79339  (0.80982)
     | > decoder_ssim_loss: 0.32385  (0.31413)
     | > postnet_ssim_loss: 0.34030  (0.32723)
     | > loss: 3.21993  (3.45193)
     | > align_error: 0.98865  (0.98939)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.98159  (4.23157)
     | > current_lr: 0.00009 
     | > step_time: 1.86420  (3.52601)
     | > loader_time: 0.01270  (0.02875)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.47878 [0m(+0.02038)
     | > avg_decoder_loss:[91m 2.54565 [0m(+0.04153)
     | > avg_postnet_loss:[91m 2.37073 [0m(+0.15691)
     | > avg_stopnet_loss:[92m 1.53792 [0m(-0.00285)
     | > avg_decoder_coarse_loss:[91m 2.35062 [0m(+0.00104)
     | > avg_decoder_ddc_loss:[92m 0.00098 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00248 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.50993 [0m(-0.00118)
     | > avg_postnet_diff_spec_loss:[91m 0.83631 [0m(+0.00167)
     | > avg_decoder_ssim_loss:[92m 0.30597 [0m(-0.00012)
     | > avg_postnet_ssim_loss:[91m 0.32639 [0m(+0.00204)
     | > avg_loss:[91m 3.86199 [0m(+0.04753)
     | > avg_align_error:[91m 0.99122 [0m(+0.00004)


[4m[1m > EPOCH: 58/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:56:41) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 275125[0m
     | > decoder_loss: 1.93054  (1.85076)
     | > postnet_loss: 1.64125  (1.53355)
     | > stopnet_loss: 1.96621  (1.58494)
     | > decoder_coarse_loss: 1.89900  (1.78370)
     | > decoder_ddc_loss: 0.00094  (0.00120)
     | > ga_loss: 0.00218  (0.00231)
     | > decoder_diff_spec_loss: 0.49276  (0.48896)
     | > postnet_diff_spec_loss: 0.82285  (0.80580)
     | > decoder_ssim_loss: 0.26050  (0.31820)
     | > postnet_ssim_loss: 0.26830  (0.33130)
     | > loss: 3.80616  (3.37484)
     | > align_error: 0.99099  (0.98945)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.65558  (3.54494)
     | > current_lr: 0.00009 
     | > step_time: 4.21050  (3.87959)
     | > loader_time: 0.02740  (0.02885)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 275150[0m
     | > decoder_loss: 2.29871  (1.87380)
     | > postnet_loss: 1.92035  (1.55281)
     | > stopnet_loss: 1.55348  (1.60047)
     | > decoder_coarse_loss: 2.18807  (1.80671)
     | > decoder_ddc_loss: 0.00109  (0.00120)
     | > ga_loss: 0.00182  (0.00227)
     | > decoder_diff_spec_loss: 0.60985  (0.49583)
     | > postnet_diff_spec_loss: 0.88263  (0.80961)
     | > decoder_ssim_loss: 0.30368  (0.31589)
     | > postnet_ssim_loss: 0.31487  (0.32897)
     | > loss: 3.69239  (3.40804)
     | > align_error: 0.98949  (0.98935)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.00567  (3.96246)
     | > current_lr: 0.00009 
     | > step_time: 4.39720  (3.73399)
     | > loader_time: 0.06000  (0.02999)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 275175[0m
     | > decoder_loss: 1.88489  (1.87629)
     | > postnet_loss: 1.57684  (1.55674)
     | > stopnet_loss: 1.33856  (1.62519)
     | > decoder_coarse_loss: 1.79891  (1.80756)
     | > decoder_ddc_loss: 0.00109  (0.00119)
     | > ga_loss: 0.00207  (0.00227)
     | > decoder_diff_spec_loss: 0.51030  (0.49526)
     | > postnet_diff_spec_loss: 0.83057  (0.80982)
     | > decoder_ssim_loss: 0.34706  (0.31491)
     | > postnet_ssim_loss: 0.35528  (0.32804)
     | > loss: 3.17514  (3.43399)
     | > align_error: 0.98954  (0.98930)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.73592  (3.91823)
     | > current_lr: 0.00009 
     | > step_time: 3.79460  (3.73943)
     | > loader_time: 0.05340  (0.02995)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.48802 [0m(+0.00924)
     | > avg_decoder_loss:[92m 2.45760 [0m(-0.08805)
     | > avg_postnet_loss:[92m 2.27055 [0m(-0.10019)
     | > avg_stopnet_loss:[91m 1.54196 [0m(+0.00404)
     | > avg_decoder_coarse_loss:[92m 2.29409 [0m(-0.05653)
     | > avg_decoder_ddc_loss:[92m 0.00097 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00248 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.50961 [0m(-0.00032)
     | > avg_postnet_diff_spec_loss:[92m 0.83388 [0m(-0.00242)
     | > avg_decoder_ssim_loss:[92m 0.30516 [0m(-0.00082)
     | > avg_postnet_ssim_loss:[92m 0.32360 [0m(-0.00279)
     | > avg_loss:[92m 3.80324 [0m(-0.05875)
     | > avg_align_error:[92m 0.99122 [0m(-0.00000)


[4m[1m > EPOCH: 59/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:03:54) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 275200[0m
     | > decoder_loss: 1.86860  (1.82042)
     | > postnet_loss: 1.62198  (1.50975)
     | > stopnet_loss: 1.60778  (1.50897)
     | > decoder_coarse_loss: 1.77879  (1.75171)
     | > decoder_ddc_loss: 0.00133  (0.00105)
     | > ga_loss: 0.00272  (0.00212)
     | > decoder_diff_spec_loss: 0.51060  (0.48899)
     | > postnet_diff_spec_loss: 0.82580  (0.80390)
     | > decoder_ssim_loss: 0.32253  (0.31671)
     | > postnet_ssim_loss: 0.33796  (0.33054)
     | > loss: 3.43827  (3.27535)
     | > align_error: 0.98768  (0.99030)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 7.75717  (2.89036)
     | > current_lr: 0.00009 
     | > step_time: 1.87040  (4.19865)
     | > loader_time: 0.02040  (0.04435)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 275225[0m
     | > decoder_loss: 1.83349  (1.85896)
     | > postnet_loss: 1.59136  (1.53707)
     | > stopnet_loss: 1.13795  (1.55856)
     | > decoder_coarse_loss: 1.74238  (1.78801)
     | > decoder_ddc_loss: 0.00166  (0.00119)
     | > ga_loss: 0.00267  (0.00230)
     | > decoder_diff_spec_loss: 0.49470  (0.49306)
     | > postnet_diff_spec_loss: 0.82371  (0.80711)
     | > decoder_ssim_loss: 0.41276  (0.31857)
     | > postnet_ssim_loss: 0.43011  (0.33177)
     | > loss: 2.98386  (3.35398)
     | > align_error: 0.98588  (0.98940)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.55604  (3.59079)
     | > current_lr: 0.00009 
     | > step_time: 3.07350  (3.68629)
     | > loader_time: 0.02150  (0.03235)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 275250[0m
     | > decoder_loss: 1.90759  (1.86981)
     | > postnet_loss: 1.45614  (1.54791)
     | > stopnet_loss: 1.63469  (1.62300)
     | > decoder_coarse_loss: 1.73954  (1.79428)
     | > decoder_ddc_loss: 0.00129  (0.00116)
     | > ga_loss: 0.00270  (0.00227)
     | > decoder_diff_spec_loss: 0.49754  (0.49430)
     | > postnet_diff_spec_loss: 0.78573  (0.80890)
     | > decoder_ssim_loss: 0.31457  (0.31084)
     | > postnet_ssim_loss: 0.33217  (0.32394)
     | > loss: 3.40682  (3.42216)
     | > align_error: 0.98840  (0.98947)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.27174  (4.02082)
     | > current_lr: 0.00009 
     | > step_time: 3.09910  (3.73151)
     | > loader_time: 0.01760  (0.03303)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 275275[0m
     | > decoder_loss: 1.88558  (1.87222)
     | > postnet_loss: 1.44650  (1.55106)
     | > stopnet_loss: 1.36937  (1.61929)
     | > decoder_coarse_loss: 1.78936  (1.79940)
     | > decoder_ddc_loss: 0.00125  (0.00118)
     | > ga_loss: 0.00263  (0.00230)
     | > decoder_diff_spec_loss: 0.50671  (0.49460)
     | > postnet_diff_spec_loss: 0.80223  (0.80953)
     | > decoder_ssim_loss: 0.36646  (0.31312)
     | > postnet_ssim_loss: 0.37921  (0.32665)
     | > loss: 3.17686  (3.42271)
     | > align_error: 0.98889  (0.98933)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.88225  (4.18681)
     | > current_lr: 0.00009 
     | > step_time: 1.88900  (3.64373)
     | > loader_time: 0.01440  (0.03060)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.29640 [0m(-0.19161)
     | > avg_decoder_loss:[91m 2.47986 [0m(+0.02226)
     | > avg_postnet_loss:[91m 2.32534 [0m(+0.05479)
     | > avg_stopnet_loss:[92m 1.54167 [0m(-0.00029)
     | > avg_decoder_coarse_loss:[91m 2.31915 [0m(+0.02506)
     | > avg_decoder_ddc_loss:[91m 0.00099 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00248 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50918 [0m(-0.00043)
     | > avg_postnet_diff_spec_loss:[91m 0.83645 [0m(+0.00256)
     | > avg_decoder_ssim_loss:[92m 0.30467 [0m(-0.00049)
     | > avg_postnet_ssim_loss:[91m 0.32526 [0m(+0.00166)
     | > avg_loss:[91m 3.82928 [0m(+0.02603)
     | > avg_align_error:[92m 0.99104 [0m(-0.00018)


[4m[1m > EPOCH: 60/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:11:01) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 275300[0m
     | > decoder_loss: 1.85413  (1.83094)
     | > postnet_loss: 1.58838  (1.51680)
     | > stopnet_loss: 1.98163  (1.56457)
     | > decoder_coarse_loss: 1.73762  (1.76144)
     | > decoder_ddc_loss: 0.00135  (0.00119)
     | > ga_loss: 0.00268  (0.00232)
     | > decoder_diff_spec_loss: 0.48432  (0.48794)
     | > postnet_diff_spec_loss: 0.81365  (0.80483)
     | > decoder_ssim_loss: 0.26382  (0.32014)
     | > postnet_ssim_loss: 0.27797  (0.33420)
     | > loss: 3.75032  (3.34053)
     | > align_error: 0.98789  (0.98940)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.13795  (3.48458)
     | > current_lr: 0.00009 
     | > step_time: 3.05250  (3.68776)
     | > loader_time: 0.02110  (0.04474)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 275325[0m
     | > decoder_loss: 1.79081  (1.85398)
     | > postnet_loss: 1.55359  (1.53536)
     | > stopnet_loss: 1.28780  (1.59568)
     | > decoder_coarse_loss: 1.69293  (1.78416)
     | > decoder_ddc_loss: 0.00089  (0.00119)
     | > ga_loss: 0.00183  (0.00228)
     | > decoder_diff_spec_loss: 0.46264  (0.49215)
     | > postnet_diff_spec_loss: 0.79691  (0.80773)
     | > decoder_ssim_loss: 0.34471  (0.31539)
     | > postnet_ssim_loss: 0.36436  (0.32914)
     | > loss: 3.04865  (3.38685)
     | > align_error: 0.99209  (0.98934)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.83620  (3.88918)
     | > current_lr: 0.00009 
     | > step_time: 4.94460  (3.62331)
     | > loader_time: 0.02250  (0.03599)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 275350[0m
     | > decoder_loss: 1.89743  (1.86959)
     | > postnet_loss: 1.51343  (1.54794)
     | > stopnet_loss: 1.12942  (1.62079)
     | > decoder_coarse_loss: 1.83331  (1.79472)
     | > decoder_ddc_loss: 0.00160  (0.00119)
     | > ga_loss: 0.00239  (0.00226)
     | > decoder_diff_spec_loss: 0.49759  (0.49411)
     | > postnet_diff_spec_loss: 0.81142  (0.80935)
     | > decoder_ssim_loss: 0.38663  (0.31366)
     | > postnet_ssim_loss: 0.40805  (0.32747)
     | > loss: 2.97874  (3.42162)
     | > align_error: 0.98613  (0.98929)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.70589  (3.80796)
     | > current_lr: 0.00009 
     | > step_time: 2.44650  (3.67817)
     | > loader_time: 0.02920  (0.03550)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.82874 [0m(+0.53234)
     | > avg_decoder_loss:[91m 2.49090 [0m(+0.01103)
     | > avg_postnet_loss:[92m 2.22286 [0m(-0.10248)
     | > avg_stopnet_loss:[91m 1.54181 [0m(+0.00014)
     | > avg_decoder_coarse_loss:[91m 2.34888 [0m(+0.02973)
     | > avg_decoder_ddc_loss:[92m 0.00098 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00246 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50811 [0m(-0.00107)
     | > avg_postnet_diff_spec_loss:[92m 0.83408 [0m(-0.00237)
     | > avg_decoder_ssim_loss:[92m 0.30440 [0m(-0.00027)
     | > avg_postnet_ssim_loss:[92m 0.32386 [0m(-0.00140)
     | > avg_loss:[92m 3.81264 [0m(-0.01664)
     | > avg_align_error:[91m 0.99109 [0m(+0.00005)


[4m[1m > EPOCH: 61/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:18:12) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 275375[0m
     | > decoder_loss: 1.98976  (1.80354)
     | > postnet_loss: 1.59413  (1.48414)
     | > stopnet_loss: 1.24160  (1.54081)
     | > decoder_coarse_loss: 1.91295  (1.74223)
     | > decoder_ddc_loss: 0.00122  (0.00102)
     | > ga_loss: 0.00171  (0.00202)
     | > decoder_diff_spec_loss: 0.54594  (0.48693)
     | > postnet_diff_spec_loss: 0.84357  (0.80117)
     | > decoder_ssim_loss: 0.36138  (0.31445)
     | > postnet_ssim_loss: 0.37115  (0.32908)
     | > loss: 3.15518  (3.29155)
     | > align_error: 0.98942  (0.99060)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.79855  (2.26045)
     | > current_lr: 0.00009 
     | > step_time: 4.29030  (4.75411)
     | > loader_time: 0.06520  (0.04489)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 275400[0m
     | > decoder_loss: 1.78846  (1.84286)
     | > postnet_loss: 1.47095  (1.51342)
     | > stopnet_loss: 2.02287  (1.60002)
     | > decoder_coarse_loss: 1.74569  (1.77948)
     | > decoder_ddc_loss: 0.00089  (0.00120)
     | > ga_loss: 0.00211  (0.00226)
     | > decoder_diff_spec_loss: 0.47985  (0.49236)
     | > postnet_diff_spec_loss: 0.78885  (0.80662)
     | > decoder_ssim_loss: 0.25209  (0.31449)
     | > postnet_ssim_loss: 0.26853  (0.32845)
     | > loss: 3.73225  (3.38104)
     | > align_error: 0.99172  (0.98942)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.48185  (3.51622)
     | > current_lr: 0.00009 
     | > step_time: 3.39740  (3.66681)
     | > loader_time: 0.04660  (0.03332)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 275425[0m
     | > decoder_loss: 1.93860  (1.85205)
     | > postnet_loss: 1.61814  (1.52974)
     | > stopnet_loss: 1.67456  (1.63509)
     | > decoder_coarse_loss: 1.87707  (1.78405)
     | > decoder_ddc_loss: 0.00173  (0.00120)
     | > ga_loss: 0.00255  (0.00224)
     | > decoder_diff_spec_loss: 0.51394  (0.49363)
     | > postnet_diff_spec_loss: 0.81784  (0.80911)
     | > decoder_ssim_loss: 0.29458  (0.30981)
     | > postnet_ssim_loss: 0.30721  (0.32355)
     | > loss: 3.52961  (3.42206)
     | > align_error: 0.98483  (0.98937)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.33016  (3.77541)
     | > current_lr: 0.00009 
     | > step_time: 3.81850  (3.75484)
     | > loader_time: 0.04350  (0.03405)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 275450[0m
     | > decoder_loss: 1.87275  (1.85624)
     | > postnet_loss: 1.57418  (1.52987)
     | > stopnet_loss: 1.25906  (1.62912)
     | > decoder_coarse_loss: 1.81911  (1.78848)
     | > decoder_ddc_loss: 0.00070  (0.00122)
     | > ga_loss: 0.00175  (0.00226)
     | > decoder_diff_spec_loss: 0.48696  (0.49344)
     | > postnet_diff_spec_loss: 0.81057  (0.80926)
     | > decoder_ssim_loss: 0.35502  (0.31143)
     | > postnet_ssim_loss: 0.37254  (0.32545)
     | > loss: 3.09078  (3.41924)
     | > align_error: 0.99397  (0.98919)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.38702  (3.87228)
     | > current_lr: 0.00009 
     | > step_time: 2.81090  (3.65111)
     | > loader_time: 0.01360  (0.03008)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.54084 [0m(-0.28790)
     | > avg_decoder_loss:[91m 2.51732 [0m(+0.02643)
     | > avg_postnet_loss:[91m 2.50732 [0m(+0.28446)
     | > avg_stopnet_loss:[91m 1.54195 [0m(+0.00015)
     | > avg_decoder_coarse_loss:[91m 2.35990 [0m(+0.01102)
     | > avg_decoder_ddc_loss:[91m 0.00099 [0m(+0.00001)
     | > avg_ga_loss:[91m 0.00246 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.50892 [0m(+0.00081)
     | > avg_postnet_diff_spec_loss:[91m 0.83642 [0m(+0.00234)
     | > avg_decoder_ssim_loss:[92m 0.30402 [0m(-0.00038)
     | > avg_postnet_ssim_loss:[91m 0.32660 [0m(+0.00274)
     | > avg_loss:[91m 3.89465 [0m(+0.08201)
     | > avg_align_error:[92m 0.99108 [0m(-0.00001)


[4m[1m > EPOCH: 62/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:25:19) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 275475[0m
     | > decoder_loss: 1.87298  (1.81807)
     | > postnet_loss: 1.49852  (1.49756)
     | > stopnet_loss: 1.31783  (1.51943)
     | > decoder_coarse_loss: 1.76734  (1.75366)
     | > decoder_ddc_loss: 0.00109  (0.00121)
     | > ga_loss: 0.00215  (0.00228)
     | > decoder_diff_spec_loss: 0.51346  (0.48841)
     | > postnet_diff_spec_loss: 0.81119  (0.80412)
     | > decoder_ssim_loss: 0.34482  (0.32204)
     | > postnet_ssim_loss: 0.35731  (0.33668)
     | > loss: 3.12027  (3.28624)
     | > align_error: 0.99006  (0.98942)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.08723  (3.19743)
     | > current_lr: 0.00009 
     | > step_time: 3.08900  (3.74162)
     | > loader_time: 0.02550  (0.04558)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 275500[0m
     | > decoder_loss: 1.69223  (1.84114)
     | > postnet_loss: 1.39155  (1.51397)
     | > stopnet_loss: 2.18385  (1.58607)
     | > decoder_coarse_loss: 1.65439  (1.77377)
     | > decoder_ddc_loss: 0.00078  (0.00122)
     | > ga_loss: 0.00194  (0.00227)
     | > decoder_diff_spec_loss: 0.46965  (0.49238)
     | > postnet_diff_spec_loss: 0.79128  (0.80767)
     | > decoder_ssim_loss: 0.23322  (0.31382)
     | > postnet_ssim_loss: 0.24522  (0.32773)
     | > loss: 3.81312  (3.36535)
     | > align_error: 0.99232  (0.98923)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.92705  (3.78405)
     | > current_lr: 0.00009 
     | > step_time: 4.80220  (3.69016)
     | > loader_time: 0.02540  (0.03767)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 275525[0m
     | > decoder_loss: 1.96491  (1.84856)
     | > postnet_loss: 1.52904  (1.51988)
     | > stopnet_loss: 1.95628  (1.61701)
     | > decoder_coarse_loss: 1.89600  (1.78320)
     | > decoder_ddc_loss: 0.00075  (0.00120)
     | > ga_loss: 0.00185  (0.00224)
     | > decoder_diff_spec_loss: 0.52569  (0.49355)
     | > postnet_diff_spec_loss: 0.82686  (0.80873)
     | > decoder_ssim_loss: 0.25657  (0.31155)
     | > postnet_ssim_loss: 0.25911  (0.32555)
     | > loss: 3.78028  (3.40129)
     | > align_error: 0.99270  (0.98927)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.72343  (3.88649)
     | > current_lr: 0.00009 
     | > step_time: 4.80340  (3.71972)
     | > loader_time: 0.03280  (0.03516)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.41360 [0m(-0.12724)
     | > avg_decoder_loss:[92m 2.46736 [0m(-0.04997)
     | > avg_postnet_loss:[92m 2.24601 [0m(-0.26131)
     | > avg_stopnet_loss:[92m 1.54090 [0m(-0.00106)
     | > avg_decoder_coarse_loss:[92m 2.21446 [0m(-0.14544)
     | > avg_decoder_ddc_loss:[91m 0.00101 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00246 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50735 [0m(-0.00157)
     | > avg_postnet_diff_spec_loss:[92m 0.83373 [0m(-0.00269)
     | > avg_decoder_ssim_loss:[92m 0.30343 [0m(-0.00059)
     | > avg_postnet_ssim_loss:[92m 0.32363 [0m(-0.00297)
     | > avg_loss:[92m 3.77742 [0m(-0.11723)
     | > avg_align_error:[92m 0.99103 [0m(-0.00005)


[4m[1m > EPOCH: 63/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:32:25) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 275550[0m
     | > decoder_loss: 1.57117  (1.76886)
     | > postnet_loss: 1.32131  (1.45266)
     | > stopnet_loss: 1.59341  (1.56101)
     | > decoder_coarse_loss: 1.50052  (1.70357)
     | > decoder_ddc_loss: 0.00078  (0.00099)
     | > ga_loss: 0.00165  (0.00206)
     | > decoder_diff_spec_loss: 0.44170  (0.47508)
     | > postnet_diff_spec_loss: 0.77771  (0.79294)
     | > decoder_ssim_loss: 0.27903  (0.30595)
     | > postnet_ssim_loss: 0.30244  (0.32170)
     | > loss: 3.15033  (3.27675)
     | > align_error: 0.99243  (0.99080)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.11392  (2.55539)
     | > current_lr: 0.00008 
     | > step_time: 4.31800  (4.54533)
     | > loader_time: 0.02080  (0.04928)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 275575[0m
     | > decoder_loss: 1.74569  (1.84099)
     | > postnet_loss: 1.42761  (1.49863)
     | > stopnet_loss: 1.39371  (1.55943)
     | > decoder_coarse_loss: 1.69496  (1.76889)
     | > decoder_ddc_loss: 0.00123  (0.00122)
     | > ga_loss: 0.00235  (0.00226)
     | > decoder_diff_spec_loss: 0.49059  (0.49204)
     | > postnet_diff_spec_loss: 0.78771  (0.80615)
     | > decoder_ssim_loss: 0.35098  (0.31600)
     | > postnet_ssim_loss: 0.36550  (0.32962)
     | > loss: 3.12152  (3.33410)
     | > align_error: 0.98933  (0.98926)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.71592  (3.78297)
     | > current_lr: 0.00008 
     | > step_time: 2.94920  (3.62855)
     | > loader_time: 0.01650  (0.03788)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 275600[0m
     | > decoder_loss: 1.89172  (1.84438)
     | > postnet_loss: 1.57633  (1.51519)
     | > stopnet_loss: 1.12962  (1.62974)
     | > decoder_coarse_loss: 1.79014  (1.77259)
     | > decoder_ddc_loss: 0.00090  (0.00119)
     | > ga_loss: 0.00179  (0.00223)
     | > decoder_diff_spec_loss: 0.50416  (0.49243)
     | > postnet_diff_spec_loss: 0.80393  (0.80795)
     | > decoder_ssim_loss: 0.37633  (0.30930)
     | > postnet_ssim_loss: 0.39435  (0.32311)
     | > loss: 2.97303  (3.40742)
     | > align_error: 0.99196  (0.98941)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.68440  (4.17494)
     | > current_lr: 0.00008 
     | > step_time: 3.98060  (3.66928)
     | > loader_time: 0.02270  (0.03541)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 275625[0m
     | > decoder_loss: 1.85302  (1.84964)
     | > postnet_loss: 1.59773  (1.51859)
     | > stopnet_loss: 1.62047  (1.62947)
     | > decoder_coarse_loss: 1.80517  (1.77958)
     | > decoder_ddc_loss: 0.00204  (0.00122)
     | > ga_loss: 0.00392  (0.00226)
     | > decoder_diff_spec_loss: 0.48742  (0.49322)
     | > postnet_diff_spec_loss: 0.81498  (0.80831)
     | > decoder_ssim_loss: 0.33107  (0.31024)
     | > postnet_ssim_loss: 0.35176  (0.32417)
     | > loss: 3.45087  (3.41202)
     | > align_error: 0.98201  (0.98913)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 10.43487  (4.21130)
     | > current_lr: 0.00008 
     | > step_time: 1.22460  (3.61503)
     | > loader_time: 0.01500  (0.03213)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.68678 [0m(+0.27318)
     | > avg_decoder_loss:[91m 2.49010 [0m(+0.02274)
     | > avg_postnet_loss:[91m 2.38741 [0m(+0.14140)
     | > avg_stopnet_loss:[92m 1.54078 [0m(-0.00012)
     | > avg_decoder_coarse_loss:[91m 2.31595 [0m(+0.10149)
     | > avg_decoder_ddc_loss:[92m 0.00099 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00246 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50623 [0m(-0.00112)
     | > avg_postnet_diff_spec_loss:[91m 0.83528 [0m(+0.00155)
     | > avg_decoder_ssim_loss:[92m 0.30333 [0m(-0.00010)
     | > avg_postnet_ssim_loss:[91m 0.32559 [0m(+0.00196)
     | > avg_loss:[91m 3.84432 [0m(+0.06690)
     | > avg_align_error:[91m 0.99123 [0m(+0.00020)


[4m[1m > EPOCH: 64/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:39:37) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 275650[0m
     | > decoder_loss: 1.98990  (1.80694)
     | > postnet_loss: 1.54556  (1.47994)
     | > stopnet_loss: 1.83407  (1.52850)
     | > decoder_coarse_loss: 1.90004  (1.74475)
     | > decoder_ddc_loss: 0.00115  (0.00126)
     | > ga_loss: 0.00228  (0.00226)
     | > decoder_diff_spec_loss: 0.51824  (0.48609)
     | > postnet_diff_spec_loss: 0.82922  (0.80251)
     | > decoder_ssim_loss: 0.28551  (0.32014)
     | > postnet_ssim_loss: 0.29912  (0.33490)
     | > loss: 3.68767  (3.28392)
     | > align_error: 0.98986  (0.98919)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.92815  (3.14429)
     | > current_lr: 0.00008 
     | > step_time: 2.84590  (3.70737)
     | > loader_time: 0.06010  (0.03876)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 275675[0m
     | > decoder_loss: 1.93490  (1.83870)
     | > postnet_loss: 1.55973  (1.49866)
     | > stopnet_loss: 1.17825  (1.57285)
     | > decoder_coarse_loss: 1.80548  (1.77063)
     | > decoder_ddc_loss: 0.00177  (0.00124)
     | > ga_loss: 0.00263  (0.00226)
     | > decoder_diff_spec_loss: 0.49454  (0.49287)
     | > postnet_diff_spec_loss: 0.80559  (0.80693)
     | > decoder_ssim_loss: 0.38632  (0.31503)
     | > postnet_ssim_loss: 0.40926  (0.32896)
     | > loss: 3.04080  (3.34743)
     | > align_error: 0.98496  (0.98903)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.29210  (3.45194)
     | > current_lr: 0.00008 
     | > step_time: 2.99340  (3.64223)
     | > loader_time: 0.02020  (0.03788)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 275700[0m
     | > decoder_loss: 2.16175  (1.84089)
     | > postnet_loss: 1.74153  (1.50447)
     | > stopnet_loss: 1.67407  (1.60431)
     | > decoder_coarse_loss: 2.00983  (1.77160)
     | > decoder_ddc_loss: 0.00144  (0.00123)
     | > ga_loss: 0.00233  (0.00224)
     | > decoder_diff_spec_loss: 0.53357  (0.49273)
     | > postnet_diff_spec_loss: 0.83864  (0.80768)
     | > decoder_ssim_loss: 0.28942  (0.31171)
     | > postnet_ssim_loss: 0.30483  (0.32593)
     | > loss: 3.65599  (3.37958)
     | > align_error: 0.98709  (0.98909)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.56409  (3.57190)
     | > current_lr: 0.00008 
     | > step_time: 3.28530  (3.69953)
     | > loader_time: 0.02020  (0.03434)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.63599 [0m(-0.05079)
     | > avg_decoder_loss:[92m 2.48690 [0m(-0.00320)
     | > avg_postnet_loss:[91m 2.44571 [0m(+0.05830)
     | > avg_stopnet_loss:[91m 1.54254 [0m(+0.00176)
     | > avg_decoder_coarse_loss:[91m 2.36271 [0m(+0.04676)
     | > avg_decoder_ddc_loss:[91m 0.00102 [0m(+0.00003)
     | > avg_ga_loss:[92m 0.00245 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.50753 [0m(+0.00130)
     | > avg_postnet_diff_spec_loss:[92m 0.83452 [0m(-0.00077)
     | > avg_decoder_ssim_loss:[92m 0.30276 [0m(-0.00058)
     | > avg_postnet_ssim_loss:[92m 0.32520 [0m(-0.00038)
     | > avg_loss:[91m 3.87139 [0m(+0.02707)
     | > avg_align_error:[92m 0.99099 [0m(-0.00024)


[4m[1m > EPOCH: 65/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:46:41) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 275725[0m
     | > decoder_loss: 1.86789  (1.80799)
     | > postnet_loss: 1.51357  (1.47059)
     | > stopnet_loss: 1.45513  (1.55356)
     | > decoder_coarse_loss: 1.76846  (1.73055)
     | > decoder_ddc_loss: 0.00082  (0.00110)
     | > ga_loss: 0.00187  (0.00212)
     | > decoder_diff_spec_loss: 0.49533  (0.48181)
     | > postnet_diff_spec_loss: 0.80642  (0.79545)
     | > decoder_ssim_loss: 0.32106  (0.31072)
     | > postnet_ssim_loss: 0.33689  (0.32516)
     | > loss: 3.24210  (3.29499)
     | > align_error: 0.99229  (0.99034)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.62507  (2.11363)
     | > current_lr: 0.00008 
     | > step_time: 4.52470  (4.73413)
     | > loader_time: 0.06060  (0.04502)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 275750[0m
     | > decoder_loss: 2.01513  (1.83007)
     | > postnet_loss: 1.55752  (1.48688)
     | > stopnet_loss: 1.81521  (1.56771)
     | > decoder_coarse_loss: 1.93387  (1.76424)
     | > decoder_ddc_loss: 0.00119  (0.00121)
     | > ga_loss: 0.00223  (0.00225)
     | > decoder_diff_spec_loss: 0.53279  (0.49234)
     | > postnet_diff_spec_loss: 0.83816  (0.80598)
     | > decoder_ssim_loss: 0.27812  (0.31419)
     | > postnet_ssim_loss: 0.28559  (0.32787)
     | > loss: 3.68697  (3.33467)
     | > align_error: 0.98907  (0.98933)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.90675  (3.77125)
     | > current_lr: 0.00008 
     | > step_time: 3.02880  (3.75044)
     | > loader_time: 0.01790  (0.03111)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 275775[0m
     | > decoder_loss: 1.67930  (1.83198)
     | > postnet_loss: 1.44573  (1.49600)
     | > stopnet_loss: 1.19221  (1.63440)
     | > decoder_coarse_loss: 1.59871  (1.76199)
     | > decoder_ddc_loss: 0.00150  (0.00119)
     | > ga_loss: 0.00253  (0.00223)
     | > decoder_diff_spec_loss: 0.43828  (0.49223)
     | > postnet_diff_spec_loss: 0.78948  (0.80747)
     | > decoder_ssim_loss: 0.38223  (0.30751)
     | > postnet_ssim_loss: 0.40721  (0.32125)
     | > loss: 2.89046  (3.40047)
     | > align_error: 0.98747  (0.98940)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.06363  (4.06895)
     | > current_lr: 0.00008 
     | > step_time: 2.44770  (3.73802)
     | > loader_time: 0.01880  (0.03241)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 275800[0m
     | > decoder_loss: 1.74668  (1.83962)
     | > postnet_loss: 1.39670  (1.50143)
     | > stopnet_loss: 1.53767  (1.62761)
     | > decoder_coarse_loss: 1.70638  (1.76749)
     | > decoder_ddc_loss: 0.00116  (0.00120)
     | > ga_loss: 0.00204  (0.00224)
     | > decoder_diff_spec_loss: 0.45624  (0.49298)
     | > postnet_diff_spec_loss: 0.77436  (0.80768)
     | > decoder_ssim_loss: 0.30693  (0.30941)
     | > postnet_ssim_loss: 0.32435  (0.32341)
     | > loss: 3.22606  (3.39960)
     | > align_error: 0.98917  (0.98922)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.31664  (4.08004)
     | > current_lr: 0.00008 
     | > step_time: 3.03270  (3.68604)
     | > loader_time: 0.02410  (0.03264)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.71514 [0m(+0.07915)
     | > avg_decoder_loss:[91m 2.52736 [0m(+0.04047)
     | > avg_postnet_loss:[92m 2.29699 [0m(-0.14872)
     | > avg_stopnet_loss:[92m 1.54248 [0m(-0.00005)
     | > avg_decoder_coarse_loss:[92m 2.31699 [0m(-0.04573)
     | > avg_decoder_ddc_loss:[92m 0.00101 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00244 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.50808 [0m(+0.00056)
     | > avg_postnet_diff_spec_loss:[92m 0.83197 [0m(-0.00254)
     | > avg_decoder_ssim_loss:[91m 0.30291 [0m(+0.00015)
     | > avg_postnet_ssim_loss:[92m 0.32199 [0m(-0.00321)
     | > avg_loss:[92m 3.83153 [0m(-0.03985)
     | > avg_align_error:[91m 0.99115 [0m(+0.00016)


[4m[1m > EPOCH: 66/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:53:55) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 275825[0m
     | > decoder_loss: 1.82206  (1.78642)
     | > postnet_loss: 1.41777  (1.45812)
     | > stopnet_loss: 1.72932  (1.51331)
     | > decoder_coarse_loss: 1.72086  (1.72622)
     | > decoder_ddc_loss: 0.00095  (0.00123)
     | > ga_loss: 0.00180  (0.00226)
     | > decoder_diff_spec_loss: 0.46247  (0.48394)
     | > postnet_diff_spec_loss: 0.77481  (0.80044)
     | > decoder_ssim_loss: 0.27165  (0.32160)
     | > postnet_ssim_loss: 0.28641  (0.33629)
     | > loss: 3.42757  (3.25320)
     | > align_error: 0.99164  (0.98921)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.10211  (2.95096)
     | > current_lr: 0.00008 
     | > step_time: 4.71550  (3.82045)
     | > loader_time: 0.01790  (0.04025)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 275850[0m
     | > decoder_loss: 1.76169  (1.82261)
     | > postnet_loss: 1.49648  (1.47867)
     | > stopnet_loss: 1.33595  (1.58919)
     | > decoder_coarse_loss: 1.71967  (1.75959)
     | > decoder_ddc_loss: 0.00141  (0.00122)
     | > ga_loss: 0.00257  (0.00225)
     | > decoder_diff_spec_loss: 0.47969  (0.49162)
     | > postnet_diff_spec_loss: 0.81020  (0.80633)
     | > decoder_ssim_loss: 0.36275  (0.31265)
     | > postnet_ssim_loss: 0.37691  (0.32636)
     | > loss: 3.10098  (3.35023)
     | > align_error: 0.98757  (0.98912)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.55098  (3.51753)
     | > current_lr: 0.00008 
     | > step_time: 3.53310  (3.65437)
     | > loader_time: 0.02050  (0.03338)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 275875[0m
     | > decoder_loss: 1.89392  (1.82200)
     | > postnet_loss: 1.48601  (1.48137)
     | > stopnet_loss: 1.57168  (1.60954)
     | > decoder_coarse_loss: 1.83029  (1.75960)
     | > decoder_ddc_loss: 0.00095  (0.00122)
     | > ga_loss: 0.00190  (0.00223)
     | > decoder_diff_spec_loss: 0.53920  (0.49132)
     | > postnet_diff_spec_loss: 0.83654  (0.80641)
     | > decoder_ssim_loss: 0.29955  (0.31139)
     | > postnet_ssim_loss: 0.30949  (0.32558)
     | > loss: 3.38018  (3.37042)
     | > align_error: 0.99154  (0.98911)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.93823  (3.62936)
     | > current_lr: 0.00008 
     | > step_time: 4.09760  (3.69565)
     | > loader_time: 0.06460  (0.03209)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.76328 [0m(+0.04815)
     | > avg_decoder_loss:[92m 2.47287 [0m(-0.05449)
     | > avg_postnet_loss:[92m 2.29202 [0m(-0.00497)
     | > avg_stopnet_loss:[91m 1.54254 [0m(+0.00005)
     | > avg_decoder_coarse_loss:[91m 2.39271 [0m(+0.07572)
     | > avg_decoder_ddc_loss:[91m 0.00107 [0m(+0.00006)
     | > avg_ga_loss:[92m 0.00243 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50606 [0m(-0.00202)
     | > avg_postnet_diff_spec_loss:[91m 0.83210 [0m(+0.00013)
     | > avg_decoder_ssim_loss:[92m 0.30208 [0m(-0.00083)
     | > avg_postnet_ssim_loss:[91m 0.32222 [0m(+0.00023)
     | > avg_loss:[91m 3.83499 [0m(+0.00345)
     | > avg_align_error:[92m 0.99083 [0m(-0.00032)


[4m[1m > EPOCH: 67/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:01:03) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 275900[0m
     | > decoder_loss: 1.89500  (1.76919)
     | > postnet_loss: 1.52503  (1.44760)
     | > stopnet_loss: 1.26340  (1.56116)
     | > decoder_coarse_loss: 1.79575  (1.71481)
     | > decoder_ddc_loss: 0.00157  (0.00118)
     | > ga_loss: 0.00245  (0.00219)
     | > decoder_diff_spec_loss: 0.49639  (0.47584)
     | > postnet_diff_spec_loss: 0.81116  (0.79299)
     | > decoder_ssim_loss: 0.35527  (0.30733)
     | > postnet_ssim_loss: 0.37300  (0.32205)
     | > loss: 3.08897  (3.27987)
     | > align_error: 0.98683  (0.98981)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.07996  (2.15553)
     | > current_lr: 0.00008 
     | > step_time: 3.10440  (4.65805)
     | > loader_time: 0.02500  (0.05450)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 275925[0m
     | > decoder_loss: 2.19052  (1.81728)
     | > postnet_loss: 1.66525  (1.47129)
     | > stopnet_loss: 1.23111  (1.54904)
     | > decoder_coarse_loss: 2.09802  (1.75192)
     | > decoder_ddc_loss: 0.00118  (0.00128)
     | > ga_loss: 0.00171  (0.00223)
     | > decoder_diff_spec_loss: 0.54873  (0.49046)
     | > postnet_diff_spec_loss: 0.80172  (0.80506)
     | > decoder_ssim_loss: 0.35308  (0.31470)
     | > postnet_ssim_loss: 0.37551  (0.32929)
     | > loss: 3.24818  (3.30553)
     | > align_error: 0.99021  (0.98907)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.57976  (3.49158)
     | > current_lr: 0.00008 
     | > step_time: 3.52280  (3.76757)
     | > loader_time: 0.02220  (0.03069)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 275950[0m
     | > decoder_loss: 1.80524  (1.82616)
     | > postnet_loss: 1.49713  (1.48306)
     | > stopnet_loss: 2.67630  (1.62727)
     | > decoder_coarse_loss: 1.76902  (1.76123)
     | > decoder_ddc_loss: 0.00097  (0.00124)
     | > ga_loss: 0.00238  (0.00221)
     | > decoder_diff_spec_loss: 0.50635  (0.49254)
     | > postnet_diff_spec_loss: 0.81082  (0.80773)
     | > decoder_ssim_loss: 0.19435  (0.30561)
     | > postnet_ssim_loss: 0.19983  (0.31960)
     | > loss: 4.38415  (3.38759)
     | > align_error: 0.99002  (0.98919)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.76258  (3.89056)
     | > current_lr: 0.00008 
     | > step_time: 4.02410  (3.75484)
     | > loader_time: 0.02170  (0.03346)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 275975[0m
     | > decoder_loss: 2.05129  (1.82924)
     | > postnet_loss: 1.60930  (1.48499)
     | > stopnet_loss: 1.14665  (1.61529)
     | > decoder_coarse_loss: 2.01479  (1.76681)
     | > decoder_ddc_loss: 0.00137  (0.00126)
     | > ga_loss: 0.00205  (0.00222)
     | > decoder_diff_spec_loss: 0.53997  (0.49255)
     | > postnet_diff_spec_loss: 0.82641  (0.80793)
     | > decoder_ssim_loss: 0.38972  (0.30880)
     | > postnet_ssim_loss: 0.40776  (0.32318)
     | > loss: 3.11705  (3.38007)
     | > align_error: 0.98787  (0.98899)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.79672  (3.75869)
     | > current_lr: 0.00008 
     | > step_time: 2.76360  (3.71874)
     | > loader_time: 0.01840  (0.03186)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.18824 [0m(-0.57504)
     | > avg_decoder_loss:[92m 2.41546 [0m(-0.05741)
     | > avg_postnet_loss:[91m 2.30653 [0m(+0.01451)
     | > avg_stopnet_loss:[91m 1.54276 [0m(+0.00022)
     | > avg_decoder_coarse_loss:[92m 2.26232 [0m(-0.13039)
     | > avg_decoder_ddc_loss:[92m 0.00102 [0m(-0.00005)
     | > avg_ga_loss:[91m 0.00243 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.50822 [0m(+0.00216)
     | > avg_postnet_diff_spec_loss:[91m 0.83361 [0m(+0.00151)
     | > avg_decoder_ssim_loss:[92m 0.30177 [0m(-0.00031)
     | > avg_postnet_ssim_loss:[91m 0.32388 [0m(+0.00166)
     | > avg_loss:[92m 3.79314 [0m(-0.04185)
     | > avg_align_error:[91m 0.99091 [0m(+0.00008)


[4m[1m > EPOCH: 68/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:08:07) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 276000[0m
     | > decoder_loss: 1.67118  (1.78002)
     | > postnet_loss: 1.36860  (1.45276)
     | > stopnet_loss: 1.15663  (1.47219)
     | > decoder_coarse_loss: 1.59855  (1.72034)
     | > decoder_ddc_loss: 0.00182  (0.00126)
     | > ga_loss: 0.00279  (0.00230)
     | > decoder_diff_spec_loss: 0.45984  (0.48510)
     | > postnet_diff_spec_loss: 0.79589  (0.80138)
     | > decoder_ssim_loss: 0.40388  (0.32402)
     | > postnet_ssim_loss: 0.43176  (0.33898)
     | > loss: 2.85345  (3.20963)
     | > align_error: 0.98650  (0.98907)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.84015  (3.27263)
     | > current_lr: 0.00008 
     | > step_time: 2.35450  (3.80404)
     | > loader_time: 0.01920  (0.03669)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 276025[0m
     | > decoder_loss: 2.03371  (1.81652)
     | > postnet_loss: 1.59119  (1.46457)
     | > stopnet_loss: 1.33653  (1.57450)
     | > decoder_coarse_loss: 1.98762  (1.75374)
     | > decoder_ddc_loss: 0.00158  (0.00124)
     | > ga_loss: 0.00217  (0.00224)
     | > decoder_diff_spec_loss: 0.55270  (0.49251)
     | > postnet_diff_spec_loss: 0.84326  (0.80557)
     | > decoder_ssim_loss: 0.35509  (0.31091)
     | > postnet_ssim_loss: 0.36331  (0.32466)
     | > loss: 3.27952  (3.32813)
     | > align_error: 0.98656  (0.98906)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.71634  (3.89283)
     | > current_lr: 0.00008 
     | > step_time: 4.18270  (3.68190)
     | > loader_time: 0.05410  (0.03989)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 276050[0m
     | > decoder_loss: 1.96852  (1.81416)
     | > postnet_loss: 1.51095  (1.47143)
     | > stopnet_loss: 1.65486  (1.59657)
     | > decoder_coarse_loss: 1.89742  (1.75436)
     | > decoder_ddc_loss: 0.00086  (0.00123)
     | > ga_loss: 0.00197  (0.00223)
     | > decoder_diff_spec_loss: 0.51530  (0.49051)
     | > postnet_diff_spec_loss: 0.81657  (0.80547)
     | > decoder_ssim_loss: 0.28743  (0.31090)
     | > postnet_ssim_loss: 0.29700  (0.32536)
     | > loss: 3.48824  (3.35107)
     | > align_error: 0.99177  (0.98901)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.64147  (4.02562)
     | > current_lr: 0.00008 
     | > step_time: 4.69040  (3.69057)
     | > loader_time: 0.02200  (0.03675)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.49497 [0m(+0.30672)
     | > avg_decoder_loss:[91m 2.43729 [0m(+0.02184)
     | > avg_postnet_loss:[92m 2.19779 [0m(-0.10874)
     | > avg_stopnet_loss:[92m 1.54143 [0m(-0.00133)
     | > avg_decoder_coarse_loss:[91m 2.38808 [0m(+0.12576)
     | > avg_decoder_ddc_loss:[92m 0.00101 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00242 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50693 [0m(-0.00129)
     | > avg_postnet_diff_spec_loss:[92m 0.83242 [0m(-0.00119)
     | > avg_decoder_ssim_loss:[92m 0.30136 [0m(-0.00041)
     | > avg_postnet_ssim_loss:[92m 0.32220 [0m(-0.00168)
     | > avg_loss:[91m 3.80031 [0m(+0.00718)
     | > avg_align_error:[91m 0.99094 [0m(+0.00003)


[4m[1m > EPOCH: 69/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:15:17) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 276075[0m
     | > decoder_loss: 1.72705  (1.72194)
     | > postnet_loss: 1.44887  (1.40358)
     | > stopnet_loss: 1.43752  (1.69438)
     | > decoder_coarse_loss: 1.67184  (1.67963)
     | > decoder_ddc_loss: 0.00113  (0.00098)
     | > ga_loss: 0.00209  (0.00211)
     | > decoder_diff_spec_loss: 0.46373  (0.46816)
     | > postnet_diff_spec_loss: 0.78218  (0.78511)
     | > decoder_ssim_loss: 0.32784  (0.29091)
     | > postnet_ssim_loss: 0.34309  (0.30486)
     | > loss: 3.13941  (3.36874)
     | > align_error: 0.98955  (0.99093)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.07098  (2.17732)
     | > current_lr: 0.00008 
     | > step_time: 4.16680  (5.23054)
     | > loader_time: 0.02800  (0.07953)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 276100[0m
     | > decoder_loss: 1.94802  (1.79111)
     | > postnet_loss: 1.52840  (1.45513)
     | > stopnet_loss: 1.25643  (1.57146)
     | > decoder_coarse_loss: 1.87016  (1.73936)
     | > decoder_ddc_loss: 0.00167  (0.00122)
     | > ga_loss: 0.00255  (0.00225)
     | > decoder_diff_spec_loss: 0.53635  (0.48806)
     | > postnet_diff_spec_loss: 0.82535  (0.80413)
     | > decoder_ssim_loss: 0.37473  (0.31257)
     | > postnet_ssim_loss: 0.38706  (0.32694)
     | > loss: 3.13713  (3.31236)
     | > align_error: 0.98582  (0.98915)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.15778  (3.86560)
     | > current_lr: 0.00008 
     | > step_time: 3.03340  (3.71234)
     | > loader_time: 0.05000  (0.03494)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 276125[0m
     | > decoder_loss: 1.78075  (1.81919)
     | > postnet_loss: 1.39444  (1.47946)
     | > stopnet_loss: 1.83659  (1.61521)
     | > decoder_coarse_loss: 1.70373  (1.75571)
     | > decoder_ddc_loss: 0.00095  (0.00119)
     | > ga_loss: 0.00222  (0.00220)
     | > decoder_diff_spec_loss: 0.48987  (0.49226)
     | > postnet_diff_spec_loss: 0.78989  (0.80679)
     | > decoder_ssim_loss: 0.26310  (0.30700)
     | > postnet_ssim_loss: 0.27526  (0.32114)
     | > loss: 3.52220  (3.37191)
     | > align_error: 0.99059  (0.98928)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.34778  (4.24652)
     | > current_lr: 0.00008 
     | > step_time: 3.51410  (3.71041)
     | > loader_time: 0.02510  (0.03140)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 276150[0m
     | > decoder_loss: 1.61432  (1.81946)
     | > postnet_loss: 1.34193  (1.47970)
     | > stopnet_loss: 1.38853  (1.62424)
     | > decoder_coarse_loss: 1.59490  (1.75456)
     | > decoder_ddc_loss: 0.00105  (0.00120)
     | > ga_loss: 0.00172  (0.00222)
     | > decoder_diff_spec_loss: 0.44674  (0.49179)
     | > postnet_diff_spec_loss: 0.78141  (0.80684)
     | > decoder_ssim_loss: 0.32935  (0.30703)
     | > postnet_ssim_loss: 0.34991  (0.32148)
     | > loss: 3.01205  (3.38085)
     | > align_error: 0.99067  (0.98912)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.91192  (4.05699)
     | > current_lr: 0.00008 
     | > step_time: 3.52500  (3.66562)
     | > loader_time: 0.01950  (0.03232)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.37299 [0m(-0.12197)
     | > avg_decoder_loss:[92m 2.40279 [0m(-0.03451)
     | > avg_postnet_loss:[91m 2.29626 [0m(+0.09847)
     | > avg_stopnet_loss:[91m 1.54230 [0m(+0.00087)
     | > avg_decoder_coarse_loss:[92m 2.26798 [0m(-0.12010)
     | > avg_decoder_ddc_loss:[92m 0.00100 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00242 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.50475 [0m(-0.00219)
     | > avg_postnet_diff_spec_loss:[91m 0.83263 [0m(+0.00020)
     | > avg_decoder_ssim_loss:[92m 0.30106 [0m(-0.00030)
     | > avg_postnet_ssim_loss:[91m 0.32269 [0m(+0.00049)
     | > avg_loss:[92m 3.78668 [0m(-0.01363)
     | > avg_align_error:[92m 0.99093 [0m(-0.00001)


[4m[1m > EPOCH: 70/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:22:21) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 276175[0m
     | > decoder_loss: 1.67217  (1.77336)
     | > postnet_loss: 1.44443  (1.44664)
     | > stopnet_loss: 1.86650  (1.51110)
     | > decoder_coarse_loss: 1.60324  (1.72058)
     | > decoder_ddc_loss: 0.00149  (0.00123)
     | > ga_loss: 0.00231  (0.00223)
     | > decoder_diff_spec_loss: 0.45101  (0.48422)
     | > postnet_diff_spec_loss: 0.79064  (0.80116)
     | > decoder_ssim_loss: 0.25729  (0.31750)
     | > postnet_ssim_loss: 0.27628  (0.33198)
     | > loss: 3.50218  (3.24143)
     | > align_error: 0.98766  (0.98913)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.24509  (3.20284)
     | > current_lr: 0.00008 
     | > step_time: 3.95690  (3.76011)
     | > loader_time: 0.01630  (0.03587)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 276200[0m
     | > decoder_loss: 1.83499  (1.80227)
     | > postnet_loss: 1.47465  (1.45637)
     | > stopnet_loss: 1.40755  (1.58566)
     | > decoder_coarse_loss: 1.78525  (1.74259)
     | > decoder_ddc_loss: 0.00125  (0.00122)
     | > ga_loss: 0.00215  (0.00221)
     | > decoder_diff_spec_loss: 0.50168  (0.49003)
     | > postnet_diff_spec_loss: 0.81561  (0.80419)
     | > decoder_ssim_loss: 0.32734  (0.30895)
     | > postnet_ssim_loss: 0.34388  (0.32336)
     | > loss: 3.18946  (3.32897)
     | > align_error: 0.98868  (0.98904)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.91209  (3.85377)
     | > current_lr: 0.00008 
     | > step_time: 3.31240  (3.67561)
     | > loader_time: 0.01780  (0.04007)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 276225[0m
     | > decoder_loss: 1.82960  (1.80430)
     | > postnet_loss: 1.47441  (1.46316)
     | > stopnet_loss: 1.19122  (1.59918)
     | > decoder_coarse_loss: 1.76557  (1.74451)
     | > decoder_ddc_loss: 0.00143  (0.00124)
     | > ga_loss: 0.00217  (0.00221)
     | > decoder_diff_spec_loss: 0.49665  (0.48931)
     | > postnet_diff_spec_loss: 0.80046  (0.80496)
     | > decoder_ssim_loss: 0.39972  (0.31065)
     | > postnet_ssim_loss: 0.41535  (0.32553)
     | > loss: 2.99789  (3.34614)
     | > align_error: 0.98807  (0.98885)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.16061  (3.99830)
     | > current_lr: 0.00008 
     | > step_time: 3.19550  (3.66676)
     | > loader_time: 0.05300  (0.03900)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.47387 [0m(+0.10088)
     | > avg_decoder_loss:[92m 2.37824 [0m(-0.02455)
     | > avg_postnet_loss:[92m 2.21861 [0m(-0.07764)
     | > avg_stopnet_loss:[92m 1.54185 [0m(-0.00045)
     | > avg_decoder_coarse_loss:[92m 2.25055 [0m(-0.01742)
     | > avg_decoder_ddc_loss:[92m 0.00100 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00241 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.50571 [0m(+0.00097)
     | > avg_postnet_diff_spec_loss:[92m 0.83115 [0m(-0.00148)
     | > avg_decoder_ssim_loss:[92m 0.30056 [0m(-0.00050)
     | > avg_postnet_ssim_loss:[92m 0.32091 [0m(-0.00178)
     | > avg_loss:[92m 3.75561 [0m(-0.03107)
     | > avg_align_error:[91m 0.99097 [0m(+0.00004)


[4m[1m > EPOCH: 71/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:29:25) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 276250[0m
     | > decoder_loss: 1.76111  (1.70148)
     | > postnet_loss: 1.39170  (1.36235)
     | > stopnet_loss: 1.57995  (1.78602)
     | > decoder_coarse_loss: 1.72081  (1.64629)
     | > decoder_ddc_loss: 0.00110  (0.00094)
     | > ga_loss: 0.00217  (0.00211)
     | > decoder_diff_spec_loss: 0.48203  (0.46701)
     | > postnet_diff_spec_loss: 0.78535  (0.78581)
     | > decoder_ssim_loss: 0.29757  (0.27115)
     | > postnet_ssim_loss: 0.31115  (0.28393)
     | > loss: 3.27848  (3.42631)
     | > align_error: 0.99025  (0.99149)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.12920  (2.07014)
     | > current_lr: 0.00008 
     | > step_time: 4.56960  (5.72876)
     | > loader_time: 0.06930  (0.08806)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 276275[0m
     | > decoder_loss: 1.64452  (1.77809)
     | > postnet_loss: 1.32716  (1.43813)
     | > stopnet_loss: 2.00826  (1.56779)
     | > decoder_coarse_loss: 1.59144  (1.71865)
     | > decoder_ddc_loss: 0.00133  (0.00122)
     | > ga_loss: 0.00251  (0.00223)
     | > decoder_diff_spec_loss: 0.44405  (0.48485)
     | > postnet_diff_spec_loss: 0.77026  (0.80261)
     | > decoder_ssim_loss: 0.25383  (0.30965)
     | > postnet_ssim_loss: 0.27192  (0.32421)
     | > loss: 3.59694  (3.29331)
     | > align_error: 0.98843  (0.98919)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.46774  (4.16292)
     | > current_lr: 0.00008 
     | > step_time: 3.28960  (3.76442)
     | > loader_time: 0.04360  (0.03892)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 276300[0m
     | > decoder_loss: 1.68718  (1.81080)
     | > postnet_loss: 1.46628  (1.46188)
     | > stopnet_loss: 1.48698  (1.60136)
     | > decoder_coarse_loss: 1.60735  (1.74765)
     | > decoder_ddc_loss: 0.00098  (0.00122)
     | > ga_loss: 0.00190  (0.00219)
     | > decoder_diff_spec_loss: 0.44371  (0.49137)
     | > postnet_diff_spec_loss: 0.79219  (0.80645)
     | > decoder_ssim_loss: 0.30806  (0.30715)
     | > postnet_ssim_loss: 0.32509  (0.32154)
     | > loss: 3.15421  (3.34932)
     | > align_error: 0.99092  (0.98915)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.88446  (4.36629)
     | > current_lr: 0.00008 
     | > step_time: 3.85300  (3.75594)
     | > loader_time: 0.02390  (0.03411)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 276325[0m
     | > decoder_loss: 2.05836  (1.81405)
     | > postnet_loss: 1.61819  (1.46171)
     | > stopnet_loss: 2.14747  (1.62180)
     | > decoder_coarse_loss: 1.96649  (1.75010)
     | > decoder_ddc_loss: 0.00121  (0.00124)
     | > ga_loss: 0.00273  (0.00221)
     | > decoder_diff_spec_loss: 0.57239  (0.49129)
     | > postnet_diff_spec_loss: 0.87219  (0.80660)
     | > decoder_ssim_loss: 0.24247  (0.30619)
     | > postnet_ssim_loss: 0.25229  (0.32066)
     | > loss: 4.05703  (3.37082)
     | > align_error: 0.98907  (0.98896)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.85313  (4.09171)
     | > current_lr: 0.00008 
     | > step_time: 2.98410  (3.73930)
     | > loader_time: 0.02390  (0.03436)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.60116 [0m(+0.12729)
     | > avg_decoder_loss:[92m 2.35189 [0m(-0.02635)
     | > avg_postnet_loss:[92m 2.11169 [0m(-0.10693)
     | > avg_stopnet_loss:[91m 1.54256 [0m(+0.00071)
     | > avg_decoder_coarse_loss:[92m 2.22752 [0m(-0.02303)
     | > avg_decoder_ddc_loss:[91m 0.00104 [0m(+0.00004)
     | > avg_ga_loss:[92m 0.00239 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.50503 [0m(-0.00068)
     | > avg_postnet_diff_spec_loss:[91m 0.83204 [0m(+0.00089)
     | > avg_decoder_ssim_loss:[92m 0.30004 [0m(-0.00052)
     | > avg_postnet_ssim_loss:[91m 0.32126 [0m(+0.00034)
     | > avg_loss:[92m 3.71714 [0m(-0.03846)
     | > avg_align_error:[92m 0.99064 [0m(-0.00032)


[4m[1m > EPOCH: 72/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:36:30) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 276350[0m
     | > decoder_loss: 1.73986  (1.76949)
     | > postnet_loss: 1.42279  (1.43551)
     | > stopnet_loss: 1.63254  (1.48265)
     | > decoder_coarse_loss: 1.67445  (1.72005)
     | > decoder_ddc_loss: 0.00164  (0.00124)
     | > ga_loss: 0.00319  (0.00222)
     | > decoder_diff_spec_loss: 0.46791  (0.48694)
     | > postnet_diff_spec_loss: 0.79786  (0.80144)
     | > decoder_ssim_loss: 0.30548  (0.32148)
     | > postnet_ssim_loss: 0.31921  (0.33583)
     | > loss: 3.33079  (3.21172)
     | > align_error: 0.98606  (0.98907)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.58469  (3.21634)
     | > current_lr: 0.00008 
     | > step_time: 2.09590  (3.82750)
     | > loader_time: 0.02310  (0.03989)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 276375[0m
     | > decoder_loss: 1.90517  (1.78964)
     | > postnet_loss: 1.53549  (1.43864)
     | > stopnet_loss: 1.43549  (1.58121)
     | > decoder_coarse_loss: 1.87196  (1.73591)
     | > decoder_ddc_loss: 0.00148  (0.00122)
     | > ga_loss: 0.00218  (0.00221)
     | > decoder_diff_spec_loss: 0.50637  (0.48865)
     | > postnet_diff_spec_loss: 0.82044  (0.80324)
     | > decoder_ssim_loss: 0.32806  (0.30814)
     | > postnet_ssim_loss: 0.34182  (0.32231)
     | > loss: 3.27408  (3.31419)
     | > align_error: 0.98830  (0.98900)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.32834  (3.79584)
     | > current_lr: 0.00008 
     | > step_time: 3.87160  (3.67180)
     | > loader_time: 0.07100  (0.03704)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 276400[0m
     | > decoder_loss: 1.66850  (1.78968)
     | > postnet_loss: 1.39155  (1.44672)
     | > stopnet_loss: 1.79984  (1.59944)
     | > decoder_coarse_loss: 1.62007  (1.73445)
     | > decoder_ddc_loss: 0.00144  (0.00125)
     | > ga_loss: 0.00243  (0.00220)
     | > decoder_diff_spec_loss: 0.45988  (0.48819)
     | > postnet_diff_spec_loss: 0.78675  (0.80434)
     | > decoder_ssim_loss: 0.27365  (0.30877)
     | > postnet_ssim_loss: 0.28738  (0.32360)
     | > loss: 3.43430  (3.33468)
     | > align_error: 0.98589  (0.98879)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.53081  (3.80252)
     | > current_lr: 0.00008 
     | > step_time: 4.59300  (3.70866)
     | > loader_time: 0.02070  (0.03475)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.85942 [0m(+0.25826)
     | > avg_decoder_loss:[91m 2.36488 [0m(+0.01300)
     | > avg_postnet_loss:[91m 2.13190 [0m(+0.02021)
     | > avg_stopnet_loss:[92m 1.54179 [0m(-0.00077)
     | > avg_decoder_coarse_loss:[91m 2.25023 [0m(+0.02271)
     | > avg_decoder_ddc_loss:[92m 0.00100 [0m(-0.00004)
     | > avg_ga_loss:[91m 0.00241 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.50590 [0m(+0.00087)
     | > avg_postnet_diff_spec_loss:[92m 0.83122 [0m(-0.00082)
     | > avg_decoder_ssim_loss:[92m 0.29994 [0m(-0.00009)
     | > avg_postnet_ssim_loss:[92m 0.32044 [0m(-0.00082)
     | > avg_loss:[91m 3.73020 [0m(+0.01306)
     | > avg_align_error:[91m 0.99075 [0m(+0.00010)


[4m[1m > EPOCH: 73/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:43:43) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 276425[0m
     | > decoder_loss: 1.64425  (1.64425)
     | > postnet_loss: 1.32655  (1.32655)
     | > stopnet_loss: 1.97191  (1.97191)
     | > decoder_coarse_loss: 1.58703  (1.58703)
     | > decoder_ddc_loss: 0.00080  (0.00080)
     | > ga_loss: 0.00204  (0.00204)
     | > decoder_diff_spec_loss: 0.45733  (0.45733)
     | > postnet_diff_spec_loss: 0.78639  (0.78639)
     | > decoder_ssim_loss: 0.24555  (0.24555)
     | > postnet_ssim_loss: 0.25659  (0.25659)
     | > loss: 3.55824  (3.55824)
     | > align_error: 0.99267  (0.99267)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.85468  (1.85468)
     | > current_lr: 0.00008 
     | > step_time: 6.92600  (6.92596)
     | > loader_time: 0.09770  (0.09768)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 276450[0m
     | > decoder_loss: 1.85159  (1.77595)
     | > postnet_loss: 1.50391  (1.43556)
     | > stopnet_loss: 1.90541  (1.53171)
     | > decoder_coarse_loss: 1.78994  (1.72454)
     | > decoder_ddc_loss: 0.00090  (0.00124)
     | > ga_loss: 0.00196  (0.00219)
     | > decoder_diff_spec_loss: 0.50729  (0.48608)
     | > postnet_diff_spec_loss: 0.81985  (0.80375)
     | > decoder_ssim_loss: 0.25636  (0.31152)
     | > postnet_ssim_loss: 0.26251  (0.32595)
     | > loss: 3.66328  (3.25882)
     | > align_error: 0.99165  (0.98906)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.07888  (3.84873)
     | > current_lr: 0.00008 
     | > step_time: 3.96140  (3.83151)
     | > loader_time: 0.04990  (0.03698)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 276475[0m
     | > decoder_loss: 1.82206  (1.80181)
     | > postnet_loss: 1.46915  (1.44714)
     | > stopnet_loss: 2.13162  (1.58825)
     | > decoder_coarse_loss: 1.71233  (1.74283)
     | > decoder_ddc_loss: 0.00108  (0.00121)
     | > ga_loss: 0.00224  (0.00218)
     | > decoder_diff_spec_loss: 0.48406  (0.49129)
     | > postnet_diff_spec_loss: 0.82350  (0.80627)
     | > decoder_ssim_loss: 0.23814  (0.30671)
     | > postnet_ssim_loss: 0.25023  (0.32107)
     | > loss: 3.84294  (3.32875)
     | > align_error: 0.98969  (0.98906)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.97093  (3.84226)
     | > current_lr: 0.00008 
     | > step_time: 4.23290  (3.76613)
     | > loader_time: 0.03940  (0.03597)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 276500[0m
     | > decoder_loss: 1.78734  (1.79910)
     | > postnet_loss: 1.54421  (1.44739)
     | > stopnet_loss: 2.32737  (1.60238)
     | > decoder_coarse_loss: 1.71915  (1.74033)
     | > decoder_ddc_loss: 0.00073  (0.00122)
     | > ga_loss: 0.00206  (0.00220)
     | > decoder_diff_spec_loss: 0.47259  (0.48897)
     | > postnet_diff_spec_loss: 0.81156  (0.80521)
     | > decoder_ssim_loss: 0.22046  (0.30651)
     | > postnet_ssim_loss: 0.23215  (0.32118)
     | > loss: 4.03471  (3.34085)
     | > align_error: 0.99211  (0.98893)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.83143  (3.71015)
     | > current_lr: 0.00008 
     | > step_time: 3.89110  (3.76123)
     | > loader_time: 0.01890  (0.03436)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.65672 [0m(-0.20270)
     | > avg_decoder_loss:[91m 2.36509 [0m(+0.00021)
     | > avg_postnet_loss:[91m 2.17692 [0m(+0.04502)
     | > avg_stopnet_loss:[91m 1.54282 [0m(+0.00103)
     | > avg_decoder_coarse_loss:[92m 2.17726 [0m(-0.07297)
     | > avg_decoder_ddc_loss:[92m 0.00100 [0m(-0.00000)
     | > avg_ga_loss:[91m 0.00241 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.50422 [0m(-0.00167)
     | > avg_postnet_diff_spec_loss:[91m 0.83220 [0m(+0.00098)
     | > avg_decoder_ssim_loss:[92m 0.29973 [0m(-0.00022)
     | > avg_postnet_ssim_loss:[91m 0.32195 [0m(+0.00152)
     | > avg_loss:[92m 3.72445 [0m(-0.00575)
     | > avg_align_error:[91m 0.99078 [0m(+0.00004)


[4m[1m > EPOCH: 74/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:50:49) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 276525[0m
     | > decoder_loss: 1.79685  (1.77291)
     | > postnet_loss: 1.38903  (1.42884)
     | > stopnet_loss: 1.63699  (1.47991)
     | > decoder_coarse_loss: 1.70775  (1.71135)
     | > decoder_ddc_loss: 0.00125  (0.00118)
     | > ga_loss: 0.00240  (0.00214)
     | > decoder_diff_spec_loss: 0.52131  (0.48818)
     | > postnet_diff_spec_loss: 0.81419  (0.80141)
     | > decoder_ssim_loss: 0.30045  (0.32240)
     | > postnet_ssim_loss: 0.30635  (0.33673)
     | > loss: 3.35832  (3.20638)
     | > align_error: 0.98851  (0.98939)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.74513  (2.93620)
     | > current_lr: 0.00008 
     | > step_time: 3.19630  (3.82746)
     | > loader_time: 0.02100  (0.03870)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 276550[0m
     | > decoder_loss: 1.71988  (1.78435)
     | > postnet_loss: 1.37313  (1.43072)
     | > stopnet_loss: 2.02261  (1.58781)
     | > decoder_coarse_loss: 1.66269  (1.72075)
     | > decoder_ddc_loss: 0.00107  (0.00120)
     | > ga_loss: 0.00206  (0.00220)
     | > decoder_diff_spec_loss: 0.47364  (0.48853)
     | > postnet_diff_spec_loss: 0.79516  (0.80253)
     | > decoder_ssim_loss: 0.24312  (0.30708)
     | > postnet_ssim_loss: 0.25373  (0.32152)
     | > loss: 3.66353  (3.31299)
     | > align_error: 0.98885  (0.98900)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.06736  (3.78871)
     | > current_lr: 0.00008 
     | > step_time: 4.49620  (3.57867)
     | > loader_time: 0.02060  (0.03510)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 276575[0m
     | > decoder_loss: 1.67457  (1.78905)
     | > postnet_loss: 1.45421  (1.43936)
     | > stopnet_loss: 1.20469  (1.60059)
     | > decoder_coarse_loss: 1.63545  (1.72677)
     | > decoder_ddc_loss: 0.00118  (0.00124)
     | > ga_loss: 0.00200  (0.00219)
     | > decoder_diff_spec_loss: 0.45646  (0.48885)
     | > postnet_diff_spec_loss: 0.81074  (0.80408)
     | > decoder_ssim_loss: 0.37158  (0.30875)
     | > postnet_ssim_loss: 0.39914  (0.32373)
     | > loss: 2.91551  (3.33198)
     | > align_error: 0.98943  (0.98880)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.85803  (3.78139)
     | > current_lr: 0.00008 
     | > step_time: 3.26120  (3.62176)
     | > loader_time: 0.03360  (0.03324)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.75176 [0m(+0.09504)
     | > avg_decoder_loss:[92m 2.36009 [0m(-0.00500)
     | > avg_postnet_loss:[92m 2.14869 [0m(-0.02824)
     | > avg_stopnet_loss:[92m 1.54022 [0m(-0.00260)
     | > avg_decoder_coarse_loss:[91m 2.19321 [0m(+0.01595)
     | > avg_decoder_ddc_loss:[91m 0.00101 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00240 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50309 [0m(-0.00114)
     | > avg_postnet_diff_spec_loss:[92m 0.83053 [0m(-0.00168)
     | > avg_decoder_ssim_loss:[92m 0.29941 [0m(-0.00032)
     | > avg_postnet_ssim_loss:[92m 0.32015 [0m(-0.00180)
     | > avg_loss:[92m 3.71626 [0m(-0.00819)
     | > avg_align_error:[91m 0.99081 [0m(+0.00003)


[4m[1m > EPOCH: 75/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:57:55) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 276600[0m
     | > decoder_loss: 1.56248  (1.56248)
     | > postnet_loss: 1.30524  (1.30524)
     | > stopnet_loss: 1.03510  (1.03510)
     | > decoder_coarse_loss: 1.52917  (1.52917)
     | > decoder_ddc_loss: 0.00134  (0.00134)
     | > ga_loss: 0.00190  (0.00190)
     | > decoder_diff_spec_loss: 0.45222  (0.45222)
     | > postnet_diff_spec_loss: 0.77353  (0.77353)
     | > decoder_ssim_loss: 0.41949  (0.41949)
     | > postnet_ssim_loss: 0.44795  (0.44795)
     | > loss: 2.66745  (2.66745)
     | > align_error: 0.98928  (0.98928)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.06418  (4.06418)
     | > current_lr: 0.00008 
     | > step_time: 4.06620  (4.06619)
     | > loader_time: 10.72370  (10.72369)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 276625[0m
     | > decoder_loss: 1.67257  (1.77207)
     | > postnet_loss: 1.34192  (1.42340)
     | > stopnet_loss: 1.45996  (1.53623)
     | > decoder_coarse_loss: 1.60964  (1.71330)
     | > decoder_ddc_loss: 0.00141  (0.00125)
     | > ga_loss: 0.00204  (0.00219)
     | > decoder_diff_spec_loss: 0.46505  (0.48478)
     | > postnet_diff_spec_loss: 0.78592  (0.80187)
     | > decoder_ssim_loss: 0.31799  (0.31323)
     | > postnet_ssim_loss: 0.33336  (0.32780)
     | > loss: 3.10215  (3.25658)
     | > align_error: 0.98788  (0.98891)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.47949  (4.13231)
     | > current_lr: 0.00008 
     | > step_time: 3.54230  (3.65557)
     | > loader_time: 0.01640  (0.03479)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 276650[0m
     | > decoder_loss: 1.90573  (1.79810)
     | > postnet_loss: 1.60776  (1.43904)
     | > stopnet_loss: 2.05865  (1.58781)
     | > decoder_coarse_loss: 1.80312  (1.73422)
     | > decoder_ddc_loss: 0.00098  (0.00123)
     | > ga_loss: 0.00176  (0.00216)
     | > decoder_diff_spec_loss: 0.51375  (0.49144)
     | > postnet_diff_spec_loss: 0.83317  (0.80515)
     | > decoder_ssim_loss: 0.23632  (0.30753)
     | > postnet_ssim_loss: 0.24908  (0.32187)
     | > loss: 3.85495  (3.32323)
     | > align_error: 0.99053  (0.98892)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.53987  (4.09708)
     | > current_lr: 0.00008 
     | > step_time: 3.84370  (3.61869)
     | > loader_time: 0.02100  (0.03622)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 276675[0m
     | > decoder_loss: 1.75499  (1.79556)
     | > postnet_loss: 1.44502  (1.43857)
     | > stopnet_loss: 1.52251  (1.59797)
     | > decoder_coarse_loss: 1.64312  (1.73151)
     | > decoder_ddc_loss: 0.00170  (0.00124)
     | > ga_loss: 0.00287  (0.00217)
     | > decoder_diff_spec_loss: 0.44890  (0.48968)
     | > postnet_diff_spec_loss: 0.78374  (0.80459)
     | > decoder_ssim_loss: 0.32702  (0.30719)
     | > postnet_ssim_loss: 0.34827  (0.32170)
     | > loss: 3.22508  (3.33135)
     | > align_error: 0.98538  (0.98877)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 8.41597  (3.91271)
     | > current_lr: 0.00008 
     | > step_time: 2.85260  (3.63609)
     | > loader_time: 0.01720  (0.03422)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.56330 [0m(-0.18847)
     | > avg_decoder_loss:[91m 2.38198 [0m(+0.02188)
     | > avg_postnet_loss:[92m 2.10097 [0m(-0.04772)
     | > avg_stopnet_loss:[91m 1.54133 [0m(+0.00112)
     | > avg_decoder_coarse_loss:[92m 2.17482 [0m(-0.01839)
     | > avg_decoder_ddc_loss:[92m 0.00101 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00239 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.50552 [0m(+0.00243)
     | > avg_postnet_diff_spec_loss:[92m 0.83037 [0m(-0.00016)
     | > avg_decoder_ssim_loss:[92m 0.29933 [0m(-0.00008)
     | > avg_postnet_ssim_loss:[92m 0.31957 [0m(-0.00058)
     | > avg_loss:[92m 3.70665 [0m(-0.00961)
     | > avg_align_error:[92m 0.99075 [0m(-0.00007)


[4m[1m > EPOCH: 76/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:05:03) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 276700[0m
     | > decoder_loss: 1.83051  (1.76247)
     | > postnet_loss: 1.45010  (1.42217)
     | > stopnet_loss: 1.25215  (1.44090)
     | > decoder_coarse_loss: 1.73893  (1.70354)
     | > decoder_ddc_loss: 0.00132  (0.00118)
     | > ga_loss: 0.00236  (0.00210)
     | > decoder_diff_spec_loss: 0.48670  (0.48466)
     | > postnet_diff_spec_loss: 0.80183  (0.79988)
     | > decoder_ssim_loss: 0.36023  (0.32356)
     | > postnet_ssim_loss: 0.37116  (0.33898)
     | > loss: 3.02413  (3.16053)
     | > align_error: 0.98872  (0.98939)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.48124  (3.04709)
     | > current_lr: 0.00008 
     | > step_time: 3.53860  (3.84249)
     | > loader_time: 0.03770  (0.03689)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 276725[0m
     | > decoder_loss: 1.77187  (1.77910)
     | > postnet_loss: 1.37646  (1.42473)
     | > stopnet_loss: 1.97360  (1.56826)
     | > decoder_coarse_loss: 1.65071  (1.71654)
     | > decoder_ddc_loss: 0.00092  (0.00122)
     | > ga_loss: 0.00220  (0.00219)
     | > decoder_diff_spec_loss: 0.47559  (0.48722)
     | > postnet_diff_spec_loss: 0.78728  (0.80214)
     | > decoder_ssim_loss: 0.24667  (0.30822)
     | > postnet_ssim_loss: 0.25787  (0.32288)
     | > loss: 3.62646  (3.28974)
     | > align_error: 0.99064  (0.98896)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.30886  (4.07000)
     | > current_lr: 0.00008 
     | > step_time: 3.69770  (3.63276)
     | > loader_time: 0.02420  (0.03040)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 276750[0m
     | > decoder_loss: 1.85428  (1.78622)
     | > postnet_loss: 1.42304  (1.43227)
     | > stopnet_loss: 1.52106  (1.59425)
     | > decoder_coarse_loss: 1.78799  (1.72345)
     | > decoder_ddc_loss: 0.00171  (0.00123)
     | > ga_loss: 0.00232  (0.00218)
     | > decoder_diff_spec_loss: 0.48461  (0.48868)
     | > postnet_diff_spec_loss: 0.78494  (0.80365)
     | > decoder_ssim_loss: 0.30727  (0.30734)
     | > postnet_ssim_loss: 0.31912  (0.32222)
     | > loss: 3.27339  (3.32141)
     | > align_error: 0.98488  (0.98878)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.95641  (3.92901)
     | > current_lr: 0.00008 
     | > step_time: 3.60990  (3.65118)
     | > loader_time: 0.01790  (0.03280)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 276775[0m
     | > decoder_loss: 1.93010  (1.79533)
     | > postnet_loss: 1.91379  (1.44123)
     | > stopnet_loss: 1.64389  (1.59697)
     | > decoder_coarse_loss: 1.79618  (1.72971)
     | > decoder_ddc_loss: 0.00572  (0.00128)
     | > ga_loss: 0.00735  (0.00225)
     | > decoder_diff_spec_loss: 0.50982  (0.48966)
     | > postnet_diff_spec_loss: 0.88261  (0.80502)
     | > decoder_ssim_loss: 0.48134  (0.30879)
     | > postnet_ssim_loss: 0.49778  (0.32364)
     | > loss: 3.68497  (3.33188)
     | > align_error: 0.95527  (0.98842)
     | > amp_scaler: 16384.00000  (20903.72414)
     | > grad_norm: 0.00000  (4.02435)
     | > current_lr: 0.00008 
     | > step_time: 0.48710  (3.52459)
     | > loader_time: 0.00780  (0.03162)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.80493 [0m(+0.24163)
     | > avg_decoder_loss:[92m 2.30786 [0m(-0.07412)
     | > avg_postnet_loss:[92m 2.03482 [0m(-0.06615)
     | > avg_stopnet_loss:[92m 1.54013 [0m(-0.00121)
     | > avg_decoder_coarse_loss:[92m 2.10536 [0m(-0.06946)
     | > avg_decoder_ddc_loss:[92m 0.00099 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00239 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.50262 [0m(-0.00290)
     | > avg_postnet_diff_spec_loss:[91m 0.83090 [0m(+0.00053)
     | > avg_decoder_ssim_loss:[92m 0.29876 [0m(-0.00057)
     | > avg_postnet_ssim_loss:[91m 0.32002 [0m(+0.00045)
     | > avg_loss:[92m 3.65240 [0m(-0.05425)
     | > avg_align_error:[91m 0.99078 [0m(+0.00003)


[4m[1m > EPOCH: 77/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:12:07) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 276800[0m
     | > decoder_loss: 1.86725  (1.76242)
     | > postnet_loss: 1.53426  (1.42175)
     | > stopnet_loss: 1.37852  (1.52114)
     | > decoder_coarse_loss: 1.85600  (1.70457)
     | > decoder_ddc_loss: 0.00162  (0.00123)
     | > ga_loss: 0.00270  (0.00219)
     | > decoder_diff_spec_loss: 0.52047  (0.48562)
     | > postnet_diff_spec_loss: 0.83351  (0.80274)
     | > decoder_ssim_loss: 0.33277  (0.31244)
     | > postnet_ssim_loss: 0.34715  (0.32744)
     | > loss: 3.21530  (3.23665)
     | > align_error: 0.98558  (0.98895)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.76489  (3.75395)
     | > current_lr: 0.00008 
     | > step_time: 3.13220  (3.79792)
     | > loader_time: 0.02050  (0.03591)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 276825[0m
     | > decoder_loss: 1.88128  (1.78583)
     | > postnet_loss: 1.43688  (1.43345)
     | > stopnet_loss: 2.19952  (1.56740)
     | > decoder_coarse_loss: 1.78001  (1.72693)
     | > decoder_ddc_loss: 0.00089  (0.00122)
     | > ga_loss: 0.00197  (0.00216)
     | > decoder_diff_spec_loss: 0.52169  (0.49073)
     | > postnet_diff_spec_loss: 0.82680  (0.80466)
     | > decoder_ssim_loss: 0.22401  (0.30851)
     | > postnet_ssim_loss: 0.23052  (0.32339)
     | > loss: 3.93491  (3.29690)
     | > align_error: 0.99068  (0.98887)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.34445  (3.86234)
     | > current_lr: 0.00008 
     | > step_time: 4.54700  (3.69733)
     | > loader_time: 0.02240  (0.03200)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 276850[0m
     | > decoder_loss: 1.66706  (1.78707)
     | > postnet_loss: 1.32882  (1.43497)
     | > stopnet_loss: 2.07255  (1.59039)
     | > decoder_coarse_loss: 1.64663  (1.72615)
     | > decoder_ddc_loss: 0.00091  (0.00122)
     | > ga_loss: 0.00213  (0.00216)
     | > decoder_diff_spec_loss: 0.46602  (0.48978)
     | > postnet_diff_spec_loss: 0.79390  (0.80459)
     | > decoder_ssim_loss: 0.23773  (0.30637)
     | > postnet_ssim_loss: 0.24820  (0.32124)
     | > loss: 3.68050  (3.31905)
     | > align_error: 0.99143  (0.98883)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.92232  (3.64082)
     | > current_lr: 0.00008 
     | > step_time: 4.70660  (3.72371)
     | > loader_time: 0.01900  (0.03290)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.95816 [0m(+0.15323)
     | > avg_decoder_loss:[91m 2.37538 [0m(+0.06752)
     | > avg_postnet_loss:[91m 2.30879 [0m(+0.27397)
     | > avg_stopnet_loss:[91m 1.54176 [0m(+0.00163)
     | > avg_decoder_coarse_loss:[91m 2.22880 [0m(+0.12344)
     | > avg_decoder_ddc_loss:[91m 0.00101 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00238 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.50488 [0m(+0.00226)
     | > avg_postnet_diff_spec_loss:[91m 0.83257 [0m(+0.00168)
     | > avg_decoder_ssim_loss:[92m 0.29867 [0m(-0.00009)
     | > avg_postnet_ssim_loss:[91m 0.32225 [0m(+0.00222)
     | > avg_loss:[91m 3.77174 [0m(+0.11934)
     | > avg_align_error:[92m 0.99069 [0m(-0.00009)


[4m[1m > EPOCH: 78/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:19:17) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 276875[0m
     | > decoder_loss: 1.60545  (1.74902)
     | > postnet_loss: 1.34957  (1.41891)
     | > stopnet_loss: 1.71381  (1.45134)
     | > decoder_coarse_loss: 1.57452  (1.69569)
     | > decoder_ddc_loss: 0.00107  (0.00119)
     | > ga_loss: 0.00195  (0.00208)
     | > decoder_diff_spec_loss: 0.45619  (0.48450)
     | > postnet_diff_spec_loss: 0.78911  (0.79942)
     | > decoder_ssim_loss: 0.26767  (0.31973)
     | > postnet_ssim_loss: 0.28466  (0.33559)
     | > loss: 3.30563  (3.16275)
     | > align_error: 0.99035  (0.98936)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.71956  (2.98549)
     | > current_lr: 0.00008 
     | > step_time: 3.95360  (4.05577)
     | > loader_time: 0.07070  (0.04097)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 276900[0m
     | > decoder_loss: 1.75152  (1.77415)
     | > postnet_loss: 1.36070  (1.42437)
     | > stopnet_loss: 1.41871  (1.54622)
     | > decoder_coarse_loss: 1.69110  (1.71097)
     | > decoder_ddc_loss: 0.00094  (0.00125)
     | > ga_loss: 0.00195  (0.00219)
     | > decoder_diff_spec_loss: 0.47429  (0.48837)
     | > postnet_diff_spec_loss: 0.78224  (0.80258)
     | > decoder_ssim_loss: 0.31618  (0.30969)
     | > postnet_ssim_loss: 0.33052  (0.32480)
     | > loss: 3.10535  (3.26620)
     | > align_error: 0.99063  (0.98879)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.28073  (3.56466)
     | > current_lr: 0.00008 
     | > step_time: 4.04820  (3.73246)
     | > loader_time: 0.06470  (0.04187)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 276925[0m
     | > decoder_loss: 1.72284  (1.77935)
     | > postnet_loss: 1.48404  (1.43326)
     | > stopnet_loss: 0.96113  (1.59202)
     | > decoder_coarse_loss: 1.69930  (1.72159)
     | > decoder_ddc_loss: 0.00217  (0.00124)
     | > ga_loss: 0.00262  (0.00217)
     | > decoder_diff_spec_loss: 0.49590  (0.48864)
     | > postnet_diff_spec_loss: 0.81912  (0.80379)
     | > decoder_ssim_loss: 0.45197  (0.30687)
     | > postnet_ssim_loss: 0.47192  (0.32220)
     | > loss: 2.76103  (3.31712)
     | > align_error: 0.98271  (0.98875)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.88947  (3.77141)
     | > current_lr: 0.00008 
     | > step_time: 1.94670  (3.72395)
     | > loader_time: 0.01720  (0.03666)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 276950[0m
     | > decoder_loss: 1.69110  (1.78781)
     | > postnet_loss: 1.31078  (1.43285)
     | > stopnet_loss: 1.41409  (1.59461)
     | > decoder_coarse_loss: 1.61658  (1.72708)
     | > decoder_ddc_loss: 0.00101  (0.00125)
     | > ga_loss: 0.00176  (0.00218)
     | > decoder_diff_spec_loss: 0.47289  (0.48916)
     | > postnet_diff_spec_loss: 0.77600  (0.80381)
     | > decoder_ssim_loss: 0.30640  (0.30628)
     | > postnet_ssim_loss: 0.32175  (0.32152)
     | > loss: 3.04701  (3.32297)
     | > align_error: 0.99107  (0.98874)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 7.03390  (3.93696)
     | > current_lr: 0.00008 
     | > step_time: 3.54090  (3.62190)
     | > loader_time: 0.02110  (0.03507)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.69495 [0m(-0.26321)
     | > avg_decoder_loss:[92m 2.30671 [0m(-0.06867)
     | > avg_postnet_loss:[92m 2.09791 [0m(-0.21088)
     | > avg_stopnet_loss:[92m 1.54026 [0m(-0.00150)
     | > avg_decoder_coarse_loss:[92m 2.20283 [0m(-0.02597)
     | > avg_decoder_ddc_loss:[91m 0.00106 [0m(+0.00004)
     | > avg_ga_loss:[91m 0.00238 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.50040 [0m(-0.00447)
     | > avg_postnet_diff_spec_loss:[92m 0.83008 [0m(-0.00249)
     | > avg_decoder_ssim_loss:[92m 0.29806 [0m(-0.00061)
     | > avg_postnet_ssim_loss:[92m 0.32036 [0m(-0.00188)
     | > avg_loss:[92m 3.69153 [0m(-0.08021)
     | > avg_align_error:[92m 0.99063 [0m(-0.00005)


[4m[1m > EPOCH: 79/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:26:26) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 276975[0m
     | > decoder_loss: 1.84755  (1.75292)
     | > postnet_loss: 1.48203  (1.40976)
     | > stopnet_loss: 1.55952  (1.53444)
     | > decoder_coarse_loss: 1.82086  (1.70078)
     | > decoder_ddc_loss: 0.00103  (0.00122)
     | > ga_loss: 0.00185  (0.00218)
     | > decoder_diff_spec_loss: 0.50799  (0.48338)
     | > postnet_diff_spec_loss: 0.82339  (0.80060)
     | > decoder_ssim_loss: 0.29328  (0.31103)
     | > postnet_ssim_loss: 0.30636  (0.32596)
     | > loss: 3.33937  (3.24174)
     | > align_error: 0.98978  (0.98907)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.20332  (3.84304)
     | > current_lr: 0.00008 
     | > step_time: 4.61370  (3.91152)
     | > loader_time: 0.02180  (0.02473)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 277000[0m
     | > decoder_loss: 1.74448  (1.78162)
     | > postnet_loss: 1.42071  (1.42448)
     | > stopnet_loss: 2.19277  (1.55505)
     | > decoder_coarse_loss: 1.66821  (1.72209)
     | > decoder_ddc_loss: 0.00081  (0.00122)
     | > ga_loss: 0.00176  (0.00218)
     | > decoder_diff_spec_loss: 0.46694  (0.48962)
     | > postnet_diff_spec_loss: 0.79669  (0.80350)
     | > decoder_ssim_loss: 0.22645  (0.30979)
     | > postnet_ssim_loss: 0.23255  (0.32465)
     | > loss: 3.84080  (3.28019)
     | > align_error: 0.99231  (0.98892)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.29243  (3.96970)
     | > current_lr: 0.00008 
     | > step_time: 4.52920  (3.80068)
     | > loader_time: 0.02140  (0.02567)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 277025[0m
     | > decoder_loss: 1.88589  (1.78398)
     | > postnet_loss: 1.42732  (1.42762)
     | > stopnet_loss: 1.89474  (1.58831)
     | > decoder_coarse_loss: 1.83839  (1.72408)
     | > decoder_ddc_loss: 0.00086  (0.00123)
     | > ga_loss: 0.00185  (0.00217)
     | > decoder_diff_spec_loss: 0.50892  (0.48930)
     | > postnet_diff_spec_loss: 0.80370  (0.80406)
     | > decoder_ssim_loss: 0.25179  (0.30683)
     | > postnet_ssim_loss: 0.25971  (0.32168)
     | > loss: 3.64815  (3.31383)
     | > align_error: 0.99110  (0.98877)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.26408  (3.89772)
     | > current_lr: 0.00008 
     | > step_time: 4.86850  (3.75105)
     | > loader_time: 0.02080  (0.02570)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.65434 [0m(-0.04062)
     | > avg_decoder_loss:[91m 2.38282 [0m(+0.07611)
     | > avg_postnet_loss:[91m 2.17844 [0m(+0.08053)
     | > avg_stopnet_loss:[91m 1.54114 [0m(+0.00088)
     | > avg_decoder_coarse_loss:[91m 2.25551 [0m(+0.05268)
     | > avg_decoder_ddc_loss:[92m 0.00105 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00236 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.50311 [0m(+0.00270)
     | > avg_postnet_diff_spec_loss:[92m 0.82930 [0m(-0.00078)
     | > avg_decoder_ssim_loss:[91m 0.29821 [0m(+0.00015)
     | > avg_postnet_ssim_loss:[92m 0.31972 [0m(-0.00064)
     | > avg_loss:[91m 3.74497 [0m(+0.05345)
     | > avg_align_error:[91m 0.99065 [0m(+0.00001)


[4m[1m > EPOCH: 80/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:33:37) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 277050[0m
     | > decoder_loss: 1.84827  (1.75661)
     | > postnet_loss: 1.44957  (1.41242)
     | > stopnet_loss: 1.05310  (1.42685)
     | > decoder_coarse_loss: 1.82435  (1.70562)
     | > decoder_ddc_loss: 0.00155  (0.00122)
     | > ga_loss: 0.00218  (0.00209)
     | > decoder_diff_spec_loss: 0.51411  (0.48603)
     | > postnet_diff_spec_loss: 0.81304  (0.80021)
     | > decoder_ssim_loss: 0.40211  (0.32419)
     | > postnet_ssim_loss: 0.41217  (0.34034)
     | > loss: 2.88030  (3.14396)
     | > align_error: 0.98645  (0.98920)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.88713  (2.81611)
     | > current_lr: 0.00008 
     | > step_time: 3.57600  (3.90599)
     | > loader_time: 0.02080  (0.03978)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 277075[0m
     | > decoder_loss: 1.71630  (1.76573)
     | > postnet_loss: 1.40299  (1.41425)
     | > stopnet_loss: 1.80449  (1.55440)
     | > decoder_coarse_loss: 1.67229  (1.70519)
     | > decoder_ddc_loss: 0.00112  (0.00126)
     | > ga_loss: 0.00249  (0.00219)
     | > decoder_diff_spec_loss: 0.45802  (0.48745)
     | > postnet_diff_spec_loss: 0.78547  (0.80263)
     | > decoder_ssim_loss: 0.26542  (0.30893)
     | > postnet_ssim_loss: 0.28264  (0.32413)
     | > loss: 3.46299  (3.26775)
     | > align_error: 0.98875  (0.98876)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.59637  (3.74002)
     | > current_lr: 0.00008 
     | > step_time: 4.54590  (3.56976)
     | > loader_time: 0.06590  (0.04198)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 277100[0m
     | > decoder_loss: 1.60797  (1.77225)
     | > postnet_loss: 1.35495  (1.42165)
     | > stopnet_loss: 2.63051  (1.60402)
     | > decoder_coarse_loss: 1.58463  (1.71148)
     | > decoder_ddc_loss: 0.00086  (0.00124)
     | > ga_loss: 0.00194  (0.00216)
     | > decoder_diff_spec_loss: 0.44704  (0.48700)
     | > postnet_diff_spec_loss: 0.78969  (0.80294)
     | > decoder_ssim_loss: 0.19370  (0.30395)
     | > postnet_ssim_loss: 0.20707  (0.31922)
     | > loss: 4.18668  (3.31976)
     | > align_error: 0.99094  (0.98880)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.19618  (3.82196)
     | > current_lr: 0.00008 
     | > step_time: 4.37910  (3.66194)
     | > loader_time: 0.02580  (0.04068)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 277125[0m
     | > decoder_loss: 1.79611  (1.78058)
     | > postnet_loss: 1.39967  (1.42568)
     | > stopnet_loss: 2.19911  (1.59680)
     | > decoder_coarse_loss: 1.69720  (1.71882)
     | > decoder_ddc_loss: 0.00102  (0.00126)
     | > ga_loss: 0.00207  (0.00219)
     | > decoder_diff_spec_loss: 0.47927  (0.48804)
     | > postnet_diff_spec_loss: 0.77817  (0.80356)
     | > decoder_ssim_loss: 0.21897  (0.30578)
     | > postnet_ssim_loss: 0.22974  (0.32097)
     | > loss: 3.85948  (3.31889)
     | > align_error: 0.98888  (0.98866)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.46357  (3.81937)
     | > current_lr: 0.00007 
     | > step_time: 3.14410  (3.56025)
     | > loader_time: 0.01600  (0.03628)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.27658 [0m(-0.37776)
     | > avg_decoder_loss:[91m 2.40915 [0m(+0.02633)
     | > avg_postnet_loss:[92m 2.04732 [0m(-0.13112)
     | > avg_stopnet_loss:[92m 1.54080 [0m(-0.00034)
     | > avg_decoder_coarse_loss:[91m 2.25757 [0m(+0.00206)
     | > avg_decoder_ddc_loss:[91m 0.00107 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00236 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.50319 [0m(+0.00008)
     | > avg_postnet_diff_spec_loss:[92m 0.82869 [0m(-0.00061)
     | > avg_decoder_ssim_loss:[92m 0.29799 [0m(-0.00022)
     | > avg_postnet_ssim_loss:[92m 0.31925 [0m(-0.00047)
     | > avg_loss:[92m 3.71865 [0m(-0.02633)
     | > avg_align_error:[92m 0.99058 [0m(-0.00007)


[4m[1m > EPOCH: 81/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:40:40) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 277150[0m
     | > decoder_loss: 1.59989  (1.73958)
     | > postnet_loss: 1.31710  (1.39790)
     | > stopnet_loss: 1.41843  (1.51877)
     | > decoder_coarse_loss: 1.52800  (1.68671)
     | > decoder_ddc_loss: 0.00104  (0.00127)
     | > ga_loss: 0.00175  (0.00217)
     | > decoder_diff_spec_loss: 0.45324  (0.48132)
     | > postnet_diff_spec_loss: 0.78752  (0.79914)
     | > decoder_ssim_loss: 0.32087  (0.31116)
     | > postnet_ssim_loss: 0.33737  (0.32659)
     | > loss: 3.01342  (3.21553)
     | > align_error: 0.99040  (0.98890)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 8.29793  (3.79312)
     | > current_lr: 0.00007 
     | > step_time: 4.39140  (3.71251)
     | > loader_time: 0.02210  (0.03241)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 277175[0m
     | > decoder_loss: 1.77553  (1.77173)
     | > postnet_loss: 1.37656  (1.41551)
     | > stopnet_loss: 1.07809  (1.53725)
     | > decoder_coarse_loss: 1.71375  (1.71469)
     | > decoder_ddc_loss: 0.00169  (0.00128)
     | > ga_loss: 0.00254  (0.00216)
     | > decoder_diff_spec_loss: 0.47961  (0.48922)
     | > postnet_diff_spec_loss: 0.78377  (0.80299)
     | > decoder_ssim_loss: 0.41311  (0.31085)
     | > postnet_ssim_loss: 0.43906  (0.32617)
     | > loss: 2.83654  (3.25615)
     | > align_error: 0.98595  (0.98863)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.67996  (3.83603)
     | > current_lr: 0.00007 
     | > step_time: 2.19410  (3.66376)
     | > loader_time: 0.05000  (0.03314)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 277200[0m
     | > decoder_loss: 1.76832  (1.77520)
     | > postnet_loss: 1.48715  (1.42016)
     | > stopnet_loss: 1.88506  (1.57753)
     | > decoder_coarse_loss: 1.69232  (1.71588)
     | > decoder_ddc_loss: 0.00152  (0.00127)
     | > ga_loss: 0.00248  (0.00215)
     | > decoder_diff_spec_loss: 0.46850  (0.48851)
     | > postnet_diff_spec_loss: 0.79095  (0.80357)
     | > decoder_ssim_loss: 0.26085  (0.30709)
     | > postnet_ssim_loss: 0.27437  (0.32217)
     | > loss: 3.58345  (3.29675)
     | > align_error: 0.98672  (0.98858)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.23009  (3.63470)
     | > current_lr: 0.00007 
     | > step_time: 3.58870  (3.67436)
     | > loader_time: 0.02350  (0.03347)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.84351 [0m(+0.56694)
     | > avg_decoder_loss:[91m 2.42324 [0m(+0.01409)
     | > avg_postnet_loss:[91m 2.29308 [0m(+0.24576)
     | > avg_stopnet_loss:[92m 1.54029 [0m(-0.00051)
     | > avg_decoder_coarse_loss:[92m 2.17953 [0m(-0.07804)
     | > avg_decoder_ddc_loss:[92m 0.00104 [0m(-0.00003)
     | > avg_ga_loss:[92m 0.00235 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.50327 [0m(+0.00008)
     | > avg_postnet_diff_spec_loss:[91m 0.82938 [0m(+0.00069)
     | > avg_decoder_ssim_loss:[92m 0.29783 [0m(-0.00016)
     | > avg_postnet_ssim_loss:[91m 0.32130 [0m(+0.00205)
     | > avg_loss:[91m 3.76423 [0m(+0.04558)
     | > avg_align_error:[91m 0.99064 [0m(+0.00006)


[4m[1m > EPOCH: 82/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:47:47) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 277225[0m
     | > decoder_loss: 1.88723  (1.74073)
     | > postnet_loss: 1.46915  (1.40677)
     | > stopnet_loss: 1.21154  (1.45390)
     | > decoder_coarse_loss: 1.77905  (1.68949)
     | > decoder_ddc_loss: 0.00154  (0.00119)
     | > ga_loss: 0.00242  (0.00206)
     | > decoder_diff_spec_loss: 0.49745  (0.48443)
     | > postnet_diff_spec_loss: 0.79347  (0.79830)
     | > decoder_ssim_loss: 0.36244  (0.31497)
     | > postnet_ssim_loss: 0.37947  (0.33139)
     | > loss: 3.01608  (3.15603)
     | > align_error: 0.98751  (0.98945)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.91085  (3.24013)
     | > current_lr: 0.00007 
     | > step_time: 2.96500  (4.03526)
     | > loader_time: 0.02280  (0.04163)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 277250[0m
     | > decoder_loss: 1.76303  (1.76351)
     | > postnet_loss: 1.42931  (1.40645)
     | > stopnet_loss: 1.91686  (1.53403)
     | > decoder_coarse_loss: 1.69906  (1.70316)
     | > decoder_ddc_loss: 0.00116  (0.00128)
     | > ga_loss: 0.00208  (0.00216)
     | > decoder_diff_spec_loss: 0.50141  (0.48829)
     | > postnet_diff_spec_loss: 0.83008  (0.80213)
     | > decoder_ssim_loss: 0.25180  (0.30965)
     | > postnet_ssim_loss: 0.25620  (0.32459)
     | > loss: 3.61026  (3.24459)
     | > align_error: 0.98817  (0.98860)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.66046  (3.85808)
     | > current_lr: 0.00007 
     | > step_time: 3.21680  (3.61473)
     | > loader_time: 0.03930  (0.03810)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 277275[0m
     | > decoder_loss: 1.62400  (1.77095)
     | > postnet_loss: 1.30533  (1.41052)
     | > stopnet_loss: 1.06736  (1.57546)
     | > decoder_coarse_loss: 1.59638  (1.70759)
     | > decoder_ddc_loss: 0.00163  (0.00125)
     | > ga_loss: 0.00231  (0.00214)
     | > decoder_diff_spec_loss: 0.45149  (0.48810)
     | > postnet_diff_spec_loss: 0.77515  (0.80250)
     | > decoder_ssim_loss: 0.39029  (0.30545)
     | > postnet_ssim_loss: 0.41732  (0.32055)
     | > loss: 2.71930  (3.28790)
     | > align_error: 0.98671  (0.98867)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.66547  (3.84457)
     | > current_lr: 0.00007 
     | > step_time: 2.86950  (3.67460)
     | > loader_time: 0.01430  (0.03389)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 277300[0m
     | > decoder_loss: 1.63171  (1.77577)
     | > postnet_loss: 1.39994  (1.41639)
     | > stopnet_loss: 1.50634  (1.57824)
     | > decoder_coarse_loss: 1.55207  (1.71366)
     | > decoder_ddc_loss: 0.00142  (0.00126)
     | > ga_loss: 0.00248  (0.00217)
     | > decoder_diff_spec_loss: 0.46054  (0.48834)
     | > postnet_diff_spec_loss: 0.78911  (0.80321)
     | > decoder_ssim_loss: 0.31517  (0.30640)
     | > postnet_ssim_loss: 0.33575  (0.32156)
     | > loss: 3.14019  (3.29572)
     | > align_error: 0.98794  (0.98855)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.57183  (3.88392)
     | > current_lr: 0.00007 
     | > step_time: 1.86120  (3.58847)
     | > loader_time: 0.01170  (0.03112)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.74597 [0m(-0.09754)
     | > avg_decoder_loss:[92m 2.38616 [0m(-0.03708)
     | > avg_postnet_loss:[92m 2.26456 [0m(-0.02853)
     | > avg_stopnet_loss:[92m 1.53959 [0m(-0.00070)
     | > avg_decoder_coarse_loss:[91m 2.20807 [0m(+0.02854)
     | > avg_decoder_ddc_loss:[92m 0.00098 [0m(-0.00005)
     | > avg_ga_loss:[91m 0.00236 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50277 [0m(-0.00050)
     | > avg_postnet_diff_spec_loss:[91m 0.82945 [0m(+0.00008)
     | > avg_decoder_ssim_loss:[92m 0.29778 [0m(-0.00005)
     | > avg_postnet_ssim_loss:[92m 0.32003 [0m(-0.00126)
     | > avg_loss:[92m 3.75386 [0m(-0.01036)
     | > avg_align_error:[91m 0.99073 [0m(+0.00009)


[4m[1m > EPOCH: 83/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:55:02) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 277325[0m
     | > decoder_loss: 1.82427  (1.73897)
     | > postnet_loss: 1.49372  (1.39749)
     | > stopnet_loss: 1.89047  (1.52212)
     | > decoder_coarse_loss: 1.77250  (1.68883)
     | > decoder_ddc_loss: 0.00098  (0.00122)
     | > ga_loss: 0.00205  (0.00219)
     | > decoder_diff_spec_loss: 0.48942  (0.48189)
     | > postnet_diff_spec_loss: 0.81891  (0.79974)
     | > decoder_ssim_loss: 0.25503  (0.31035)
     | > postnet_ssim_loss: 0.26533  (0.32596)
     | > loss: 3.63074  (3.21918)
     | > align_error: 0.99045  (0.98892)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 8.10740  (3.89958)
     | > current_lr: 0.00007 
     | > step_time: 4.00980  (3.63796)
     | > loader_time: 0.02500  (0.04147)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 277350[0m
     | > decoder_loss: 2.18425  (1.76646)
     | > postnet_loss: 1.69739  (1.41351)
     | > stopnet_loss: 1.51381  (1.53649)
     | > decoder_coarse_loss: 2.09526  (1.71290)
     | > decoder_ddc_loss: 0.00114  (0.00123)
     | > ga_loss: 0.00176  (0.00215)
     | > decoder_diff_spec_loss: 0.59143  (0.48872)
     | > postnet_diff_spec_loss: 0.87801  (0.80317)
     | > decoder_ssim_loss: 0.29487  (0.30827)
     | > postnet_ssim_loss: 0.30960  (0.32356)
     | > loss: 3.53562  (3.25171)
     | > align_error: 0.98893  (0.98872)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.16213  (4.08653)
     | > current_lr: 0.00007 
     | > step_time: 4.13540  (3.63790)
     | > loader_time: 0.02260  (0.03532)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 277375[0m
     | > decoder_loss: 1.77880  (1.77010)
     | > postnet_loss: 1.41774  (1.41464)
     | > stopnet_loss: 1.30311  (1.55890)
     | > decoder_coarse_loss: 1.75850  (1.71395)
     | > decoder_ddc_loss: 0.00116  (0.00124)
     | > ga_loss: 0.00196  (0.00214)
     | > decoder_diff_spec_loss: 0.50309  (0.48809)
     | > postnet_diff_spec_loss: 0.82322  (0.80350)
     | > decoder_ssim_loss: 0.33801  (0.30722)
     | > postnet_ssim_loss: 0.35012  (0.32262)
     | > loss: 3.05557  (3.27494)
     | > align_error: 0.98874  (0.98860)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.71768  (3.73066)
     | > current_lr: 0.00007 
     | > step_time: 3.69360  (3.58421)
     | > loader_time: 0.01680  (0.03252)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.27291 [0m(-0.47306)
     | > avg_decoder_loss:[92m 2.35011 [0m(-0.03605)
     | > avg_postnet_loss:[92m 2.25381 [0m(-0.01074)
     | > avg_stopnet_loss:[92m 1.53858 [0m(-0.00101)
     | > avg_decoder_coarse_loss:[92m 2.20204 [0m(-0.00603)
     | > avg_decoder_ddc_loss:[91m 0.00099 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00236 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50262 [0m(-0.00015)
     | > avg_postnet_diff_spec_loss:[92m 0.82859 [0m(-0.00086)
     | > avg_decoder_ssim_loss:[92m 0.29745 [0m(-0.00033)
     | > avg_postnet_ssim_loss:[92m 0.31970 [0m(-0.00033)
     | > avg_loss:[92m 3.73920 [0m(-0.01466)
     | > avg_align_error:[92m 0.99065 [0m(-0.00008)


[4m[1m > EPOCH: 84/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:02:07) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 277400[0m
     | > decoder_loss: 1.75352  (1.72895)
     | > postnet_loss: 1.46522  (1.40061)
     | > stopnet_loss: 1.47342  (1.48589)
     | > decoder_coarse_loss: 1.68895  (1.66985)
     | > decoder_ddc_loss: 0.00151  (0.00113)
     | > ga_loss: 0.00256  (0.00201)
     | > decoder_diff_spec_loss: 0.50241  (0.48131)
     | > postnet_diff_spec_loss: 0.82003  (0.79791)
     | > decoder_ssim_loss: 0.31483  (0.30902)
     | > postnet_ssim_loss: 0.33200  (0.32525)
     | > loss: 3.20584  (3.17446)
     | > align_error: 0.98680  (0.98959)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 7.19946  (3.42902)
     | > current_lr: 0.00007 
     | > step_time: 2.23020  (4.23040)
     | > loader_time: 0.02780  (0.03760)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 277425[0m
     | > decoder_loss: 1.70896  (1.76131)
     | > postnet_loss: 1.48045  (1.40382)
     | > stopnet_loss: 1.15632  (1.52811)
     | > decoder_coarse_loss: 1.70375  (1.70011)
     | > decoder_ddc_loss: 0.00171  (0.00127)
     | > ga_loss: 0.00247  (0.00216)
     | > decoder_diff_spec_loss: 0.48893  (0.48708)
     | > postnet_diff_spec_loss: 0.82000  (0.80090)
     | > decoder_ssim_loss: 0.40257  (0.31121)
     | > postnet_ssim_loss: 0.42591  (0.32648)
     | > loss: 2.92675  (3.23695)
     | > align_error: 0.98472  (0.98861)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.45988  (4.02373)
     | > current_lr: 0.00007 
     | > step_time: 2.79440  (3.63935)
     | > loader_time: 0.03410  (0.03601)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 277450[0m
     | > decoder_loss: 1.79801  (1.76557)
     | > postnet_loss: 1.32732  (1.41125)
     | > stopnet_loss: 1.55452  (1.59059)
     | > decoder_coarse_loss: 1.68756  (1.70374)
     | > decoder_ddc_loss: 0.00143  (0.00124)
     | > ga_loss: 0.00245  (0.00214)
     | > decoder_diff_spec_loss: 0.48635  (0.48798)
     | > postnet_diff_spec_loss: 0.77748  (0.80250)
     | > decoder_ssim_loss: 0.30772  (0.30350)
     | > postnet_ssim_loss: 0.32427  (0.31871)
     | > loss: 3.24431  (3.29989)
     | > align_error: 0.98714  (0.98866)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.47446  (3.93607)
     | > current_lr: 0.00007 
     | > step_time: 3.36710  (3.69115)
     | > loader_time: 0.02500  (0.03414)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 277475[0m
     | > decoder_loss: 1.82200  (1.77141)
     | > postnet_loss: 1.34646  (1.41429)
     | > stopnet_loss: 1.37164  (1.58514)
     | > decoder_coarse_loss: 1.72326  (1.70908)
     | > decoder_ddc_loss: 0.00138  (0.00126)
     | > ga_loss: 0.00244  (0.00215)
     | > decoder_diff_spec_loss: 0.50485  (0.48822)
     | > postnet_diff_spec_loss: 0.79622  (0.80314)
     | > decoder_ssim_loss: 0.36062  (0.30594)
     | > postnet_ssim_loss: 0.37251  (0.32125)
     | > loss: 3.11565  (3.29956)
     | > align_error: 0.98827  (0.98850)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.05925  (3.99464)
     | > current_lr: 0.00007 
     | > step_time: 1.60210  (3.59228)
     | > loader_time: 0.01420  (0.03254)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.73681 [0m(+0.46390)
     | > avg_decoder_loss:[92m 2.30330 [0m(-0.04681)
     | > avg_postnet_loss:[92m 2.08534 [0m(-0.16848)
     | > avg_stopnet_loss:[91m 1.53862 [0m(+0.00005)
     | > avg_decoder_coarse_loss:[92m 2.14615 [0m(-0.05589)
     | > avg_decoder_ddc_loss:[91m 0.00105 [0m(+0.00005)
     | > avg_ga_loss:[92m 0.00235 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50010 [0m(-0.00252)
     | > avg_postnet_diff_spec_loss:[92m 0.82699 [0m(-0.00160)
     | > avg_decoder_ssim_loss:[92m 0.29686 [0m(-0.00059)
     | > avg_postnet_ssim_loss:[92m 0.31825 [0m(-0.00146)
     | > avg_loss:[92m 3.66990 [0m(-0.06930)
     | > avg_align_error:[92m 0.99052 [0m(-0.00013)


[4m[1m > EPOCH: 85/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:09:15) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 277500[0m
     | > decoder_loss: 1.73096  (1.73625)
     | > postnet_loss: 1.45632  (1.39748)
     | > stopnet_loss: 1.89863  (1.51554)
     | > decoder_coarse_loss: 1.63496  (1.67594)
     | > decoder_ddc_loss: 0.00147  (0.00129)
     | > ga_loss: 0.00249  (0.00218)
     | > decoder_diff_spec_loss: 0.47510  (0.48084)
     | > postnet_diff_spec_loss: 0.80495  (0.79844)
     | > decoder_ssim_loss: 0.25556  (0.31274)
     | > postnet_ssim_loss: 0.27261  (0.32870)
     | > loss: 3.56904  (3.20935)
     | > align_error: 0.98715  (0.98863)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.72462  (3.70833)
     | > current_lr: 0.00007 
     | > step_time: 2.94940  (3.68940)
     | > loader_time: 0.01680  (0.02779)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 277525[0m
     | > decoder_loss: 1.69138  (1.75670)
     | > postnet_loss: 1.42067  (1.40742)
     | > stopnet_loss: 1.27001  (1.54595)
     | > decoder_coarse_loss: 1.64060  (1.69407)
     | > decoder_ddc_loss: 0.00097  (0.00127)
     | > ga_loss: 0.00173  (0.00214)
     | > decoder_diff_spec_loss: 0.46373  (0.48646)
     | > postnet_diff_spec_loss: 0.79107  (0.80108)
     | > decoder_ssim_loss: 0.33703  (0.30827)
     | > postnet_ssim_loss: 0.35768  (0.32355)
     | > loss: 2.95442  (3.25136)
     | > align_error: 0.99137  (0.98854)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 7.52318  (4.20270)
     | > current_lr: 0.00007 
     | > step_time: 4.42620  (3.68447)
     | > loader_time: 0.02250  (0.02979)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 277550[0m
     | > decoder_loss: 1.82558  (1.76921)
     | > postnet_loss: 1.40325  (1.41720)
     | > stopnet_loss: 1.13661  (1.57438)
     | > decoder_coarse_loss: 1.74875  (1.70279)
     | > decoder_ddc_loss: 0.00170  (0.00127)
     | > ga_loss: 0.00222  (0.00213)
     | > decoder_diff_spec_loss: 0.49232  (0.48764)
     | > postnet_diff_spec_loss: 0.80530  (0.80289)
     | > decoder_ssim_loss: 0.37677  (0.30650)
     | > postnet_ssim_loss: 0.40099  (0.32194)
     | > loss: 2.91136  (3.28740)
     | > align_error: 0.98517  (0.98849)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.42069  (3.93006)
     | > current_lr: 0.00007 
     | > step_time: 3.81720  (3.68414)
     | > loader_time: 0.02270  (0.03083)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.19550 [0m(-0.54131)
     | > avg_decoder_loss:[92m 2.27162 [0m(-0.03168)
     | > avg_postnet_loss:[91m 2.10125 [0m(+0.01592)
     | > avg_stopnet_loss:[92m 1.53781 [0m(-0.00081)
     | > avg_decoder_coarse_loss:[91m 2.20029 [0m(+0.05414)
     | > avg_decoder_ddc_loss:[91m 0.00107 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00232 [0m(-0.00003)
     | > avg_decoder_diff_spec_loss:[91m 0.50448 [0m(+0.00438)
     | > avg_postnet_diff_spec_loss:[92m 0.82664 [0m(-0.00035)
     | > avg_decoder_ssim_loss:[92m 0.29677 [0m(-0.00009)
     | > avg_postnet_ssim_loss:[92m 0.31740 [0m(-0.00084)
     | > avg_loss:[91m 3.67929 [0m(+0.00939)
     | > avg_align_error:[92m 0.99031 [0m(-0.00021)


[4m[1m > EPOCH: 86/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:16:23) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 277575[0m
     | > decoder_loss: 1.87914  (1.71354)
     | > postnet_loss: 1.49803  (1.38620)
     | > stopnet_loss: 1.19239  (1.48133)
     | > decoder_coarse_loss: 1.86695  (1.66749)
     | > decoder_ddc_loss: 0.00130  (0.00111)
     | > ga_loss: 0.00163  (0.00191)
     | > decoder_diff_spec_loss: 0.54162  (0.47777)
     | > postnet_diff_spec_loss: 0.83550  (0.79525)
     | > decoder_ssim_loss: 0.35529  (0.30783)
     | > postnet_ssim_loss: 0.36486  (0.32439)
     | > loss: 3.03620  (3.15926)
     | > align_error: 0.98864  (0.98985)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.93690  (2.50815)
     | > current_lr: 0.00007 
     | > step_time: 4.02860  (4.43008)
     | > loader_time: 0.07220  (0.05412)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 277600[0m
     | > decoder_loss: 1.70496  (1.75285)
     | > postnet_loss: 1.32006  (1.39863)
     | > stopnet_loss: 1.90243  (1.53417)
     | > decoder_coarse_loss: 1.62141  (1.69885)
     | > decoder_ddc_loss: 0.00091  (0.00126)
     | > ga_loss: 0.00200  (0.00213)
     | > decoder_diff_spec_loss: 0.47458  (0.48627)
     | > postnet_diff_spec_loss: 0.77946  (0.80005)
     | > decoder_ssim_loss: 0.24710  (0.30776)
     | > postnet_ssim_loss: 0.26203  (0.32330)
     | > loss: 3.51508  (3.23707)
     | > align_error: 0.99124  (0.98862)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.43021  (3.52887)
     | > current_lr: 0.00007 
     | > step_time: 3.51600  (3.64688)
     | > loader_time: 0.02200  (0.03920)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 277625[0m
     | > decoder_loss: 1.82123  (1.75942)
     | > postnet_loss: 1.45966  (1.40576)
     | > stopnet_loss: 1.67577  (1.58789)
     | > decoder_coarse_loss: 1.71651  (1.70049)
     | > decoder_ddc_loss: 0.00163  (0.00124)
     | > ga_loss: 0.00238  (0.00212)
     | > decoder_diff_spec_loss: 0.50961  (0.48682)
     | > postnet_diff_spec_loss: 0.81271  (0.80283)
     | > decoder_ssim_loss: 0.28841  (0.30290)
     | > postnet_ssim_loss: 0.30235  (0.31835)
     | > loss: 3.41571  (3.29293)
     | > align_error: 0.98375  (0.98861)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.49009  (3.69867)
     | > current_lr: 0.00007 
     | > step_time: 3.47060  (3.68945)
     | > loader_time: 0.01760  (0.03635)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 277650[0m
     | > decoder_loss: 1.79400  (1.76770)
     | > postnet_loss: 1.46206  (1.41342)
     | > stopnet_loss: 1.26465  (1.58447)
     | > decoder_coarse_loss: 1.72258  (1.70700)
     | > decoder_ddc_loss: 0.00073  (0.00127)
     | > ga_loss: 0.00169  (0.00214)
     | > decoder_diff_spec_loss: 0.48254  (0.48700)
     | > postnet_diff_spec_loss: 0.80394  (0.80303)
     | > decoder_ssim_loss: 0.34712  (0.30471)
     | > postnet_ssim_loss: 0.36671  (0.32040)
     | > loss: 3.01804  (3.29629)
     | > align_error: 0.99356  (0.98842)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.12044  (3.99889)
     | > current_lr: 0.00007 
     | > step_time: 2.39690  (3.60240)
     | > loader_time: 0.01560  (0.03294)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.68642 [0m(+0.49091)
     | > avg_decoder_loss:[92m 2.22320 [0m(-0.04842)
     | > avg_postnet_loss:[92m 1.89847 [0m(-0.20278)
     | > avg_stopnet_loss:[92m 1.53714 [0m(-0.00067)
     | > avg_decoder_coarse_loss:[92m 2.14457 [0m(-0.05572)
     | > avg_decoder_ddc_loss:[91m 0.00108 [0m(+0.00002)
     | > avg_ga_loss:[91m 0.00233 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50134 [0m(-0.00314)
     | > avg_postnet_diff_spec_loss:[91m 0.82759 [0m(+0.00095)
     | > avg_decoder_ssim_loss:[92m 0.29611 [0m(-0.00066)
     | > avg_postnet_ssim_loss:[92m 0.31653 [0m(-0.00088)
     | > avg_loss:[92m 3.60101 [0m(-0.07828)
     | > avg_align_error:[92m 0.99031 [0m(-0.00000)


[4m[1m > EPOCH: 87/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:23:29) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 277675[0m
     | > decoder_loss: 1.79247  (1.74817)
     | > postnet_loss: 1.40005  (1.40710)
     | > stopnet_loss: 1.31147  (1.49352)
     | > decoder_coarse_loss: 1.73940  (1.69072)
     | > decoder_ddc_loss: 0.00121  (0.00128)
     | > ga_loss: 0.00205  (0.00215)
     | > decoder_diff_spec_loss: 0.50439  (0.48322)
     | > postnet_diff_spec_loss: 0.80564  (0.79780)
     | > decoder_ssim_loss: 0.33884  (0.31564)
     | > postnet_ssim_loss: 0.35202  (0.33192)
     | > loss: 3.05521  (3.19824)
     | > align_error: 0.98931  (0.98867)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.70871  (3.75336)
     | > current_lr: 0.00007 
     | > step_time: 2.57010  (3.63259)
     | > loader_time: 0.02000  (0.02996)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 277700[0m
     | > decoder_loss: 1.64716  (1.76437)
     | > postnet_loss: 1.32703  (1.41505)
     | > stopnet_loss: 2.07724  (1.55093)
     | > decoder_coarse_loss: 1.59642  (1.70447)
     | > decoder_ddc_loss: 0.00085  (0.00128)
     | > ga_loss: 0.00183  (0.00214)
     | > decoder_diff_spec_loss: 0.47312  (0.48696)
     | > postnet_diff_spec_loss: 0.78653  (0.80103)
     | > decoder_ssim_loss: 0.22845  (0.30742)
     | > postnet_ssim_loss: 0.24003  (0.32270)
     | > loss: 3.66129  (3.26245)
     | > align_error: 0.99168  (0.98839)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.17654  (4.15668)
     | > current_lr: 0.00007 
     | > step_time: 4.73220  (3.62073)
     | > loader_time: 0.03890  (0.03023)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 277725[0m
     | > decoder_loss: 1.95103  (1.76964)
     | > postnet_loss: 1.45716  (1.41665)
     | > stopnet_loss: 1.91020  (1.57769)
     | > decoder_coarse_loss: 1.87827  (1.71137)
     | > decoder_ddc_loss: 0.00080  (0.00128)
     | > ga_loss: 0.00179  (0.00211)
     | > decoder_diff_spec_loss: 0.51815  (0.48798)
     | > postnet_diff_spec_loss: 0.82336  (0.80262)
     | > decoder_ssim_loss: 0.25243  (0.30521)
     | > postnet_ssim_loss: 0.25537  (0.32073)
     | > loss: 3.70327  (3.29213)
     | > align_error: 0.99207  (0.98839)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.57945  (3.96133)
     | > current_lr: 0.00007 
     | > step_time: 4.68430  (3.66553)
     | > loader_time: 0.08990  (0.03041)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.63678 [0m(-0.04964)
     | > avg_decoder_loss:[92m 2.07577 [0m(-0.14743)
     | > avg_postnet_loss:[92m 1.70452 [0m(-0.19395)
     | > avg_stopnet_loss:[92m 1.53658 [0m(-0.00056)
     | > avg_decoder_coarse_loss:[92m 1.91403 [0m(-0.23055)
     | > avg_decoder_ddc_loss:[91m 0.00110 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00232 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.50344 [0m(+0.00211)
     | > avg_postnet_diff_spec_loss:[92m 0.82631 [0m(-0.00128)
     | > avg_decoder_ssim_loss:[92m 0.29573 [0m(-0.00037)
     | > avg_postnet_ssim_loss:[92m 0.31453 [0m(-0.00200)
     | > avg_loss:[92m 3.45702 [0m(-0.14399)
     | > avg_align_error:[92m 0.99022 [0m(-0.00010)


[4m[1m > EPOCH: 88/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:30:39) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 277750[0m
     | > decoder_loss: 1.49950  (1.70013)
     | > postnet_loss: 1.24884  (1.38440)
     | > stopnet_loss: 1.61284  (1.54624)
     | > decoder_coarse_loss: 1.46676  (1.65679)
     | > decoder_ddc_loss: 0.00078  (0.00105)
     | > ga_loss: 0.00158  (0.00195)
     | > decoder_diff_spec_loss: 0.42830  (0.46439)
     | > postnet_diff_spec_loss: 0.77323  (0.78777)
     | > decoder_ssim_loss: 0.27180  (0.29932)
     | > postnet_ssim_loss: 0.29983  (0.31792)
     | > loss: 3.11801  (3.20892)
     | > align_error: 0.99205  (0.99018)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.24790  (2.73383)
     | > current_lr: 0.00007 
     | > step_time: 4.44650  (4.53939)
     | > loader_time: 0.05240  (0.03545)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 277775[0m
     | > decoder_loss: 1.65927  (1.76154)
     | > postnet_loss: 1.35087  (1.42722)
     | > stopnet_loss: 1.32832  (1.52375)
     | > decoder_coarse_loss: 1.63916  (1.71481)
     | > decoder_ddc_loss: 0.00130  (0.00127)
     | > ga_loss: 0.00219  (0.00213)
     | > decoder_diff_spec_loss: 0.48769  (0.48729)
     | > postnet_diff_spec_loss: 0.78439  (0.80093)
     | > decoder_ssim_loss: 0.34494  (0.30937)
     | > postnet_ssim_loss: 0.36192  (0.32558)
     | > loss: 2.99668  (3.24143)
     | > align_error: 0.98852  (0.98854)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.09412  (3.77682)
     | > current_lr: 0.00007 
     | > step_time: 2.42520  (3.69698)
     | > loader_time: 0.05990  (0.04014)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 277800[0m
     | > decoder_loss: 1.82338  (1.76536)
     | > postnet_loss: 1.40078  (1.42856)
     | > stopnet_loss: 1.10202  (1.58244)
     | > decoder_coarse_loss: 1.75473  (1.71140)
     | > decoder_ddc_loss: 0.00107  (0.00125)
     | > ga_loss: 0.00172  (0.00211)
     | > decoder_diff_spec_loss: 0.49284  (0.48678)
     | > postnet_diff_spec_loss: 0.79858  (0.80270)
     | > decoder_ssim_loss: 0.36659  (0.30299)
     | > postnet_ssim_loss: 0.38881  (0.31887)
     | > loss: 2.86731  (3.29745)
     | > align_error: 0.99118  (0.98864)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.60535  (3.85996)
     | > current_lr: 0.00007 
     | > step_time: 4.41360  (3.72227)
     | > loader_time: 0.01920  (0.03351)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 277825[0m
     | > decoder_loss: 1.83084  (1.77136)
     | > postnet_loss: 1.48670  (1.42648)
     | > stopnet_loss: 1.65092  (1.58250)
     | > decoder_coarse_loss: 1.75007  (1.71886)
     | > decoder_ddc_loss: 0.00229  (0.00129)
     | > ga_loss: 0.00375  (0.00214)
     | > decoder_diff_spec_loss: 0.47583  (0.48706)
     | > postnet_diff_spec_loss: 0.80983  (0.80309)
     | > decoder_ssim_loss: 0.32484  (0.30399)
     | > postnet_ssim_loss: 0.34830  (0.31998)
     | > loss: 3.42684  (3.30121)
     | > align_error: 0.98117  (0.98830)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 14.95775  (3.95553)
     | > current_lr: 0.00007 
     | > step_time: 1.41320  (3.64133)
     | > loader_time: 0.01790  (0.03152)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.51043 [0m(-0.12634)
     | > avg_decoder_loss:[92m 2.03659 [0m(-0.03918)
     | > avg_postnet_loss:[92m 1.68653 [0m(-0.01798)
     | > avg_stopnet_loss:[92m 1.53581 [0m(-0.00077)
     | > avg_decoder_coarse_loss:[92m 1.84220 [0m(-0.07182)
     | > avg_decoder_ddc_loss:[91m 0.00110 [0m(+0.00000)
     | > avg_ga_loss:[92m 0.00231 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50291 [0m(-0.00053)
     | > avg_postnet_diff_spec_loss:[92m 0.82464 [0m(-0.00167)
     | > avg_decoder_ssim_loss:[92m 0.29536 [0m(-0.00038)
     | > avg_postnet_ssim_loss:[92m 0.31385 [0m(-0.00068)
     | > avg_loss:[92m 3.42315 [0m(-0.03387)
     | > avg_align_error:[92m 0.99019 [0m(-0.00003)


[4m[1m > EPOCH: 89/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:37:54) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 277850[0m
     | > decoder_loss: 1.87650  (1.73620)
     | > postnet_loss: 1.42741  (1.38993)
     | > stopnet_loss: 1.71699  (1.47750)
     | > decoder_coarse_loss: 1.87415  (1.68829)
     | > decoder_ddc_loss: 0.00110  (0.00126)
     | > ga_loss: 0.00220  (0.00216)
     | > decoder_diff_spec_loss: 0.50973  (0.48038)
     | > postnet_diff_spec_loss: 0.82094  (0.79678)
     | > decoder_ssim_loss: 0.27921  (0.31397)
     | > postnet_ssim_loss: 0.29486  (0.32998)
     | > loss: 3.49896  (3.17249)
     | > align_error: 0.98925  (0.98862)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.66712  (3.65143)
     | > current_lr: 0.00007 
     | > step_time: 2.46260  (3.86681)
     | > loader_time: 0.01620  (0.03928)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 277875[0m
     | > decoder_loss: 1.83212  (1.76049)
     | > postnet_loss: 1.45636  (1.41886)
     | > stopnet_loss: 1.20416  (1.52652)
     | > decoder_coarse_loss: 1.78589  (1.70449)
     | > decoder_ddc_loss: 0.00190  (0.00129)
     | > ga_loss: 0.00243  (0.00214)
     | > decoder_diff_spec_loss: 0.49036  (0.48672)
     | > postnet_diff_spec_loss: 0.80182  (0.80096)
     | > decoder_ssim_loss: 0.37730  (0.30889)
     | > postnet_ssim_loss: 0.40257  (0.32446)
     | > loss: 3.00340  (3.23875)
     | > align_error: 0.98357  (0.98825)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.46062  (4.25807)
     | > current_lr: 0.00007 
     | > step_time: 2.95380  (3.67065)
     | > loader_time: 0.02080  (0.03235)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 277900[0m
     | > decoder_loss: 2.03916  (1.76627)
     | > postnet_loss: 1.56651  (1.41759)
     | > stopnet_loss: 1.64356  (1.56446)
     | > decoder_coarse_loss: 1.91991  (1.70794)
     | > decoder_ddc_loss: 0.00138  (0.00127)
     | > ga_loss: 0.00227  (0.00212)
     | > decoder_diff_spec_loss: 0.53248  (0.48623)
     | > postnet_diff_spec_loss: 0.82937  (0.80190)
     | > decoder_ssim_loss: 0.28420  (0.30571)
     | > postnet_ssim_loss: 0.29935  (0.32146)
     | > loss: 3.52301  (3.27715)
     | > align_error: 0.98641  (0.98834)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.90475  (3.97105)
     | > current_lr: 0.00007 
     | > step_time: 2.94190  (3.68940)
     | > loader_time: 0.05940  (0.03299)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.47362 [0m(-0.03681)
     | > avg_decoder_loss:[91m 2.05349 [0m(+0.01690)
     | > avg_postnet_loss:[91m 1.76953 [0m(+0.08300)
     | > avg_stopnet_loss:[92m 1.53561 [0m(-0.00020)
     | > avg_decoder_coarse_loss:[91m 1.86766 [0m(+0.02546)
     | > avg_decoder_ddc_loss:[91m 0.00112 [0m(+0.00003)
     | > avg_ga_loss:[92m 0.00230 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50240 [0m(-0.00051)
     | > avg_postnet_diff_spec_loss:[91m 0.82627 [0m(+0.00162)
     | > avg_decoder_ssim_loss:[92m 0.29510 [0m(-0.00026)
     | > avg_postnet_ssim_loss:[91m 0.31574 [0m(+0.00189)
     | > avg_loss:[91m 3.45492 [0m(+0.03178)
     | > avg_align_error:[92m 0.99009 [0m(-0.00010)


[4m[1m > EPOCH: 90/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:45:02) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 277925[0m
     | > decoder_loss: 1.79370  (1.70927)
     | > postnet_loss: 1.46227  (1.37745)
     | > stopnet_loss: 1.43385  (1.53710)
     | > decoder_coarse_loss: 1.71948  (1.66372)
     | > decoder_ddc_loss: 0.00084  (0.00110)
     | > ga_loss: 0.00179  (0.00201)
     | > decoder_diff_spec_loss: 0.48008  (0.47406)
     | > postnet_diff_spec_loss: 0.80147  (0.79055)
     | > decoder_ssim_loss: 0.31555  (0.30430)
     | > postnet_ssim_loss: 0.33413  (0.32162)
     | > loss: 3.16966  (3.20769)
     | > align_error: 0.99169  (0.98959)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.65945  (2.26187)
     | > current_lr: 0.00007 
     | > step_time: 4.50550  (4.56414)
     | > loader_time: 0.03730  (0.04950)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 277950[0m
     | > decoder_loss: 1.93230  (1.75087)
     | > postnet_loss: 1.46466  (1.40438)
     | > stopnet_loss: 1.74306  (1.51906)
     | > decoder_coarse_loss: 1.84793  (1.69371)
     | > decoder_ddc_loss: 0.00132  (0.00131)
     | > ga_loss: 0.00203  (0.00211)
     | > decoder_diff_spec_loss: 0.52973  (0.48744)
     | > postnet_diff_spec_loss: 0.83099  (0.80043)
     | > decoder_ssim_loss: 0.27281  (0.30769)
     | > postnet_ssim_loss: 0.28162  (0.32369)
     | > loss: 3.54354  (3.22198)
     | > align_error: 0.98761  (0.98826)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.98024  (3.86102)
     | > current_lr: 0.00007 
     | > step_time: 3.87450  (3.73051)
     | > loader_time: 0.02130  (0.02871)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 277975[0m
     | > decoder_loss: 1.58247  (1.75463)
     | > postnet_loss: 1.35994  (1.41012)
     | > stopnet_loss: 1.22711  (1.58983)
     | > decoder_coarse_loss: 1.56043  (1.69820)
     | > decoder_ddc_loss: 0.00171  (0.00128)
     | > ga_loss: 0.00238  (0.00210)
     | > decoder_diff_spec_loss: 0.43617  (0.48653)
     | > postnet_diff_spec_loss: 0.78386  (0.80196)
     | > decoder_ssim_loss: 0.37369  (0.30139)
     | > postnet_ssim_loss: 0.40040  (0.31715)
     | > loss: 2.86368  (3.29313)
     | > align_error: 0.98643  (0.98839)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.40876  (4.12751)
     | > current_lr: 0.00007 
     | > step_time: 2.66160  (3.70859)
     | > loader_time: 0.05510  (0.03137)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 278000[0m
     | > decoder_loss: 1.68626  (1.75965)
     | > postnet_loss: 1.34059  (1.40872)
     | > stopnet_loss: 1.49878  (1.58023)
     | > decoder_coarse_loss: 1.60684  (1.70401)
     | > decoder_ddc_loss: 0.00120  (0.00130)
     | > ga_loss: 0.00195  (0.00210)
     | > decoder_diff_spec_loss: 0.45426  (0.48695)
     | > postnet_diff_spec_loss: 0.77126  (0.80234)
     | > decoder_ssim_loss: 0.30099  (0.30330)
     | > postnet_ssim_loss: 0.32009  (0.31915)
     | > loss: 3.12892  (3.28711)
     | > align_error: 0.98838  (0.98824)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.34328  (3.86672)
     | > current_lr: 0.00007 
     | > step_time: 2.65380  (3.65578)
     | > loader_time: 0.01700  (0.03563)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.52927 [0m(+0.05565)
     | > avg_decoder_loss:[91m 2.11621 [0m(+0.06272)
     | > avg_postnet_loss:[91m 1.82164 [0m(+0.05211)
     | > avg_stopnet_loss:[92m 1.53453 [0m(-0.00107)
     | > avg_decoder_coarse_loss:[91m 1.87826 [0m(+0.01060)
     | > avg_decoder_ddc_loss:[91m 0.00112 [0m(+0.00000)
     | > avg_ga_loss:[92m 0.00228 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.50258 [0m(+0.00019)
     | > avg_postnet_diff_spec_loss:[92m 0.82587 [0m(-0.00040)
     | > avg_decoder_ssim_loss:[92m 0.29507 [0m(-0.00003)
     | > avg_postnet_ssim_loss:[92m 0.31531 [0m(-0.00043)
     | > avg_loss:[91m 3.48497 [0m(+0.03005)
     | > avg_align_error:[92m 0.99003 [0m(-0.00006)


[4m[1m > EPOCH: 91/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:52:14) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 278025[0m
     | > decoder_loss: 1.71993  (1.70771)
     | > postnet_loss: 1.32322  (1.36702)
     | > stopnet_loss: 1.71988  (1.47700)
     | > decoder_coarse_loss: 1.62155  (1.65530)
     | > decoder_ddc_loss: 0.00098  (0.00132)
     | > ga_loss: 0.00169  (0.00213)
     | > decoder_diff_spec_loss: 0.46177  (0.47918)
     | > postnet_diff_spec_loss: 0.77140  (0.79537)
     | > decoder_ssim_loss: 0.26646  (0.31517)
     | > postnet_ssim_loss: 0.28377  (0.33196)
     | > loss: 3.34061  (3.15091)
     | > align_error: 0.99074  (0.98830)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.24805  (3.19407)
     | > current_lr: 0.00007 
     | > step_time: 4.65100  (3.84429)
     | > loader_time: 0.01710  (0.03817)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 278050[0m
     | > decoder_loss: 1.69522  (1.75087)
     | > postnet_loss: 1.38653  (1.40129)
     | > stopnet_loss: 1.30196  (1.54168)
     | > decoder_coarse_loss: 1.63860  (1.68582)
     | > decoder_ddc_loss: 0.00169  (0.00133)
     | > ga_loss: 0.00233  (0.00211)
     | > decoder_diff_spec_loss: 0.47151  (0.48750)
     | > postnet_diff_spec_loss: 0.80674  (0.80106)
     | > decoder_ssim_loss: 0.35586  (0.30678)
     | > postnet_ssim_loss: 0.37259  (0.32230)
     | > loss: 2.99577  (3.24146)
     | > align_error: 0.98629  (0.98811)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.88269  (4.09888)
     | > current_lr: 0.00007 
     | > step_time: 2.65420  (3.64192)
     | > loader_time: 0.01800  (0.03415)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 278075[0m
     | > decoder_loss: 1.83808  (1.75301)
     | > postnet_loss: 1.41861  (1.40145)
     | > stopnet_loss: 1.54864  (1.56639)
     | > decoder_coarse_loss: 1.78282  (1.69297)
     | > decoder_ddc_loss: 0.00097  (0.00131)
     | > ga_loss: 0.00181  (0.00210)
     | > decoder_diff_spec_loss: 0.53458  (0.48583)
     | > postnet_diff_spec_loss: 0.83223  (0.80143)
     | > decoder_ssim_loss: 0.29383  (0.30562)
     | > postnet_ssim_loss: 0.30560  (0.32156)
     | > loss: 3.30938  (3.26767)
     | > align_error: 0.99081  (0.98818)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.81014  (3.87444)
     | > current_lr: 0.00007 
     | > step_time: 4.59150  (3.66261)
     | > loader_time: 0.02210  (0.03288)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.37085 [0m(-0.15842)
     | > avg_decoder_loss:[92m 2.07669 [0m(-0.03952)
     | > avg_postnet_loss:[92m 1.77890 [0m(-0.04274)
     | > avg_stopnet_loss:[91m 1.53520 [0m(+0.00067)
     | > avg_decoder_coarse_loss:[91m 1.88641 [0m(+0.00815)
     | > avg_decoder_ddc_loss:[92m 0.00112 [0m(-0.00000)
     | > avg_ga_loss:[91m 0.00229 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.50296 [0m(+0.00037)
     | > avg_postnet_diff_spec_loss:[91m 0.82597 [0m(+0.00010)
     | > avg_decoder_ssim_loss:[92m 0.29500 [0m(-0.00006)
     | > avg_postnet_ssim_loss:[91m 0.31562 [0m(+0.00031)
     | > avg_loss:[92m 3.46730 [0m(-0.01767)
     | > avg_align_error:[92m 0.98999 [0m(-0.00003)


[4m[1m > EPOCH: 92/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:59:23) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 278100[0m
     | > decoder_loss: 1.77878  (1.69500)
     | > postnet_loss: 1.39932  (1.34568)
     | > stopnet_loss: 1.28622  (1.55912)
     | > decoder_coarse_loss: 1.72869  (1.62829)
     | > decoder_ddc_loss: 0.00164  (0.00122)
     | > ga_loss: 0.00229  (0.00206)
     | > decoder_diff_spec_loss: 0.48574  (0.47122)
     | > postnet_diff_spec_loss: 0.80711  (0.78624)
     | > decoder_ssim_loss: 0.34744  (0.30117)
     | > postnet_ssim_loss: 0.36767  (0.31675)
     | > loss: 3.02677  (3.20583)
     | > align_error: 0.98591  (0.98896)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.55969  (2.08715)
     | > current_lr: 0.00007 
     | > step_time: 2.81600  (4.74533)
     | > loader_time: 0.03500  (0.06788)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 278125[0m
     | > decoder_loss: 2.04871  (1.73774)
     | > postnet_loss: 1.51195  (1.38515)
     | > stopnet_loss: 1.20849  (1.51436)
     | > decoder_coarse_loss: 1.98368  (1.67886)
     | > decoder_ddc_loss: 0.00113  (0.00132)
     | > ga_loss: 0.00164  (0.00210)
     | > decoder_diff_spec_loss: 0.54039  (0.48437)
     | > postnet_diff_spec_loss: 0.79554  (0.79888)
     | > decoder_ssim_loss: 0.34327  (0.30851)
     | > postnet_ssim_loss: 0.36790  (0.32442)
     | > loss: 3.11485  (3.20467)
     | > align_error: 0.98955  (0.98823)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.43088  (3.50303)
     | > current_lr: 0.00007 
     | > step_time: 3.96830  (3.63972)
     | > loader_time: 0.01900  (0.03678)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 278150[0m
     | > decoder_loss: 1.74210  (1.74960)
     | > postnet_loss: 1.41082  (1.39462)
     | > stopnet_loss: 2.59508  (1.58981)
     | > decoder_coarse_loss: 1.65384  (1.68594)
     | > decoder_ddc_loss: 0.00101  (0.00129)
     | > ga_loss: 0.00229  (0.00207)
     | > decoder_diff_spec_loss: 0.49466  (0.48630)
     | > postnet_diff_spec_loss: 0.80631  (0.80169)
     | > decoder_ssim_loss: 0.19044  (0.29965)
     | > postnet_ssim_loss: 0.19727  (0.31491)
     | > loss: 4.23063  (3.28366)
     | > align_error: 0.98943  (0.98832)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.46579  (3.78958)
     | > current_lr: 0.00007 
     | > step_time: 4.39640  (3.64235)
     | > loader_time: 0.02230  (0.03293)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 278175[0m
     | > decoder_loss: 1.97091  (1.75331)
     | > postnet_loss: 1.48806  (1.39627)
     | > stopnet_loss: 1.08305  (1.57429)
     | > decoder_coarse_loss: 1.87526  (1.68861)
     | > decoder_ddc_loss: 0.00135  (0.00131)
     | > ga_loss: 0.00192  (0.00209)
     | > decoder_diff_spec_loss: 0.53879  (0.48643)
     | > postnet_diff_spec_loss: 0.82034  (0.80207)
     | > decoder_ssim_loss: 0.38453  (0.30294)
     | > postnet_ssim_loss: 0.40256  (0.31856)
     | > loss: 2.96311  (3.27210)
     | > align_error: 0.98695  (0.98811)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.98662  (3.64372)
     | > current_lr: 0.00007 
     | > step_time: 2.90470  (3.62309)
     | > loader_time: 0.03490  (0.03190)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.58992 [0m(+0.21907)
     | > avg_decoder_loss:[92m 2.06741 [0m(-0.00928)
     | > avg_postnet_loss:[92m 1.75839 [0m(-0.02050)
     | > avg_stopnet_loss:[91m 1.53558 [0m(+0.00038)
     | > avg_decoder_coarse_loss:[92m 1.87739 [0m(-0.00902)
     | > avg_decoder_ddc_loss:[92m 0.00109 [0m(-0.00003)
     | > avg_ga_loss:[91m 0.00229 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.50417 [0m(+0.00121)
     | > avg_postnet_diff_spec_loss:[91m 0.82646 [0m(+0.00048)
     | > avg_decoder_ssim_loss:[92m 0.29493 [0m(-0.00008)
     | > avg_postnet_ssim_loss:[92m 0.31541 [0m(-0.00021)
     | > avg_loss:[92m 3.45833 [0m(-0.00897)
     | > avg_align_error:[91m 0.99007 [0m(+0.00007)


[4m[1m > EPOCH: 93/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:06:29) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 278200[0m
     | > decoder_loss: 1.61325  (1.71839)
     | > postnet_loss: 1.29970  (1.37329)
     | > stopnet_loss: 1.13942  (1.45484)
     | > decoder_coarse_loss: 1.55481  (1.66209)
     | > decoder_ddc_loss: 0.00184  (0.00136)
     | > ga_loss: 0.00252  (0.00214)
     | > decoder_diff_spec_loss: 0.45782  (0.48073)
     | > postnet_diff_spec_loss: 0.78977  (0.79670)
     | > decoder_ssim_loss: 0.39648  (0.31834)
     | > postnet_ssim_loss: 0.42557  (0.33489)
     | > loss: 2.78684  (3.13697)
     | > align_error: 0.98546  (0.98802)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 4.20027  (3.21270)
     | > current_lr: 0.00007 
     | > step_time: 2.33500  (3.70486)
     | > loader_time: 0.02100  (0.03366)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 278225[0m
     | > decoder_loss: 1.97502  (1.74943)
     | > postnet_loss: 1.49521  (1.39251)
     | > stopnet_loss: 1.28201  (1.54065)
     | > decoder_coarse_loss: 1.88103  (1.68973)
     | > decoder_ddc_loss: 0.00167  (0.00132)
     | > ga_loss: 0.00208  (0.00209)
     | > decoder_diff_spec_loss: 0.54057  (0.48652)
     | > postnet_diff_spec_loss: 0.83441  (0.80016)
     | > decoder_ssim_loss: 0.34878  (0.30532)
     | > postnet_ssim_loss: 0.35626  (0.32076)
     | > loss: 3.15065  (3.23757)
     | > align_error: 0.98561  (0.98813)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.12953  (3.86345)
     | > current_lr: 0.00007 
     | > step_time: 3.34670  (3.65918)
     | > loader_time: 0.02560  (0.03646)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 278250[0m
     | > decoder_loss: 1.89083  (1.74888)
     | > postnet_loss: 1.41873  (1.39309)
     | > stopnet_loss: 1.65464  (1.55984)
     | > decoder_coarse_loss: 1.83249  (1.68769)
     | > decoder_ddc_loss: 0.00098  (0.00133)
     | > ga_loss: 0.00188  (0.00209)
     | > decoder_diff_spec_loss: 0.51673  (0.48403)
     | > postnet_diff_spec_loss: 0.81246  (0.80033)
     | > decoder_ssim_loss: 0.28339  (0.30550)
     | > postnet_ssim_loss: 0.29288  (0.32136)
     | > loss: 3.42618  (3.25583)
     | > align_error: 0.99099  (0.98804)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.98446  (3.73610)
     | > current_lr: 0.00007 
     | > step_time: 4.38500  (3.67122)
     | > loader_time: 0.01890  (0.03301)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.74328 [0m(+0.15336)
     | > avg_decoder_loss:[92m 2.04964 [0m(-0.01777)
     | > avg_postnet_loss:[92m 1.75097 [0m(-0.00742)
     | > avg_stopnet_loss:[92m 1.53299 [0m(-0.00260)
     | > avg_decoder_coarse_loss:[91m 1.89638 [0m(+0.01899)
     | > avg_decoder_ddc_loss:[91m 0.00115 [0m(+0.00006)
     | > avg_ga_loss:[92m 0.00228 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50303 [0m(-0.00114)
     | > avg_postnet_diff_spec_loss:[92m 0.82592 [0m(-0.00054)
     | > avg_decoder_ssim_loss:[92m 0.29444 [0m(-0.00049)
     | > avg_postnet_ssim_loss:[92m 0.31517 [0m(-0.00023)
     | > avg_loss:[92m 3.45357 [0m(-0.00477)
     | > avg_align_error:[92m 0.98988 [0m(-0.00019)


[4m[1m > EPOCH: 94/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:13:38) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 278275[0m
     | > decoder_loss: 1.67326  (1.65947)
     | > postnet_loss: 1.35584  (1.33025)
     | > stopnet_loss: 1.40763  (1.61754)
     | > decoder_coarse_loss: 1.58081  (1.58576)
     | > decoder_ddc_loss: 0.00121  (0.00107)
     | > ga_loss: 0.00194  (0.00197)
     | > decoder_diff_spec_loss: 0.46215  (0.46461)
     | > postnet_diff_spec_loss: 0.77447  (0.77956)
     | > decoder_ssim_loss: 0.32215  (0.28491)
     | > postnet_ssim_loss: 0.33570  (0.30001)
     | > loss: 3.04373  (3.22883)
     | > align_error: 0.98829  (0.98994)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.16939  (1.91873)
     | > current_lr: 0.00007 
     | > step_time: 3.58050  (5.07440)
     | > loader_time: 0.02130  (0.06833)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 278300[0m
     | > decoder_loss: 1.87226  (1.72376)
     | > postnet_loss: 1.50223  (1.38226)
     | > stopnet_loss: 1.20469  (1.51854)
     | > decoder_coarse_loss: 1.79017  (1.66274)
     | > decoder_ddc_loss: 0.00182  (0.00131)
     | > ga_loss: 0.00236  (0.00211)
     | > decoder_diff_spec_loss: 0.52403  (0.48209)
     | > postnet_diff_spec_loss: 0.82079  (0.79867)
     | > decoder_ssim_loss: 0.36636  (0.30684)
     | > postnet_ssim_loss: 0.38209  (0.32259)
     | > loss: 3.03143  (3.19917)
     | > align_error: 0.98467  (0.98816)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.45645  (3.69387)
     | > current_lr: 0.00007 
     | > step_time: 2.61970  (3.69346)
     | > loader_time: 0.01820  (0.04090)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 278325[0m
     | > decoder_loss: 1.71745  (1.75040)
     | > postnet_loss: 1.29836  (1.39792)
     | > stopnet_loss: 1.84194  (1.57161)
     | > decoder_coarse_loss: 1.61641  (1.68695)
     | > decoder_ddc_loss: 0.00105  (0.00127)
     | > ga_loss: 0.00208  (0.00207)
     | > decoder_diff_spec_loss: 0.47450  (0.48556)
     | > postnet_diff_spec_loss: 0.78637  (0.80143)
     | > decoder_ssim_loss: 0.25800  (0.30132)
     | > postnet_ssim_loss: 0.27259  (0.31700)
     | > loss: 3.45850  (3.26741)
     | > align_error: 0.99000  (0.98835)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.29767  (3.84936)
     | > current_lr: 0.00007 
     | > step_time: 3.58910  (3.69641)
     | > loader_time: 0.01790  (0.03915)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 278350[0m
     | > decoder_loss: 1.58297  (1.75062)
     | > postnet_loss: 1.29624  (1.39591)
     | > stopnet_loss: 1.33400  (1.58292)
     | > decoder_coarse_loss: 1.54278  (1.68918)
     | > decoder_ddc_loss: 0.00115  (0.00130)
     | > ga_loss: 0.00161  (0.00209)
     | > decoder_diff_spec_loss: 0.44351  (0.48549)
     | > postnet_diff_spec_loss: 0.77828  (0.80158)
     | > decoder_ssim_loss: 0.32397  (0.30157)
     | > postnet_ssim_loss: 0.34612  (0.31732)
     | > loss: 2.92083  (3.27909)
     | > align_error: 0.99004  (0.98815)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.52059  (3.69800)
     | > current_lr: 0.00007 
     | > step_time: 3.36710  (3.65544)
     | > loader_time: 0.06100  (0.03721)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.24564 [0m(-0.49764)
     | > avg_decoder_loss:[92m 2.04470 [0m(-0.00494)
     | > avg_postnet_loss:[92m 1.72057 [0m(-0.03040)
     | > avg_stopnet_loss:[92m 1.53204 [0m(-0.00094)
     | > avg_decoder_coarse_loss:[92m 1.88537 [0m(-0.01101)
     | > avg_decoder_ddc_loss:[92m 0.00114 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00226 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.50351 [0m(+0.00048)
     | > avg_postnet_diff_spec_loss:[92m 0.82498 [0m(-0.00094)
     | > avg_decoder_ssim_loss:[92m 0.29434 [0m(-0.00010)
     | > avg_postnet_ssim_loss:[92m 0.31385 [0m(-0.00132)
     | > avg_loss:[92m 3.44046 [0m(-0.01310)
     | > avg_align_error:[92m 0.98983 [0m(-0.00004)


[4m[1m > EPOCH: 95/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:20:40) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 278375[0m
     | > decoder_loss: 1.62471  (1.71078)
     | > postnet_loss: 1.35353  (1.36967)
     | > stopnet_loss: 1.85138  (1.47537)
     | > decoder_coarse_loss: 1.55390  (1.66200)
     | > decoder_ddc_loss: 0.00153  (0.00134)
     | > ga_loss: 0.00219  (0.00210)
     | > decoder_diff_spec_loss: 0.45242  (0.48057)
     | > postnet_diff_spec_loss: 0.78562  (0.79605)
     | > decoder_ssim_loss: 0.25444  (0.31246)
     | > postnet_ssim_loss: 0.27311  (0.32830)
     | > loss: 3.43711  (3.15117)
     | > align_error: 0.98665  (0.98814)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.40151  (3.46852)
     | > current_lr: 0.00007 
     | > step_time: 3.72720  (3.77582)
     | > loader_time: 0.01700  (0.04817)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 278400[0m
     | > decoder_loss: 1.77032  (1.73725)
     | > postnet_loss: 1.41897  (1.39412)
     | > stopnet_loss: 1.41368  (1.54317)
     | > decoder_coarse_loss: 1.70488  (1.67616)
     | > decoder_ddc_loss: 0.00133  (0.00132)
     | > ga_loss: 0.00201  (0.00208)
     | > decoder_diff_spec_loss: 0.48630  (0.48492)
     | > postnet_diff_spec_loss: 0.80868  (0.79919)
     | > decoder_ssim_loss: 0.32058  (0.30388)
     | > postnet_ssim_loss: 0.34004  (0.31979)
     | > loss: 3.13650  (3.23274)
     | > align_error: 0.98793  (0.98810)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.33779  (3.89549)
     | > current_lr: 0.00007 
     | > step_time: 4.09840  (3.68364)
     | > loader_time: 0.02190  (0.03818)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 278425[0m
     | > decoder_loss: 1.76771  (1.73919)
     | > postnet_loss: 1.37000  (1.39288)
     | > stopnet_loss: 1.08847  (1.55767)
     | > decoder_coarse_loss: 1.69109  (1.67614)
     | > decoder_ddc_loss: 0.00169  (0.00133)
     | > ga_loss: 0.00203  (0.00208)
     | > decoder_diff_spec_loss: 0.49958  (0.48357)
     | > postnet_diff_spec_loss: 0.79400  (0.79985)
     | > decoder_ssim_loss: 0.39546  (0.30542)
     | > postnet_ssim_loss: 0.40978  (0.32168)
     | > loss: 2.83094  (3.24811)
     | > align_error: 0.98660  (0.98794)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.10828  (3.67488)
     | > current_lr: 0.00007 
     | > step_time: 3.33410  (3.66931)
     | > loader_time: 0.02020  (0.03356)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.58293 [0m(+0.33729)
     | > avg_decoder_loss:[91m 2.05926 [0m(+0.01456)
     | > avg_postnet_loss:[91m 1.86529 [0m(+0.14472)
     | > avg_stopnet_loss:[91m 1.53237 [0m(+0.00032)
     | > avg_decoder_coarse_loss:[92m 1.86703 [0m(-0.01834)
     | > avg_decoder_ddc_loss:[92m 0.00112 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00228 [0m(+0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.50126 [0m(-0.00225)
     | > avg_postnet_diff_spec_loss:[91m 0.82714 [0m(+0.00216)
     | > avg_decoder_ssim_loss:[92m 0.29434 [0m(-0.00000)
     | > avg_postnet_ssim_loss:[91m 0.31677 [0m(+0.00292)
     | > avg_loss:[91m 3.47682 [0m(+0.03636)
     | > avg_align_error:[91m 0.98997 [0m(+0.00014)


[4m[1m > EPOCH: 96/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:27:47) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 278450[0m
     | > decoder_loss: 1.72105  (1.65927)
     | > postnet_loss: 1.33439  (1.31143)
     | > stopnet_loss: 1.53170  (1.74907)
     | > decoder_coarse_loss: 1.68314  (1.59598)
     | > decoder_ddc_loss: 0.00119  (0.00103)
     | > ga_loss: 0.00204  (0.00198)
     | > decoder_diff_spec_loss: 0.47418  (0.46228)
     | > postnet_diff_spec_loss: 0.78132  (0.78262)
     | > decoder_ssim_loss: 0.29292  (0.26677)
     | > postnet_ssim_loss: 0.31018  (0.28290)
     | > loss: 3.19149  (3.34954)
     | > align_error: 0.98919  (0.99053)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.55185  (1.73978)
     | > current_lr: 0.00007 
     | > step_time: 5.08200  (5.96085)
     | > loader_time: 0.04960  (0.07490)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 278475[0m
     | > decoder_loss: 1.60782  (1.71380)
     | > postnet_loss: 1.28307  (1.36788)
     | > stopnet_loss: 1.89083  (1.53121)
     | > decoder_coarse_loss: 1.52518  (1.65681)
     | > decoder_ddc_loss: 0.00129  (0.00133)
     | > ga_loss: 0.00231  (0.00209)
     | > decoder_diff_spec_loss: 0.44278  (0.47986)
     | > postnet_diff_spec_loss: 0.76604  (0.79788)
     | > decoder_ssim_loss: 0.25087  (0.30478)
     | > postnet_ssim_loss: 0.26738  (0.32037)
     | > loss: 3.43850  (3.20236)
     | > align_error: 0.98717  (0.98816)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.19731  (3.42289)
     | > current_lr: 0.00007 
     | > step_time: 3.75810  (3.65489)
     | > loader_time: 0.05220  (0.03673)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 278500[0m
     | > decoder_loss: 1.61346  (1.74264)
     | > postnet_loss: 1.36072  (1.38521)
     | > stopnet_loss: 1.43994  (1.56683)
     | > decoder_coarse_loss: 1.55034  (1.68256)
     | > decoder_ddc_loss: 0.00111  (0.00131)
     | > ga_loss: 0.00180  (0.00206)
     | > decoder_diff_spec_loss: 0.43331  (0.48551)
     | > postnet_diff_spec_loss: 0.78681  (0.80142)
     | > decoder_ssim_loss: 0.30186  (0.30207)
     | > postnet_ssim_loss: 0.32288  (0.31762)
     | > loss: 3.04157  (3.25672)
     | > align_error: 0.99017  (0.98818)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 1.91318  (3.59085)
     | > current_lr: 0.00007 
     | > step_time: 3.86610  (3.62265)
     | > loader_time: 0.02770  (0.03477)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 278525[0m
     | > decoder_loss: 1.97146  (1.74362)
     | > postnet_loss: 1.52476  (1.38532)
     | > stopnet_loss: 2.02600  (1.58856)
     | > decoder_coarse_loss: 1.92489  (1.68332)
     | > decoder_ddc_loss: 0.00126  (0.00133)
     | > ga_loss: 0.00260  (0.00208)
     | > decoder_diff_spec_loss: 0.56971  (0.48572)
     | > postnet_diff_spec_loss: 0.86892  (0.80156)
     | > decoder_ssim_loss: 0.23852  (0.30106)
     | > postnet_ssim_loss: 0.24928  (0.31668)
     | > loss: 3.87618  (3.27863)
     | > align_error: 0.98790  (0.98797)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.96704  (3.50827)
     | > current_lr: 0.00007 
     | > step_time: 3.30830  (3.62610)
     | > loader_time: 0.02720  (0.03267)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.75000 [0m(+0.16707)
     | > avg_decoder_loss:[91m 2.09115 [0m(+0.03189)
     | > avg_postnet_loss:[92m 1.80007 [0m(-0.06522)
     | > avg_stopnet_loss:[92m 1.53184 [0m(-0.00053)
     | > avg_decoder_coarse_loss:[91m 1.90083 [0m(+0.03380)
     | > avg_decoder_ddc_loss:[92m 0.00110 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00229 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50060 [0m(-0.00066)
     | > avg_postnet_diff_spec_loss:[92m 0.82440 [0m(-0.00274)
     | > avg_decoder_ssim_loss:[92m 0.29432 [0m(-0.00002)
     | > avg_postnet_ssim_loss:[92m 0.31452 [0m(-0.00225)
     | > avg_loss:[92m 3.47503 [0m(-0.00179)
     | > avg_align_error:[91m 0.99002 [0m(+0.00004)


[4m[1m > EPOCH: 97/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:34:51) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 278550[0m
     | > decoder_loss: 1.68942  (1.70891)
     | > postnet_loss: 1.37231  (1.35945)
     | > stopnet_loss: 1.61329  (1.45145)
     | > decoder_coarse_loss: 1.60402  (1.65913)
     | > decoder_ddc_loss: 0.00176  (0.00135)
     | > ga_loss: 0.00298  (0.00210)
     | > decoder_diff_spec_loss: 0.46448  (0.48230)
     | > postnet_diff_spec_loss: 0.79353  (0.79668)
     | > decoder_ssim_loss: 0.29971  (0.31581)
     | > postnet_ssim_loss: 0.31591  (0.33178)
     | > loss: 3.26349  (3.12581)
     | > align_error: 0.98477  (0.98807)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 6.64123  (3.29800)
     | > current_lr: 0.00007 
     | > step_time: 2.56890  (3.73585)
     | > loader_time: 0.01470  (0.04187)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 278575[0m
     | > decoder_loss: 1.84041  (1.72627)
     | > postnet_loss: 1.49301  (1.37932)
     | > stopnet_loss: 1.35972  (1.55619)
     | > decoder_coarse_loss: 1.85570  (1.66980)
     | > decoder_ddc_loss: 0.00168  (0.00135)
     | > ga_loss: 0.00196  (0.00208)
     | > decoder_diff_spec_loss: 0.49638  (0.48421)
     | > postnet_diff_spec_loss: 0.81694  (0.79853)
     | > decoder_ssim_loss: 0.32074  (0.30273)
     | > postnet_ssim_loss: 0.33835  (0.31878)
     | > loss: 3.16034  (3.23685)
     | > align_error: 0.98695  (0.98797)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.79939  (4.03831)
     | > current_lr: 0.00007 
     | > step_time: 2.96070  (3.65926)
     | > loader_time: 0.06090  (0.03432)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 278600[0m
     | > decoder_loss: 1.63841  (1.73024)
     | > postnet_loss: 1.33590  (1.38195)
     | > stopnet_loss: 1.78128  (1.57181)
     | > decoder_coarse_loss: 1.58182  (1.67418)
     | > decoder_ddc_loss: 0.00157  (0.00136)
     | > ga_loss: 0.00233  (0.00208)
     | > decoder_diff_spec_loss: 0.45484  (0.48279)
     | > postnet_diff_spec_loss: 0.78362  (0.79965)
     | > decoder_ssim_loss: 0.27071  (0.30347)
     | > postnet_ssim_loss: 0.28443  (0.31989)
     | > loss: 3.38078  (3.25558)
     | > align_error: 0.98476  (0.98778)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.65213  (3.79452)
     | > current_lr: 0.00007 
     | > step_time: 2.92550  (3.67433)
     | > loader_time: 0.02170  (0.03557)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.48977 [0m(-0.26024)
     | > avg_decoder_loss:[91m 2.09693 [0m(+0.00578)
     | > avg_postnet_loss:[91m 1.82943 [0m(+0.02936)
     | > avg_stopnet_loss:[92m 1.53165 [0m(-0.00019)
     | > avg_decoder_coarse_loss:[92m 1.87532 [0m(-0.02552)
     | > avg_decoder_ddc_loss:[91m 0.00115 [0m(+0.00005)
     | > avg_ga_loss:[92m 0.00226 [0m(-0.00003)
     | > avg_decoder_diff_spec_loss:[91m 0.50190 [0m(+0.00129)
     | > avg_postnet_diff_spec_loss:[91m 0.82480 [0m(+0.00040)
     | > avg_decoder_ssim_loss:[92m 0.29412 [0m(-0.00020)
     | > avg_postnet_ssim_loss:[91m 0.31497 [0m(+0.00045)
     | > avg_loss:[91m 3.47760 [0m(+0.00257)
     | > avg_align_error:[92m 0.98973 [0m(-0.00028)


[4m[1m > EPOCH: 98/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:42:04) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 278625[0m
     | > decoder_loss: 1.55375  (1.55375)
     | > postnet_loss: 1.24884  (1.24884)
     | > stopnet_loss: 1.93097  (1.93097)
     | > decoder_coarse_loss: 1.52809  (1.52809)
     | > decoder_ddc_loss: 0.00081  (0.00081)
     | > ga_loss: 0.00194  (0.00194)
     | > decoder_diff_spec_loss: 0.45460  (0.45460)
     | > postnet_diff_spec_loss: 0.78202  (0.78202)
     | > decoder_ssim_loss: 0.24007  (0.24007)
     | > postnet_ssim_loss: 0.25421  (0.25421)
     | > loss: 3.45629  (3.45629)
     | > align_error: 0.99195  (0.99195)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 2.53009  (2.53009)
     | > current_lr: 0.00007 
     | > step_time: 6.27010  (6.27009)
     | > loader_time: 0.09610  (0.09610)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 278650[0m
     | > decoder_loss: 1.75975  (1.70500)
     | > postnet_loss: 1.41626  (1.36330)
     | > stopnet_loss: 1.87454  (1.51778)
     | > decoder_coarse_loss: 1.70084  (1.65893)
     | > decoder_ddc_loss: 0.00100  (0.00134)
     | > ga_loss: 0.00182  (0.00207)
     | > decoder_diff_spec_loss: 0.49698  (0.48081)
     | > postnet_diff_spec_loss: 0.81320  (0.79864)
     | > decoder_ssim_loss: 0.25129  (0.30614)
     | > postnet_ssim_loss: 0.25779  (0.32224)
     | > loss: 3.55792  (3.18723)
     | > align_error: 0.99065  (0.98810)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.42038  (4.16396)
     | > current_lr: 0.00007 
     | > step_time: 4.46810  (3.71725)
     | > loader_time: 0.05770  (0.03391)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 278675[0m
     | > decoder_loss: 1.81580  (1.73964)
     | > postnet_loss: 1.39803  (1.38474)
     | > stopnet_loss: 2.01479  (1.56634)
     | > decoder_coarse_loss: 1.70274  (1.68219)
     | > decoder_ddc_loss: 0.00106  (0.00133)
     | > ga_loss: 0.00210  (0.00205)
     | > decoder_diff_spec_loss: 0.48052  (0.48602)
     | > postnet_diff_spec_loss: 0.82096  (0.80145)
     | > decoder_ssim_loss: 0.23559  (0.30160)
     | > postnet_ssim_loss: 0.24757  (0.31729)
     | > loss: 3.70087  (3.25516)
     | > align_error: 0.98898  (0.98799)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 5.65107  (4.16028)
     | > current_lr: 0.00007 
     | > step_time: 4.05120  (3.67537)
     | > loader_time: 0.06760  (0.03350)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 278700[0m
     | > decoder_loss: 1.71304  (1.73445)
     | > postnet_loss: 1.48112  (1.38000)
     | > stopnet_loss: 2.30229  (1.57806)
     | > decoder_coarse_loss: 1.65020  (1.67906)
     | > decoder_ddc_loss: 0.00082  (0.00134)
     | > ga_loss: 0.00193  (0.00207)
     | > decoder_diff_spec_loss: 0.46735  (0.48406)
     | > postnet_diff_spec_loss: 0.80620  (0.80048)
     | > decoder_ssim_loss: 0.21706  (0.30147)
     | > postnet_ssim_loss: 0.22903  (0.31739)
     | > loss: 3.95313  (3.26295)
     | > align_error: 0.99126  (0.98785)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.91283  (3.81276)
     | > current_lr: 0.00007 
     | > step_time: 4.56580  (3.63459)
     | > loader_time: 0.02950  (0.03088)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.68869 [0m(+0.19893)
     | > avg_decoder_loss:[92m 2.07362 [0m(-0.02331)
     | > avg_postnet_loss:[92m 1.82700 [0m(-0.00243)
     | > avg_stopnet_loss:[92m 1.53037 [0m(-0.00128)
     | > avg_decoder_coarse_loss:[91m 1.92319 [0m(+0.04787)
     | > avg_decoder_ddc_loss:[92m 0.00113 [0m(-0.00003)
     | > avg_ga_loss:[91m 0.00227 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50064 [0m(-0.00126)
     | > avg_postnet_diff_spec_loss:[92m 0.82345 [0m(-0.00135)
     | > avg_decoder_ssim_loss:[92m 0.29393 [0m(-0.00019)
     | > avg_postnet_ssim_loss:[92m 0.31269 [0m(-0.00228)
     | > avg_loss:[91m 3.48063 [0m(+0.00303)
     | > avg_align_error:[91m 0.98975 [0m(+0.00001)


[4m[1m > EPOCH: 99/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:49:09) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 278725[0m
     | > decoder_loss: 1.71272  (1.71046)
     | > postnet_loss: 1.32013  (1.35090)
     | > stopnet_loss: 1.58000  (1.43863)
     | > decoder_coarse_loss: 1.65545  (1.65342)
     | > decoder_ddc_loss: 0.00139  (0.00132)
     | > ga_loss: 0.00229  (0.00201)
     | > decoder_diff_spec_loss: 0.51294  (0.48401)
     | > postnet_diff_spec_loss: 0.80999  (0.79655)
     | > decoder_ssim_loss: 0.29674  (0.31713)
     | > postnet_ssim_loss: 0.30404  (0.33259)
     | > loss: 3.24479  (3.11029)
     | > align_error: 0.98718  (0.98818)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.39729  (3.04871)
     | > current_lr: 0.00007 
     | > step_time: 3.22680  (3.93954)
     | > loader_time: 0.02120  (0.03383)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 278750[0m
     | > decoder_loss: 1.66383  (1.71576)
     | > postnet_loss: 1.31767  (1.36522)
     | > stopnet_loss: 1.97415  (1.55366)
     | > decoder_coarse_loss: 1.62042  (1.66239)
     | > decoder_ddc_loss: 0.00113  (0.00134)
     | > ga_loss: 0.00198  (0.00207)
     | > decoder_diff_spec_loss: 0.46742  (0.48355)
     | > postnet_diff_spec_loss: 0.78987  (0.79765)
     | > decoder_ssim_loss: 0.24023  (0.30207)
     | > postnet_ssim_loss: 0.25088  (0.31789)
     | > loss: 3.57194  (3.22549)
     | > align_error: 0.98828  (0.98791)
     | > amp_scaler: 16384.00000  (16384.00000)
     | > grad_norm: 3.79580  (3.87780)
     | > current_lr: 0.00007 
     | > step_time: 4.88250  (3.69374)
     | > loader_time: 0.02300  (0.02817)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 278775[0m
     | > decoder_loss: 1.65213  (1.72642)
     | > postnet_loss: 1.41386  (1.37409)
     | > stopnet_loss: 1.16336  (1.56260)
     | > decoder_coarse_loss: 1.59028  (1.66864)
     | > decoder_ddc_loss: 0.00125  (0.00136)
     | > ga_loss: 0.00197  (0.00207)
     | > decoder_diff_spec_loss: 0.45829  (0.48296)
     | > postnet_diff_spec_loss: 0.80908  (0.79962)
     | > decoder_ssim_loss: 0.36637  (0.30373)
     | > postnet_ssim_loss: 0.39582  (0.32011)
     | > loss: 2.84500  (3.24217)
     | > align_error: 0.98847  (0.98779)
     | > amp_scaler: 32768.00000  (16644.06349)
     | > grad_norm: 2.56029  (3.68279)
     | > current_lr: 0.00007 
     | > step_time: 3.35310  (3.62899)
     | > loader_time: 0.02680  (0.02951)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.72063 [0m(+0.03194)
     | > avg_decoder_loss:[92m 2.03859 [0m(-0.03503)
     | > avg_postnet_loss:[92m 1.78996 [0m(-0.03705)
     | > avg_stopnet_loss:[91m 1.53056 [0m(+0.00018)
     | > avg_decoder_coarse_loss:[92m 1.85988 [0m(-0.06330)
     | > avg_decoder_ddc_loss:[91m 0.00113 [0m(+0.00000)
     | > avg_ga_loss:[91m 0.00227 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.50177 [0m(+0.00113)
     | > avg_postnet_diff_spec_loss:[91m 0.82560 [0m(+0.00216)
     | > avg_decoder_ssim_loss:[92m 0.29365 [0m(-0.00028)
     | > avg_postnet_ssim_loss:[91m 0.31433 [0m(+0.00165)
     | > avg_loss:[92m 3.44813 [0m(-0.03250)
     | > avg_align_error:[91m 0.98978 [0m(+0.00003)

