 > Using CUDA:  True
 > Number of GPUs:  4
 > `speakers.json` is saved to /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf/speakers.json.
 > `speakers_file` is updated in the config.json.
 > Restoring from model_file.pth.tar ...
 > Restoring Model...
 > Partial model initialization...
 | > Layer missing in the model definition: encoder.convolutions.0.convolution1d.weight
 | > Layer missing in the model definition: encoder.convolutions.0.convolution1d.bias
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.weight
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.bias
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.running_mean
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.running_var
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: encoder.convolutions.1.convolution1d.weight
 | > Layer missing in the model definition: encoder.convolutions.1.convolution1d.bias
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.weight
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.bias
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.running_mean
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.running_var
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: encoder.convolutions.2.convolution1d.weight
 | > Layer missing in the model definition: encoder.convolutions.2.convolution1d.bias
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.weight
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.bias
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.running_mean
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.running_var
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: encoder.lstm.weight_ih_l0
 | > Layer missing in the model definition: encoder.lstm.weight_hh_l0
 | > Layer missing in the model definition: encoder.lstm.bias_ih_l0
 | > Layer missing in the model definition: encoder.lstm.bias_hh_l0
 | > Layer missing in the model definition: encoder.lstm.weight_ih_l0_reverse
 | > Layer missing in the model definition: encoder.lstm.weight_hh_l0_reverse
 | > Layer missing in the model definition: encoder.lstm.bias_ih_l0_reverse
 | > Layer missing in the model definition: encoder.lstm.bias_hh_l0_reverse
 | > Layer missing in the model definition: decoder.attention.prior
 | > Layer missing in the model definition: decoder.attention.query_layer.weight
 | > Layer missing in the model definition: decoder.attention.query_layer.bias
 | > Layer missing in the model definition: decoder.attention.key_layer.weight
 | > Layer missing in the model definition: decoder.attention.static_filter_conv.weight
 | > Layer missing in the model definition: decoder.attention.static_filter_layer.weight
 | > Layer missing in the model definition: decoder.attention.dynamic_filter_layer.weight
 | > Layer missing in the model definition: decoder.attention.dynamic_filter_layer.bias
 | > Layer missing in the model definition: decoder.attention.v.weight
 | > Layer missing in the model definition: decoder.decoder_rnn.weight_ih
 | > Layer missing in the model definition: decoder.decoder_rnn.weight_hh
 | > Layer missing in the model definition: decoder.decoder_rnn.bias_ih
 | > Layer missing in the model definition: decoder.decoder_rnn.bias_hh
 | > Layer missing in the model definition: decoder.linear_projection.linear_layer.weight
 | > Layer missing in the model definition: decoder.linear_projection.linear_layer.bias
 | > Layer missing in the model definition: decoder.stopnet.1.linear_layer.weight
 | > Layer missing in the model definition: decoder.stopnet.1.linear_layer.bias
 | > Layer missing in the model definition: postnet.convolutions.0.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.0.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.1.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.1.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.2.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.2.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.3.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.3.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.4.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.4.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.num_batches_tracked
 | > 1 / 281 layers are restored.
 > Model restored from step 270000

 > Model has 9749029 parameters
 > Restoring best loss from  ...
 > Starting with loaded last best loss 0.09947767853736877.

[4m[1m > EPOCH: 0/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 09:38:16) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 270000[0m
     | > decoder_loss: 32.09527  (32.09527)
     | > postnet_loss: 17.73347  (17.73347)
     | > stopnet_loss: 1.22274  (1.22274)
     | > decoder_coarse_loss: 32.19782  (32.19782)
     | > decoder_ddc_loss: 0.00063  (0.00063)
     | > ga_loss: 0.00277  (0.00277)
     | > decoder_diff_spec_loss: 0.41323  (0.41323)
     | > postnet_diff_spec_loss: 0.84427  (0.84427)
     | > decoder_ssim_loss: 0.58742  (0.58742)
     | > postnet_ssim_loss: 0.58736  (0.58736)
     | > loss: 22.35149  (22.35149)
     | > align_error: 0.99345  (0.99345)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.70246  (1.70246)
     | > current_lr: 2.5000000000000002e-08 
     | > step_time: 2.39750  (2.39745)
     | > loader_time: 11.91760  (11.91756)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 270025[0m
     | > decoder_loss: 34.66506  (34.05558)
     | > postnet_loss: 19.56840  (20.21666)
     | > stopnet_loss: 1.62264  (1.94483)
     | > decoder_coarse_loss: 34.80579  (34.17148)
     | > decoder_ddc_loss: 0.00059  (0.00055)
     | > ga_loss: 0.00258  (0.00263)
     | > decoder_diff_spec_loss: 0.42300  (0.43700)
     | > postnet_diff_spec_loss: 0.85244  (0.86499)
     | > decoder_ssim_loss: 0.44953  (0.39349)
     | > postnet_ssim_loss: 0.44950  (0.39346)
     | > loss: 24.43910  (24.59127)
     | > align_error: 0.99369  (0.99465)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.83154  (1.78261)
     | > current_lr: 6.5e-07 
     | > step_time: 3.35340  (3.99740)
     | > loader_time: 0.02200  (0.03606)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 270050[0m
     | > decoder_loss: 34.20626  (34.21482)
     | > postnet_loss: 21.12496  (20.27235)
     | > stopnet_loss: 1.84875  (1.92312)
     | > decoder_coarse_loss: 34.29517  (34.32986)
     | > decoder_ddc_loss: 0.00059  (0.00055)
     | > ga_loss: 0.00268  (0.00264)
     | > decoder_diff_spec_loss: 0.44639  (0.44060)
     | > postnet_diff_spec_loss: 0.85878  (0.87075)
     | > decoder_ssim_loss: 0.41439  (0.39693)
     | > postnet_ssim_loss: 0.41434  (0.39689)
     | > loss: 24.80239  (24.66700)
     | > align_error: 0.99384  (0.99451)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.92423  (1.79583)
     | > current_lr: 1.275e-06 
     | > step_time: 3.27340  (3.91028)
     | > loader_time: 0.02340  (0.03606)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 270075[0m
     | > decoder_loss: 31.98949  (34.07513)
     | > postnet_loss: 18.52859  (20.25998)
     | > stopnet_loss: 1.84442  (1.91052)
     | > decoder_coarse_loss: 32.07104  (34.18893)
     | > decoder_ddc_loss: 0.00056  (0.00055)
     | > ga_loss: 0.00224  (0.00270)
     | > decoder_diff_spec_loss: 0.44408  (0.43798)
     | > postnet_diff_spec_loss: 0.86890  (0.86820)
     | > decoder_ssim_loss: 0.38997  (0.39711)
     | > postnet_ssim_loss: 0.38994  (0.39707)
     | > loss: 23.02629  (24.58027)
     | > align_error: 0.99527  (0.99445)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.71593  (1.78818)
     | > current_lr: 1.9e-06 
     | > step_time: 4.87270  (3.82157)
     | > loader_time: 0.02820  (0.03533)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time: 5.09692 [0m(+0.00000)
     | > avg_decoder_loss: 30.73598 [0m(+0.00000)
     | > avg_postnet_loss: 18.74046 [0m(+0.00000)
     | > avg_stopnet_loss: 1.92131 [0m(+0.00000)
     | > avg_decoder_coarse_loss: 30.81125 [0m(+0.00000)
     | > avg_decoder_ddc_loss: 0.00031 [0m(+0.00000)
     | > avg_ga_loss: 0.00247 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss: 0.44103 [0m(+0.00000)
     | > avg_postnet_diff_spec_loss: 0.87720 [0m(+0.00000)
     | > avg_decoder_ssim_loss: 0.39271 [0m(+0.00000)
     | > avg_postnet_ssim_loss: 0.39267 [0m(+0.00000)
     | > avg_loss: 22.53154 [0m(+0.00000)
     | > avg_align_error: 0.99521 [0m(+0.00000)


[4m[1m > EPOCH: 1/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 09:46:10) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 270100[0m
     | > decoder_loss: 33.37584  (34.17419)
     | > postnet_loss: 19.01396  (19.98566)
     | > stopnet_loss: 1.71103  (1.83238)
     | > decoder_coarse_loss: 33.43844  (34.28683)
     | > decoder_ddc_loss: 0.00049  (0.00054)
     | > ga_loss: 0.00274  (0.00272)
     | > decoder_diff_spec_loss: 0.43804  (0.43494)
     | > postnet_diff_spec_loss: 0.87032  (0.86541)
     | > decoder_ssim_loss: 0.42468  (0.40885)
     | > postnet_ssim_loss: 0.42464  (0.40881)
     | > loss: 23.72135  (24.48729)
     | > align_error: 0.99454  (0.99444)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.69035  (1.76427)
     | > current_lr: 2.525e-06 
     | > step_time: 3.30680  (4.11860)
     | > loader_time: 0.02080  (0.04611)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 270125[0m
     | > decoder_loss: 34.23798  (33.87631)
     | > postnet_loss: 20.12893  (20.01848)
     | > stopnet_loss: 1.91334  (1.89291)
     | > decoder_coarse_loss: 34.35005  (33.98801)
     | > decoder_ddc_loss: 0.00059  (0.00053)
     | > ga_loss: 0.00295  (0.00269)
     | > decoder_diff_spec_loss: 0.42384  (0.43590)
     | > postnet_diff_spec_loss: 0.85378  (0.86522)
     | > decoder_ssim_loss: 0.38356  (0.40304)
     | > postnet_ssim_loss: 0.38353  (0.40301)
     | > loss: 24.61865  (24.40398)
     | > align_error: 0.99411  (0.99447)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.76799  (1.78670)
     | > current_lr: 3.1500000000000003e-06 
     | > step_time: 3.25260  (3.89820)
     | > loader_time: 0.02670  (0.03782)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 270150[0m
     | > decoder_loss: 32.77316  (34.12735)
     | > postnet_loss: 20.25375  (20.34244)
     | > stopnet_loss: 1.76701  (1.91568)
     | > decoder_coarse_loss: 32.89648  (34.23804)
     | > decoder_ddc_loss: 0.00037  (0.00053)
     | > ga_loss: 0.00267  (0.00272)
     | > decoder_diff_spec_loss: 0.39530  (0.43828)
     | > postnet_diff_spec_loss: 0.82718  (0.86888)
     | > decoder_ssim_loss: 0.41581  (0.39790)
     | > postnet_ssim_loss: 0.41578  (0.39786)
     | > loss: 23.77481  (24.63208)
     | > align_error: 0.99523  (0.99443)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.86885  (1.80294)
     | > current_lr: 3.7750000000000003e-06 
     | > step_time: 4.04990  (3.86648)
     | > loader_time: 0.03520  (0.03571)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 270175[0m
     | > decoder_loss: 39.41019  (34.10693)
     | > postnet_loss: 27.13209  (20.33550)
     | > stopnet_loss: 1.11111  (1.91576)
     | > decoder_coarse_loss: 39.46183  (34.21669)
     | > decoder_ddc_loss: 0.00074  (0.00052)
     | > ga_loss: 0.00422  (0.00270)
     | > decoder_diff_spec_loss: 0.43313  (0.43782)
     | > postnet_diff_spec_loss: 0.85006  (0.86862)
     | > decoder_ssim_loss: 0.68515  (0.39885)
     | > postnet_ssim_loss: 0.68511  (0.39882)
     | > loss: 28.29681  (24.62018)
     | > align_error: 0.98811  (0.99443)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.13929  (1.82486)
     | > current_lr: 4.4e-06 
     | > step_time: 1.27610  (3.74919)
     | > loader_time: 0.01370  (0.03341)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.40742 [0m(+0.31049)
     | > avg_decoder_loss:[92m 30.65923 [0m(-0.07675)
     | > avg_postnet_loss:[92m 18.70300 [0m(-0.03746)
     | > avg_stopnet_loss:[92m 1.91805 [0m(-0.00327)
     | > avg_decoder_coarse_loss:[92m 30.61668 [0m(-0.19457)
     | > avg_decoder_ddc_loss:[92m 0.00031 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00246 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.44191 [0m(+0.00088)
     | > avg_postnet_diff_spec_loss:[92m 0.87718 [0m(-0.00002)
     | > avg_decoder_ssim_loss:[92m 0.39270 [0m(-0.00001)
     | > avg_postnet_ssim_loss:[92m 0.39266 [0m(-0.00000)
     | > avg_loss:[92m 22.45128 [0m(-0.08026)
     | > avg_align_error:[91m 0.99522 [0m(+0.00000)


[4m[1m > EPOCH: 2/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 09:53:52) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 270200[0m
     | > decoder_loss: 32.06605  (33.79155)
     | > postnet_loss: 17.49950  (20.14050)
     | > stopnet_loss: 1.54045  (1.96691)
     | > decoder_coarse_loss: 32.14711  (33.90099)
     | > decoder_ddc_loss: 0.00046  (0.00049)
     | > ga_loss: 0.00258  (0.00262)
     | > decoder_diff_spec_loss: 0.43638  (0.44000)
     | > postnet_diff_spec_loss: 0.85439  (0.86536)
     | > decoder_ssim_loss: 0.48740  (0.39114)
     | > postnet_ssim_loss: 0.48739  (0.39111)
     | > loss: 22.54803  (24.46032)
     | > align_error: 0.99458  (0.99473)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.96958  (1.95177)
     | > current_lr: 0.00001 
     | > step_time: 3.83520  (3.96759)
     | > loader_time: 0.02430  (0.03274)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 270225[0m
     | > decoder_loss: 34.70715  (33.92215)
     | > postnet_loss: 20.03038  (20.13253)
     | > stopnet_loss: 1.99912  (1.93335)
     | > decoder_coarse_loss: 34.83541  (34.03245)
     | > decoder_ddc_loss: 0.00035  (0.00048)
     | > ga_loss: 0.00201  (0.00263)
     | > decoder_diff_spec_loss: 0.40548  (0.44434)
     | > postnet_diff_spec_loss: 0.83334  (0.87075)
     | > decoder_ssim_loss: 0.36254  (0.39655)
     | > postnet_ssim_loss: 0.36253  (0.39653)
     | > loss: 24.89345  (24.49547)
     | > align_error: 0.99572  (0.99457)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.30658  (2.04365)
     | > current_lr: 0.00001 
     | > step_time: 4.40050  (3.83582)
     | > loader_time: 0.05620  (0.03340)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 270250[0m
     | > decoder_loss: 34.07948  (33.74225)
     | > postnet_loss: 19.91213  (20.13775)
     | > stopnet_loss: 1.82825  (1.92139)
     | > decoder_coarse_loss: 34.21563  (33.85705)
     | > decoder_ddc_loss: 0.00052  (0.00047)
     | > ga_loss: 0.00224  (0.00270)
     | > decoder_diff_spec_loss: 0.46706  (0.44448)
     | > postnet_diff_spec_loss: 0.89900  (0.86788)
     | > decoder_ssim_loss: 0.40533  (0.39718)
     | > postnet_ssim_loss: 0.40532  (0.39716)
     | > loss: 24.43559  (24.39597)
     | > align_error: 0.99499  (0.99449)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.66493  (2.15678)
     | > current_lr: 0.00001 
     | > step_time: 3.45670  (3.68476)
     | > loader_time: 0.01850  (0.03228)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.17018 [0m(+0.76276)
     | > avg_decoder_loss:[92m 30.44615 [0m(-0.21308)
     | > avg_postnet_loss:[92m 18.64066 [0m(-0.06234)
     | > avg_stopnet_loss:[91m 1.92151 [0m(+0.00347)
     | > avg_decoder_coarse_loss:[92m 30.12909 [0m(-0.48759)
     | > avg_decoder_ddc_loss:[92m 0.00029 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00246 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.44795 [0m(+0.00605)
     | > avg_postnet_diff_spec_loss:[92m 0.87678 [0m(-0.00039)
     | > avg_decoder_ssim_loss:[92m 0.39267 [0m(-0.00002)
     | > avg_postnet_ssim_loss:[92m 0.39266 [0m(-0.00000)
     | > avg_loss:[92m 22.26537 [0m(-0.18591)
     | > avg_align_error:[91m 0.99523 [0m(+0.00001)


[4m[1m > EPOCH: 3/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:01:25) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 270275[0m
     | > decoder_loss: 35.71668  (33.43561)
     | > postnet_loss: 19.90992  (19.80362)
     | > stopnet_loss: 1.65072  (1.85713)
     | > decoder_coarse_loss: 35.89083  (33.60636)
     | > decoder_ddc_loss: 0.00026  (0.00042)
     | > ga_loss: 0.00214  (0.00270)
     | > decoder_diff_spec_loss: 0.43326  (0.46317)
     | > postnet_diff_spec_loss: 0.82437  (0.86427)
     | > decoder_ssim_loss: 0.43732  (0.40731)
     | > postnet_ssim_loss: 0.43738  (0.40735)
     | > loss: 25.07391  (24.11768)
     | > align_error: 0.99624  (0.99451)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 3.21356  (2.96335)
     | > current_lr: 0.00001 
     | > step_time: 5.69050  (4.37064)
     | > loader_time: 0.01910  (0.03392)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 270300[0m
     | > decoder_loss: 32.19094  (32.87384)
     | > postnet_loss: 18.08977  (19.70496)
     | > stopnet_loss: 1.61009  (1.90238)
     | > decoder_coarse_loss: 32.40145  (33.06133)
     | > decoder_ddc_loss: 0.00026  (0.00041)
     | > ga_loss: 0.00214  (0.00267)
     | > decoder_diff_spec_loss: 0.51156  (0.47679)
     | > postnet_diff_spec_loss: 0.88566  (0.86478)
     | > decoder_ssim_loss: 0.44448  (0.40346)
     | > postnet_ssim_loss: 0.44462  (0.40352)
     | > loss: 22.86295  (23.86299)
     | > align_error: 0.99609  (0.99456)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 3.99667  (3.35784)
     | > current_lr: 0.00001 
     | > step_time: 4.42930  (3.86986)
     | > loader_time: 0.05700  (0.03671)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 270325[0m
     | > decoder_loss: 34.57055  (32.88324)
     | > postnet_loss: 22.86355  (19.97753)
     | > stopnet_loss: 1.78860  (1.92618)
     | > decoder_coarse_loss: 34.91174  (33.11127)
     | > decoder_ddc_loss: 0.00045  (0.00040)
     | > ga_loss: 0.00332  (0.00270)
     | > decoder_diff_spec_loss: 0.54010  (0.49900)
     | > postnet_diff_spec_loss: 0.84317  (0.86876)
     | > decoder_ssim_loss: 0.42334  (0.39742)
     | > postnet_ssim_loss: 0.42365  (0.39754)
     | > loss: 25.44936  (23.97346)
     | > align_error: 0.99344  (0.99451)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 5.11746  (3.86971)
     | > current_lr: 0.00001 
     | > step_time: 2.99980  (3.79275)
     | > loader_time: 0.01640  (0.03532)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 270350[0m
     | > decoder_loss: 30.02535  (32.40153)
     | > postnet_loss: 18.50285  (19.83304)
     | > stopnet_loss: 1.63680  (1.93131)
     | > decoder_coarse_loss: 30.57235  (32.69534)
     | > decoder_ddc_loss: 0.00034  (0.00039)
     | > ga_loss: 0.00233  (0.00266)
     | > decoder_diff_spec_loss: 0.64290  (0.53082)
     | > postnet_diff_spec_loss: 0.84444  (0.86800)
     | > decoder_ssim_loss: 0.43692  (0.39523)
     | > postnet_ssim_loss: 0.43773  (0.39545)
     | > loss: 22.01416  (23.72454)
     | > align_error: 0.99529  (0.99460)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 6.91822  (4.54567)
     | > current_lr: 0.00001 
     | > step_time: 2.83520  (3.71640)
     | > loader_time: 0.02640  (0.03419)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.46058 [0m(-0.70960)
     | > avg_decoder_loss:[92m 29.47910 [0m(-0.96705)
     | > avg_postnet_loss:[91m 18.77873 [0m(+0.13807)
     | > avg_stopnet_loss:[92m 1.91904 [0m(-0.00247)
     | > avg_decoder_coarse_loss:[92m 28.56308 [0m(-1.56601)
     | > avg_decoder_ddc_loss:[92m 0.00028 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00245 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.48340 [0m(+0.03545)
     | > avg_postnet_diff_spec_loss:[92m 0.87609 [0m(-0.00069)
     | > avg_decoder_ssim_loss:[92m 0.39249 [0m(-0.00018)
     | > avg_postnet_ssim_loss:[91m 0.39268 [0m(+0.00002)
     | > avg_loss:[92m 21.67275 [0m(-0.59262)
     | > avg_align_error:[92m 0.99522 [0m(-0.00001)


[4m[1m > EPOCH: 4/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:09:00) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 270375[0m
     | > decoder_loss: 28.52905  (30.06086)
     | > postnet_loss: 17.72943  (19.54324)
     | > stopnet_loss: 1.88734  (1.96598)
     | > decoder_coarse_loss: 29.23950  (30.71508)
     | > decoder_ddc_loss: 0.00031  (0.00037)
     | > ga_loss: 0.00249  (0.00259)
     | > decoder_diff_spec_loss: 0.78132  (0.73980)
     | > postnet_diff_spec_loss: 0.87638  (0.86475)
     | > decoder_ssim_loss: 0.37678  (0.38588)
     | > postnet_ssim_loss: 0.37791  (0.38687)
     | > loss: 21.37745  (22.65314)
     | > align_error: 0.99485  (0.99481)
     | > amp_scaler: 32768.00000  (58412.52174)
     | > grad_norm: 8.19081  (7.48900)
     | > current_lr: 0.00001 
     | > step_time: 3.48640  (4.00541)
     | > loader_time: 0.03010  (0.04058)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 270400[0m
     | > decoder_loss: 27.73248  (29.46119)
     | > postnet_loss: 19.63582  (19.36718)
     | > stopnet_loss: 2.33471  (1.89532)
     | > decoder_coarse_loss: 28.80768  (30.19209)
     | > decoder_ddc_loss: 0.00036  (0.00040)
     | > ga_loss: 0.00232  (0.00260)
     | > decoder_diff_spec_loss: 1.06742  (0.81030)
     | > postnet_diff_spec_loss: 0.89503  (0.87052)
     | > decoder_ssim_loss: 0.30223  (0.39585)
     | > postnet_ssim_loss: 0.30419  (0.39717)
     | > loss: 22.03259  (22.28200)
     | > align_error: 0.99585  (0.99459)
     | > amp_scaler: 32768.00000  (45056.00000)
     | > grad_norm: 10.38530  (8.43892)
     | > current_lr: 0.00001 
     | > step_time: 4.06690  (3.84772)
     | > loader_time: 0.01530  (0.03821)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 270425[0m
     | > decoder_loss: 26.50697  (28.53014)
     | > postnet_loss: 20.23107  (19.29169)
     | > stopnet_loss: 1.73999  (1.86399)
     | > decoder_coarse_loss: 27.58050  (29.35702)
     | > decoder_ddc_loss: 0.00054  (0.00043)
     | > ga_loss: 0.00280  (0.00265)
     | > decoder_diff_spec_loss: 1.18159  (0.89419)
     | > postnet_diff_spec_loss: 0.87855  (0.86651)
     | > decoder_ssim_loss: 0.40298  (0.39508)
     | > postnet_ssim_loss: 0.40694  (0.39697)
     | > loss: 21.05126  (21.81025)
     | > align_error: 0.99447  (0.99449)
     | > amp_scaler: 32768.00000  (40847.78082)
     | > grad_norm: 11.24657  (9.09897)
     | > current_lr: 0.00001 
     | > step_time: 3.33840  (3.74071)
     | > loader_time: 0.02110  (0.03656)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.53779 [0m(+0.07721)
     | > avg_decoder_loss:[92m 26.48867 [0m(-2.99043)
     | > avg_postnet_loss:[91m 18.92111 [0m(+0.14238)
     | > avg_stopnet_loss:[92m 1.80266 [0m(-0.11639)
     | > avg_decoder_coarse_loss:[92m 24.88315 [0m(-3.67993)
     | > avg_decoder_ddc_loss:[91m 0.00032 [0m(+0.00003)
     | > avg_ga_loss:[92m 0.00244 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.61509 [0m(+0.13169)
     | > avg_postnet_diff_spec_loss:[92m 0.87591 [0m(-0.00018)
     | > avg_decoder_ssim_loss:[92m 0.39124 [0m(-0.00125)
     | > avg_postnet_ssim_loss:[91m 0.39269 [0m(+0.00001)
     | > avg_loss:[92m 19.95690 [0m(-1.71585)
     | > avg_align_error:[92m 0.99519 [0m(-0.00003)


[4m[1m > EPOCH: 5/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:16:27) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 270450[0m
     | > decoder_loss: 23.59284  (24.09457)
     | > postnet_loss: 18.31246  (18.48063)
     | > stopnet_loss: 1.24269  (1.69808)
     | > decoder_coarse_loss: 24.77733  (25.29008)
     | > decoder_ddc_loss: 0.00070  (0.00064)
     | > ga_loss: 0.00343  (0.00266)
     | > decoder_diff_spec_loss: 1.31181  (1.30794)
     | > postnet_diff_spec_loss: 0.88523  (0.86761)
     | > decoder_ssim_loss: 0.52029  (0.39916)
     | > postnet_ssim_loss: 0.52668  (0.40421)
     | > loss: 18.74165  (19.42258)
     | > align_error: 0.99291  (0.99412)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.43232  (10.53441)
     | > current_lr: 0.00001 
     | > step_time: 2.20340  (4.17302)
     | > loader_time: 0.07370  (0.03879)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 270475[0m
     | > decoder_loss: 19.53975  (22.72574)
     | > postnet_loss: 15.88958  (18.25408)
     | > stopnet_loss: 1.20088  (1.68254)
     | > decoder_coarse_loss: 20.63960  (23.93220)
     | > decoder_ddc_loss: 0.00128  (0.00065)
     | > ga_loss: 0.00328  (0.00258)
     | > decoder_diff_spec_loss: 1.36898  (1.39725)
     | > postnet_diff_spec_loss: 0.85134  (0.86353)
     | > decoder_ssim_loss: 0.51233  (0.39585)
     | > postnet_ssim_loss: 0.52286  (0.40216)
     | > loss: 16.04870  (18.68832)
     | > align_error: 0.99086  (0.99422)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.89476  (9.88046)
     | > current_lr: 0.00001 
     | > step_time: 2.21390  (3.78874)
     | > loader_time: 0.03660  (0.03333)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 270500[0m
     | > decoder_loss: 16.70477  (21.43727)
     | > postnet_loss: 16.24483  (18.15045)
     | > stopnet_loss: 1.42917  (1.66975)
     | > decoder_coarse_loss: 17.89985  (22.65704)
     | > decoder_ddc_loss: 0.00114  (0.00068)
     | > ga_loss: 0.00333  (0.00257)
     | > decoder_diff_spec_loss: 1.55357  (1.47634)
     | > postnet_diff_spec_loss: 0.84546  (0.86848)
     | > decoder_ssim_loss: 0.43520  (0.38900)
     | > postnet_ssim_loss: 0.44920  (0.39685)
     | > loss: 14.97934  (18.02665)
     | > align_error: 0.99144  (0.99412)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.70276  (8.80776)
     | > current_lr: 0.00001 
     | > step_time: 3.19320  (3.77505)
     | > loader_time: 0.02400  (0.03329)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 270525[0m
     | > decoder_loss: 12.70722  (19.73154)
     | > postnet_loss: 16.36424  (17.71067)
     | > stopnet_loss: 2.18158  (1.66523)
     | > decoder_coarse_loss: 13.79408  (20.94367)
     | > decoder_ddc_loss: 0.00050  (0.00072)
     | > ga_loss: 0.00194  (0.00254)
     | > decoder_diff_spec_loss: 1.66678  (1.52376)
     | > postnet_diff_spec_loss: 0.86106  (0.86759)
     | > decoder_ssim_loss: 0.28047  (0.38485)
     | > postnet_ssim_loss: 0.29241  (0.39459)
     | > loss: 13.68298  (17.06728)
     | > align_error: 0.99542  (0.99408)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.13736  (8.03991)
     | > current_lr: 0.00001 
     | > step_time: 3.52770  (3.70073)
     | > loader_time: 0.02480  (0.03505)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.07228 [0m(+0.53449)
     | > avg_decoder_loss:[92m 19.74190 [0m(-6.74677)
     | > avg_postnet_loss:[92m 18.18334 [0m(-0.73777)
     | > avg_stopnet_loss:[92m 1.55157 [0m(-0.25108)
     | > avg_decoder_coarse_loss:[92m 17.09422 [0m(-7.78893)
     | > avg_decoder_ddc_loss:[91m 0.00035 [0m(+0.00003)
     | > avg_ga_loss:[91m 0.00246 [0m(+0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.73454 [0m(+0.11945)
     | > avg_postnet_diff_spec_loss:[91m 0.87593 [0m(+0.00002)
     | > avg_decoder_ssim_loss:[92m 0.38512 [0m(-0.00612)
     | > avg_postnet_ssim_loss:[92m 0.39264 [0m(-0.00005)
     | > avg_loss:[92m 15.91588 [0m(-4.04102)
     | > avg_align_error:[92m 0.99517 [0m(-0.00002)


[4m[1m > EPOCH: 6/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:23:56) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 270550[0m
     | > decoder_loss: 11.50178  (12.14564)
     | > postnet_loss: 16.27331  (15.60796)
     | > stopnet_loss: 1.11344  (1.74284)
     | > decoder_coarse_loss: 12.60763  (13.27842)
     | > decoder_ddc_loss: 0.00066  (0.00078)
     | > ga_loss: 0.00187  (0.00245)
     | > decoder_diff_spec_loss: 1.47164  (1.55338)
     | > postnet_diff_spec_loss: 0.85713  (0.86408)
     | > decoder_ssim_loss: 0.46168  (0.36719)
     | > postnet_ssim_loss: 0.48830  (0.38622)
     | > loss: 12.03831  (12.80598)
     | > align_error: 0.99468  (0.99386)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.95802  (7.72520)
     | > current_lr: 0.00001 
     | > step_time: 3.93970  (4.08520)
     | > loader_time: 0.02030  (0.03806)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 270575[0m
     | > decoder_loss: 8.50508  (11.00467)
     | > postnet_loss: 13.14045  (14.98551)
     | > stopnet_loss: 1.31780  (1.65860)
     | > decoder_coarse_loss: 9.54759  (12.11460)
     | > decoder_ddc_loss: 0.00163  (0.00086)
     | > ga_loss: 0.00313  (0.00246)
     | > decoder_diff_spec_loss: 1.24064  (1.46407)
     | > postnet_diff_spec_loss: 0.86777  (0.86988)
     | > decoder_ssim_loss: 0.47932  (0.37659)
     | > postnet_ssim_loss: 0.50877  (0.39782)
     | > loss: 9.90627  (11.97438)
     | > align_error: 0.98798  (0.99339)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.09286  (7.22386)
     | > current_lr: 0.00001 
     | > step_time: 2.09310  (3.87639)
     | > loader_time: 0.04070  (0.03620)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 270600[0m
     | > decoder_loss: 6.78799  (9.82912)
     | > postnet_loss: 12.63560  (14.53225)
     | > stopnet_loss: 1.32206  (1.68385)
     | > decoder_coarse_loss: 7.76067  (10.92221)
     | > decoder_ddc_loss: 0.00109  (0.00087)
     | > ga_loss: 0.00259  (0.00250)
     | > decoder_diff_spec_loss: 1.07314  (1.36751)
     | > postnet_diff_spec_loss: 0.87601  (0.86623)
     | > decoder_ssim_loss: 0.45854  (0.37206)
     | > postnet_ssim_loss: 0.49233  (0.39520)
     | > loss: 8.85633  (11.26771)
     | > align_error: 0.99197  (0.99325)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.67247  (6.76977)
     | > current_lr: 0.00002 
     | > step_time: 2.98930  (3.72375)
     | > loader_time: 0.02260  (0.03513)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.47393 [0m(-0.59836)
     | > avg_decoder_loss:[92m 14.04753 [0m(-5.69437)
     | > avg_postnet_loss:[92m 15.03944 [0m(-3.14390)
     | > avg_stopnet_loss:[91m 1.56821 [0m(+0.01663)
     | > avg_decoder_coarse_loss:[92m 10.95013 [0m(-6.14409)
     | > avg_decoder_ddc_loss:[91m 0.00035 [0m(+0.00000)
     | > avg_ga_loss:[91m 0.00249 [0m(+0.00003)
     | > avg_decoder_diff_spec_loss:[92m 0.59798 [0m(-0.13656)
     | > avg_postnet_diff_spec_loss:[92m 0.87581 [0m(-0.00012)
     | > avg_decoder_ssim_loss:[92m 0.37632 [0m(-0.00880)
     | > avg_postnet_ssim_loss:[92m 0.39189 [0m(-0.00076)
     | > avg_loss:[92m 12.15054 [0m(-3.76534)
     | > avg_align_error:[92m 0.99512 [0m(-0.00005)


[4m[1m > EPOCH: 7/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:31:22) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 270625[0m
     | > decoder_loss: 5.60650  (5.38222)
     | > postnet_loss: 12.63944  (12.29270)
     | > stopnet_loss: 1.50167  (1.81302)
     | > decoder_coarse_loss: 6.50963  (6.30099)
     | > decoder_ddc_loss: 0.00185  (0.00100)
     | > ga_loss: 0.00345  (0.00246)
     | > decoder_diff_spec_loss: 0.81544  (0.88307)
     | > postnet_diff_spec_loss: 0.83689  (0.86548)
     | > decoder_ssim_loss: 0.44305  (0.35717)
     | > postnet_ssim_loss: 0.48050  (0.38780)
     | > loss: 8.35224  (8.44295)
     | > align_error: 0.98828  (0.99254)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.92972  (4.88244)
     | > current_lr: 0.00002 
     | > step_time: 2.49420  (4.28788)
     | > loader_time: 0.03660  (0.04145)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 270650[0m
     | > decoder_loss: 4.62116  (4.92509)
     | > postnet_loss: 12.07274  (11.98181)
     | > stopnet_loss: 1.54372  (1.75833)
     | > decoder_coarse_loss: 5.38761  (5.76657)
     | > decoder_ddc_loss: 0.00163  (0.00092)
     | > ga_loss: 0.00292  (0.00244)
     | > decoder_diff_spec_loss: 0.62524  (0.79008)
     | > postnet_diff_spec_loss: 0.81793  (0.86381)
     | > decoder_ssim_loss: 0.39223  (0.36268)
     | > postnet_ssim_loss: 0.42735  (0.39541)
     | > loss: 7.64480  (8.04214)
     | > align_error: 0.98810  (0.99272)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.73091  (5.12706)
     | > current_lr: 0.00002 
     | > step_time: 2.69870  (3.77133)
     | > loader_time: 0.07070  (0.03425)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 270675[0m
     | > decoder_loss: 3.71693  (4.62017)
     | > postnet_loss: 10.88458  (11.76991)
     | > stopnet_loss: 1.94946  (1.77811)
     | > decoder_coarse_loss: 4.31806  (5.37785)
     | > decoder_ddc_loss: 0.00068  (0.00093)
     | > ga_loss: 0.00234  (0.00246)
     | > decoder_diff_spec_loss: 0.58891  (0.71765)
     | > postnet_diff_spec_loss: 0.89603  (0.86881)
     | > decoder_ssim_loss: 0.31597  (0.35864)
     | > postnet_ssim_loss: 0.35239  (0.39255)
     | > loss: 7.22957  (7.81704)
     | > align_error: 0.99409  (0.99260)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.36332  (4.68824)
     | > current_lr: 0.00002 
     | > step_time: 3.79310  (3.72371)
     | > loader_time: 0.02290  (0.03406)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 270700[0m
     | > decoder_loss: 3.57713  (4.34870)
     | > postnet_loss: 10.74628  (11.41326)
     | > stopnet_loss: 2.10816  (1.78127)
     | > decoder_coarse_loss: 3.98878  (5.02199)
     | > decoder_ddc_loss: 0.00096  (0.00094)
     | > ga_loss: 0.00258  (0.00246)
     | > decoder_diff_spec_loss: 0.48950  (0.65731)
     | > postnet_diff_spec_loss: 0.88885  (0.86756)
     | > decoder_ssim_loss: 0.29433  (0.35695)
     | > postnet_ssim_loss: 0.32652  (0.39221)
     | > loss: 7.19913  (7.55828)
     | > align_error: 0.99270  (0.99256)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.57130  (4.40957)
     | > current_lr: 0.00002 
     | > step_time: 4.00340  (3.67793)
     | > loader_time: 0.02740  (0.03254)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.69047 [0m(+0.21655)
     | > avg_decoder_loss:[92m 10.30852 [0m(-3.73901)
     | > avg_postnet_loss:[92m 11.63535 [0m(-3.40410)
     | > avg_stopnet_loss:[92m 1.53079 [0m(-0.03742)
     | > avg_decoder_coarse_loss:[92m 7.90331 [0m(-3.04682)
     | > avg_decoder_ddc_loss:[91m 0.00037 [0m(+0.00002)
     | > avg_ga_loss:[91m 0.00250 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50194 [0m(-0.09603)
     | > avg_postnet_diff_spec_loss:[91m 0.87598 [0m(+0.00016)
     | > avg_decoder_ssim_loss:[92m 0.36800 [0m(-0.00833)
     | > avg_postnet_ssim_loss:[92m 0.39021 [0m(-0.00167)
     | > avg_loss:[92m 9.53922 [0m(-2.61132)
     | > avg_align_error:[92m 0.99505 [0m(-0.00006)


[4m[1m > EPOCH: 8/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:38:55) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 270725[0m
     | > decoder_loss: 3.50759  (3.43074)
     | > postnet_loss: 10.30173  (10.06004)
     | > stopnet_loss: 1.40475  (1.89330)
     | > decoder_coarse_loss: 3.75952  (3.73744)
     | > decoder_ddc_loss: 0.00093  (0.00094)
     | > ga_loss: 0.00206  (0.00243)
     | > decoder_diff_spec_loss: 0.48582  (0.46186)
     | > postnet_diff_spec_loss: 0.90138  (0.86392)
     | > decoder_ssim_loss: 0.40335  (0.33845)
     | > postnet_ssim_loss: 0.44985  (0.37740)
     | > loss: 6.36758  (6.72317)
     | > align_error: 0.99303  (0.99281)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.70105  (3.92431)
     | > current_lr: 0.00002 
     | > step_time: 4.01120  (4.11903)
     | > loader_time: 0.02030  (0.03297)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 270750[0m
     | > decoder_loss: 4.10100  (3.48909)
     | > postnet_loss: 10.68957  (9.75558)
     | > stopnet_loss: 1.51436  (1.80301)
     | > decoder_coarse_loss: 4.30029  (3.74484)
     | > decoder_ddc_loss: 0.00120  (0.00100)
     | > ga_loss: 0.00236  (0.00242)
     | > decoder_diff_spec_loss: 0.44874  (0.45160)
     | > postnet_diff_spec_loss: 0.87266  (0.86946)
     | > decoder_ssim_loss: 0.38095  (0.35019)
     | > postnet_ssim_loss: 0.42705  (0.39142)
     | > loss: 6.83151  (6.57840)
     | > align_error: 0.99215  (0.99249)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.83858  (3.51621)
     | > current_lr: 0.00002 
     | > step_time: 3.85280  (3.95325)
     | > loader_time: 0.02020  (0.03061)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 270775[0m
     | > decoder_loss: 3.52002  (3.42534)
     | > postnet_loss: 7.55741  (9.51242)
     | > stopnet_loss: 1.85258  (1.81409)
     | > decoder_coarse_loss: 3.60939  (3.63566)
     | > decoder_ddc_loss: 0.00146  (0.00102)
     | > ga_loss: 0.00318  (0.00248)
     | > decoder_diff_spec_loss: 0.41136  (0.43996)
     | > postnet_diff_spec_loss: 0.85094  (0.86562)
     | > decoder_ssim_loss: 0.35490  (0.34818)
     | > postnet_ssim_loss: 0.39914  (0.38985)
     | > loss: 6.04463  (6.48102)
     | > align_error: 0.99064  (0.99236)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.41126  (3.46845)
     | > current_lr: 0.00002 
     | > step_time: 2.97600  (3.81400)
     | > loader_time: 0.05940  (0.02932)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.32062 [0m(-0.36985)
     | > avg_decoder_loss:[92m 9.38994 [0m(-0.91858)
     | > avg_postnet_loss:[92m 9.40661 [0m(-2.22873)
     | > avg_stopnet_loss:[92m 1.52262 [0m(-0.00816)
     | > avg_decoder_coarse_loss:[92m 7.13280 [0m(-0.77051)
     | > avg_decoder_ddc_loss:[91m 0.00040 [0m(+0.00003)
     | > avg_ga_loss:[92m 0.00250 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.48522 [0m(-0.01672)
     | > avg_postnet_diff_spec_loss:[91m 0.87621 [0m(+0.00023)
     | > avg_decoder_ssim_loss:[92m 0.36501 [0m(-0.00298)
     | > avg_postnet_ssim_loss:[92m 0.38870 [0m(-0.00151)
     | > avg_loss:[92m 8.54636 [0m(-0.99286)
     | > avg_align_error:[92m 0.99503 [0m(-0.00002)


[4m[1m > EPOCH: 9/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:46:15) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 270800[0m
     | > decoder_loss: 2.64338  (3.19223)
     | > postnet_loss: 6.43360  (8.28034)
     | > stopnet_loss: 1.51997  (1.86040)
     | > decoder_coarse_loss: 2.68093  (3.26073)
     | > decoder_ddc_loss: 0.00123  (0.00095)
     | > ga_loss: 0.00291  (0.00232)
     | > decoder_diff_spec_loss: 0.41668  (0.41850)
     | > postnet_diff_spec_loss: 0.86194  (0.86862)
     | > decoder_ssim_loss: 0.38233  (0.33163)
     | > postnet_ssim_loss: 0.43097  (0.37295)
     | > loss: 4.99729  (6.05346)
     | > align_error: 0.98812  (0.99279)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.47453  (3.79016)
     | > current_lr: 0.00002 
     | > step_time: 2.78000  (4.68911)
     | > loader_time: 0.07090  (0.06599)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 270825[0m
     | > decoder_loss: 3.45298  (3.30934)
     | > postnet_loss: 8.60702  (8.19707)
     | > stopnet_loss: 1.59834  (1.82464)
     | > decoder_coarse_loss: 3.50534  (3.36298)
     | > decoder_ddc_loss: 0.00112  (0.00098)
     | > ga_loss: 0.00236  (0.00241)
     | > decoder_diff_spec_loss: 0.43704  (0.41570)
     | > postnet_diff_spec_loss: 0.88535  (0.86481)
     | > decoder_ssim_loss: 0.39341  (0.34735)
     | > postnet_ssim_loss: 0.44362  (0.39102)
     | > loss: 6.04161  (6.05902)
     | > align_error: 0.99008  (0.99260)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.04295  (3.74456)
     | > current_lr: 0.00002 
     | > step_time: 3.56790  (3.99356)
     | > loader_time: 0.13660  (0.04125)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 270850[0m
     | > decoder_loss: 3.41661  (3.33791)
     | > postnet_loss: 8.44374  (8.12049)
     | > stopnet_loss: 1.62188  (1.82147)
     | > decoder_coarse_loss: 3.46327  (3.38318)
     | > decoder_ddc_loss: 0.00101  (0.00102)
     | > ga_loss: 0.00237  (0.00245)
     | > decoder_diff_spec_loss: 0.41060  (0.41637)
     | > postnet_diff_spec_loss: 0.86552  (0.86794)
     | > decoder_ssim_loss: 0.35852  (0.34648)
     | > postnet_ssim_loss: 0.40293  (0.38993)
     | > loss: 5.97429  (6.04957)
     | > align_error: 0.99300  (0.99238)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.79447  (3.55944)
     | > current_lr: 0.00002 
     | > step_time: 3.84160  (3.88442)
     | > loader_time: 0.02560  (0.03817)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 270875[0m
     | > decoder_loss: 3.30873  (3.33351)
     | > postnet_loss: 7.59783  (7.90747)
     | > stopnet_loss: 2.00748  (1.81208)
     | > decoder_coarse_loss: 3.31954  (3.37133)
     | > decoder_ddc_loss: 0.00076  (0.00100)
     | > ga_loss: 0.00196  (0.00245)
     | > decoder_diff_spec_loss: 0.40742  (0.41448)
     | > postnet_diff_spec_loss: 0.86690  (0.86691)
     | > decoder_ssim_loss: 0.29005  (0.34640)
     | > postnet_ssim_loss: 0.32668  (0.38978)
     | > loss: 6.04677  (5.98207)
     | > align_error: 0.99431  (0.99245)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.42498  (3.42049)
     | > current_lr: 0.00002 
     | > step_time: 3.52150  (3.78758)
     | > loader_time: 0.02330  (0.03545)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.23671 [0m(+0.91609)
     | > avg_decoder_loss:[92m 9.22234 [0m(-0.16760)
     | > avg_postnet_loss:[92m 8.06915 [0m(-1.33746)
     | > avg_stopnet_loss:[91m 1.52276 [0m(+0.00014)
     | > avg_decoder_coarse_loss:[92m 6.91977 [0m(-0.21303)
     | > avg_decoder_ddc_loss:[91m 0.00046 [0m(+0.00006)
     | > avg_ga_loss:[92m 0.00250 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.48409 [0m(-0.00113)
     | > avg_postnet_diff_spec_loss:[91m 0.87680 [0m(+0.00059)
     | > avg_decoder_ssim_loss:[92m 0.36429 [0m(-0.00072)
     | > avg_postnet_ssim_loss:[92m 0.38782 [0m(-0.00088)
     | > avg_loss:[92m 8.11644 [0m(-0.42991)
     | > avg_align_error:[92m 0.99500 [0m(-0.00003)


[4m[1m > EPOCH: 10/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:53:52) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 270900[0m
     | > decoder_loss: 3.22315  (3.22369)
     | > postnet_loss: 7.26362  (7.09828)
     | > stopnet_loss: 2.27045  (1.94133)
     | > decoder_coarse_loss: 3.23023  (3.23691)
     | > decoder_ddc_loss: 0.00072  (0.00093)
     | > ga_loss: 0.00255  (0.00246)
     | > decoder_diff_spec_loss: 0.43276  (0.41014)
     | > postnet_diff_spec_loss: 0.86820  (0.86173)
     | > decoder_ssim_loss: 0.28528  (0.33003)
     | > postnet_ssim_loss: 0.32094  (0.37106)
     | > loss: 6.18941  (5.83682)
     | > align_error: 0.99387  (0.99296)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.29942  (4.06235)
     | > current_lr: 0.00002 
     | > step_time: 2.96960  (4.05812)
     | > loader_time: 0.02020  (0.03438)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 270925[0m
     | > decoder_loss: 3.87746  (3.31452)
     | > postnet_loss: 7.14746  (6.91892)
     | > stopnet_loss: 2.42498  (1.82699)
     | > decoder_coarse_loss: 3.89087  (3.32934)
     | > decoder_ddc_loss: 0.00091  (0.00098)
     | > ga_loss: 0.00232  (0.00241)
     | > decoder_diff_spec_loss: 0.45478  (0.41493)
     | > postnet_diff_spec_loss: 0.92942  (0.86907)
     | > decoder_ssim_loss: 0.26210  (0.34509)
     | > postnet_ssim_loss: 0.29380  (0.38796)
     | > loss: 6.65077  (5.73426)
     | > align_error: 0.99323  (0.99268)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.01347  (3.49921)
     | > current_lr: 0.00002 
     | > step_time: 3.88950  (3.92515)
     | > loader_time: 0.04390  (0.03293)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 270950[0m
     | > decoder_loss: 3.19902  (3.28803)
     | > postnet_loss: 6.08779  (6.79784)
     | > stopnet_loss: 2.02102  (1.81935)
     | > decoder_coarse_loss: 3.20528  (3.30163)
     | > decoder_ddc_loss: 0.00095  (0.00099)
     | > ga_loss: 0.00232  (0.00247)
     | > decoder_diff_spec_loss: 0.40374  (0.41197)
     | > postnet_diff_spec_loss: 0.85851  (0.86553)
     | > decoder_ssim_loss: 0.29799  (0.34439)
     | > postnet_ssim_loss: 0.33494  (0.38707)
     | > loss: 5.62970  (5.68107)
     | > align_error: 0.99207  (0.99262)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.81438  (3.34798)
     | > current_lr: 0.00002 
     | > step_time: 3.83050  (3.76764)
     | > loader_time: 0.02340  (0.03494)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.58026 [0m(-0.65645)
     | > avg_decoder_loss:[92m 8.87830 [0m(-0.34404)
     | > avg_postnet_loss:[92m 6.89463 [0m(-1.17452)
     | > avg_stopnet_loss:[92m 1.51839 [0m(-0.00437)
     | > avg_decoder_coarse_loss:[92m 6.66805 [0m(-0.25173)
     | > avg_decoder_ddc_loss:[91m 0.00064 [0m(+0.00017)
     | > avg_ga_loss:[91m 0.00250 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.48200 [0m(-0.00209)
     | > avg_postnet_diff_spec_loss:[91m 0.87751 [0m(+0.00071)
     | > avg_decoder_ssim_loss:[92m 0.36343 [0m(-0.00086)
     | > avg_postnet_ssim_loss:[92m 0.38687 [0m(-0.00095)
     | > avg_loss:[92m 7.66876 [0m(-0.44768)
     | > avg_align_error:[92m 0.99491 [0m(-0.00009)


[4m[1m > EPOCH: 11/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:01:32) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 270975[0m
     | > decoder_loss: 3.77607  (3.20339)
     | > postnet_loss: 7.77502  (6.15788)
     | > stopnet_loss: 1.42654  (1.91216)
     | > decoder_coarse_loss: 3.79344  (3.21730)
     | > decoder_ddc_loss: 0.00087  (0.00085)
     | > ga_loss: 0.00190  (0.00223)
     | > decoder_diff_spec_loss: 0.43283  (0.41358)
     | > postnet_diff_spec_loss: 0.88186  (0.86941)
     | > decoder_ssim_loss: 0.38504  (0.32328)
     | > postnet_ssim_loss: 0.43020  (0.36251)
     | > loss: 5.80488  (5.56037)
     | > align_error: 0.99393  (0.99381)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.55465  (3.48007)
     | > current_lr: 0.00002 
     | > step_time: 4.46610  (4.84234)
     | > loader_time: 0.02240  (0.02885)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 271000[0m
     | > decoder_loss: 3.59000  (3.24109)
     | > postnet_loss: 6.14752  (5.94576)
     | > stopnet_loss: 1.79803  (1.83294)
     | > decoder_coarse_loss: 3.61070  (3.25679)
     | > decoder_ddc_loss: 0.00062  (0.00089)
     | > ga_loss: 0.00200  (0.00243)
     | > decoder_diff_spec_loss: 0.38657  (0.41066)
     | > postnet_diff_spec_loss: 0.85517  (0.86387)
     | > decoder_ssim_loss: 0.31400  (0.34486)
     | > postnet_ssim_loss: 0.35271  (0.38709)
     | > loss: 5.62238  (5.45784)
     | > align_error: 0.99488  (0.99309)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.57570  (4.03549)
     | > current_lr: 0.00003 
     | > step_time: 4.47420  (3.83929)
     | > loader_time: 0.02810  (0.03564)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 271025[0m
     | > decoder_loss: 3.69690  (3.27003)
     | > postnet_loss: 5.71937  (5.92341)
     | > stopnet_loss: 1.66649  (1.81577)
     | > decoder_coarse_loss: 3.71430  (3.28607)
     | > decoder_ddc_loss: 0.00136  (0.00094)
     | > ga_loss: 0.00277  (0.00247)
     | > decoder_diff_spec_loss: 0.39344  (0.41277)
     | > postnet_diff_spec_loss: 0.85310  (0.86769)
     | > decoder_ssim_loss: 0.34608  (0.34533)
     | > postnet_ssim_loss: 0.38673  (0.38747)
     | > loss: 5.45817  (5.45158)
     | > align_error: 0.99079  (0.99283)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.39460  (3.84737)
     | > current_lr: 0.00003 
     | > step_time: 3.38900  (3.75768)
     | > loader_time: 0.02030  (0.03236)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 271050[0m
     | > decoder_loss: 3.62879  (3.26850)
     | > postnet_loss: 6.34925  (5.79766)
     | > stopnet_loss: 1.28428  (1.80333)
     | > decoder_coarse_loss: 3.66072  (3.28655)
     | > decoder_ddc_loss: 0.00083  (0.00092)
     | > ga_loss: 0.00197  (0.00247)
     | > decoder_diff_spec_loss: 0.43873  (0.41131)
     | > postnet_diff_spec_loss: 0.90371  (0.86667)
     | > decoder_ssim_loss: 0.42309  (0.34626)
     | > postnet_ssim_loss: 0.47005  (0.38837)
     | > loss: 5.26291  (5.40724)
     | > align_error: 0.99390  (0.99290)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.90909  (3.69804)
     | > current_lr: 0.00003 
     | > step_time: 3.47940  (3.71878)
     | > loader_time: 0.01980  (0.03362)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.76484 [0m(+0.18458)
     | > avg_decoder_loss:[91m 8.94987 [0m(+0.07156)
     | > avg_postnet_loss:[92m 6.12335 [0m(-0.77128)
     | > avg_stopnet_loss:[91m 1.52208 [0m(+0.00369)
     | > avg_decoder_coarse_loss:[92m 6.58737 [0m(-0.08068)
     | > avg_decoder_ddc_loss:[91m 0.00068 [0m(+0.00005)
     | > avg_ga_loss:[92m 0.00249 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.48243 [0m(+0.00043)
     | > avg_postnet_diff_spec_loss:[91m 0.87775 [0m(+0.00024)
     | > avg_decoder_ssim_loss:[91m 0.36366 [0m(+0.00023)
     | > avg_postnet_ssim_loss:[92m 0.38597 [0m(-0.00090)
     | > avg_loss:[92m 7.47732 [0m(-0.19144)
     | > avg_align_error:[92m 0.99487 [0m(-0.00004)


[4m[1m > EPOCH: 12/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:09:05) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 271075[0m
     | > decoder_loss: 2.95298  (3.14439)
     | > postnet_loss: 5.83616  (5.29389)
     | > stopnet_loss: 2.33037  (1.95641)
     | > decoder_coarse_loss: 2.97477  (3.17105)
     | > decoder_ddc_loss: 0.00047  (0.00081)
     | > ga_loss: 0.00210  (0.00249)
     | > decoder_diff_spec_loss: 0.38372  (0.40723)
     | > postnet_diff_spec_loss: 0.83297  (0.86118)
     | > decoder_ssim_loss: 0.25359  (0.33180)
     | > postnet_ssim_loss: 0.28623  (0.37180)
     | > loss: 5.72109  (5.36438)
     | > align_error: 0.99603  (0.99352)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.88832  (4.03192)
     | > current_lr: 0.00003 
     | > step_time: 3.90210  (4.01191)
     | > loader_time: 0.02220  (0.03022)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 271100[0m
     | > decoder_loss: 3.30798  (3.22232)
     | > postnet_loss: 5.46207  (5.20984)
     | > stopnet_loss: 2.56538  (1.83137)
     | > decoder_coarse_loss: 3.35294  (3.25649)
     | > decoder_ddc_loss: 0.00058  (0.00084)
     | > ga_loss: 0.00221  (0.00244)
     | > decoder_diff_spec_loss: 0.43643  (0.41257)
     | > postnet_diff_spec_loss: 0.90667  (0.86756)
     | > decoder_ssim_loss: 0.24013  (0.34642)
     | > postnet_ssim_loss: 0.27023  (0.38822)
     | > loss: 6.07069  (5.26964)
     | > align_error: 0.99493  (0.99333)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.08820  (3.69500)
     | > current_lr: 0.00003 
     | > step_time: 4.86120  (3.83814)
     | > loader_time: 0.02680  (0.03225)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 271125[0m
     | > decoder_loss: 3.31798  (3.20429)
     | > postnet_loss: 4.28135  (5.14871)
     | > stopnet_loss: 2.28309  (1.84101)
     | > decoder_coarse_loss: 3.39206  (3.24182)
     | > decoder_ddc_loss: 0.00054  (0.00085)
     | > ga_loss: 0.00219  (0.00249)
     | > decoder_diff_spec_loss: 0.41041  (0.41090)
     | > postnet_diff_spec_loss: 0.85240  (0.86549)
     | > decoder_ssim_loss: 0.26639  (0.34448)
     | > postnet_ssim_loss: 0.29826  (0.38597)
     | > loss: 5.49889  (5.25410)
     | > align_error: 0.99590  (0.99327)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.18980  (3.59948)
     | > current_lr: 0.00003 
     | > step_time: 5.01160  (3.75235)
     | > loader_time: 0.01910  (0.03306)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.55958 [0m(-0.20526)
     | > avg_decoder_loss:[92m 8.46194 [0m(-0.48793)
     | > avg_postnet_loss:[92m 5.39942 [0m(-0.72392)
     | > avg_stopnet_loss:[92m 1.51993 [0m(-0.00214)
     | > avg_decoder_coarse_loss:[92m 6.32899 [0m(-0.25838)
     | > avg_decoder_ddc_loss:[91m 0.00093 [0m(+0.00024)
     | > avg_ga_loss:[92m 0.00249 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.48245 [0m(+0.00002)
     | > avg_postnet_diff_spec_loss:[91m 0.87796 [0m(+0.00021)
     | > avg_decoder_ssim_loss:[92m 0.36274 [0m(-0.00092)
     | > avg_postnet_ssim_loss:[92m 0.38503 [0m(-0.00094)
     | > avg_loss:[92m 7.10725 [0m(-0.37007)
     | > avg_align_error:[92m 0.99469 [0m(-0.00018)


[4m[1m > EPOCH: 13/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:16:33) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 271150[0m
     | > decoder_loss: 3.09482  (3.00386)
     | > postnet_loss: 4.32833  (4.53745)
     | > stopnet_loss: 1.47095  (1.99362)
     | > decoder_coarse_loss: 3.15041  (3.06106)
     | > decoder_ddc_loss: 0.00078  (0.00064)
     | > ga_loss: 0.00226  (0.00233)
     | > decoder_diff_spec_loss: 0.41328  (0.41119)
     | > postnet_diff_spec_loss: 0.86495  (0.86728)
     | > decoder_ssim_loss: 0.39546  (0.31251)
     | > postnet_ssim_loss: 0.44066  (0.34970)
     | > loss: 4.65440  (5.14121)
     | > align_error: 0.99272  (0.99417)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.27940  (3.34054)
     | > current_lr: 0.00003 
     | > step_time: 3.51130  (4.59292)
     | > loader_time: 0.02400  (0.04534)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 271175[0m
     | > decoder_loss: 2.95808  (3.11323)
     | > postnet_loss: 4.46963  (4.64119)
     | > stopnet_loss: 2.69895  (1.82351)
     | > decoder_coarse_loss: 3.03599  (3.18593)
     | > decoder_ddc_loss: 0.00050  (0.00074)
     | > ga_loss: 0.00241  (0.00248)
     | > decoder_diff_spec_loss: 0.39392  (0.41242)
     | > postnet_diff_spec_loss: 0.83854  (0.86410)
     | > decoder_ssim_loss: 0.24677  (0.34523)
     | > postnet_ssim_loss: 0.27741  (0.38657)
     | > loss: 5.76620  (5.07328)
     | > align_error: 0.99556  (0.99353)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.13435  (4.31069)
     | > current_lr: 0.00003 
     | > step_time: 4.82510  (3.73226)
     | > loader_time: 0.05870  (0.03810)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 271200[0m
     | > decoder_loss: 2.99874  (3.13718)
     | > postnet_loss: 4.94908  (4.65937)
     | > stopnet_loss: 1.28020  (1.80943)
     | > decoder_coarse_loss: 3.08243  (3.21868)
     | > decoder_ddc_loss: 0.00083  (0.00077)
     | > ga_loss: 0.00252  (0.00250)
     | > decoder_diff_spec_loss: 0.42612  (0.41478)
     | > postnet_diff_spec_loss: 0.87848  (0.86795)
     | > decoder_ssim_loss: 0.41791  (0.34466)
     | > postnet_ssim_loss: 0.46705  (0.38589)
     | > loss: 4.59796  (5.07925)
     | > align_error: 0.99307  (0.99336)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.84533  (3.75675)
     | > current_lr: 0.00003 
     | > step_time: 3.65990  (3.74086)
     | > loader_time: 0.01800  (0.03419)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 271225[0m
     | > decoder_loss: 3.69254  (3.12795)
     | > postnet_loss: 5.05555  (4.57650)
     | > stopnet_loss: 2.13913  (1.80680)
     | > decoder_coarse_loss: 3.83211  (3.21859)
     | > decoder_ddc_loss: 0.00072  (0.00076)
     | > ga_loss: 0.00252  (0.00251)
     | > decoder_diff_spec_loss: 0.39404  (0.41334)
     | > postnet_diff_spec_loss: 0.83788  (0.86620)
     | > decoder_ssim_loss: 0.30026  (0.34463)
     | > postnet_ssim_loss: 0.33694  (0.38579)
     | > loss: 5.76424  (5.05280)
     | > align_error: 0.99378  (0.99336)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.27218  (3.60159)
     | > current_lr: 0.00003 
     | > step_time: 2.72470  (3.67409)
     | > loader_time: 0.01780  (0.03328)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.46473 [0m(-0.09485)
     | > avg_decoder_loss:[92m 7.57382 [0m(-0.88812)
     | > avg_postnet_loss:[92m 4.85057 [0m(-0.54885)
     | > avg_stopnet_loss:[92m 1.51795 [0m(-0.00198)
     | > avg_decoder_coarse_loss:[92m 6.02501 [0m(-0.30397)
     | > avg_decoder_ddc_loss:[91m 0.00132 [0m(+0.00039)
     | > avg_ga_loss:[91m 0.00249 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.48466 [0m(+0.00221)
     | > avg_postnet_diff_spec_loss:[91m 0.87865 [0m(+0.00068)
     | > avg_decoder_ssim_loss:[92m 0.36096 [0m(-0.00178)
     | > avg_postnet_ssim_loss:[92m 0.38381 [0m(-0.00122)
     | > avg_loss:[92m 6.67011 [0m(-0.43714)
     | > avg_align_error:[92m 0.99438 [0m(-0.00031)


[4m[1m > EPOCH: 14/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:24:00) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 271250[0m
     | > decoder_loss: 3.05770  (2.97308)
     | > postnet_loss: 4.69942  (4.27097)
     | > stopnet_loss: 2.09687  (1.91359)
     | > decoder_coarse_loss: 3.21671  (3.10310)
     | > decoder_ddc_loss: 0.00036  (0.00067)
     | > ga_loss: 0.00208  (0.00254)
     | > decoder_diff_spec_loss: 0.40766  (0.41493)
     | > postnet_diff_spec_loss: 0.85506  (0.86263)
     | > decoder_ssim_loss: 0.28163  (0.33536)
     | > postnet_ssim_loss: 0.31519  (0.37514)
     | > loss: 5.31573  (5.01028)
     | > align_error: 0.99588  (0.99357)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.83984  (4.20632)
     | > current_lr: 0.00003 
     | > step_time: 5.61510  (3.98737)
     | > loader_time: 0.02820  (0.04615)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 271275[0m
     | > decoder_loss: 3.19004  (3.02533)
     | > postnet_loss: 4.03600  (4.26464)
     | > stopnet_loss: 1.29545  (1.79805)
     | > decoder_coarse_loss: 3.33010  (3.17277)
     | > decoder_ddc_loss: 0.00101  (0.00071)
     | > ga_loss: 0.00239  (0.00250)
     | > decoder_diff_spec_loss: 0.44162  (0.41984)
     | > postnet_diff_spec_loss: 0.88658  (0.86658)
     | > decoder_ssim_loss: 0.44979  (0.34816)
     | > postnet_ssim_loss: 0.50054  (0.38955)
     | > loss: 4.51631  (4.93243)
     | > align_error: 0.99233  (0.99342)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.50929  (3.68732)
     | > current_lr: 0.00003 
     | > step_time: 2.84640  (3.84963)
     | > loader_time: 0.02660  (0.03913)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 271300[0m
     | > decoder_loss: 2.93616  (2.99698)
     | > postnet_loss: 3.98836  (4.24467)
     | > stopnet_loss: 1.65446  (1.81602)
     | > decoder_coarse_loss: 3.13488  (3.15231)
     | > decoder_ddc_loss: 0.00088  (0.00073)
     | > ga_loss: 0.00274  (0.00256)
     | > decoder_diff_spec_loss: 0.40779  (0.42023)
     | > postnet_diff_spec_loss: 0.85334  (0.86563)
     | > decoder_ssim_loss: 0.35436  (0.34479)
     | > postnet_ssim_loss: 0.39809  (0.38588)
     | > loss: 4.68665  (4.93164)
     | > align_error: 0.99177  (0.99324)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.02729  (3.54803)
     | > current_lr: 0.00003 
     | > step_time: 3.14990  (3.73829)
     | > loader_time: 0.02460  (0.03902)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 8.41815 [0m(+2.95342)
     | > avg_decoder_loss:[92m 7.35097 [0m(-0.22285)
     | > avg_postnet_loss:[92m 4.59363 [0m(-0.25694)
     | > avg_stopnet_loss:[91m 1.52840 [0m(+0.01044)
     | > avg_decoder_coarse_loss:[92m 5.96919 [0m(-0.05582)
     | > avg_decoder_ddc_loss:[91m 0.00167 [0m(+0.00035)
     | > avg_ga_loss:[92m 0.00249 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.49648 [0m(+0.01181)
     | > avg_postnet_diff_spec_loss:[91m 0.87895 [0m(+0.00030)
     | > avg_decoder_ssim_loss:[91m 0.36113 [0m(+0.00017)
     | > avg_postnet_ssim_loss:[92m 0.38356 [0m(-0.00025)
     | > avg_loss:[92m 6.54974 [0m(-0.12037)
     | > avg_align_error:[92m 0.99412 [0m(-0.00026)


[4m[1m > EPOCH: 15/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:31:42) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 271325[0m
     | > decoder_loss: 2.70989  (2.74034)
     | > postnet_loss: 3.89139  (3.87326)
     | > stopnet_loss: 2.03319  (2.07178)
     | > decoder_coarse_loss: 2.86727  (2.91444)
     | > decoder_ddc_loss: 0.00045  (0.00048)
     | > ga_loss: 0.00243  (0.00243)
     | > decoder_diff_spec_loss: 0.41530  (0.42755)
     | > postnet_diff_spec_loss: 0.86652  (0.86777)
     | > decoder_ssim_loss: 0.30118  (0.29464)
     | > postnet_ssim_loss: 0.33985  (0.33036)
     | > loss: 4.89330  (4.94614)
     | > align_error: 0.99442  (0.99392)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.51925  (4.43837)
     | > current_lr: 0.00003 
     | > step_time: 4.00580  (5.14227)
     | > loader_time: 0.01800  (0.02890)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 271350[0m
     | > decoder_loss: 2.71388  (2.84553)
     | > postnet_loss: 3.49807  (3.97080)
     | > stopnet_loss: 1.46273  (1.81305)
     | > decoder_coarse_loss: 2.89921  (3.03648)
     | > decoder_ddc_loss: 0.00053  (0.00070)
     | > ga_loss: 0.00244  (0.00262)
     | > decoder_diff_spec_loss: 0.46218  (0.43591)
     | > postnet_diff_spec_loss: 0.88412  (0.86484)
     | > decoder_ssim_loss: 0.38814  (0.34762)
     | > postnet_ssim_loss: 0.43298  (0.38886)
     | > loss: 4.29469  (4.79882)
     | > align_error: 0.99315  (0.99254)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.78278  (4.04396)
     | > current_lr: 0.00003 
     | > step_time: 4.26140  (3.92632)
     | > loader_time: 0.01580  (0.02827)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 271375[0m
     | > decoder_loss: 2.48981  (2.86064)
     | > postnet_loss: 3.84883  (3.98584)
     | > stopnet_loss: 2.04984  (1.83548)
     | > decoder_coarse_loss: 2.58832  (3.04655)
     | > decoder_ddc_loss: 0.00044  (0.00070)
     | > ga_loss: 0.00277  (0.00265)
     | > decoder_diff_spec_loss: 0.41301  (0.44118)
     | > postnet_diff_spec_loss: 0.84411  (0.86746)
     | > decoder_ssim_loss: 0.28961  (0.34250)
     | > postnet_ssim_loss: 0.32527  (0.38289)
     | > loss: 4.76353  (4.83066)
     | > align_error: 0.99317  (0.99215)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.29548  (3.48459)
     | > current_lr: 0.00003 
     | > step_time: 3.32540  (3.81744)
     | > loader_time: 0.01660  (0.02880)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 271400[0m
     | > decoder_loss: 3.77162  (2.84189)
     | > postnet_loss: 4.61361  (3.92612)
     | > stopnet_loss: 2.10502  (1.82077)
     | > decoder_coarse_loss: 4.05192  (3.01617)
     | > decoder_ddc_loss: 0.00039  (0.00073)
     | > ga_loss: 0.00216  (0.00268)
     | > decoder_diff_spec_loss: 0.43617  (0.44165)
     | > postnet_diff_spec_loss: 0.86544  (0.86587)
     | > decoder_ssim_loss: 0.27839  (0.34431)
     | > postnet_ssim_loss: 0.31049  (0.38449)
     | > loss: 5.69781  (4.78945)
     | > align_error: 0.99454  (0.99196)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.01723  (3.34336)
     | > current_lr: 0.00004 
     | > step_time: 4.16640  (3.74051)
     | > loader_time: 0.02050  (0.02870)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 6.17904 [0m(-2.23911)
     | > avg_decoder_loss:[92m 4.38051 [0m(-2.97045)
     | > avg_postnet_loss:[92m 4.45955 [0m(-0.13408)
     | > avg_stopnet_loss:[91m 1.53916 [0m(+0.01077)
     | > avg_decoder_coarse_loss:[92m 3.63627 [0m(-2.33292)
     | > avg_decoder_ddc_loss:[91m 0.00185 [0m(+0.00018)
     | > avg_ga_loss:[91m 0.00281 [0m(+0.00032)
     | > avg_decoder_diff_spec_loss:[92m 0.47842 [0m(-0.01805)
     | > avg_postnet_diff_spec_loss:[92m 0.87442 [0m(-0.00452)
     | > avg_decoder_ssim_loss:[92m 0.35152 [0m(-0.00961)
     | > avg_postnet_ssim_loss:[92m 0.37833 [0m(-0.00523)
     | > avg_loss:[92m 5.19345 [0m(-1.35629)
     | > avg_align_error:[92m 0.99211 [0m(-0.00201)


[4m[1m > EPOCH: 16/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:39:11) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 271425[0m
     | > decoder_loss: 2.62278  (2.68911)
     | > postnet_loss: 3.65220  (3.64146)
     | > stopnet_loss: 1.80808  (1.88541)
     | > decoder_coarse_loss: 2.73718  (2.81660)
     | > decoder_ddc_loss: 0.00097  (0.00095)
     | > ga_loss: 0.00247  (0.00277)
     | > decoder_diff_spec_loss: 0.41100  (0.44790)
     | > postnet_diff_spec_loss: 0.81766  (0.85979)
     | > decoder_ssim_loss: 0.34003  (0.33732)
     | > postnet_ssim_loss: 0.37841  (0.37332)
     | > loss: 4.56051  (4.69086)
     | > align_error: 0.99245  (0.99153)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.70020  (4.13249)
     | > current_lr: 0.00004 
     | > step_time: 4.58320  (4.02627)
     | > loader_time: 0.06490  (0.03117)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 271450[0m
     | > decoder_loss: 2.65550  (2.74865)
     | > postnet_loss: 3.32773  (3.66105)
     | > stopnet_loss: 2.13972  (1.79463)
     | > decoder_coarse_loss: 2.73196  (2.85750)
     | > decoder_ddc_loss: 0.00073  (0.00106)
     | > ga_loss: 0.00205  (0.00269)
     | > decoder_diff_spec_loss: 0.46163  (0.45054)
     | > postnet_diff_spec_loss: 0.87755  (0.86235)
     | > decoder_ssim_loss: 0.29035  (0.34458)
     | > postnet_ssim_loss: 0.31524  (0.38121)
     | > loss: 4.81513  (4.63480)
     | > align_error: 0.99359  (0.99158)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.68057  (3.66306)
     | > current_lr: 0.00004 
     | > step_time: 4.96030  (3.88980)
     | > loader_time: 0.06670  (0.03380)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 271475[0m
     | > decoder_loss: 2.63762  (2.74658)
     | > postnet_loss: 3.46854  (3.63262)
     | > stopnet_loss: 1.87861  (1.81031)
     | > decoder_coarse_loss: 2.65224  (2.83938)
     | > decoder_ddc_loss: 0.00062  (0.00108)
     | > ga_loss: 0.00215  (0.00275)
     | > decoder_diff_spec_loss: 0.45010  (0.45026)
     | > postnet_diff_spec_loss: 0.84349  (0.86103)
     | > decoder_ssim_loss: 0.30252  (0.34355)
     | > postnet_ssim_loss: 0.32735  (0.37913)
     | > loss: 4.55996  (4.63747)
     | > align_error: 0.99437  (0.99142)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.40764  (3.56589)
     | > current_lr: 0.00004 
     | > step_time: 4.08590  (3.77203)
     | > loader_time: 0.02520  (0.03484)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.96411 [0m(-0.21493)
     | > avg_decoder_loss:[92m 3.13496 [0m(-1.24555)
     | > avg_postnet_loss:[92m 3.60942 [0m(-0.85013)
     | > avg_stopnet_loss:[91m 1.54863 [0m(+0.00946)
     | > avg_decoder_coarse_loss:[92m 3.06901 [0m(-0.56727)
     | > avg_decoder_ddc_loss:[92m 0.00159 [0m(-0.00026)
     | > avg_ga_loss:[91m 0.00282 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.50587 [0m(+0.02744)
     | > avg_postnet_diff_spec_loss:[92m 0.86888 [0m(-0.00554)
     | > avg_decoder_ssim_loss:[92m 0.34595 [0m(-0.00557)
     | > avg_postnet_ssim_loss:[92m 0.37045 [0m(-0.00788)
     | > avg_loss:[92m 4.53924 [0m(-0.65421)
     | > avg_align_error:[92m 0.99087 [0m(-0.00124)


[4m[1m > EPOCH: 17/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:46:52) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 271500[0m
     | > decoder_loss: 2.59100  (2.54199)
     | > postnet_loss: 3.35169  (3.17129)
     | > stopnet_loss: 2.65645  (2.08156)
     | > decoder_coarse_loss: 2.66116  (2.58766)
     | > decoder_ddc_loss: 0.00054  (0.00094)
     | > ga_loss: 0.00235  (0.00259)
     | > decoder_diff_spec_loss: 0.45626  (0.45399)
     | > postnet_diff_spec_loss: 0.87504  (0.85971)
     | > decoder_ssim_loss: 0.23459  (0.29284)
     | > postnet_ssim_loss: 0.25623  (0.31604)
     | > loss: 5.27485  (4.65060)
     | > align_error: 0.99442  (0.99237)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.98850  (3.16188)
     | > current_lr: 0.00004 
     | > step_time: 5.44410  (4.91338)
     | > loader_time: 0.17060  (0.10376)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 271525[0m
     | > decoder_loss: 3.05912  (2.70355)
     | > postnet_loss: 3.40200  (3.32391)
     | > stopnet_loss: 1.50831  (1.81252)
     | > decoder_coarse_loss: 3.02176  (2.72627)
     | > decoder_ddc_loss: 0.00177  (0.00124)
     | > ga_loss: 0.00367  (0.00275)
     | > decoder_diff_spec_loss: 0.48289  (0.45084)
     | > postnet_diff_spec_loss: 0.90053  (0.85498)
     | > decoder_ssim_loss: 0.41800  (0.34509)
     | > postnet_ssim_loss: 0.45274  (0.37613)
     | > loss: 4.46137  (4.52176)
     | > align_error: 0.98799  (0.99142)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.05903  (4.12952)
     | > current_lr: 0.00004 
     | > step_time: 1.95900  (3.76199)
     | > loader_time: 0.02030  (0.03950)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 271550[0m
     | > decoder_loss: 2.75102  (2.72561)
     | > postnet_loss: 3.33349  (3.31541)
     | > stopnet_loss: 2.29028  (1.81627)
     | > decoder_coarse_loss: 2.77209  (2.75063)
     | > decoder_ddc_loss: 0.00173  (0.00130)
     | > ga_loss: 0.00318  (0.00274)
     | > decoder_diff_spec_loss: 0.46430  (0.45359)
     | > postnet_diff_spec_loss: 0.83799  (0.85811)
     | > decoder_ssim_loss: 0.27878  (0.34207)
     | > postnet_ssim_loss: 0.30331  (0.37218)
     | > loss: 4.99187  (4.53470)
     | > align_error: 0.98952  (0.99125)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.39256  (3.79567)
     | > current_lr: 0.00004 
     | > step_time: 3.85230  (3.81229)
     | > loader_time: 0.01440  (0.03317)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 271575[0m
     | > decoder_loss: 2.40226  (2.70888)
     | > postnet_loss: 2.72464  (3.25128)
     | > stopnet_loss: 1.52676  (1.79965)
     | > decoder_coarse_loss: 2.37396  (2.72239)
     | > decoder_ddc_loss: 0.00216  (0.00137)
     | > ga_loss: 0.00319  (0.00276)
     | > decoder_diff_spec_loss: 0.44810  (0.45084)
     | > postnet_diff_spec_loss: 0.84788  (0.85575)
     | > decoder_ssim_loss: 0.40265  (0.34386)
     | > postnet_ssim_loss: 0.42807  (0.37292)
     | > loss: 3.95014  (4.49027)
     | > align_error: 0.98888  (0.99122)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.87502  (3.61752)
     | > current_lr: 0.00004 
     | > step_time: 2.89400  (3.73859)
     | > loader_time: 0.01910  (0.03587)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.03646 [0m(-0.92764)
     | > avg_decoder_loss:[91m 3.26547 [0m(+0.13052)
     | > avg_postnet_loss:[92m 3.43733 [0m(-0.17209)
     | > avg_stopnet_loss:[92m 1.54738 [0m(-0.00124)
     | > avg_decoder_coarse_loss:[91m 3.54176 [0m(+0.47275)
     | > avg_decoder_ddc_loss:[91m 0.00179 [0m(+0.00020)
     | > avg_ga_loss:[92m 0.00277 [0m(-0.00005)
     | > avg_decoder_diff_spec_loss:[91m 0.50914 [0m(+0.00328)
     | > avg_postnet_diff_spec_loss:[92m 0.86393 [0m(-0.00495)
     | > avg_decoder_ssim_loss:[91m 0.34665 [0m(+0.00070)
     | > avg_postnet_ssim_loss:[92m 0.36505 [0m(-0.00540)
     | > avg_loss:[91m 4.64399 [0m(+0.10475)
     | > avg_align_error:[91m 0.99097 [0m(+0.00010)


[4m[1m > EPOCH: 18/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:54:33) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 271600[0m
     | > decoder_loss: 2.75324  (2.63159)
     | > postnet_loss: 3.68209  (3.01084)
     | > stopnet_loss: 1.98698  (1.92317)
     | > decoder_coarse_loss: 2.79495  (2.63185)
     | > decoder_ddc_loss: 0.00144  (0.00148)
     | > ga_loss: 0.00273  (0.00278)
     | > decoder_diff_spec_loss: 0.45170  (0.45387)
     | > postnet_diff_spec_loss: 0.84206  (0.85183)
     | > decoder_ssim_loss: 0.30060  (0.33589)
     | > postnet_ssim_loss: 0.32299  (0.36051)
     | > loss: 4.78791  (4.50656)
     | > align_error: 0.99131  (0.99131)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.03436  (4.80796)
     | > current_lr: 0.00004 
     | > step_time: 3.94520  (3.90992)
     | > loader_time: 0.03030  (0.04316)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 271625[0m
     | > decoder_loss: 2.72485  (2.67803)
     | > postnet_loss: 2.91614  (3.04919)
     | > stopnet_loss: 1.70999  (1.78949)
     | > decoder_coarse_loss: 2.78165  (2.67397)
     | > decoder_ddc_loss: 0.00217  (0.00163)
     | > ga_loss: 0.00293  (0.00268)
     | > decoder_diff_spec_loss: 0.46318  (0.45173)
     | > postnet_diff_spec_loss: 0.88441  (0.85105)
     | > decoder_ssim_loss: 0.31669  (0.34479)
     | > postnet_ssim_loss: 0.33877  (0.37014)
     | > loss: 4.33160  (4.40803)
     | > align_error: 0.99025  (0.99146)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.80565  (3.98728)
     | > current_lr: 0.00004 
     | > step_time: 3.61920  (3.84639)
     | > loader_time: 0.02460  (0.03466)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 271650[0m
     | > decoder_loss: 2.41496  (2.67809)
     | > postnet_loss: 2.54496  (3.02939)
     | > stopnet_loss: 2.09241  (1.78720)
     | > decoder_coarse_loss: 2.40628  (2.66959)
     | > decoder_ddc_loss: 0.00157  (0.00178)
     | > ga_loss: 0.00232  (0.00274)
     | > decoder_diff_spec_loss: 0.45014  (0.45198)
     | > postnet_diff_spec_loss: 0.84547  (0.85045)
     | > decoder_ssim_loss: 0.29427  (0.34303)
     | > postnet_ssim_loss: 0.31339  (0.36752)
     | > loss: 4.42179  (4.39884)
     | > align_error: 0.99287  (0.99130)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.00730  (3.71747)
     | > current_lr: 0.00004 
     | > step_time: 4.96550  (3.77320)
     | > loader_time: 0.13630  (0.03780)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.27522 [0m(+0.23875)
     | > avg_decoder_loss:[92m 2.98259 [0m(-0.28289)
     | > avg_postnet_loss:[92m 3.09933 [0m(-0.33800)
     | > avg_stopnet_loss:[92m 1.54272 [0m(-0.00466)
     | > avg_decoder_coarse_loss:[92m 3.48110 [0m(-0.06066)
     | > avg_decoder_ddc_loss:[91m 0.00206 [0m(+0.00026)
     | > avg_ga_loss:[92m 0.00263 [0m(-0.00014)
     | > avg_decoder_diff_spec_loss:[91m 0.52566 [0m(+0.01651)
     | > avg_postnet_diff_spec_loss:[92m 0.86083 [0m(-0.00310)
     | > avg_decoder_ssim_loss:[92m 0.34452 [0m(-0.00213)
     | > avg_postnet_ssim_loss:[92m 0.36091 [0m(-0.00414)
     | > avg_loss:[92m 4.47010 [0m(-0.17389)
     | > avg_align_error:[92m 0.99071 [0m(-0.00026)


[4m[1m > EPOCH: 19/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:02:27) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 271675[0m
     | > decoder_loss: 2.50739  (2.48711)
     | > postnet_loss: 2.53444  (2.69045)
     | > stopnet_loss: 1.81082  (1.97189)
     | > decoder_coarse_loss: 2.47589  (2.46356)
     | > decoder_ddc_loss: 0.00150  (0.00187)
     | > ga_loss: 0.00214  (0.00262)
     | > decoder_diff_spec_loss: 0.46039  (0.45431)
     | > postnet_diff_spec_loss: 0.84752  (0.84669)
     | > decoder_ssim_loss: 0.31422  (0.31167)
     | > postnet_ssim_loss: 0.33225  (0.32745)
     | > loss: 4.18995  (4.38074)
     | > align_error: 0.99360  (0.99173)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.33333  (3.17713)
     | > current_lr: 0.00004 
     | > step_time: 6.56030  (5.45112)
     | > loader_time: 0.02540  (0.05150)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 271700[0m
     | > decoder_loss: 2.54256  (2.61632)
     | > postnet_loss: 2.55365  (2.84821)
     | > stopnet_loss: 1.87996  (1.83230)
     | > decoder_coarse_loss: 2.53605  (2.58857)
     | > decoder_ddc_loss: 0.00165  (0.00203)
     | > ga_loss: 0.00260  (0.00265)
     | > decoder_diff_spec_loss: 0.45390  (0.45225)
     | > postnet_diff_spec_loss: 0.85074  (0.84490)
     | > decoder_ssim_loss: 0.31145  (0.34173)
     | > postnet_ssim_loss: 0.32842  (0.36348)
     | > loss: 4.28756  (4.35993)
     | > align_error: 0.99306  (0.99159)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.85959  (4.05342)
     | > current_lr: 0.00004 
     | > step_time: 3.65400  (3.87330)
     | > loader_time: 0.03030  (0.03608)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 271725[0m
     | > decoder_loss: 2.48249  (2.64963)
     | > postnet_loss: 2.64445  (2.84928)
     | > stopnet_loss: 1.69385  (1.81076)
     | > decoder_coarse_loss: 2.49512  (2.62203)
     | > decoder_ddc_loss: 0.00278  (0.00218)
     | > ga_loss: 0.00338  (0.00268)
     | > decoder_diff_spec_loss: 0.42970  (0.45646)
     | > postnet_diff_spec_loss: 0.85737  (0.84944)
     | > decoder_ssim_loss: 0.37912  (0.34258)
     | > postnet_ssim_loss: 0.40258  (0.36343)
     | > loss: 4.13413  (4.35790)
     | > align_error: 0.98970  (0.99132)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.76971  (3.83682)
     | > current_lr: 0.00004 
     | > step_time: 2.36110  (3.82214)
     | > loader_time: 0.01880  (0.03840)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 271750[0m
     | > decoder_loss: 2.18058  (2.63299)
     | > postnet_loss: 2.35279  (2.81039)
     | > stopnet_loss: 2.92806  (1.79600)
     | > decoder_coarse_loss: 2.15640  (2.60574)
     | > decoder_ddc_loss: 0.00143  (0.00226)
     | > ga_loss: 0.00259  (0.00271)
     | > decoder_diff_spec_loss: 0.40434  (0.45484)
     | > postnet_diff_spec_loss: 0.83479  (0.84670)
     | > decoder_ssim_loss: 0.21101  (0.34243)
     | > postnet_ssim_loss: 0.22036  (0.36260)
     | > loss: 5.03143  (4.32402)
     | > align_error: 0.99341  (0.99125)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.76386  (3.67902)
     | > current_lr: 0.00004 
     | > step_time: 4.42340  (3.73712)
     | > loader_time: 0.05430  (0.03762)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.40491 [0m(+0.12969)
     | > avg_decoder_loss:[92m 2.96419 [0m(-0.01839)
     | > avg_postnet_loss:[92m 3.04044 [0m(-0.05890)
     | > avg_stopnet_loss:[91m 1.54324 [0m(+0.00053)
     | > avg_decoder_coarse_loss:[91m 3.56886 [0m(+0.08776)
     | > avg_decoder_ddc_loss:[91m 0.00233 [0m(+0.00028)
     | > avg_ga_loss:[91m 0.00263 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.53112 [0m(+0.00546)
     | > avg_postnet_diff_spec_loss:[92m 0.85701 [0m(-0.00383)
     | > avg_decoder_ssim_loss:[92m 0.34375 [0m(-0.00077)
     | > avg_postnet_ssim_loss:[92m 0.35665 [0m(-0.00426)
     | > avg_loss:[91m 4.47246 [0m(+0.00237)
     | > avg_align_error:[91m 0.99079 [0m(+0.00009)


[4m[1m > EPOCH: 20/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:10:06) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 271775[0m
     | > decoder_loss: 2.80446  (2.55736)
     | > postnet_loss: 2.95221  (2.63981)
     | > stopnet_loss: 1.41901  (1.83478)
     | > decoder_coarse_loss: 2.71945  (2.52465)
     | > decoder_ddc_loss: 0.00251  (0.00230)
     | > ga_loss: 0.00275  (0.00276)
     | > decoder_diff_spec_loss: 0.47968  (0.46000)
     | > postnet_diff_spec_loss: 0.86848  (0.84535)
     | > decoder_ssim_loss: 0.41836  (0.33820)
     | > postnet_ssim_loss: 0.43421  (0.35562)
     | > loss: 4.10261  (4.27940)
     | > align_error: 0.99042  (0.99128)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.94727  (4.03528)
     | > current_lr: 0.00004 
     | > step_time: 3.73250  (4.10828)
     | > loader_time: 0.01650  (0.03236)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 271800[0m
     | > decoder_loss: 3.52723  (2.59570)
     | > postnet_loss: 3.82228  (2.69707)
     | > stopnet_loss: 2.18473  (1.75062)
     | > decoder_coarse_loss: 3.41594  (2.56664)
     | > decoder_ddc_loss: 0.00142  (0.00231)
     | > ga_loss: 0.00197  (0.00265)
     | > decoder_diff_spec_loss: 0.53307  (0.45755)
     | > postnet_diff_spec_loss: 0.92167  (0.84310)
     | > decoder_ssim_loss: 0.25434  (0.34495)
     | > postnet_ssim_loss: 0.26747  (0.36291)
     | > loss: 5.38045  (4.23143)
     | > align_error: 0.99386  (0.99143)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.89371  (3.69418)
     | > current_lr: 0.00005 
     | > step_time: 5.44410  (3.87648)
     | > loader_time: 0.02660  (0.02854)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 271825[0m
     | > decoder_loss: 2.64090  (2.60432)
     | > postnet_loss: 3.01411  (2.68601)
     | > stopnet_loss: 1.93664  (1.76803)
     | > decoder_coarse_loss: 2.62220  (2.57195)
     | > decoder_ddc_loss: 0.00142  (0.00238)
     | > ga_loss: 0.00216  (0.00271)
     | > decoder_diff_spec_loss: 0.45781  (0.45773)
     | > postnet_diff_spec_loss: 0.82964  (0.84353)
     | > decoder_ssim_loss: 0.31118  (0.34320)
     | > postnet_ssim_loss: 0.32252  (0.36077)
     | > loss: 4.49737  (4.24907)
     | > align_error: 0.99393  (0.99122)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.28823  (3.67417)
     | > current_lr: 0.00005 
     | > step_time: 4.78300  (3.74865)
     | > loader_time: 0.02190  (0.03153)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.71876 [0m(+0.31384)
     | > avg_decoder_loss:[91m 3.09827 [0m(+0.13408)
     | > avg_postnet_loss:[91m 3.09156 [0m(+0.05113)
     | > avg_stopnet_loss:[92m 1.54112 [0m(-0.00212)
     | > avg_decoder_coarse_loss:[91m 3.89717 [0m(+0.32831)
     | > avg_decoder_ddc_loss:[91m 0.00240 [0m(+0.00007)
     | > avg_ga_loss:[92m 0.00262 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.52409 [0m(-0.00703)
     | > avg_postnet_diff_spec_loss:[92m 0.85384 [0m(-0.00317)
     | > avg_decoder_ssim_loss:[91m 0.34454 [0m(+0.00079)
     | > avg_postnet_ssim_loss:[92m 0.35494 [0m(-0.00171)
     | > avg_loss:[91m 4.59592 [0m(+0.12345)
     | > avg_align_error:[91m 0.99104 [0m(+0.00025)


[4m[1m > EPOCH: 21/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:17:39) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 271850[0m
     | > decoder_loss: 2.40571  (2.43006)
     | > postnet_loss: 2.33834  (2.46141)
     | > stopnet_loss: 1.81388  (1.95861)
     | > decoder_coarse_loss: 2.39503  (2.40521)
     | > decoder_ddc_loss: 0.00227  (0.00243)
     | > ga_loss: 0.00273  (0.00282)
     | > decoder_diff_spec_loss: 0.44465  (0.45927)
     | > postnet_diff_spec_loss: 0.82877  (0.84180)
     | > decoder_ssim_loss: 0.32895  (0.31013)
     | > postnet_ssim_loss: 0.33592  (0.32038)
     | > loss: 4.09743  (4.28039)
     | > align_error: 0.99180  (0.99088)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.27467  (3.32923)
     | > current_lr: 0.00005 
     | > step_time: 5.21190  (5.70070)
     | > loader_time: 0.02430  (0.02207)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 271875[0m
     | > decoder_loss: 2.45945  (2.54543)
     | > postnet_loss: 2.44908  (2.57914)
     | > stopnet_loss: 1.48082  (1.81721)
     | > decoder_coarse_loss: 2.42427  (2.51347)
     | > decoder_ddc_loss: 0.00321  (0.00230)
     | > ga_loss: 0.00289  (0.00265)
     | > decoder_diff_spec_loss: 0.44217  (0.45875)
     | > postnet_diff_spec_loss: 0.81801  (0.83831)
     | > decoder_ssim_loss: 0.40400  (0.34215)
     | > postnet_ssim_loss: 0.42117  (0.35771)
     | > loss: 3.85059  (4.23979)
     | > align_error: 0.98913  (0.99150)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.06840  (4.36319)
     | > current_lr: 0.00005 
     | > step_time: 3.30260  (3.88416)
     | > loader_time: 0.01860  (0.03254)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 271900[0m
     | > decoder_loss: 2.50215  (2.57828)
     | > postnet_loss: 2.18426  (2.56877)
     | > stopnet_loss: 2.24049  (1.79710)
     | > decoder_coarse_loss: 2.40221  (2.54274)
     | > decoder_ddc_loss: 0.00195  (0.00233)
     | > ga_loss: 0.00297  (0.00266)
     | > decoder_diff_spec_loss: 0.45576  (0.46365)
     | > postnet_diff_spec_loss: 0.82170  (0.84308)
     | > decoder_ssim_loss: 0.27198  (0.34106)
     | > postnet_ssim_loss: 0.28565  (0.35592)
     | > loss: 4.48677  (4.23438)
     | > align_error: 0.99183  (0.99134)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.38266  (3.83293)
     | > current_lr: 0.00005 
     | > step_time: 4.13400  (3.85316)
     | > loader_time: 0.07020  (0.03697)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 271925[0m
     | > decoder_loss: 2.76419  (2.56935)
     | > postnet_loss: 2.63716  (2.54701)
     | > stopnet_loss: 1.44857  (1.78195)
     | > decoder_coarse_loss: 2.74066  (2.53124)
     | > decoder_ddc_loss: 0.00225  (0.00238)
     | > ga_loss: 0.00224  (0.00270)
     | > decoder_diff_spec_loss: 0.50177  (0.46150)
     | > postnet_diff_spec_loss: 0.87142  (0.84108)
     | > decoder_ssim_loss: 0.39061  (0.34328)
     | > postnet_ssim_loss: 0.40130  (0.35799)
     | > loss: 4.03711  (4.20890)
     | > align_error: 0.99211  (0.99125)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.70242  (3.75199)
     | > current_lr: 0.00005 
     | > step_time: 4.22980  (3.70017)
     | > loader_time: 0.01900  (0.03683)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.75357 [0m(+0.03482)
     | > avg_decoder_loss:[91m 3.11071 [0m(+0.01244)
     | > avg_postnet_loss:[91m 3.19410 [0m(+0.10254)
     | > avg_stopnet_loss:[91m 1.54717 [0m(+0.00604)
     | > avg_decoder_coarse_loss:[91m 3.96313 [0m(+0.06596)
     | > avg_decoder_ddc_loss:[92m 0.00235 [0m(-0.00005)
     | > avg_ga_loss:[92m 0.00257 [0m(-0.00004)
     | > avg_decoder_diff_spec_loss:[91m 0.53343 [0m(+0.00935)
     | > avg_postnet_diff_spec_loss:[92m 0.85275 [0m(-0.00109)
     | > avg_decoder_ssim_loss:[92m 0.34385 [0m(-0.00068)
     | > avg_postnet_ssim_loss:[92m 0.35350 [0m(-0.00144)
     | > avg_loss:[91m 4.64850 [0m(+0.05258)
     | > avg_align_error:[91m 0.99106 [0m(+0.00002)


[4m[1m > EPOCH: 22/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:25:26) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 271950[0m
     | > decoder_loss: 2.67556  (2.48820)
     | > postnet_loss: 2.41550  (2.41283)
     | > stopnet_loss: 2.93507  (1.92002)
     | > decoder_coarse_loss: 2.60881  (2.44095)
     | > decoder_ddc_loss: 0.00257  (0.00237)
     | > ga_loss: 0.00353  (0.00275)
     | > decoder_diff_spec_loss: 0.47299  (0.46368)
     | > postnet_diff_spec_loss: 0.83045  (0.83904)
     | > decoder_ssim_loss: 0.22910  (0.33153)
     | > postnet_ssim_loss: 0.23270  (0.34485)
     | > loss: 5.31962  (4.26462)
     | > align_error: 0.98943  (0.99144)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 11.22658  (4.50669)
     | > current_lr: 0.00005 
     | > step_time: 2.80310  (4.03693)
     | > loader_time: 0.02620  (0.05568)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 271975[0m
     | > decoder_loss: 2.61618  (2.51580)
     | > postnet_loss: 2.61486  (2.45439)
     | > stopnet_loss: 1.54528  (1.75546)
     | > decoder_coarse_loss: 2.58642  (2.46431)
     | > decoder_ddc_loss: 0.00205  (0.00245)
     | > ga_loss: 0.00200  (0.00265)
     | > decoder_diff_spec_loss: 0.47291  (0.46275)
     | > postnet_diff_spec_loss: 0.83511  (0.83644)
     | > decoder_ssim_loss: 0.37040  (0.34642)
     | > postnet_ssim_loss: 0.38800  (0.35990)
     | > loss: 4.02676  (4.12933)
     | > align_error: 0.99275  (0.99143)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.86714  (4.11891)
     | > current_lr: 0.00005 
     | > step_time: 4.81120  (3.83188)
     | > loader_time: 0.02220  (0.03985)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 272000[0m
     | > decoder_loss: 2.43269  (2.54407)
     | > postnet_loss: 2.28727  (2.46871)
     | > stopnet_loss: 1.43925  (1.77198)
     | > decoder_coarse_loss: 2.36560  (2.49477)
     | > decoder_ddc_loss: 0.00275  (0.00247)
     | > ga_loss: 0.00296  (0.00271)
     | > decoder_diff_spec_loss: 0.42440  (0.46431)
     | > postnet_diff_spec_loss: 0.82156  (0.83915)
     | > decoder_ssim_loss: 0.41083  (0.34277)
     | > postnet_ssim_loss: 0.42812  (0.35596)
     | > loss: 3.74735  (4.16356)
     | > align_error: 0.98946  (0.99127)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.04931  (3.83202)
     | > current_lr: 0.00005 
     | > step_time: 2.68790  (3.73118)
     | > loader_time: 0.01470  (0.03696)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.64371 [0m(-0.10986)
     | > avg_decoder_loss:[92m 2.94124 [0m(-0.16947)
     | > avg_postnet_loss:[92m 2.96790 [0m(-0.22620)
     | > avg_stopnet_loss:[92m 1.53589 [0m(-0.01128)
     | > avg_decoder_coarse_loss:[92m 3.77789 [0m(-0.18525)
     | > avg_decoder_ddc_loss:[91m 0.00249 [0m(+0.00014)
     | > avg_ga_loss:[92m 0.00256 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.52111 [0m(-0.01233)
     | > avg_postnet_diff_spec_loss:[92m 0.84930 [0m(-0.00346)
     | > avg_decoder_ssim_loss:[92m 0.34202 [0m(-0.00183)
     | > avg_postnet_ssim_loss:[92m 0.35246 [0m(-0.00104)
     | > avg_loss:[92m 4.48728 [0m(-0.16122)
     | > avg_align_error:[91m 0.99121 [0m(+0.00015)


[4m[1m > EPOCH: 23/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:33:13) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 272025[0m
     | > decoder_loss: 2.40755  (2.40755)
     | > postnet_loss: 2.38056  (2.38056)
     | > stopnet_loss: 2.01581  (2.01581)
     | > decoder_coarse_loss: 2.39475  (2.39475)
     | > decoder_ddc_loss: 0.00258  (0.00258)
     | > ga_loss: 0.00297  (0.00297)
     | > decoder_diff_spec_loss: 0.48270  (0.48270)
     | > postnet_diff_spec_loss: 0.85057  (0.85057)
     | > decoder_ssim_loss: 0.29014  (0.29014)
     | > postnet_ssim_loss: 0.30015  (0.30015)
     | > loss: 4.30789  (4.30789)
     | > align_error: 0.98993  (0.98993)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.82480  (5.82480)
     | > current_lr: 0.00005 
     | > step_time: 5.13620  (5.13618)
     | > loader_time: 0.02280  (0.02277)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 272050[0m
     | > decoder_loss: 2.69406  (2.48774)
     | > postnet_loss: 2.51782  (2.40715)
     | > stopnet_loss: 1.76563  (1.80435)
     | > decoder_coarse_loss: 2.59066  (2.44119)
     | > decoder_ddc_loss: 0.00262  (0.00226)
     | > ga_loss: 0.00311  (0.00263)
     | > decoder_diff_spec_loss: 0.47168  (0.46755)
     | > postnet_diff_spec_loss: 0.83917  (0.83541)
     | > decoder_ssim_loss: 0.37005  (0.33839)
     | > postnet_ssim_loss: 0.38387  (0.35069)
     | > loss: 4.24868  (4.15012)
     | > align_error: 0.99007  (0.99170)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.51606  (4.17115)
     | > current_lr: 0.00005 
     | > step_time: 2.99600  (3.90577)
     | > loader_time: 0.02190  (0.02988)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 272075[0m
     | > decoder_loss: 2.67351  (2.51682)
     | > postnet_loss: 2.80849  (2.39829)
     | > stopnet_loss: 1.42339  (1.75942)
     | > decoder_coarse_loss: 2.62555  (2.47010)
     | > decoder_ddc_loss: 0.00345  (0.00237)
     | > ga_loss: 0.00377  (0.00265)
     | > decoder_diff_spec_loss: 0.48380  (0.47121)
     | > postnet_diff_spec_loss: 0.85207  (0.84007)
     | > decoder_ssim_loss: 0.40194  (0.34097)
     | > postnet_ssim_loss: 0.41431  (0.35303)
     | > loss: 4.00802  (4.12087)
     | > align_error: 0.98886  (0.99144)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.06613  (3.72783)
     | > current_lr: 0.00005 
     | > step_time: 2.38170  (3.80101)
     | > loader_time: 0.02560  (0.02985)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 272100[0m
     | > decoder_loss: 2.42459  (2.50366)
     | > postnet_loss: 2.33360  (2.37352)
     | > stopnet_loss: 1.33592  (1.76118)
     | > decoder_coarse_loss: 2.38984  (2.45242)
     | > decoder_ddc_loss: 0.00459  (0.00242)
     | > ga_loss: 0.00370  (0.00270)
     | > decoder_diff_spec_loss: 0.49849  (0.46827)
     | > postnet_diff_spec_loss: 0.86887  (0.83714)
     | > decoder_ssim_loss: 0.45378  (0.34131)
     | > postnet_ssim_loss: 0.46618  (0.35295)
     | > loss: 3.71441  (4.10759)
     | > align_error: 0.98524  (0.99132)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.99024  (3.74100)
     | > current_lr: 0.00005 
     | > step_time: 2.52500  (3.68749)
     | > loader_time: 0.01780  (0.03112)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.17142 [0m(-0.47229)
     | > avg_decoder_loss:[92m 2.91019 [0m(-0.03105)
     | > avg_postnet_loss:[91m 3.03288 [0m(+0.06498)
     | > avg_stopnet_loss:[91m 1.53715 [0m(+0.00126)
     | > avg_decoder_coarse_loss:[92m 3.66487 [0m(-0.11301)
     | > avg_decoder_ddc_loss:[91m 0.00256 [0m(+0.00006)
     | > avg_ga_loss:[92m 0.00255 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.51727 [0m(-0.00384)
     | > avg_postnet_diff_spec_loss:[92m 0.84897 [0m(-0.00033)
     | > avg_decoder_ssim_loss:[92m 0.34085 [0m(-0.00117)
     | > avg_postnet_ssim_loss:[92m 0.35159 [0m(-0.00087)
     | > avg_loss:[92m 4.46719 [0m(-0.02009)
     | > avg_align_error:[91m 0.99129 [0m(+0.00008)


[4m[1m > EPOCH: 24/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:40:52) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 272125[0m
     | > decoder_loss: 2.53756  (2.41291)
     | > postnet_loss: 2.38364  (2.25418)
     | > stopnet_loss: 3.04356  (1.80339)
     | > decoder_coarse_loss: 2.43541  (2.36786)
     | > decoder_ddc_loss: 0.00124  (0.00240)
     | > ga_loss: 0.00246  (0.00269)
     | > decoder_diff_spec_loss: 0.48918  (0.46928)
     | > postnet_diff_spec_loss: 0.85167  (0.83568)
     | > decoder_ssim_loss: 0.19358  (0.33788)
     | > postnet_ssim_loss: 0.20186  (0.34903)
     | > loss: 5.32940  (4.07416)
     | > align_error: 0.99474  (0.99158)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.52678  (3.69098)
     | > current_lr: 0.00005 
     | > step_time: 4.17960  (4.10225)
     | > loader_time: 0.02530  (0.04779)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 272150[0m
     | > decoder_loss: 2.50511  (2.44144)
     | > postnet_loss: 2.26950  (2.29675)
     | > stopnet_loss: 1.70813  (1.75505)
     | > decoder_coarse_loss: 2.45259  (2.39158)
     | > decoder_ddc_loss: 0.00255  (0.00245)
     | > ga_loss: 0.00265  (0.00268)
     | > decoder_diff_spec_loss: 0.46627  (0.46846)
     | > postnet_diff_spec_loss: 0.82937  (0.83304)
     | > decoder_ssim_loss: 0.33134  (0.34399)
     | > postnet_ssim_loss: 0.34347  (0.35553)
     | > loss: 4.02143  (4.05174)
     | > align_error: 0.99152  (0.99136)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.78184  (4.03884)
     | > current_lr: 0.00005 
     | > step_time: 3.21780  (3.75711)
     | > loader_time: 0.02350  (0.03780)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 272175[0m
     | > decoder_loss: 2.55901  (2.47314)
     | > postnet_loss: 2.36874  (2.31540)
     | > stopnet_loss: 1.71591  (1.77689)
     | > decoder_coarse_loss: 2.53077  (2.41979)
     | > decoder_ddc_loss: 0.00261  (0.00247)
     | > ga_loss: 0.00321  (0.00270)
     | > decoder_diff_spec_loss: 0.46765  (0.47155)
     | > postnet_diff_spec_loss: 0.83417  (0.83567)
     | > decoder_ssim_loss: 0.35868  (0.33992)
     | > postnet_ssim_loss: 0.37325  (0.35097)
     | > loss: 4.10566  (4.09263)
     | > align_error: 0.99093  (0.99128)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.10900  (3.91590)
     | > current_lr: 0.00005 
     | > step_time: 2.96360  (3.72669)
     | > loader_time: 0.01800  (0.03554)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.99719 [0m(+0.82576)
     | > avg_decoder_loss:[91m 3.06577 [0m(+0.15558)
     | > avg_postnet_loss:[91m 3.03326 [0m(+0.00038)
     | > avg_stopnet_loss:[91m 1.53924 [0m(+0.00209)
     | > avg_decoder_coarse_loss:[91m 3.82628 [0m(+0.16140)
     | > avg_decoder_ddc_loss:[92m 0.00251 [0m(-0.00005)
     | > avg_ga_loss:[91m 0.00258 [0m(+0.00003)
     | > avg_decoder_diff_spec_loss:[91m 0.53181 [0m(+0.01454)
     | > avg_postnet_diff_spec_loss:[91m 0.84930 [0m(+0.00033)
     | > avg_decoder_ssim_loss:[91m 0.34087 [0m(+0.00002)
     | > avg_postnet_ssim_loss:[92m 0.35057 [0m(-0.00102)
     | > avg_loss:[91m 4.55223 [0m(+0.08503)
     | > avg_align_error:[92m 0.99127 [0m(-0.00002)


[4m[1m > EPOCH: 25/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:48:28) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 272200[0m
     | > decoder_loss: 2.21897  (2.21897)
     | > postnet_loss: 2.06240  (2.06240)
     | > stopnet_loss: 1.04065  (1.04065)
     | > decoder_coarse_loss: 2.16175  (2.16175)
     | > decoder_ddc_loss: 0.00320  (0.00320)
     | > ga_loss: 0.00278  (0.00278)
     | > decoder_diff_spec_loss: 0.45474  (0.45474)
     | > postnet_diff_spec_loss: 0.81221  (0.81221)
     | > decoder_ssim_loss: 0.49885  (0.49885)
     | > postnet_ssim_loss: 0.51208  (0.51208)
     | > loss: 3.23560  (3.23560)
     | > align_error: 0.98961  (0.98961)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.74831  (2.74831)
     | > current_lr: 0.00006 
     | > step_time: 2.92060  (2.92059)
     | > loader_time: 9.15810  (9.15809)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 272225[0m
     | > decoder_loss: 2.35931  (2.41375)
     | > postnet_loss: 2.05443  (2.27396)
     | > stopnet_loss: 1.43818  (1.81789)
     | > decoder_coarse_loss: 2.25338  (2.36367)
     | > decoder_ddc_loss: 0.00278  (0.00229)
     | > ga_loss: 0.00258  (0.00261)
     | > decoder_diff_spec_loss: 0.46294  (0.47483)
     | > postnet_diff_spec_loss: 0.81973  (0.83130)
     | > decoder_ssim_loss: 0.38278  (0.33562)
     | > postnet_ssim_loss: 0.39170  (0.34586)
     | > loss: 3.63285  (4.09126)
     | > align_error: 0.99011  (0.99187)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.95024  (4.33021)
     | > current_lr: 0.00006 
     | > step_time: 3.10960  (3.88168)
     | > loader_time: 0.01730  (0.03728)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 272250[0m
     | > decoder_loss: 2.47853  (2.44013)
     | > postnet_loss: 2.26799  (2.25022)
     | > stopnet_loss: 1.56575  (1.78121)
     | > decoder_coarse_loss: 2.46386  (2.39356)
     | > decoder_ddc_loss: 0.00257  (0.00235)
     | > ga_loss: 0.00270  (0.00261)
     | > decoder_diff_spec_loss: 0.47766  (0.47911)
     | > postnet_diff_spec_loss: 0.82499  (0.83564)
     | > decoder_ssim_loss: 0.35265  (0.33809)
     | > postnet_ssim_loss: 0.36746  (0.34811)
     | > loss: 3.88816  (4.06609)
     | > align_error: 0.99073  (0.99158)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.84143  (3.90496)
     | > current_lr: 0.00006 
     | > step_time: 3.17140  (3.86877)
     | > loader_time: 0.06400  (0.03998)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 272275[0m
     | > decoder_loss: 2.23544  (2.42453)
     | > postnet_loss: 1.85801  (2.23301)
     | > stopnet_loss: 1.70329  (1.77847)
     | > decoder_coarse_loss: 2.22653  (2.37911)
     | > decoder_ddc_loss: 0.00189  (0.00237)
     | > ga_loss: 0.00223  (0.00268)
     | > decoder_diff_spec_loss: 0.49743  (0.47691)
     | > postnet_diff_spec_loss: 0.82283  (0.83238)
     | > decoder_ssim_loss: 0.32956  (0.33785)
     | > postnet_ssim_loss: 0.33397  (0.34775)
     | > loss: 3.79086  (4.05035)
     | > align_error: 0.99281  (0.99148)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.44107  (3.87233)
     | > current_lr: 0.00006 
     | > step_time: 4.45330  (3.76693)
     | > loader_time: 0.05000  (0.03617)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.13152 [0m(-0.86567)
     | > avg_decoder_loss:[92m 3.00477 [0m(-0.06100)
     | > avg_postnet_loss:[91m 3.08063 [0m(+0.04737)
     | > avg_stopnet_loss:[92m 1.53786 [0m(-0.00138)
     | > avg_decoder_coarse_loss:[92m 3.71390 [0m(-0.11238)
     | > avg_decoder_ddc_loss:[92m 0.00234 [0m(-0.00017)
     | > avg_ga_loss:[92m 0.00255 [0m(-0.00003)
     | > avg_decoder_diff_spec_loss:[92m 0.53164 [0m(-0.00017)
     | > avg_postnet_diff_spec_loss:[91m 0.84940 [0m(+0.00010)
     | > avg_decoder_ssim_loss:[92m 0.33887 [0m(-0.00200)
     | > avg_postnet_ssim_loss:[91m 0.35059 [0m(+0.00002)
     | > avg_loss:[92m 4.51863 [0m(-0.03359)
     | > avg_align_error:[91m 0.99150 [0m(+0.00023)


[4m[1m > EPOCH: 26/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:56:05) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 272300[0m
     | > decoder_loss: 2.37769  (2.30779)
     | > postnet_loss: 2.24068  (2.10937)
     | > stopnet_loss: 1.70859  (1.68872)
     | > decoder_coarse_loss: 2.31279  (2.27598)
     | > decoder_ddc_loss: 0.00238  (0.00237)
     | > ga_loss: 0.00271  (0.00270)
     | > decoder_diff_spec_loss: 0.47516  (0.47631)
     | > postnet_diff_spec_loss: 0.83250  (0.82897)
     | > decoder_ssim_loss: 0.35936  (0.34688)
     | > postnet_ssim_loss: 0.37300  (0.35704)
     | > loss: 3.96555  (3.87838)
     | > align_error: 0.99166  (0.99148)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.26705  (3.70362)
     | > current_lr: 0.00006 
     | > step_time: 3.20480  (4.18088)
     | > loader_time: 0.02080  (0.04788)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 272325[0m
     | > decoder_loss: 2.23936  (2.34843)
     | > postnet_loss: 1.92385  (2.15525)
     | > stopnet_loss: 1.88364  (1.75946)
     | > decoder_coarse_loss: 2.19384  (2.30800)
     | > decoder_ddc_loss: 0.00246  (0.00229)
     | > ga_loss: 0.00291  (0.00266)
     | > decoder_diff_spec_loss: 0.47752  (0.47852)
     | > postnet_diff_spec_loss: 0.81752  (0.82778)
     | > decoder_ssim_loss: 0.32473  (0.34190)
     | > postnet_ssim_loss: 0.33079  (0.35151)
     | > loss: 3.97569  (3.97619)
     | > align_error: 0.99118  (0.99159)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.30188  (4.24365)
     | > current_lr: 0.00006 
     | > step_time: 2.99610  (3.85788)
     | > loader_time: 0.02490  (0.03305)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 272350[0m
     | > decoder_loss: 2.17520  (2.37403)
     | > postnet_loss: 2.06526  (2.16436)
     | > stopnet_loss: 1.53047  (1.77422)
     | > decoder_coarse_loss: 2.21598  (2.34025)
     | > decoder_ddc_loss: 0.00194  (0.00232)
     | > ga_loss: 0.00265  (0.00269)
     | > decoder_diff_spec_loss: 0.43732  (0.48257)
     | > postnet_diff_spec_loss: 0.79059  (0.83023)
     | > decoder_ssim_loss: 0.34935  (0.33710)
     | > postnet_ssim_loss: 0.36052  (0.34626)
     | > loss: 3.64275  (4.00693)
     | > align_error: 0.99244  (0.99149)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.43188  (4.10344)
     | > current_lr: 0.00006 
     | > step_time: 3.69040  (3.79461)
     | > loader_time: 0.06210  (0.03243)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 272375[0m
     | > decoder_loss: 2.50678  (2.37059)
     | > postnet_loss: 2.43037  (2.15623)
     | > stopnet_loss: 0.69857  (1.76895)
     | > decoder_coarse_loss: 2.37087  (2.33823)
     | > decoder_ddc_loss: 0.00716  (0.00230)
     | > ga_loss: 0.00421  (0.00267)
     | > decoder_diff_spec_loss: 0.49084  (0.48255)
     | > postnet_diff_spec_loss: 0.80894  (0.82917)
     | > decoder_ssim_loss: 0.55481  (0.33757)
     | > postnet_ssim_loss: 0.59300  (0.34663)
     | > loss: 3.16033  (3.99811)
     | > align_error: 0.97934  (0.99151)
     | > amp_scaler: 65536.00000  (34651.21839)
     | > grad_norm: 4.03688  (3.88674)
     | > current_lr: 0.00006 
     | > step_time: 1.26040  (3.71495)
     | > loader_time: 0.00730  (0.03182)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.88319 [0m(+0.75168)
     | > avg_decoder_loss:[92m 2.84648 [0m(-0.15829)
     | > avg_postnet_loss:[92m 2.99629 [0m(-0.08435)
     | > avg_stopnet_loss:[92m 1.53642 [0m(-0.00144)
     | > avg_decoder_coarse_loss:[92m 3.53927 [0m(-0.17462)
     | > avg_decoder_ddc_loss:[92m 0.00225 [0m(-0.00008)
     | > avg_ga_loss:[92m 0.00252 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.53393 [0m(+0.00229)
     | > avg_postnet_diff_spec_loss:[92m 0.84875 [0m(-0.00065)
     | > avg_decoder_ssim_loss:[92m 0.33606 [0m(-0.00282)
     | > avg_postnet_ssim_loss:[92m 0.34892 [0m(-0.00168)
     | > avg_loss:[92m 4.41203 [0m(-0.10661)
     | > avg_align_error:[91m 0.99166 [0m(+0.00016)


[4m[1m > EPOCH: 27/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:03:44) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 272400[0m
     | > decoder_loss: 2.30696  (2.29858)
     | > postnet_loss: 2.08614  (2.12491)
     | > stopnet_loss: 1.21833  (1.82185)
     | > decoder_coarse_loss: 2.31544  (2.29251)
     | > decoder_ddc_loss: 0.00239  (0.00202)
     | > ga_loss: 0.00254  (0.00260)
     | > decoder_diff_spec_loss: 0.47804  (0.48941)
     | > postnet_diff_spec_loss: 0.81656  (0.82673)
     | > decoder_ssim_loss: 0.41303  (0.33009)
     | > postnet_ssim_loss: 0.42215  (0.33950)
     | > loss: 3.44123  (4.01076)
     | > align_error: 0.99166  (0.99202)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 7.42050  (4.77694)
     | > current_lr: 0.00006 
     | > step_time: 3.75380  (4.00868)
     | > loader_time: 0.01990  (0.04424)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 272425[0m
     | > decoder_loss: 2.05359  (2.32162)
     | > postnet_loss: 1.75208  (2.09095)
     | > stopnet_loss: 1.81330  (1.77696)
     | > decoder_coarse_loss: 2.06618  (2.31802)
     | > decoder_ddc_loss: 0.00153  (0.00217)
     | > ga_loss: 0.00200  (0.00260)
     | > decoder_diff_spec_loss: 0.44978  (0.49262)
     | > postnet_diff_spec_loss: 0.79482  (0.83023)
     | > decoder_ssim_loss: 0.30218  (0.33434)
     | > postnet_ssim_loss: 0.31194  (0.34295)
     | > loss: 3.75634  (3.97320)
     | > align_error: 0.99322  (0.99173)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.56890  (4.09116)
     | > current_lr: 0.00006 
     | > step_time: 4.79000  (3.92269)
     | > loader_time: 0.02200  (0.03947)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 272450[0m
     | > decoder_loss: 2.47251  (2.30636)
     | > postnet_loss: 2.18764  (2.07805)
     | > stopnet_loss: 1.62518  (1.76164)
     | > decoder_coarse_loss: 2.42561  (2.30630)
     | > decoder_ddc_loss: 0.00171  (0.00220)
     | > ga_loss: 0.00226  (0.00268)
     | > decoder_diff_spec_loss: 0.51165  (0.48967)
     | > postnet_diff_spec_loss: 0.85114  (0.82698)
     | > decoder_ssim_loss: 0.34387  (0.33453)
     | > postnet_ssim_loss: 0.35042  (0.34315)
     | > loss: 3.92264  (3.94683)
     | > align_error: 0.99261  (0.99160)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.96882  (3.80031)
     | > current_lr: 0.00006 
     | > step_time: 3.88210  (3.80148)
     | > loader_time: 0.10570  (0.03556)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.88299 [0m(-0.00020)
     | > avg_decoder_loss:[92m 2.78602 [0m(-0.06046)
     | > avg_postnet_loss:[92m 2.93679 [0m(-0.05950)
     | > avg_stopnet_loss:[92m 1.52603 [0m(-0.01040)
     | > avg_decoder_coarse_loss:[92m 3.51324 [0m(-0.02603)
     | > avg_decoder_ddc_loss:[91m 0.00226 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00251 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.53653 [0m(+0.00260)
     | > avg_postnet_diff_spec_loss:[92m 0.84855 [0m(-0.00020)
     | > avg_decoder_ssim_loss:[92m 0.33377 [0m(-0.00229)
     | > avg_postnet_ssim_loss:[91m 0.34960 [0m(+0.00068)
     | > avg_loss:[92m 4.36525 [0m(-0.04678)
     | > avg_align_error:[91m 0.99168 [0m(+0.00002)


[4m[1m > EPOCH: 28/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:11:28) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 272475[0m
     | > decoder_loss: 1.92832  (2.18702)
     | > postnet_loss: 1.74187  (1.98375)
     | > stopnet_loss: 1.48142  (1.72238)
     | > decoder_coarse_loss: 1.92891  (2.19865)
     | > decoder_ddc_loss: 0.00155  (0.00226)
     | > ga_loss: 0.00211  (0.00267)
     | > decoder_diff_spec_loss: 0.44864  (0.48939)
     | > postnet_diff_spec_loss: 0.79502  (0.82415)
     | > decoder_ssim_loss: 0.36912  (0.34316)
     | > postnet_ssim_loss: 0.38649  (0.35215)
     | > loss: 3.39193  (3.83089)
     | > align_error: 0.99409  (0.99149)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.07850  (4.17556)
     | > current_lr: 0.00006 
     | > step_time: 4.63080  (4.15864)
     | > loader_time: 0.01860  (0.03863)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 272500[0m
     | > decoder_loss: 2.16196  (2.23558)
     | > postnet_loss: 1.89506  (2.04417)
     | > stopnet_loss: 1.46057  (1.74866)
     | > decoder_coarse_loss: 2.22551  (2.23696)
     | > decoder_ddc_loss: 0.00164  (0.00216)
     | > ga_loss: 0.00212  (0.00264)
     | > decoder_diff_spec_loss: 0.49662  (0.48958)
     | > postnet_diff_spec_loss: 0.84080  (0.82388)
     | > decoder_ssim_loss: 0.37772  (0.33878)
     | > postnet_ssim_loss: 0.38013  (0.34788)
     | > loss: 3.56603  (3.89159)
     | > align_error: 0.99396  (0.99162)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.64568  (4.59396)
     | > current_lr: 0.00006 
     | > step_time: 4.93780  (3.86705)
     | > loader_time: 0.04730  (0.03201)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 272525[0m
     | > decoder_loss: 2.19456  (2.25802)
     | > postnet_loss: 2.10655  (2.04343)
     | > stopnet_loss: 1.56246  (1.75786)
     | > decoder_coarse_loss: 2.17199  (2.26418)
     | > decoder_ddc_loss: 0.00294  (0.00218)
     | > ga_loss: 0.00335  (0.00268)
     | > decoder_diff_spec_loss: 0.48049  (0.49422)
     | > postnet_diff_spec_loss: 0.80734  (0.82689)
     | > decoder_ssim_loss: 0.35335  (0.33320)
     | > postnet_ssim_loss: 0.36599  (0.34200)
     | > loss: 3.70004  (3.91227)
     | > align_error: 0.98956  (0.99149)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.91569  (4.23844)
     | > current_lr: 0.00006 
     | > step_time: 3.00770  (3.76845)
     | > loader_time: 0.01530  (0.03481)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 272550[0m
     | > decoder_loss: 2.10620  (2.25080)
     | > postnet_loss: 1.79714  (2.03210)
     | > stopnet_loss: 1.41580  (1.76329)
     | > decoder_coarse_loss: 2.09506  (2.25701)
     | > decoder_ddc_loss: 0.00187  (0.00212)
     | > ga_loss: 0.00234  (0.00264)
     | > decoder_diff_spec_loss: 0.47175  (0.49349)
     | > postnet_diff_spec_loss: 0.80335  (0.82546)
     | > decoder_ssim_loss: 0.36731  (0.33144)
     | > postnet_ssim_loss: 0.37424  (0.33986)
     | > loss: 3.43175  (3.90956)
     | > align_error: 0.99260  (0.99166)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.58336  (4.02165)
     | > current_lr: 0.00006 
     | > step_time: 3.13180  (3.70503)
     | > loader_time: 0.02280  (0.03590)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.78474 [0m(-0.09825)
     | > avg_decoder_loss:[92m 2.69416 [0m(-0.09186)
     | > avg_postnet_loss:[92m 2.89303 [0m(-0.04375)
     | > avg_stopnet_loss:[91m 1.53003 [0m(+0.00400)
     | > avg_decoder_coarse_loss:[92m 3.33724 [0m(-0.17600)
     | > avg_decoder_ddc_loss:[92m 0.00216 [0m(-0.00010)
     | > avg_ga_loss:[92m 0.00249 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.52779 [0m(-0.00874)
     | > avg_postnet_diff_spec_loss:[92m 0.84742 [0m(-0.00114)
     | > avg_decoder_ssim_loss:[92m 0.33166 [0m(-0.00211)
     | > avg_postnet_ssim_loss:[92m 0.34923 [0m(-0.00037)
     | > avg_loss:[92m 4.28815 [0m(-0.07710)
     | > avg_align_error:[91m 0.99203 [0m(+0.00035)


[4m[1m > EPOCH: 29/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:19:06) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 272575[0m
     | > decoder_loss: 2.27768  (2.21395)
     | > postnet_loss: 2.25853  (2.03149)
     | > stopnet_loss: 1.76312  (1.80490)
     | > decoder_coarse_loss: 2.26935  (2.20542)
     | > decoder_ddc_loss: 0.00190  (0.00196)
     | > ga_loss: 0.00252  (0.00259)
     | > decoder_diff_spec_loss: 0.50417  (0.49501)
     | > postnet_diff_spec_loss: 0.82995  (0.82334)
     | > decoder_ssim_loss: 0.31876  (0.32383)
     | > postnet_ssim_loss: 0.32161  (0.33255)
     | > loss: 3.97120  (3.92476)
     | > align_error: 0.99212  (0.99207)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.72840  (4.12511)
     | > current_lr: 0.00006 
     | > step_time: 3.90370  (3.96891)
     | > loader_time: 0.05650  (0.04064)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 272600[0m
     | > decoder_loss: 2.34055  (2.23651)
     | > postnet_loss: 2.04182  (2.00171)
     | > stopnet_loss: 2.30531  (1.75223)
     | > decoder_coarse_loss: 2.38435  (2.23401)
     | > decoder_ddc_loss: 0.00138  (0.00210)
     | > ga_loss: 0.00232  (0.00261)
     | > decoder_diff_spec_loss: 0.52043  (0.49933)
     | > postnet_diff_spec_loss: 0.84716  (0.82735)
     | > decoder_ssim_loss: 0.25223  (0.33214)
     | > postnet_ssim_loss: 0.25680  (0.34028)
     | > loss: 4.47811  (3.88364)
     | > align_error: 0.99383  (0.99168)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.96873  (3.75560)
     | > current_lr: 0.00006 
     | > step_time: 3.90380  (3.84975)
     | > loader_time: 0.01800  (0.03826)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 272625[0m
     | > decoder_loss: 2.21053  (2.21461)
     | > postnet_loss: 1.96522  (1.98267)
     | > stopnet_loss: 1.68415  (1.74993)
     | > decoder_coarse_loss: 2.25183  (2.21898)
     | > decoder_ddc_loss: 0.00210  (0.00209)
     | > ga_loss: 0.00287  (0.00268)
     | > decoder_diff_spec_loss: 0.50509  (0.49493)
     | > postnet_diff_spec_loss: 0.82884  (0.82316)
     | > decoder_ssim_loss: 0.34122  (0.33159)
     | > postnet_ssim_loss: 0.34535  (0.33989)
     | > loss: 3.81103  (3.86530)
     | > align_error: 0.99153  (0.99158)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.87342  (3.93979)
     | > current_lr: 0.00007 
     | > step_time: 2.63880  (3.72983)
     | > loader_time: 0.02270  (0.03523)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.08171 [0m(+0.29696)
     | > avg_decoder_loss:[92m 2.59618 [0m(-0.09798)
     | > avg_postnet_loss:[92m 2.77079 [0m(-0.12224)
     | > avg_stopnet_loss:[92m 1.52671 [0m(-0.00332)
     | > avg_decoder_coarse_loss:[92m 3.14490 [0m(-0.19234)
     | > avg_decoder_ddc_loss:[92m 0.00197 [0m(-0.00019)
     | > avg_ga_loss:[92m 0.00247 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.52468 [0m(-0.00311)
     | > avg_postnet_diff_spec_loss:[92m 0.84593 [0m(-0.00149)
     | > avg_decoder_ssim_loss:[92m 0.32982 [0m(-0.00184)
     | > avg_postnet_ssim_loss:[92m 0.34857 [0m(-0.00065)
     | > avg_loss:[92m 4.17979 [0m(-0.10836)
     | > avg_align_error:[91m 0.99219 [0m(+0.00016)


[4m[1m > EPOCH: 30/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:26:45) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 272650[0m
     | > decoder_loss: 2.28748  (2.13267)
     | > postnet_loss: 1.91835  (1.92151)
     | > stopnet_loss: 1.21207  (1.72447)
     | > decoder_coarse_loss: 2.26048  (2.13290)
     | > decoder_ddc_loss: 0.00288  (0.00212)
     | > ga_loss: 0.00355  (0.00274)
     | > decoder_diff_spec_loss: 0.51140  (0.49766)
     | > postnet_diff_spec_loss: 0.83127  (0.82518)
     | > decoder_ssim_loss: 0.43726  (0.33747)
     | > postnet_ssim_loss: 0.44579  (0.34598)
     | > loss: 3.40355  (3.78704)
     | > align_error: 0.98952  (0.99121)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.60034  (3.37186)
     | > current_lr: 0.00007 
     | > step_time: 2.09170  (4.22653)
     | > loader_time: 0.01480  (0.03341)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 272675[0m
     | > decoder_loss: 1.97730  (2.16384)
     | > postnet_loss: 1.80785  (1.95144)
     | > stopnet_loss: 1.26813  (1.74462)
     | > decoder_coarse_loss: 1.92166  (2.15475)
     | > decoder_ddc_loss: 0.00407  (0.00203)
     | > ga_loss: 0.00343  (0.00265)
     | > decoder_diff_spec_loss: 0.47825  (0.49459)
     | > postnet_diff_spec_loss: 0.81481  (0.82064)
     | > decoder_ssim_loss: 0.43743  (0.33508)
     | > postnet_ssim_loss: 0.44870  (0.34435)
     | > loss: 3.25782  (3.82455)
     | > align_error: 0.98694  (0.99156)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.57192  (4.26686)
     | > current_lr: 0.00007 
     | > step_time: 2.66860  (3.82136)
     | > loader_time: 0.01560  (0.03171)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 272700[0m
     | > decoder_loss: 2.06522  (2.18896)
     | > postnet_loss: 1.82374  (1.95384)
     | > stopnet_loss: 1.61319  (1.75458)
     | > decoder_coarse_loss: 2.06955  (2.17966)
     | > decoder_ddc_loss: 0.00298  (0.00204)
     | > ga_loss: 0.00359  (0.00266)
     | > decoder_diff_spec_loss: 0.45550  (0.49931)
     | > postnet_diff_spec_loss: 0.80775  (0.82429)
     | > decoder_ssim_loss: 0.37093  (0.33045)
     | > postnet_ssim_loss: 0.38282  (0.33907)
     | > loss: 3.62577  (3.84728)
     | > align_error: 0.98786  (0.99148)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.62106  (4.12335)
     | > current_lr: 0.00007 
     | > step_time: 2.40840  (3.76532)
     | > loader_time: 0.05400  (0.03592)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 272725[0m
     | > decoder_loss: 2.21275  (2.18294)
     | > postnet_loss: 2.27950  (1.95017)
     | > stopnet_loss: 2.44824  (1.77123)
     | > decoder_coarse_loss: 2.19007  (2.17486)
     | > decoder_ddc_loss: 0.00112  (0.00198)
     | > ga_loss: 0.00205  (0.00263)
     | > decoder_diff_spec_loss: 0.50926  (0.49850)
     | > postnet_diff_spec_loss: 0.81293  (0.82288)
     | > decoder_ssim_loss: 0.24596  (0.32859)
     | > postnet_ssim_loss: 0.25050  (0.33699)
     | > loss: 4.58401  (3.85863)
     | > align_error: 0.99373  (0.99157)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.23797  (3.91528)
     | > current_lr: 0.00007 
     | > step_time: 3.49360  (3.72067)
     | > loader_time: 0.02110  (0.03453)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 6.03047 [0m(-0.05124)
     | > avg_decoder_loss:[92m 2.56669 [0m(-0.02949)
     | > avg_postnet_loss:[92m 2.65993 [0m(-0.11086)
     | > avg_stopnet_loss:[92m 1.52646 [0m(-0.00025)
     | > avg_decoder_coarse_loss:[91m 3.21892 [0m(+0.07403)
     | > avg_decoder_ddc_loss:[91m 0.00198 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00246 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.52110 [0m(-0.00359)
     | > avg_postnet_diff_spec_loss:[92m 0.84367 [0m(-0.00226)
     | > avg_decoder_ssim_loss:[92m 0.32854 [0m(-0.00128)
     | > avg_postnet_ssim_loss:[92m 0.34854 [0m(-0.00003)
     | > avg_loss:[92m 4.16111 [0m(-0.01868)
     | > avg_align_error:[91m 0.99219 [0m(+0.00000)


[4m[1m > EPOCH: 31/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:34:20) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 272750[0m
     | > decoder_loss: 2.16918  (2.14856)
     | > postnet_loss: 1.84887  (1.95191)
     | > stopnet_loss: 1.20995  (1.84315)
     | > decoder_coarse_loss: 2.14293  (2.12192)
     | > decoder_ddc_loss: 0.00164  (0.00176)
     | > ga_loss: 0.00195  (0.00258)
     | > decoder_diff_spec_loss: 0.51178  (0.49691)
     | > postnet_diff_spec_loss: 0.81186  (0.82040)
     | > decoder_ssim_loss: 0.40546  (0.32189)
     | > postnet_ssim_loss: 0.41705  (0.33124)
     | > loss: 3.29689  (3.90472)
     | > align_error: 0.99286  (0.99198)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.31789  (4.69137)
     | > current_lr: 0.00007 
     | > step_time: 4.07140  (3.95359)
     | > loader_time: 0.02040  (0.02939)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 272775[0m
     | > decoder_loss: 2.11059  (2.17642)
     | > postnet_loss: 1.81527  (1.93331)
     | > stopnet_loss: 1.29658  (1.74810)
     | > decoder_coarse_loss: 2.10057  (2.14960)
     | > decoder_ddc_loss: 0.00381  (0.00190)
     | > ga_loss: 0.00372  (0.00261)
     | > decoder_diff_spec_loss: 0.48894  (0.50193)
     | > postnet_diff_spec_loss: 0.81713  (0.82394)
     | > decoder_ssim_loss: 0.42064  (0.33155)
     | > postnet_ssim_loss: 0.42450  (0.33985)
     | > loss: 3.36057  (3.82576)
     | > align_error: 0.98608  (0.99157)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.78145  (4.25455)
     | > current_lr: 0.00007 
     | > step_time: 2.42240  (3.82444)
     | > loader_time: 0.05850  (0.03239)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 272800[0m
     | > decoder_loss: 2.24199  (2.15976)
     | > postnet_loss: 1.90849  (1.92016)
     | > stopnet_loss: 1.22919  (1.75673)
     | > decoder_coarse_loss: 2.17220  (2.13540)
     | > decoder_ddc_loss: 0.00209  (0.00190)
     | > ga_loss: 0.00281  (0.00266)
     | > decoder_diff_spec_loss: 0.51081  (0.49839)
     | > postnet_diff_spec_loss: 0.82581  (0.82021)
     | > decoder_ssim_loss: 0.41444  (0.32925)
     | > postnet_ssim_loss: 0.42200  (0.33762)
     | > loss: 3.36769  (3.82072)
     | > align_error: 0.99060  (0.99151)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.20474  (4.16549)
     | > current_lr: 0.00007 
     | > step_time: 3.04190  (3.73049)
     | > loader_time: 0.02370  (0.03062)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.77356 [0m(-0.25691)
     | > avg_decoder_loss:[91m 2.58721 [0m(+0.02052)
     | > avg_postnet_loss:[91m 2.73617 [0m(+0.07624)
     | > avg_stopnet_loss:[92m 1.52332 [0m(-0.00314)
     | > avg_decoder_coarse_loss:[92m 3.17958 [0m(-0.03934)
     | > avg_decoder_ddc_loss:[92m 0.00183 [0m(-0.00016)
     | > avg_ga_loss:[92m 0.00246 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.52038 [0m(-0.00071)
     | > avg_postnet_diff_spec_loss:[92m 0.84217 [0m(-0.00150)
     | > avg_decoder_ssim_loss:[92m 0.32740 [0m(-0.00113)
     | > avg_postnet_ssim_loss:[92m 0.34612 [0m(-0.00243)
     | > avg_loss:[91m 4.17082 [0m(+0.00971)
     | > avg_align_error:[91m 0.99222 [0m(+0.00003)


[4m[1m > EPOCH: 32/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:42:04) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 272825[0m
     | > decoder_loss: 2.02707  (2.07971)
     | > postnet_loss: 1.72242  (1.87972)
     | > stopnet_loss: 1.45998  (1.76967)
     | > decoder_coarse_loss: 2.00865  (2.05341)
     | > decoder_ddc_loss: 0.00323  (0.00188)
     | > ga_loss: 0.00375  (0.00264)
     | > decoder_diff_spec_loss: 0.47093  (0.49523)
     | > postnet_diff_spec_loss: 0.79125  (0.82153)
     | > decoder_ssim_loss: 0.39413  (0.32401)
     | > postnet_ssim_loss: 0.41049  (0.33339)
     | > loss: 3.43577  (3.78009)
     | > align_error: 0.98704  (0.99155)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.17122  (3.85514)
     | > current_lr: 0.00007 
     | > step_time: 1.97590  (4.00192)
     | > loader_time: 0.01060  (0.05358)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 272850[0m
     | > decoder_loss: 1.98377  (2.13039)
     | > postnet_loss: 1.72852  (1.91476)
     | > stopnet_loss: 1.60049  (1.74184)
     | > decoder_coarse_loss: 1.93165  (2.08996)
     | > decoder_ddc_loss: 0.00315  (0.00182)
     | > ga_loss: 0.00304  (0.00262)
     | > decoder_diff_spec_loss: 0.44949  (0.49770)
     | > postnet_diff_spec_loss: 0.77763  (0.81820)
     | > decoder_ssim_loss: 0.35583  (0.33013)
     | > postnet_ssim_loss: 0.36564  (0.33921)
     | > loss: 3.51459  (3.78549)
     | > align_error: 0.98743  (0.99176)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.66043  (4.81068)
     | > current_lr: 0.00007 
     | > step_time: 2.90380  (3.74687)
     | > loader_time: 0.01840  (0.03724)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 272875[0m
     | > decoder_loss: 2.17714  (2.14951)
     | > postnet_loss: 1.84045  (1.90888)
     | > stopnet_loss: 1.91829  (1.74596)
     | > decoder_coarse_loss: 2.16363  (2.11669)
     | > decoder_ddc_loss: 0.00149  (0.00189)
     | > ga_loss: 0.00241  (0.00263)
     | > decoder_diff_spec_loss: 0.52066  (0.50207)
     | > postnet_diff_spec_loss: 0.85238  (0.82208)
     | > decoder_ssim_loss: 0.29576  (0.32790)
     | > postnet_ssim_loss: 0.30112  (0.33619)
     | > loss: 3.96851  (3.80043)
     | > align_error: 0.99320  (0.99165)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.39868  (4.73134)
     | > current_lr: 0.00007 
     | > step_time: 4.30430  (3.75555)
     | > loader_time: 0.02120  (0.03326)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 272900[0m
     | > decoder_loss: 2.14258  (2.14240)
     | > postnet_loss: 1.88061  (1.89942)
     | > stopnet_loss: 1.92873  (1.74447)
     | > decoder_coarse_loss: 2.11368  (2.10769)
     | > decoder_ddc_loss: 0.00155  (0.00187)
     | > ga_loss: 0.00262  (0.00263)
     | > decoder_diff_spec_loss: 0.50885  (0.50067)
     | > postnet_diff_spec_loss: 0.83926  (0.82053)
     | > decoder_ssim_loss: 0.27275  (0.32777)
     | > postnet_ssim_loss: 0.27907  (0.33595)
     | > loss: 3.95141  (3.79170)
     | > align_error: 0.99211  (0.99165)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.58575  (4.54726)
     | > current_lr: 0.00007 
     | > step_time: 3.98500  (3.70153)
     | > loader_time: 0.03980  (0.03358)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.92862 [0m(+0.15506)
     | > avg_decoder_loss:[92m 2.47489 [0m(-0.11231)
     | > avg_postnet_loss:[92m 2.50756 [0m(-0.22861)
     | > avg_stopnet_loss:[92m 1.51976 [0m(-0.00355)
     | > avg_decoder_coarse_loss:[92m 2.89264 [0m(-0.28694)
     | > avg_decoder_ddc_loss:[91m 0.00184 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00245 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.51129 [0m(-0.00910)
     | > avg_postnet_diff_spec_loss:[92m 0.83916 [0m(-0.00301)
     | > avg_decoder_ssim_loss:[92m 0.32569 [0m(-0.00172)
     | > avg_postnet_ssim_loss:[92m 0.34586 [0m(-0.00026)
     | > avg_loss:[92m 4.00673 [0m(-0.16409)
     | > avg_align_error:[91m 0.99232 [0m(+0.00010)


[4m[1m > EPOCH: 33/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:49:43) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 272925[0m
     | > decoder_loss: 2.34834  (2.10073)
     | > postnet_loss: 2.18941  (1.91027)
     | > stopnet_loss: 1.32486  (1.83536)
     | > decoder_coarse_loss: 2.27454  (2.05812)
     | > decoder_ddc_loss: 0.00177  (0.00182)
     | > ga_loss: 0.00220  (0.00260)
     | > decoder_diff_spec_loss: 0.54635  (0.49695)
     | > postnet_diff_spec_loss: 0.85475  (0.81813)
     | > decoder_ssim_loss: 0.38239  (0.31606)
     | > postnet_ssim_loss: 0.39363  (0.32508)
     | > loss: 3.58362  (3.85515)
     | > align_error: 0.99234  (0.99198)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.77835  (4.90569)
     | > current_lr: 0.00007 
     | > step_time: 3.55850  (4.09566)
     | > loader_time: 0.04410  (0.03904)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 272950[0m
     | > decoder_loss: 2.24625  (2.12882)
     | > postnet_loss: 1.92060  (1.88555)
     | > stopnet_loss: 1.40940  (1.73229)
     | > decoder_coarse_loss: 2.22603  (2.09319)
     | > decoder_ddc_loss: 0.00205  (0.00192)
     | > ga_loss: 0.00248  (0.00257)
     | > decoder_diff_spec_loss: 0.52819  (0.50393)
     | > postnet_diff_spec_loss: 0.82438  (0.82206)
     | > decoder_ssim_loss: 0.35182  (0.32776)
     | > postnet_ssim_loss: 0.36693  (0.33614)
     | > loss: 3.53836  (3.76996)
     | > align_error: 0.99084  (0.99165)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.29597  (4.53969)
     | > current_lr: 0.00007 
     | > step_time: 3.62670  (3.96467)
     | > loader_time: 0.06800  (0.03410)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 272975[0m
     | > decoder_loss: 2.05993  (2.11232)
     | > postnet_loss: 1.72724  (1.87341)
     | > stopnet_loss: 1.67395  (1.74577)
     | > decoder_coarse_loss: 1.97617  (2.07736)
     | > decoder_ddc_loss: 0.00220  (0.00194)
     | > ga_loss: 0.00327  (0.00264)
     | > decoder_diff_spec_loss: 0.47830  (0.49951)
     | > postnet_diff_spec_loss: 0.80480  (0.81839)
     | > decoder_ssim_loss: 0.33271  (0.32617)
     | > postnet_ssim_loss: 0.34386  (0.33474)
     | > loss: 3.62162  (3.76995)
     | > align_error: 0.98962  (0.99153)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.07682  (4.47668)
     | > current_lr: 0.00007 
     | > step_time: 2.97540  (3.82038)
     | > loader_time: 0.04970  (0.03231)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.31651 [0m(-0.61211)
     | > avg_decoder_loss:[91m 2.48138 [0m(+0.00649)
     | > avg_postnet_loss:[91m 2.57318 [0m(+0.06562)
     | > avg_stopnet_loss:[91m 1.52294 [0m(+0.00318)
     | > avg_decoder_coarse_loss:[91m 2.89303 [0m(+0.00039)
     | > avg_decoder_ddc_loss:[92m 0.00173 [0m(-0.00011)
     | > avg_ga_loss:[92m 0.00245 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.51221 [0m(+0.00092)
     | > avg_postnet_diff_spec_loss:[91m 0.83992 [0m(+0.00076)
     | > avg_decoder_ssim_loss:[92m 0.32464 [0m(-0.00105)
     | > avg_postnet_ssim_loss:[92m 0.34538 [0m(-0.00048)
     | > avg_loss:[91m 4.02804 [0m(+0.02130)
     | > avg_align_error:[91m 0.99239 [0m(+0.00008)


[4m[1m > EPOCH: 34/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:57:21) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 273000[0m
     | > decoder_loss: 1.86984  (2.03383)
     | > postnet_loss: 1.71652  (1.85605)
     | > stopnet_loss: 1.57839  (1.79263)
     | > decoder_coarse_loss: 1.86427  (1.99874)
     | > decoder_ddc_loss: 0.00297  (0.00170)
     | > ga_loss: 0.00319  (0.00249)
     | > decoder_diff_spec_loss: 0.48070  (0.49834)
     | > postnet_diff_spec_loss: 0.81739  (0.82297)
     | > decoder_ssim_loss: 0.36155  (0.31382)
     | > postnet_ssim_loss: 0.37028  (0.32181)
     | > loss: 3.46519  (3.76691)
     | > align_error: 0.98840  (0.99211)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.13951  (4.07068)
     | > current_lr: 0.00007 
     | > step_time: 2.68170  (4.48365)
     | > loader_time: 0.03940  (0.04099)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 273025[0m
     | > decoder_loss: 2.22702  (2.09110)
     | > postnet_loss: 1.88238  (1.87361)
     | > stopnet_loss: 1.42757  (1.74289)
     | > decoder_coarse_loss: 2.19386  (2.04862)
     | > decoder_ddc_loss: 0.00256  (0.00178)
     | > ga_loss: 0.00267  (0.00259)
     | > decoder_diff_spec_loss: 0.53029  (0.49980)
     | > postnet_diff_spec_loss: 0.83498  (0.81769)
     | > decoder_ssim_loss: 0.37210  (0.32764)
     | > postnet_ssim_loss: 0.38120  (0.33704)
     | > loss: 3.54701  (3.75518)
     | > align_error: 0.98960  (0.99188)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.53566  (4.72255)
     | > current_lr: 0.00008 
     | > step_time: 3.93490  (3.86302)
     | > loader_time: 0.02220  (0.03227)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 273050[0m
     | > decoder_loss: 2.19391  (2.10744)
     | > postnet_loss: 1.81860  (1.86880)
     | > stopnet_loss: 1.56399  (1.74749)
     | > decoder_coarse_loss: 2.15795  (2.06673)
     | > decoder_ddc_loss: 0.00162  (0.00188)
     | > ga_loss: 0.00245  (0.00262)
     | > decoder_diff_spec_loss: 0.51413  (0.50320)
     | > postnet_diff_spec_loss: 0.81455  (0.81962)
     | > decoder_ssim_loss: 0.34012  (0.32676)
     | > postnet_ssim_loss: 0.34598  (0.33553)
     | > loss: 3.62295  (3.76809)
     | > align_error: 0.99203  (0.99157)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.01343  (4.44939)
     | > current_lr: 0.00008 
     | > step_time: 4.06450  (3.81121)
     | > loader_time: 0.06000  (0.03214)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 273075[0m
     | > decoder_loss: 2.06579  (2.10210)
     | > postnet_loss: 1.70806  (1.85995)
     | > stopnet_loss: 1.99922  (1.73800)
     | > decoder_coarse_loss: 2.03883  (2.05908)
     | > decoder_ddc_loss: 0.00126  (0.00186)
     | > ga_loss: 0.00210  (0.00262)
     | > decoder_diff_spec_loss: 0.49985  (0.50122)
     | > postnet_diff_spec_loss: 0.81732  (0.81859)
     | > decoder_ssim_loss: 0.27341  (0.32675)
     | > postnet_ssim_loss: 0.28249  (0.33534)
     | > loss: 3.93147  (3.75230)
     | > align_error: 0.99318  (0.99163)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.76102  (4.32317)
     | > current_lr: 0.00008 
     | > step_time: 3.67410  (3.76040)
     | > loader_time: 0.02230  (0.03341)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.17078 [0m(+0.85426)
     | > avg_decoder_loss:[91m 2.55662 [0m(+0.07523)
     | > avg_postnet_loss:[92m 2.52966 [0m(-0.04352)
     | > avg_stopnet_loss:[91m 1.52652 [0m(+0.00357)
     | > avg_decoder_coarse_loss:[91m 3.01960 [0m(+0.12657)
     | > avg_decoder_ddc_loss:[91m 0.00174 [0m(+0.00000)
     | > avg_ga_loss:[91m 0.00245 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.51357 [0m(+0.00136)
     | > avg_postnet_diff_spec_loss:[92m 0.83942 [0m(-0.00050)
     | > avg_decoder_ssim_loss:[92m 0.32413 [0m(-0.00051)
     | > avg_postnet_ssim_loss:[92m 0.34520 [0m(-0.00019)
     | > avg_loss:[91m 4.07123 [0m(+0.04319)
     | > avg_align_error:[92m 0.99230 [0m(-0.00010)


[4m[1m > EPOCH: 35/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:05:02) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 273100[0m
     | > decoder_loss: 2.10735  (2.05687)
     | > postnet_loss: 1.85562  (1.87481)
     | > stopnet_loss: 2.10789  (1.86942)
     | > decoder_coarse_loss: 2.05753  (2.01478)
     | > decoder_ddc_loss: 0.00141  (0.00170)
     | > ga_loss: 0.00266  (0.00260)
     | > decoder_diff_spec_loss: 0.51849  (0.49698)
     | > postnet_diff_spec_loss: 0.82232  (0.81513)
     | > decoder_ssim_loss: 0.26647  (0.31125)
     | > postnet_ssim_loss: 0.27753  (0.32072)
     | > loss: 4.09787  (3.85550)
     | > align_error: 0.99269  (0.99187)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.36004  (5.43726)
     | > current_lr: 0.00008 
     | > step_time: 3.34970  (4.00145)
     | > loader_time: 0.05230  (0.03163)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 273125[0m
     | > decoder_loss: 2.34500  (2.09533)
     | > postnet_loss: 1.89862  (1.85653)
     | > stopnet_loss: 2.25740  (1.75324)
     | > decoder_coarse_loss: 2.30523  (2.05599)
     | > decoder_ddc_loss: 0.00141  (0.00180)
     | > ga_loss: 0.00250  (0.00255)
     | > decoder_diff_spec_loss: 0.57266  (0.50468)
     | > postnet_diff_spec_loss: 0.86793  (0.82046)
     | > decoder_ssim_loss: 0.24817  (0.32569)
     | > postnet_ssim_loss: 0.24954  (0.33441)
     | > loss: 4.39205  (3.76474)
     | > align_error: 0.99178  (0.99163)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.13239  (4.80715)
     | > current_lr: 0.00008 
     | > step_time: 4.23210  (3.79292)
     | > loader_time: 0.02010  (0.03589)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 273150[0m
     | > decoder_loss: 2.09654  (2.08401)
     | > postnet_loss: 1.70989  (1.84798)
     | > stopnet_loss: 1.95894  (1.74637)
     | > decoder_coarse_loss: 2.05604  (2.04460)
     | > decoder_ddc_loss: 0.00172  (0.00183)
     | > ga_loss: 0.00256  (0.00262)
     | > decoder_diff_spec_loss: 0.48829  (0.50115)
     | > postnet_diff_spec_loss: 0.80726  (0.81711)
     | > decoder_ssim_loss: 0.27963  (0.32468)
     | > postnet_ssim_loss: 0.28769  (0.33351)
     | > loss: 3.90353  (3.74817)
     | > align_error: 0.99079  (0.99150)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.42995  (4.41403)
     | > current_lr: 0.00008 
     | > step_time: 4.04850  (3.71117)
     | > loader_time: 0.02110  (0.03544)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.29187 [0m(-0.87891)
     | > avg_decoder_loss:[92m 2.55234 [0m(-0.00427)
     | > avg_postnet_loss:[91m 2.60992 [0m(+0.08026)
     | > avg_stopnet_loss:[92m 1.52144 [0m(-0.00508)
     | > avg_decoder_coarse_loss:[92m 2.85799 [0m(-0.16162)
     | > avg_decoder_ddc_loss:[92m 0.00165 [0m(-0.00008)
     | > avg_ga_loss:[92m 0.00243 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.51186 [0m(-0.00170)
     | > avg_postnet_diff_spec_loss:[91m 0.83990 [0m(+0.00048)
     | > avg_decoder_ssim_loss:[92m 0.32345 [0m(-0.00067)
     | > avg_postnet_ssim_loss:[92m 0.34479 [0m(-0.00041)
     | > avg_loss:[92m 4.04406 [0m(-0.02716)
     | > avg_align_error:[91m 0.99242 [0m(+0.00013)


[4m[1m > EPOCH: 36/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:12:41) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 273175[0m
     | > decoder_loss: 2.22895  (2.04125)
     | > postnet_loss: 2.24678  (1.85935)
     | > stopnet_loss: 1.33778  (1.80474)
     | > decoder_coarse_loss: 2.16676  (1.99376)
     | > decoder_ddc_loss: 0.00174  (0.00160)
     | > ga_loss: 0.00200  (0.00235)
     | > decoder_diff_spec_loss: 0.54380  (0.50078)
     | > postnet_diff_spec_loss: 0.83202  (0.82370)
     | > decoder_ssim_loss: 0.36179  (0.30580)
     | > postnet_ssim_loss: 0.37539  (0.31524)
     | > loss: 3.53709  (3.77687)
     | > align_error: 0.99263  (0.99247)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.84612  (3.91455)
     | > current_lr: 0.00008 
     | > step_time: 4.06690  (4.68842)
     | > loader_time: 0.02590  (0.06655)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 273200[0m
     | > decoder_loss: 2.15542  (2.06784)
     | > postnet_loss: 1.91741  (1.84886)
     | > stopnet_loss: 1.77516  (1.74575)
     | > decoder_coarse_loss: 2.11308  (2.00953)
     | > decoder_ddc_loss: 0.00135  (0.00180)
     | > ga_loss: 0.00205  (0.00255)
     | > decoder_diff_spec_loss: 0.47152  (0.49867)
     | > postnet_diff_spec_loss: 0.80523  (0.81657)
     | > decoder_ssim_loss: 0.29199  (0.32484)
     | > postnet_ssim_loss: 0.30551  (0.33482)
     | > loss: 3.80078  (3.73424)
     | > align_error: 0.99345  (0.99176)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.89295  (4.53160)
     | > current_lr: 0.00008 
     | > step_time: 4.03790  (3.80551)
     | > loader_time: 0.02370  (0.03508)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 273225[0m
     | > decoder_loss: 2.15881  (2.08429)
     | > postnet_loss: 1.80432  (1.84400)
     | > stopnet_loss: 1.58522  (1.73233)
     | > decoder_coarse_loss: 2.10114  (2.02698)
     | > decoder_ddc_loss: 0.00225  (0.00188)
     | > ga_loss: 0.00281  (0.00259)
     | > decoder_diff_spec_loss: 0.47809  (0.50401)
     | > postnet_diff_spec_loss: 0.80547  (0.81911)
     | > decoder_ssim_loss: 0.32367  (0.32526)
     | > postnet_ssim_loss: 0.33255  (0.33463)
     | > loss: 3.60083  (3.73029)
     | > align_error: 0.98924  (0.99138)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.01887  (4.31726)
     | > current_lr: 0.00008 
     | > step_time: 3.40080  (3.72043)
     | > loader_time: 0.02360  (0.03459)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 273250[0m
     | > decoder_loss: 2.19407  (2.07941)
     | > postnet_loss: 2.07681  (1.83563)
     | > stopnet_loss: 1.24881  (1.71939)
     | > decoder_coarse_loss: 2.13627  (2.02462)
     | > decoder_ddc_loss: 0.00144  (0.00185)
     | > ga_loss: 0.00199  (0.00258)
     | > decoder_diff_spec_loss: 0.54440  (0.50270)
     | > postnet_diff_spec_loss: 0.84897  (0.81773)
     | > decoder_ssim_loss: 0.39144  (0.32607)
     | > postnet_ssim_loss: 0.40740  (0.33521)
     | > loss: 3.40897  (3.71309)
     | > align_error: 0.99241  (0.99139)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.99270  (4.22613)
     | > current_lr: 0.00008 
     | > step_time: 3.50040  (3.65645)
     | > loader_time: 0.02460  (0.03432)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.69060 [0m(+0.39873)
     | > avg_decoder_loss:[91m 2.62317 [0m(+0.07083)
     | > avg_postnet_loss:[91m 2.62423 [0m(+0.01431)
     | > avg_stopnet_loss:[92m 1.51169 [0m(-0.00975)
     | > avg_decoder_coarse_loss:[92m 2.77071 [0m(-0.08728)
     | > avg_decoder_ddc_loss:[92m 0.00149 [0m(-0.00016)
     | > avg_ga_loss:[92m 0.00241 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.50972 [0m(-0.00215)
     | > avg_postnet_diff_spec_loss:[92m 0.83862 [0m(-0.00128)
     | > avg_decoder_ssim_loss:[91m 0.32346 [0m(+0.00001)
     | > avg_postnet_ssim_loss:[92m 0.34423 [0m(-0.00056)
     | > avg_loss:[92m 4.03266 [0m(-0.01140)
     | > avg_align_error:[91m 0.99248 [0m(+0.00006)


[4m[1m > EPOCH: 37/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:20:19) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 273275[0m
     | > decoder_loss: 1.95111  (2.02750)
     | > postnet_loss: 1.87719  (1.83890)
     | > stopnet_loss: 2.30480  (1.83647)
     | > decoder_coarse_loss: 1.86759  (1.97392)
     | > decoder_ddc_loss: 0.00104  (0.00173)
     | > ga_loss: 0.00212  (0.00256)
     | > decoder_diff_spec_loss: 0.47202  (0.49405)
     | > postnet_diff_spec_loss: 0.79166  (0.81408)
     | > decoder_ssim_loss: 0.23837  (0.31209)
     | > postnet_ssim_loss: 0.25136  (0.32226)
     | > loss: 4.17800  (3.79541)
     | > align_error: 0.99466  (0.99181)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.59125  (4.39987)
     | > current_lr: 0.00008 
     | > step_time: 4.45670  (4.02060)
     | > loader_time: 0.02160  (0.03460)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 273300[0m
     | > decoder_loss: 2.12374  (2.06661)
     | > postnet_loss: 1.82473  (1.83306)
     | > stopnet_loss: 2.38352  (1.72189)
     | > decoder_coarse_loss: 2.09523  (2.01355)
     | > decoder_ddc_loss: 0.00125  (0.00176)
     | > ga_loss: 0.00227  (0.00252)
     | > decoder_diff_spec_loss: 0.53720  (0.50376)
     | > postnet_diff_spec_loss: 0.84888  (0.81874)
     | > decoder_ssim_loss: 0.22620  (0.32624)
     | > postnet_ssim_loss: 0.23209  (0.33555)
     | > loss: 4.36721  (3.70930)
     | > align_error: 0.99312  (0.99162)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.56611  (4.12313)
     | > current_lr: 0.00008 
     | > step_time: 4.87210  (3.82127)
     | > loader_time: 0.02600  (0.03587)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 273325[0m
     | > decoder_loss: 2.04002  (2.06075)
     | > postnet_loss: 1.63158  (1.82648)
     | > stopnet_loss: 2.08359  (1.72867)
     | > decoder_coarse_loss: 1.98153  (2.00762)
     | > decoder_ddc_loss: 0.00086  (0.00177)
     | > ga_loss: 0.00223  (0.00258)
     | > decoder_diff_spec_loss: 0.51158  (0.50204)
     | > postnet_diff_spec_loss: 0.79935  (0.81634)
     | > decoder_ssim_loss: 0.25265  (0.32414)
     | > postnet_ssim_loss: 0.25561  (0.33345)
     | > loss: 3.96303  (3.70970)
     | > align_error: 0.99454  (0.99147)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.25157  (4.22962)
     | > current_lr: 0.00008 
     | > step_time: 4.88400  (3.71776)
     | > loader_time: 0.02130  (0.03142)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.50103 [0m(-0.18957)
     | > avg_decoder_loss:[92m 2.51615 [0m(-0.10702)
     | > avg_postnet_loss:[92m 2.59796 [0m(-0.02627)
     | > avg_stopnet_loss:[91m 1.52172 [0m(+0.01003)
     | > avg_decoder_coarse_loss:[91m 2.79727 [0m(+0.02656)
     | > avg_decoder_ddc_loss:[91m 0.00151 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00240 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.50410 [0m(-0.00562)
     | > avg_postnet_diff_spec_loss:[92m 0.83811 [0m(-0.00051)
     | > avg_decoder_ssim_loss:[92m 0.32210 [0m(-0.00136)
     | > avg_postnet_ssim_loss:[91m 0.34453 [0m(+0.00030)
     | > avg_loss:[92m 4.01416 [0m(-0.01850)
     | > avg_align_error:[92m 0.99238 [0m(-0.00009)


[4m[1m > EPOCH: 38/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:27:52) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 273350[0m
     | > decoder_loss: 2.00734  (1.97797)
     | > postnet_loss: 1.76921  (1.77366)
     | > stopnet_loss: 1.44279  (1.88447)
     | > decoder_coarse_loss: 1.97725  (1.94944)
     | > decoder_ddc_loss: 0.00171  (0.00140)
     | > ga_loss: 0.00236  (0.00238)
     | > decoder_diff_spec_loss: 0.48772  (0.49232)
     | > postnet_diff_spec_loss: 0.81969  (0.82138)
     | > decoder_ssim_loss: 0.37362  (0.29519)
     | > postnet_ssim_loss: 0.38316  (0.30384)
     | > loss: 3.40949  (3.80018)
     | > align_error: 0.99111  (0.99245)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.23665  (3.99332)
     | > current_lr: 0.00008 
     | > step_time: 3.52640  (5.09066)
     | > loader_time: 0.02450  (0.04465)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 273375[0m
     | > decoder_loss: 1.91548  (2.04140)
     | > postnet_loss: 1.61339  (1.82170)
     | > stopnet_loss: 2.51886  (1.74280)
     | > decoder_coarse_loss: 1.86027  (1.98428)
     | > decoder_ddc_loss: 0.00107  (0.00161)
     | > ga_loss: 0.00242  (0.00254)
     | > decoder_diff_spec_loss: 0.47355  (0.49949)
     | > postnet_diff_spec_loss: 0.79041  (0.81559)
     | > decoder_ssim_loss: 0.22911  (0.32479)
     | > postnet_ssim_loss: 0.24029  (0.33474)
     | > loss: 4.31187  (3.71142)
     | > align_error: 0.99386  (0.99173)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.20255  (5.01394)
     | > current_lr: 0.00008 
     | > step_time: 4.69890  (3.90116)
     | > loader_time: 0.02250  (0.03339)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 273400[0m
     | > decoder_loss: 2.04297  (2.05803)
     | > postnet_loss: 2.01273  (1.82058)
     | > stopnet_loss: 1.25667  (1.73661)
     | > decoder_coarse_loss: 1.98291  (2.00145)
     | > decoder_ddc_loss: 0.00190  (0.00172)
     | > ga_loss: 0.00256  (0.00256)
     | > decoder_diff_spec_loss: 0.53121  (0.50435)
     | > postnet_diff_spec_loss: 0.82741  (0.81792)
     | > decoder_ssim_loss: 0.39318  (0.32413)
     | > postnet_ssim_loss: 0.40665  (0.33342)
     | > loss: 3.31919  (3.71481)
     | > align_error: 0.99118  (0.99143)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.25581  (4.48250)
     | > current_lr: 0.00008 
     | > step_time: 3.17530  (3.86539)
     | > loader_time: 0.05180  (0.03407)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 273425[0m
     | > decoder_loss: 2.13266  (2.05442)
     | > postnet_loss: 1.77153  (1.80631)
     | > stopnet_loss: 1.91461  (1.72901)
     | > decoder_coarse_loss: 2.03010  (1.99610)
     | > decoder_ddc_loss: 0.00143  (0.00170)
     | > ga_loss: 0.00255  (0.00257)
     | > decoder_diff_spec_loss: 0.47914  (0.50229)
     | > postnet_diff_spec_loss: 0.78939  (0.81620)
     | > decoder_ssim_loss: 0.27948  (0.32422)
     | > postnet_ssim_loss: 0.29184  (0.33314)
     | > loss: 3.87123  (3.70047)
     | > align_error: 0.99175  (0.99139)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.02651  (4.34255)
     | > current_lr: 0.00009 
     | > step_time: 3.00930  (3.76177)
     | > loader_time: 0.02590  (0.03250)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.00213 [0m(-0.49891)
     | > avg_decoder_loss:[92m 2.47684 [0m(-0.03931)
     | > avg_postnet_loss:[92m 2.50320 [0m(-0.09477)
     | > avg_stopnet_loss:[92m 1.51191 [0m(-0.00981)
     | > avg_decoder_coarse_loss:[92m 2.52577 [0m(-0.27150)
     | > avg_decoder_ddc_loss:[92m 0.00137 [0m(-0.00014)
     | > avg_ga_loss:[92m 0.00240 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.50060 [0m(-0.00350)
     | > avg_postnet_diff_spec_loss:[92m 0.83607 [0m(-0.00204)
     | > avg_decoder_ssim_loss:[92m 0.32164 [0m(-0.00046)
     | > avg_postnet_ssim_loss:[92m 0.34361 [0m(-0.00092)
     | > avg_loss:[92m 3.90117 [0m(-0.11299)
     | > avg_align_error:[91m 0.99251 [0m(+0.00013)


[4m[1m > EPOCH: 39/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:35:22) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 273450[0m
     | > decoder_loss: 2.06387  (2.02061)
     | > postnet_loss: 1.92122  (1.81324)
     | > stopnet_loss: 2.02511  (1.82989)
     | > decoder_coarse_loss: 1.96814  (1.95078)
     | > decoder_ddc_loss: 0.00095  (0.00166)
     | > ga_loss: 0.00207  (0.00257)
     | > decoder_diff_spec_loss: 0.49677  (0.49718)
     | > postnet_diff_spec_loss: 0.80818  (0.81395)
     | > decoder_ssim_loss: 0.26419  (0.31541)
     | > postnet_ssim_loss: 0.27537  (0.32502)
     | > loss: 3.98512  (3.77719)
     | > align_error: 0.99419  (0.99162)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 10.07125  (5.23142)
     | > current_lr: 0.00009 
     | > step_time: 5.43740  (4.02787)
     | > loader_time: 0.02110  (0.04312)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 273475[0m
     | > decoder_loss: 2.15161  (2.04955)
     | > postnet_loss: 1.82487  (1.80666)
     | > stopnet_loss: 1.15164  (1.70557)
     | > decoder_coarse_loss: 2.04492  (1.97664)
     | > decoder_ddc_loss: 0.00195  (0.00168)
     | > ga_loss: 0.00240  (0.00251)
     | > decoder_diff_spec_loss: 0.53529  (0.50389)
     | > postnet_diff_spec_loss: 0.83363  (0.81709)
     | > decoder_ssim_loss: 0.42725  (0.32759)
     | > postnet_ssim_loss: 0.43197  (0.33706)
     | > loss: 3.22652  (3.67316)
     | > align_error: 0.99071  (0.99155)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.17908  (4.74039)
     | > current_lr: 0.00009 
     | > step_time: 2.74570  (3.79149)
     | > loader_time: 0.02300  (0.03431)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 273500[0m
     | > decoder_loss: 1.92135  (2.04553)
     | > postnet_loss: 1.74295  (1.80427)
     | > stopnet_loss: 1.61230  (1.71845)
     | > decoder_coarse_loss: 1.86302  (1.97358)
     | > decoder_ddc_loss: 0.00202  (0.00171)
     | > ga_loss: 0.00271  (0.00257)
     | > decoder_diff_spec_loss: 0.47755  (0.50296)
     | > postnet_diff_spec_loss: 0.80898  (0.81578)
     | > decoder_ssim_loss: 0.33427  (0.32416)
     | > postnet_ssim_loss: 0.34871  (0.33371)
     | > loss: 3.50055  (3.68170)
     | > align_error: 0.99026  (0.99138)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.82075  (4.47248)
     | > current_lr: 0.00009 
     | > step_time: 3.17270  (3.64447)
     | > loader_time: 0.02380  (0.03412)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.49861 [0m(+0.49648)
     | > avg_decoder_loss:[91m 2.51116 [0m(+0.03433)
     | > avg_postnet_loss:[91m 2.58563 [0m(+0.08243)
     | > avg_stopnet_loss:[91m 1.51589 [0m(+0.00397)
     | > avg_decoder_coarse_loss:[91m 2.56662 [0m(+0.04085)
     | > avg_decoder_ddc_loss:[92m 0.00128 [0m(-0.00009)
     | > avg_ga_loss:[92m 0.00238 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.50010 [0m(-0.00049)
     | > avg_postnet_diff_spec_loss:[91m 0.83784 [0m(+0.00177)
     | > avg_decoder_ssim_loss:[92m 0.32117 [0m(-0.00047)
     | > avg_postnet_ssim_loss:[91m 0.34443 [0m(+0.00082)
     | > avg_loss:[91m 3.94485 [0m(+0.04368)
     | > avg_align_error:[91m 0.99252 [0m(+0.00000)


[4m[1m > EPOCH: 40/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:42:44) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 273525[0m
     | > decoder_loss: 1.95164  (1.97312)
     | > postnet_loss: 1.83519  (1.75453)
     | > stopnet_loss: 1.77262  (1.96521)
     | > decoder_coarse_loss: 1.90515  (1.92304)
     | > decoder_ddc_loss: 0.00119  (0.00125)
     | > ga_loss: 0.00236  (0.00238)
     | > decoder_diff_spec_loss: 0.48040  (0.49497)
     | > postnet_diff_spec_loss: 0.82045  (0.82106)
     | > decoder_ssim_loss: 0.28248  (0.27928)
     | > postnet_ssim_loss: 0.29598  (0.28663)
     | > loss: 3.67754  (3.86058)
     | > align_error: 0.99344  (0.99270)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.16834  (3.84166)
     | > current_lr: 0.00009 
     | > step_time: 4.61410  (5.18495)
     | > loader_time: 0.06290  (0.03808)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 273550[0m
     | > decoder_loss: 2.00506  (2.02841)
     | > postnet_loss: 1.65936  (1.79624)
     | > stopnet_loss: 1.41252  (1.70997)
     | > decoder_coarse_loss: 1.93678  (1.95299)
     | > decoder_ddc_loss: 0.00144  (0.00157)
     | > ga_loss: 0.00234  (0.00253)
     | > decoder_diff_spec_loss: 0.52453  (0.50012)
     | > postnet_diff_spec_loss: 0.83177  (0.81553)
     | > decoder_ssim_loss: 0.36736  (0.32700)
     | > postnet_ssim_loss: 0.37310  (0.33713)
     | > loss: 3.34907  (3.66236)
     | > align_error: 0.99260  (0.99162)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.02182  (4.65120)
     | > current_lr: 0.00009 
     | > step_time: 3.33660  (3.80742)
     | > loader_time: 0.06080  (0.03111)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 273575[0m
     | > decoder_loss: 1.85693  (2.04379)
     | > postnet_loss: 1.91474  (1.78909)
     | > stopnet_loss: 2.17119  (1.73227)
     | > decoder_coarse_loss: 1.82655  (1.97167)
     | > decoder_ddc_loss: 0.00137  (0.00162)
     | > ga_loss: 0.00261  (0.00254)
     | > decoder_diff_spec_loss: 0.46062  (0.50397)
     | > postnet_diff_spec_loss: 0.80203  (0.81689)
     | > decoder_ssim_loss: 0.27170  (0.32199)
     | > postnet_ssim_loss: 0.28558  (0.33136)
     | > loss: 4.03913  (3.69007)
     | > align_error: 0.99244  (0.99141)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.26364  (4.14172)
     | > current_lr: 0.00009 
     | > step_time: 3.26780  (3.77860)
     | > loader_time: 0.04060  (0.03797)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 273600[0m
     | > decoder_loss: 2.47362  (2.03771)
     | > postnet_loss: 1.94683  (1.78217)
     | > stopnet_loss: 1.93536  (1.71464)
     | > decoder_coarse_loss: 2.27885  (1.96764)
     | > decoder_ddc_loss: 0.00098  (0.00162)
     | > ga_loss: 0.00208  (0.00255)
     | > decoder_diff_spec_loss: 0.50319  (0.50286)
     | > postnet_diff_spec_loss: 0.81190  (0.81569)
     | > decoder_ssim_loss: 0.26165  (0.32377)
     | > postnet_ssim_loss: 0.26958  (0.33302)
     | > loss: 4.08241  (3.66849)
     | > align_error: 0.99382  (0.99135)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.09595  (4.14691)
     | > current_lr: 0.00009 
     | > step_time: 4.51010  (3.69415)
     | > loader_time: 0.02500  (0.03731)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.59563 [0m(+0.09702)
     | > avg_decoder_loss:[92m 2.46317 [0m(-0.04799)
     | > avg_postnet_loss:[92m 2.55296 [0m(-0.03267)
     | > avg_stopnet_loss:[92m 1.51573 [0m(-0.00016)
     | > avg_decoder_coarse_loss:[92m 2.45440 [0m(-0.11222)
     | > avg_decoder_ddc_loss:[91m 0.00131 [0m(+0.00003)
     | > avg_ga_loss:[92m 0.00238 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.49673 [0m(-0.00337)
     | > avg_postnet_diff_spec_loss:[92m 0.83605 [0m(-0.00179)
     | > avg_decoder_ssim_loss:[92m 0.32039 [0m(-0.00078)
     | > avg_postnet_ssim_loss:[92m 0.34421 [0m(-0.00022)
     | > avg_loss:[92m 3.89493 [0m(-0.04992)
     | > avg_align_error:[92m 0.99248 [0m(-0.00003)


[4m[1m > EPOCH: 41/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:49:58) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 273625[0m
     | > decoder_loss: 1.83949  (1.99745)
     | > postnet_loss: 1.57166  (1.77567)
     | > stopnet_loss: 1.54148  (1.79194)
     | > decoder_coarse_loss: 1.75934  (1.92543)
     | > decoder_ddc_loss: 0.00124  (0.00160)
     | > ga_loss: 0.00229  (0.00257)
     | > decoder_diff_spec_loss: 0.46674  (0.49818)
     | > postnet_diff_spec_loss: 0.78013  (0.81377)
     | > decoder_ssim_loss: 0.31996  (0.31744)
     | > postnet_ssim_loss: 0.33189  (0.32756)
     | > loss: 3.32055  (3.71904)
     | > align_error: 0.99264  (0.99146)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.02144  (4.94167)
     | > current_lr: 0.00009 
     | > step_time: 3.95870  (3.99540)
     | > loader_time: 0.02350  (0.03741)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 273650[0m
     | > decoder_loss: 1.99968  (2.02704)
     | > postnet_loss: 1.75423  (1.78013)
     | > stopnet_loss: 1.85097  (1.69496)
     | > decoder_coarse_loss: 1.94114  (1.95377)
     | > decoder_ddc_loss: 0.00124  (0.00160)
     | > ga_loss: 0.00198  (0.00249)
     | > decoder_diff_spec_loss: 0.51069  (0.50416)
     | > postnet_diff_spec_loss: 0.82525  (0.81591)
     | > decoder_ssim_loss: 0.27460  (0.32428)
     | > postnet_ssim_loss: 0.27634  (0.33405)
     | > loss: 3.75664  (3.64262)
     | > align_error: 0.99314  (0.99159)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.87460  (4.72424)
     | > current_lr: 0.00009 
     | > step_time: 4.81460  (3.83185)
     | > loader_time: 0.02080  (0.03526)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 273675[0m
     | > decoder_loss: 1.98878  (2.02466)
     | > postnet_loss: 1.86423  (1.77515)
     | > stopnet_loss: 1.87103  (1.70572)
     | > decoder_coarse_loss: 1.89666  (1.95384)
     | > decoder_ddc_loss: 0.00091  (0.00161)
     | > ga_loss: 0.00201  (0.00254)
     | > decoder_diff_spec_loss: 0.50244  (0.50381)
     | > postnet_diff_spec_loss: 0.80316  (0.81513)
     | > decoder_ssim_loss: 0.28464  (0.32301)
     | > postnet_ssim_loss: 0.29217  (0.33283)
     | > loss: 3.78934  (3.65091)
     | > align_error: 0.99425  (0.99143)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.47362  (4.50112)
     | > current_lr: 0.00009 
     | > step_time: 4.47200  (3.67922)
     | > loader_time: 0.02230  (0.03361)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.17798 [0m(-0.41765)
     | > avg_decoder_loss:[91m 2.55559 [0m(+0.09243)
     | > avg_postnet_loss:[91m 2.64153 [0m(+0.08857)
     | > avg_stopnet_loss:[92m 1.51292 [0m(-0.00281)
     | > avg_decoder_coarse_loss:[92m 2.41200 [0m(-0.04241)
     | > avg_decoder_ddc_loss:[92m 0.00125 [0m(-0.00006)
     | > avg_ga_loss:[92m 0.00238 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.49919 [0m(+0.00246)
     | > avg_postnet_diff_spec_loss:[91m 0.83822 [0m(+0.00217)
     | > avg_decoder_ssim_loss:[92m 0.32018 [0m(-0.00022)
     | > avg_postnet_ssim_loss:[91m 0.34457 [0m(+0.00036)
     | > avg_loss:[91m 3.92794 [0m(+0.03301)
     | > avg_align_error:[92m 0.99244 [0m(-0.00004)


[4m[1m > EPOCH: 42/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:57:32) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 273700[0m
     | > decoder_loss: 1.96899  (1.95247)
     | > postnet_loss: 1.72202  (1.70753)
     | > stopnet_loss: 2.39558  (1.97557)
     | > decoder_coarse_loss: 1.92909  (1.88674)
     | > decoder_ddc_loss: 0.00079  (0.00123)
     | > ga_loss: 0.00211  (0.00234)
     | > decoder_diff_spec_loss: 0.50867  (0.49910)
     | > postnet_diff_spec_loss: 0.83256  (0.81998)
     | > decoder_ssim_loss: 0.22149  (0.27703)
     | > postnet_ssim_loss: 0.22975  (0.28430)
     | > loss: 4.25946  (3.84438)
     | > align_error: 0.99442  (0.99247)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.74806  (4.48339)
     | > current_lr: 0.00009 
     | > step_time: 5.29890  (5.36506)
     | > loader_time: 0.04030  (0.06165)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 273725[0m
     | > decoder_loss: 2.14248  (2.01012)
     | > postnet_loss: 1.83536  (1.76664)
     | > stopnet_loss: 1.41954  (1.71424)
     | > decoder_coarse_loss: 2.09230  (1.92330)
     | > decoder_ddc_loss: 0.00228  (0.00150)
     | > ga_loss: 0.00336  (0.00251)
     | > decoder_diff_spec_loss: 0.53661  (0.50006)
     | > postnet_diff_spec_loss: 0.85767  (0.81434)
     | > decoder_ssim_loss: 0.39057  (0.32426)
     | > postnet_ssim_loss: 0.40557  (0.33545)
     | > loss: 3.50205  (3.64573)
     | > align_error: 0.98832  (0.99160)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.69940  (4.43254)
     | > current_lr: 0.00009 
     | > step_time: 1.92470  (3.86567)
     | > loader_time: 0.01670  (0.03744)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 273750[0m
     | > decoder_loss: 2.02272  (2.02451)
     | > postnet_loss: 1.61799  (1.75799)
     | > stopnet_loss: 2.16524  (1.71558)
     | > decoder_coarse_loss: 1.93060  (1.94150)
     | > decoder_ddc_loss: 0.00157  (0.00153)
     | > ga_loss: 0.00293  (0.00252)
     | > decoder_diff_spec_loss: 0.52068  (0.50583)
     | > postnet_diff_spec_loss: 0.79278  (0.81644)
     | > decoder_ssim_loss: 0.26231  (0.32144)
     | > postnet_ssim_loss: 0.27094  (0.33169)
     | > loss: 4.03477  (3.65343)
     | > align_error: 0.98966  (0.99141)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.15556  (3.95103)
     | > current_lr: 0.00009 
     | > step_time: 3.27030  (3.85180)
     | > loader_time: 0.02120  (0.03440)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 273775[0m
     | > decoder_loss: 1.84931  (2.01222)
     | > postnet_loss: 1.67733  (1.75156)
     | > stopnet_loss: 1.45996  (1.69638)
     | > decoder_coarse_loss: 1.71602  (1.93106)
     | > decoder_ddc_loss: 0.00190  (0.00151)
     | > ga_loss: 0.00287  (0.00254)
     | > decoder_diff_spec_loss: 0.48205  (0.50333)
     | > postnet_diff_spec_loss: 0.81270  (0.81495)
     | > decoder_ssim_loss: 0.37855  (0.32323)
     | > postnet_ssim_loss: 0.38825  (0.33315)
     | > loss: 3.30086  (3.62685)
     | > align_error: 0.98954  (0.99138)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.55166  (3.96287)
     | > current_lr: 0.00009 
     | > step_time: 2.77780  (3.76196)
     | > loader_time: 0.01740  (0.03128)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.51389 [0m(+1.33591)
     | > avg_decoder_loss:[92m 2.41655 [0m(-0.13904)
     | > avg_postnet_loss:[92m 2.60036 [0m(-0.04117)
     | > avg_stopnet_loss:[91m 1.51338 [0m(+0.00046)
     | > avg_decoder_coarse_loss:[92m 2.33843 [0m(-0.07357)
     | > avg_decoder_ddc_loss:[92m 0.00118 [0m(-0.00007)
     | > avg_ga_loss:[91m 0.00238 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.49151 [0m(-0.00767)
     | > avg_postnet_diff_spec_loss:[92m 0.83786 [0m(-0.00036)
     | > avg_decoder_ssim_loss:[92m 0.31899 [0m(-0.00118)
     | > avg_postnet_ssim_loss:[91m 0.34522 [0m(+0.00066)
     | > avg_loss:[92m 3.86282 [0m(-0.06512)
     | > avg_align_error:[91m 0.99260 [0m(+0.00016)


[4m[1m > EPOCH: 43/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:05:23) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 273800[0m
     | > decoder_loss: 2.13235  (1.98616)
     | > postnet_loss: 2.05335  (1.75609)
     | > stopnet_loss: 1.89084  (1.76760)
     | > decoder_coarse_loss: 1.99602  (1.90570)
     | > decoder_ddc_loss: 0.00144  (0.00149)
     | > ga_loss: 0.00246  (0.00258)
     | > decoder_diff_spec_loss: 0.49144  (0.49823)
     | > postnet_diff_spec_loss: 0.80369  (0.81532)
     | > decoder_ssim_loss: 0.28415  (0.31617)
     | > postnet_ssim_loss: 0.29480  (0.32641)
     | > loss: 3.91745  (3.68191)
     | > align_error: 0.99180  (0.99155)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.13321  (4.22072)
     | > current_lr: 0.00009 
     | > step_time: 4.08670  (3.98437)
     | > loader_time: 0.02680  (0.03924)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 273825[0m
     | > decoder_loss: 2.02043  (2.01386)
     | > postnet_loss: 1.76601  (1.75591)
     | > stopnet_loss: 1.75927  (1.68409)
     | > decoder_coarse_loss: 1.94241  (1.92637)
     | > decoder_ddc_loss: 0.00184  (0.00149)
     | > ga_loss: 0.00272  (0.00249)
     | > decoder_diff_spec_loss: 0.53676  (0.50342)
     | > postnet_diff_spec_loss: 0.84449  (0.81516)
     | > decoder_ssim_loss: 0.29843  (0.32442)
     | > postnet_ssim_loss: 0.30633  (0.33484)
     | > loss: 3.70206  (3.61543)
     | > align_error: 0.99015  (0.99164)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.59788  (4.11901)
     | > current_lr: 0.00010 
     | > step_time: 3.55210  (3.84617)
     | > loader_time: 0.01910  (0.03439)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 273850[0m
     | > decoder_loss: 1.88795  (2.01207)
     | > postnet_loss: 1.58476  (1.75036)
     | > stopnet_loss: 1.86246  (1.69173)
     | > decoder_coarse_loss: 1.81817  (1.92914)
     | > decoder_ddc_loss: 0.00112  (0.00155)
     | > ga_loss: 0.00219  (0.00253)
     | > decoder_diff_spec_loss: 0.49892  (0.50386)
     | > postnet_diff_spec_loss: 0.80859  (0.81478)
     | > decoder_ssim_loss: 0.27642  (0.32256)
     | > postnet_ssim_loss: 0.28299  (0.33268)
     | > loss: 3.66313  (3.62115)
     | > align_error: 0.99281  (0.99141)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.87018  (4.33687)
     | > current_lr: 0.00010 
     | > step_time: 4.02880  (3.78442)
     | > loader_time: 0.02300  (0.03546)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 8.25986 [0m(+1.74597)
     | > avg_decoder_loss:[91m 2.50642 [0m(+0.08987)
     | > avg_postnet_loss:[91m 2.67145 [0m(+0.07109)
     | > avg_stopnet_loss:[91m 1.51507 [0m(+0.00169)
     | > avg_decoder_coarse_loss:[92m 2.29534 [0m(-0.04309)
     | > avg_decoder_ddc_loss:[92m 0.00109 [0m(-0.00008)
     | > avg_ga_loss:[92m 0.00237 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.49213 [0m(+0.00062)
     | > avg_postnet_diff_spec_loss:[91m 0.83807 [0m(+0.00021)
     | > avg_decoder_ssim_loss:[92m 0.31874 [0m(-0.00026)
     | > avg_postnet_ssim_loss:[91m 0.34624 [0m(+0.00102)
     | > avg_loss:[91m 3.89429 [0m(+0.03147)
     | > avg_align_error:[92m 0.99260 [0m(-0.00000)


[4m[1m > EPOCH: 44/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:13:10) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 273875[0m
     | > decoder_loss: 1.95397  (1.92628)
     | > postnet_loss: 1.61363  (1.67612)
     | > stopnet_loss: 1.68449  (1.82543)
     | > decoder_coarse_loss: 1.86555  (1.85539)
     | > decoder_ddc_loss: 0.00110  (0.00133)
     | > ga_loss: 0.00198  (0.00242)
     | > decoder_diff_spec_loss: 0.49946  (0.49505)
     | > postnet_diff_spec_loss: 0.81713  (0.81410)
     | > decoder_ssim_loss: 0.29614  (0.29434)
     | > postnet_ssim_loss: 0.30514  (0.30152)
     | > loss: 3.53244  (3.67858)
     | > align_error: 0.99351  (0.99177)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.22179  (4.75299)
     | > current_lr: 0.00010 
     | > step_time: 6.38100  (5.35136)
     | > loader_time: 0.01790  (0.03267)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 273900[0m
     | > decoder_loss: 1.93396  (1.98363)
     | > postnet_loss: 1.63238  (1.73738)
     | > stopnet_loss: 1.80099  (1.71959)
     | > decoder_coarse_loss: 1.88610  (1.89564)
     | > decoder_ddc_loss: 0.00111  (0.00143)
     | > ga_loss: 0.00245  (0.00248)
     | > decoder_diff_spec_loss: 0.50594  (0.49935)
     | > postnet_diff_spec_loss: 0.82086  (0.81213)
     | > decoder_ssim_loss: 0.29181  (0.32088)
     | > postnet_ssim_loss: 0.30456  (0.33210)
     | > loss: 3.65741  (3.62761)
     | > align_error: 0.99303  (0.99169)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.83208  (4.67361)
     | > current_lr: 0.00010 
     | > step_time: 3.70710  (3.84033)
     | > loader_time: 0.01590  (0.02585)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 273925[0m
     | > decoder_loss: 1.90733  (2.00620)
     | > postnet_loss: 1.75343  (1.73248)
     | > stopnet_loss: 1.53385  (1.69976)
     | > decoder_coarse_loss: 1.88326  (1.92276)
     | > decoder_ddc_loss: 0.00205  (0.00150)
     | > ga_loss: 0.00316  (0.00250)
     | > decoder_diff_spec_loss: 0.47472  (0.50563)
     | > postnet_diff_spec_loss: 0.82222  (0.81621)
     | > decoder_ssim_loss: 0.35467  (0.32176)
     | > postnet_ssim_loss: 0.36569  (0.33203)
     | > loss: 3.44049  (3.62191)
     | > align_error: 0.98974  (0.99144)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.62427  (4.26071)
     | > current_lr: 0.00010 
     | > step_time: 2.40860  (3.72065)
     | > loader_time: 0.04960  (0.03546)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 273950[0m
     | > decoder_loss: 1.70021  (1.99379)
     | > postnet_loss: 1.68615  (1.72471)
     | > stopnet_loss: 2.77559  (1.69410)
     | > decoder_coarse_loss: 1.61935  (1.91575)
     | > decoder_ddc_loss: 0.00093  (0.00150)
     | > ga_loss: 0.00237  (0.00252)
     | > decoder_diff_spec_loss: 0.43609  (0.50344)
     | > postnet_diff_spec_loss: 0.81002  (0.81424)
     | > decoder_ssim_loss: 0.19807  (0.32164)
     | > postnet_ssim_loss: 0.20708  (0.33169)
     | > loss: 4.45193  (3.60840)
     | > align_error: 0.99313  (0.99136)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.23731  (4.16116)
     | > current_lr: 0.00010 
     | > step_time: 3.34490  (3.61759)
     | > loader_time: 0.01800  (0.03271)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.08484 [0m(-3.17502)
     | > avg_decoder_loss:[91m 2.52267 [0m(+0.01625)
     | > avg_postnet_loss:[92m 2.54062 [0m(-0.13083)
     | > avg_stopnet_loss:[92m 1.50939 [0m(-0.00568)
     | > avg_decoder_coarse_loss:[92m 2.25044 [0m(-0.04490)
     | > avg_decoder_ddc_loss:[92m 0.00104 [0m(-0.00005)
     | > avg_ga_loss:[92m 0.00237 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.49201 [0m(-0.00013)
     | > avg_postnet_diff_spec_loss:[92m 0.83570 [0m(-0.00237)
     | > avg_decoder_ssim_loss:[92m 0.31833 [0m(-0.00041)
     | > avg_postnet_ssim_loss:[92m 0.34359 [0m(-0.00265)
     | > avg_loss:[92m 3.84733 [0m(-0.04696)
     | > avg_align_error:[91m 0.99267 [0m(+0.00007)


[4m[1m > EPOCH: 45/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:20:20) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 273975[0m
     | > decoder_loss: 2.15930  (1.95681)
     | > postnet_loss: 1.97108  (1.69837)
     | > stopnet_loss: 1.29129  (1.78917)
     | > decoder_coarse_loss: 2.02904  (1.88479)
     | > decoder_ddc_loss: 0.00162  (0.00149)
     | > ga_loss: 0.00260  (0.00258)
     | > decoder_diff_spec_loss: 0.53386  (0.49925)
     | > postnet_diff_spec_loss: 0.83756  (0.81510)
     | > decoder_ssim_loss: 0.39144  (0.31727)
     | > postnet_ssim_loss: 0.40136  (0.32759)
     | > loss: 3.38562  (3.67724)
     | > align_error: 0.99037  (0.99140)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.35661  (4.63011)
     | > current_lr: 0.00010 
     | > step_time: 2.73480  (3.91578)
     | > loader_time: 0.02620  (0.03370)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 274000[0m
     | > decoder_loss: 2.63774  (1.99116)
     | > postnet_loss: 2.29872  (1.71305)
     | > stopnet_loss: 2.22869  (1.69363)
     | > decoder_coarse_loss: 2.41077  (1.90254)
     | > decoder_ddc_loss: 0.00096  (0.00149)
     | > ga_loss: 0.00186  (0.00247)
     | > decoder_diff_spec_loss: 0.61207  (0.50291)
     | > postnet_diff_spec_loss: 0.88007  (0.81346)
     | > decoder_ssim_loss: 0.23890  (0.32397)
     | > postnet_ssim_loss: 0.24658  (0.33463)
     | > loss: 4.56943  (3.60180)
     | > align_error: 0.99349  (0.99153)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.44023  (4.06535)
     | > current_lr: 0.00010 
     | > step_time: 5.51730  (3.87884)
     | > loader_time: 0.08600  (0.03556)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 274025[0m
     | > decoder_loss: 1.95421  (1.98922)
     | > postnet_loss: 1.84242  (1.71798)
     | > stopnet_loss: 1.89396  (1.69970)
     | > decoder_coarse_loss: 1.90028  (1.90586)
     | > decoder_ddc_loss: 0.00087  (0.00154)
     | > ga_loss: 0.00202  (0.00252)
     | > decoder_diff_spec_loss: 0.51034  (0.50401)
     | > postnet_diff_spec_loss: 0.79651  (0.81380)
     | > decoder_ssim_loss: 0.28949  (0.32194)
     | > postnet_ssim_loss: 0.29811  (0.33254)
     | > loss: 3.80213  (3.60903)
     | > align_error: 0.99367  (0.99126)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.99689  (4.08627)
     | > current_lr: 0.00010 
     | > step_time: 4.28890  (3.77466)
     | > loader_time: 0.03100  (0.03393)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.47270 [0m(+1.38786)
     | > avg_decoder_loss:[92m 2.47990 [0m(-0.04277)
     | > avg_postnet_loss:[91m 2.66248 [0m(+0.12186)
     | > avg_stopnet_loss:[91m 1.50956 [0m(+0.00017)
     | > avg_decoder_coarse_loss:[92m 2.19305 [0m(-0.05738)
     | > avg_decoder_ddc_loss:[92m 0.00098 [0m(-0.00006)
     | > avg_ga_loss:[91m 0.00238 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.48809 [0m(-0.00392)
     | > avg_postnet_diff_spec_loss:[92m 0.83498 [0m(-0.00072)
     | > avg_decoder_ssim_loss:[92m 0.31755 [0m(-0.00078)
     | > avg_postnet_ssim_loss:[91m 0.34423 [0m(+0.00064)
     | > avg_loss:[91m 3.85176 [0m(+0.00444)
     | > avg_align_error:[91m 0.99285 [0m(+0.00017)


[4m[1m > EPOCH: 46/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:28:03) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 274050[0m
     | > decoder_loss: 1.86065  (1.90355)
     | > postnet_loss: 1.61073  (1.69137)
     | > stopnet_loss: 1.65645  (1.87911)
     | > decoder_coarse_loss: 1.82758  (1.84132)
     | > decoder_ddc_loss: 0.00112  (0.00131)
     | > ga_loss: 0.00257  (0.00266)
     | > decoder_diff_spec_loss: 0.48126  (0.49447)
     | > postnet_diff_spec_loss: 0.79935  (0.81225)
     | > decoder_ssim_loss: 0.30859  (0.29220)
     | > postnet_ssim_loss: 0.31398  (0.29940)
     | > loss: 3.47010  (3.72636)
     | > align_error: 0.99190  (0.99101)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.63260  (6.12079)
     | > current_lr: 0.00010 
     | > step_time: 4.94600  (5.03585)
     | > loader_time: 0.11120  (0.06212)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 274075[0m
     | > decoder_loss: 1.86816  (1.96619)
     | > postnet_loss: 1.61987  (1.70387)
     | > stopnet_loss: 1.31141  (1.69428)
     | > decoder_coarse_loss: 1.79871  (1.87732)
     | > decoder_ddc_loss: 0.00170  (0.00136)
     | > ga_loss: 0.00267  (0.00249)
     | > decoder_diff_spec_loss: 0.47566  (0.49790)
     | > postnet_diff_spec_loss: 0.79162  (0.81068)
     | > decoder_ssim_loss: 0.37517  (0.32072)
     | > postnet_ssim_loss: 0.39049  (0.33231)
     | > loss: 3.15513  (3.58430)
     | > align_error: 0.98987  (0.99175)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.84811  (4.28469)
     | > current_lr: 0.00010 
     | > step_time: 3.38030  (3.92591)
     | > loader_time: 0.06400  (0.03607)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 274100[0m
     | > decoder_loss: 1.85511  (1.98842)
     | > postnet_loss: 1.48021  (1.70680)
     | > stopnet_loss: 2.03475  (1.69021)
     | > decoder_coarse_loss: 1.76153  (1.90537)
     | > decoder_ddc_loss: 0.00126  (0.00141)
     | > ga_loss: 0.00280  (0.00249)
     | > decoder_diff_spec_loss: 0.47725  (0.50541)
     | > postnet_diff_spec_loss: 0.79558  (0.81522)
     | > decoder_ssim_loss: 0.25363  (0.31975)
     | > postnet_ssim_loss: 0.26554  (0.33055)
     | > loss: 3.77126  (3.59590)
     | > align_error: 0.99172  (0.99153)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.27874  (4.03287)
     | > current_lr: 0.00010 
     | > step_time: 3.65150  (3.81191)
     | > loader_time: 0.01810  (0.03369)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 274125[0m
     | > decoder_loss: 2.16893  (1.97771)
     | > postnet_loss: 1.76892  (1.69751)
     | > stopnet_loss: 1.35846  (1.66837)
     | > decoder_coarse_loss: 2.08565  (1.89855)
     | > decoder_ddc_loss: 0.00128  (0.00143)
     | > ga_loss: 0.00209  (0.00252)
     | > decoder_diff_spec_loss: 0.54939  (0.50430)
     | > postnet_diff_spec_loss: 0.83936  (0.81335)
     | > decoder_ssim_loss: 0.36586  (0.32178)
     | > postnet_ssim_loss: 0.37382  (0.33240)
     | > loss: 3.40721  (3.56772)
     | > align_error: 0.99235  (0.99136)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.76397  (4.13631)
     | > current_lr: 0.00010 
     | > step_time: 3.59690  (3.66324)
     | > loader_time: 0.01790  (0.03236)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 8.28985 [0m(+1.81715)
     | > avg_decoder_loss:[91m 2.53909 [0m(+0.05919)
     | > avg_postnet_loss:[92m 2.54561 [0m(-0.11686)
     | > avg_stopnet_loss:[91m 1.51099 [0m(+0.00143)
     | > avg_decoder_coarse_loss:[92m 2.18428 [0m(-0.00877)
     | > avg_decoder_ddc_loss:[92m 0.00096 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00237 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.48707 [0m(-0.00101)
     | > avg_postnet_diff_spec_loss:[92m 0.83411 [0m(-0.00086)
     | > avg_decoder_ssim_loss:[92m 0.31735 [0m(-0.00020)
     | > avg_postnet_ssim_loss:[92m 0.34369 [0m(-0.00053)
     | > avg_loss:[92m 3.83587 [0m(-0.01589)
     | > avg_align_error:[92m 0.99274 [0m(-0.00011)


[4m[1m > EPOCH: 47/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:35:28) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 274150[0m
     | > decoder_loss: 2.00603  (1.93611)
     | > postnet_loss: 1.62647  (1.65923)
     | > stopnet_loss: 2.67451  (1.78979)
     | > decoder_coarse_loss: 1.92736  (1.85604)
     | > decoder_ddc_loss: 0.00145  (0.00139)
     | > ga_loss: 0.00326  (0.00256)
     | > decoder_diff_spec_loss: 0.49242  (0.49297)
     | > postnet_diff_spec_loss: 0.80402  (0.81275)
     | > decoder_ssim_loss: 0.21194  (0.31081)
     | > postnet_ssim_loss: 0.21691  (0.32198)
     | > loss: 4.51245  (3.65040)
     | > align_error: 0.98891  (0.99151)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 10.65066  (4.08759)
     | > current_lr: 0.00010 
     | > step_time: 2.84350  (4.02766)
     | > loader_time: 0.02180  (0.03852)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 274175[0m
     | > decoder_loss: 2.10173  (1.95774)
     | > postnet_loss: 1.65545  (1.67108)
     | > stopnet_loss: 1.33457  (1.64227)
     | > decoder_coarse_loss: 2.00945  (1.87682)
     | > decoder_ddc_loss: 0.00111  (0.00141)
     | > ga_loss: 0.00188  (0.00248)
     | > decoder_diff_spec_loss: 0.52791  (0.49814)
     | > postnet_diff_spec_loss: 0.80539  (0.81079)
     | > decoder_ssim_loss: 0.35116  (0.32480)
     | > postnet_ssim_loss: 0.36027  (0.33606)
     | > loss: 3.29710  (3.52386)
     | > align_error: 0.99297  (0.99152)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.29354  (4.18677)
     | > current_lr: 0.00010 
     | > step_time: 5.01660  (3.89967)
     | > loader_time: 0.02410  (0.03294)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 274200[0m
     | > decoder_loss: 1.85604  (1.97125)
     | > postnet_loss: 1.65045  (1.68615)
     | > stopnet_loss: 1.29902  (1.66228)
     | > decoder_coarse_loss: 1.77336  (1.89352)
     | > decoder_ddc_loss: 0.00177  (0.00142)
     | > ga_loss: 0.00274  (0.00252)
     | > decoder_diff_spec_loss: 0.45855  (0.50189)
     | > postnet_diff_spec_loss: 0.79917  (0.81312)
     | > decoder_ssim_loss: 0.38222  (0.32122)
     | > postnet_ssim_loss: 0.40040  (0.33231)
     | > loss: 3.14319  (3.55511)
     | > align_error: 0.98969  (0.99128)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.47237  (4.12539)
     | > current_lr: 0.00010 
     | > step_time: 3.08840  (3.75804)
     | > loader_time: 0.04120  (0.03819)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 7.07270 [0m(-1.21715)
     | > avg_decoder_loss:[92m 2.42936 [0m(-0.10973)
     | > avg_postnet_loss:[91m 2.59676 [0m(+0.05115)
     | > avg_stopnet_loss:[92m 1.50349 [0m(-0.00751)
     | > avg_decoder_coarse_loss:[92m 2.10899 [0m(-0.07530)
     | > avg_decoder_ddc_loss:[92m 0.00091 [0m(-0.00005)
     | > avg_ga_loss:[91m 0.00237 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.48140 [0m(-0.00567)
     | > avg_postnet_diff_spec_loss:[92m 0.83396 [0m(-0.00015)
     | > avg_decoder_ssim_loss:[92m 0.31678 [0m(-0.00057)
     | > avg_postnet_ssim_loss:[91m 0.34373 [0m(+0.00004)
     | > avg_loss:[92m 3.79333 [0m(-0.04254)
     | > avg_align_error:[91m 0.99295 [0m(+0.00022)


[4m[1m > EPOCH: 48/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:43:09) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 274225[0m
     | > decoder_loss: 1.90591  (1.90591)
     | > postnet_loss: 1.74850  (1.74850)
     | > stopnet_loss: 2.04778  (2.04778)
     | > decoder_coarse_loss: 1.85044  (1.85044)
     | > decoder_ddc_loss: 0.00147  (0.00147)
     | > ga_loss: 0.00269  (0.00269)
     | > decoder_diff_spec_loss: 0.50282  (0.50282)
     | > postnet_diff_spec_loss: 0.82505  (0.82505)
     | > decoder_ssim_loss: 0.27439  (0.27439)
     | > postnet_ssim_loss: 0.28466  (0.28466)
     | > loss: 3.90953  (3.90953)
     | > align_error: 0.98998  (0.98998)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.67538  (6.67538)
     | > current_lr: 0.00010 
     | > step_time: 6.08110  (6.08113)
     | > loader_time: 0.03920  (0.03917)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 274250[0m
     | > decoder_loss: 2.08615  (1.94922)
     | > postnet_loss: 1.70835  (1.66923)
     | > stopnet_loss: 1.52637  (1.68821)
     | > decoder_coarse_loss: 1.95572  (1.86046)
     | > decoder_ddc_loss: 0.00151  (0.00131)
     | > ga_loss: 0.00293  (0.00246)
     | > decoder_diff_spec_loss: 0.51262  (0.49803)
     | > postnet_diff_spec_loss: 0.81714  (0.81141)
     | > decoder_ssim_loss: 0.34555  (0.31730)
     | > postnet_ssim_loss: 0.36313  (0.32939)
     | > loss: 3.48856  (3.55958)
     | > align_error: 0.98984  (0.99166)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.58326  (4.71838)
     | > current_lr: 0.00010 
     | > step_time: 2.77590  (3.94551)
     | > loader_time: 0.02300  (0.03580)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 274275[0m
     | > decoder_loss: 2.07670  (1.97223)
     | > postnet_loss: 1.92995  (1.67471)
     | > stopnet_loss: 1.48081  (1.66970)
     | > decoder_coarse_loss: 1.95572  (1.88677)
     | > decoder_ddc_loss: 0.00202  (0.00139)
     | > ga_loss: 0.00341  (0.00246)
     | > decoder_diff_spec_loss: 0.52557  (0.50522)
     | > postnet_diff_spec_loss: 0.82916  (0.81501)
     | > decoder_ssim_loss: 0.37426  (0.31986)
     | > postnet_ssim_loss: 0.39058  (0.33106)
     | > loss: 3.51882  (3.55856)
     | > align_error: 0.98856  (0.99140)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.42085  (4.25223)
     | > current_lr: 0.00010 
     | > step_time: 2.64480  (3.85701)
     | > loader_time: 0.01510  (0.03431)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 274300[0m
     | > decoder_loss: 1.96740  (1.95635)
     | > postnet_loss: 1.65344  (1.66556)
     | > stopnet_loss: 1.18122  (1.65901)
     | > decoder_coarse_loss: 1.92347  (1.87859)
     | > decoder_ddc_loss: 0.00247  (0.00142)
     | > ga_loss: 0.00332  (0.00250)
     | > decoder_diff_spec_loss: 0.53011  (0.50242)
     | > postnet_diff_spec_loss: 0.84616  (0.81245)
     | > decoder_ssim_loss: 0.42665  (0.31999)
     | > postnet_ssim_loss: 0.44196  (0.33126)
     | > loss: 3.14573  (3.53853)
     | > align_error: 0.98585  (0.99121)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.56906  (4.08380)
     | > current_lr: 0.00010 
     | > step_time: 2.52560  (3.74937)
     | > loader_time: 0.03520  (0.03177)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.41376 [0m(-1.65894)
     | > avg_decoder_loss:[92m 2.39667 [0m(-0.03269)
     | > avg_postnet_loss:[92m 2.56329 [0m(-0.03347)
     | > avg_stopnet_loss:[91m 1.51031 [0m(+0.00682)
     | > avg_decoder_coarse_loss:[92m 2.09107 [0m(-0.01792)
     | > avg_decoder_ddc_loss:[91m 0.00095 [0m(+0.00004)
     | > avg_ga_loss:[92m 0.00236 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.48163 [0m(+0.00022)
     | > avg_postnet_diff_spec_loss:[91m 0.83460 [0m(+0.00064)
     | > avg_decoder_ssim_loss:[92m 0.31560 [0m(-0.00118)
     | > avg_postnet_ssim_loss:[91m 0.34413 [0m(+0.00040)
     | > avg_loss:[92m 3.77908 [0m(-0.01425)
     | > avg_align_error:[92m 0.99282 [0m(-0.00013)


[4m[1m > EPOCH: 49/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:50:38) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 274325[0m
     | > decoder_loss: 1.96594  (1.91086)
     | > postnet_loss: 1.69324  (1.64602)
     | > stopnet_loss: 2.93435  (1.72045)
     | > decoder_coarse_loss: 1.97644  (1.83602)
     | > decoder_ddc_loss: 0.00066  (0.00132)
     | > ga_loss: 0.00232  (0.00249)
     | > decoder_diff_spec_loss: 0.51905  (0.49434)
     | > postnet_diff_spec_loss: 0.82318  (0.81323)
     | > decoder_ssim_loss: 0.18167  (0.31735)
     | > postnet_ssim_loss: 0.18953  (0.32949)
     | > loss: 4.78337  (3.57008)
     | > align_error: 0.99456  (0.99163)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.98994  (3.98762)
     | > current_lr: 0.00010 
     | > step_time: 3.94560  (4.00792)
     | > loader_time: 0.02080  (0.03518)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 274350[0m
     | > decoder_loss: 2.02500  (1.93578)
     | > postnet_loss: 1.62642  (1.65093)
     | > stopnet_loss: 1.59274  (1.65078)
     | > decoder_coarse_loss: 1.92570  (1.85620)
     | > decoder_ddc_loss: 0.00141  (0.00137)
     | > ga_loss: 0.00246  (0.00248)
     | > decoder_diff_spec_loss: 0.50720  (0.49737)
     | > postnet_diff_spec_loss: 0.80737  (0.81043)
     | > decoder_ssim_loss: 0.31333  (0.32281)
     | > postnet_ssim_loss: 0.32326  (0.33495)
     | > loss: 3.48746  (3.51564)
     | > align_error: 0.99168  (0.99142)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.20388  (4.08303)
     | > current_lr: 0.00010 
     | > step_time: 3.35940  (3.71205)
     | > loader_time: 0.05500  (0.03343)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 274375[0m
     | > decoder_loss: 2.01818  (1.95715)
     | > postnet_loss: 1.69939  (1.66582)
     | > stopnet_loss: 1.57439  (1.66356)
     | > decoder_coarse_loss: 2.00675  (1.88028)
     | > decoder_ddc_loss: 0.00153  (0.00142)
     | > ga_loss: 0.00292  (0.00250)
     | > decoder_diff_spec_loss: 0.50145  (0.50243)
     | > postnet_diff_spec_loss: 0.80527  (0.81285)
     | > decoder_ssim_loss: 0.33708  (0.31894)
     | > postnet_ssim_loss: 0.34887  (0.33063)
     | > loss: 3.51863  (3.54345)
     | > align_error: 0.99075  (0.99120)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.45793  (4.09064)
     | > current_lr: 0.00010 
     | > step_time: 3.35000  (3.71783)
     | > loader_time: 0.01670  (0.03565)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.44227 [0m(+0.02851)
     | > avg_decoder_loss:[91m 2.41874 [0m(+0.02207)
     | > avg_postnet_loss:[92m 2.42057 [0m(-0.14271)
     | > avg_stopnet_loss:[92m 1.50888 [0m(-0.00143)
     | > avg_decoder_coarse_loss:[92m 2.05547 [0m(-0.03560)
     | > avg_decoder_ddc_loss:[92m 0.00091 [0m(-0.00003)
     | > avg_ga_loss:[91m 0.00236 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.48008 [0m(-0.00154)
     | > avg_postnet_diff_spec_loss:[92m 0.83055 [0m(-0.00406)
     | > avg_decoder_ssim_loss:[92m 0.31515 [0m(-0.00045)
     | > avg_postnet_ssim_loss:[92m 0.34016 [0m(-0.00398)
     | > avg_loss:[92m 3.73607 [0m(-0.04301)
     | > avg_align_error:[91m 0.99287 [0m(+0.00006)


[4m[1m > EPOCH: 50/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:58:32) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 274400[0m
     | > decoder_loss: 1.72485  (1.72485)
     | > postnet_loss: 1.56009  (1.56009)
     | > stopnet_loss: 0.96843  (0.96843)
     | > decoder_coarse_loss: 1.65867  (1.65867)
     | > decoder_ddc_loss: 0.00185  (0.00185)
     | > ga_loss: 0.00258  (0.00258)
     | > decoder_diff_spec_loss: 0.46438  (0.46438)
     | > postnet_diff_spec_loss: 0.79354  (0.79354)
     | > decoder_ssim_loss: 0.46475  (0.46475)
     | > postnet_ssim_loss: 0.48684  (0.48684)
     | > loss: 2.77009  (2.77009)
     | > align_error: 0.98993  (0.98993)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.85230  (3.85230)
     | > current_lr: 0.00010 
     | > step_time: 3.30410  (3.30413)
     | > loader_time: 8.44560  (8.44564)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 274425[0m
     | > decoder_loss: 1.83021  (1.92386)
     | > postnet_loss: 1.57562  (1.63806)
     | > stopnet_loss: 1.34959  (1.69850)
     | > decoder_coarse_loss: 1.77663  (1.83918)
     | > decoder_ddc_loss: 0.00149  (0.00126)
     | > ga_loss: 0.00235  (0.00242)
     | > decoder_diff_spec_loss: 0.47029  (0.49756)
     | > postnet_diff_spec_loss: 0.80235  (0.80997)
     | > decoder_ssim_loss: 0.35793  (0.31482)
     | > postnet_ssim_loss: 0.37057  (0.32721)
     | > loss: 3.15762  (3.54859)
     | > align_error: 0.99002  (0.99178)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.38256  (4.03862)
     | > current_lr: 0.00010 
     | > step_time: 3.33050  (3.97210)
     | > loader_time: 0.02440  (0.04211)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 274450[0m
     | > decoder_loss: 1.98835  (1.95047)
     | > postnet_loss: 1.56541  (1.64842)
     | > stopnet_loss: 1.59502  (1.65957)
     | > decoder_coarse_loss: 1.90181  (1.87000)
     | > decoder_ddc_loss: 0.00159  (0.00132)
     | > ga_loss: 0.00249  (0.00243)
     | > decoder_diff_spec_loss: 0.50573  (0.50450)
     | > postnet_diff_spec_loss: 0.80296  (0.81386)
     | > decoder_ssim_loss: 0.33051  (0.31748)
     | > postnet_ssim_loss: 0.34744  (0.32934)
     | > loss: 3.46843  (3.53058)
     | > align_error: 0.99084  (0.99150)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.69222  (3.89956)
     | > current_lr: 0.00009 
     | > step_time: 3.24670  (3.88344)
     | > loader_time: 0.05020  (0.03649)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 274475[0m
     | > decoder_loss: 1.84745  (1.93805)
     | > postnet_loss: 1.51506  (1.64227)
     | > stopnet_loss: 1.65414  (1.65835)
     | > decoder_coarse_loss: 1.76557  (1.86077)
     | > decoder_ddc_loss: 0.00093  (0.00133)
     | > ga_loss: 0.00211  (0.00248)
     | > decoder_diff_spec_loss: 0.51446  (0.50159)
     | > postnet_diff_spec_loss: 0.80436  (0.81130)
     | > decoder_ssim_loss: 0.31167  (0.31731)
     | > postnet_ssim_loss: 0.31818  (0.32925)
     | > loss: 3.43410  (3.52123)
     | > align_error: 0.99295  (0.99136)
     | > amp_scaler: 65536.00000  (38447.78667)
     | > grad_norm: 3.42823  (3.95066)
     | > current_lr: 0.00009 
     | > step_time: 4.31800  (3.75531)
     | > loader_time: 0.03890  (0.03390)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.48893 [0m(+0.04666)
     | > avg_decoder_loss:[91m 2.42724 [0m(+0.00850)
     | > avg_postnet_loss:[91m 2.52681 [0m(+0.10623)
     | > avg_stopnet_loss:[92m 1.50771 [0m(-0.00117)
     | > avg_decoder_coarse_loss:[91m 2.08141 [0m(+0.02594)
     | > avg_decoder_ddc_loss:[91m 0.00093 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00235 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.48004 [0m(-0.00005)
     | > avg_postnet_diff_spec_loss:[91m 0.83229 [0m(+0.00174)
     | > avg_decoder_ssim_loss:[92m 0.31441 [0m(-0.00075)
     | > avg_postnet_ssim_loss:[91m 0.34080 [0m(+0.00064)
     | > avg_loss:[91m 3.77045 [0m(+0.03438)
     | > avg_align_error:[92m 0.99277 [0m(-0.00010)


[4m[1m > EPOCH: 51/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:06:15) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 274500[0m
     | > decoder_loss: 1.96550  (1.88605)
     | > postnet_loss: 1.59592  (1.61614)
     | > stopnet_loss: 1.51026  (1.58650)
     | > decoder_coarse_loss: 1.84919  (1.81443)
     | > decoder_ddc_loss: 0.00128  (0.00136)
     | > ga_loss: 0.00255  (0.00250)
     | > decoder_diff_spec_loss: 0.49143  (0.49026)
     | > postnet_diff_spec_loss: 0.81250  (0.81168)
     | > decoder_ssim_loss: 0.33814  (0.32704)
     | > postnet_ssim_loss: 0.35185  (0.34084)
     | > loss: 3.37445  (3.42097)
     | > align_error: 0.99156  (0.99138)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.51001  (3.71893)
     | > current_lr: 0.00009 
     | > step_time: 3.34810  (4.14819)
     | > loader_time: 0.01950  (0.04928)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 274525[0m
     | > decoder_loss: 1.84248  (1.91629)
     | > postnet_loss: 1.51450  (1.62573)
     | > stopnet_loss: 1.76967  (1.64114)
     | > decoder_coarse_loss: 1.74974  (1.83788)
     | > decoder_ddc_loss: 0.00130  (0.00135)
     | > ga_loss: 0.00274  (0.00247)
     | > decoder_diff_spec_loss: 0.48606  (0.49632)
     | > postnet_diff_spec_loss: 0.80282  (0.80989)
     | > decoder_ssim_loss: 0.30323  (0.32181)
     | > postnet_ssim_loss: 0.31627  (0.33455)
     | > loss: 3.53746  (3.48947)
     | > align_error: 0.99084  (0.99143)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.36531  (3.95541)
     | > current_lr: 0.00009 
     | > step_time: 2.74850  (3.88490)
     | > loader_time: 0.02160  (0.04076)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 274550[0m
     | > decoder_loss: 1.77630  (1.93517)
     | > postnet_loss: 1.53496  (1.63538)
     | > stopnet_loss: 1.41489  (1.64948)
     | > decoder_coarse_loss: 1.71563  (1.86015)
     | > decoder_ddc_loss: 0.00125  (0.00137)
     | > ga_loss: 0.00240  (0.00249)
     | > decoder_diff_spec_loss: 0.45884  (0.50120)
     | > postnet_diff_spec_loss: 0.77774  (0.81221)
     | > decoder_ssim_loss: 0.33017  (0.31727)
     | > postnet_ssim_loss: 0.34569  (0.32966)
     | > loss: 3.16206  (3.51002)
     | > align_error: 0.99207  (0.99125)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 4.10442  (4.12625)
     | > current_lr: 0.00009 
     | > step_time: 3.95290  (3.84960)
     | > loader_time: 0.01780  (0.03959)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 274575[0m
     | > decoder_loss: 2.04093  (1.93512)
     | > postnet_loss: 1.64222  (1.63238)
     | > stopnet_loss: 0.98476  (1.64827)
     | > decoder_coarse_loss: 2.00963  (1.85932)
     | > decoder_ddc_loss: 0.00434  (0.00135)
     | > ga_loss: 0.00377  (0.00247)
     | > decoder_diff_spec_loss: 0.50408  (0.50084)
     | > postnet_diff_spec_loss: 0.78750  (0.81134)
     | > decoder_ssim_loss: 0.51473  (0.31786)
     | > postnet_ssim_loss: 0.55693  (0.33024)
     | > loss: 3.01869  (3.50774)
     | > align_error: 0.97926  (0.99124)
     | > amp_scaler: 32768.00000  (65159.35632)
     | > grad_norm: 0.00000  (4.01908)
     | > current_lr: 0.00009 
     | > step_time: 1.10480  (3.69322)
     | > loader_time: 0.00680  (0.03688)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.12453 [0m(-0.36440)
     | > avg_decoder_loss:[92m 2.36064 [0m(-0.06660)
     | > avg_postnet_loss:[92m 2.44316 [0m(-0.08364)
     | > avg_stopnet_loss:[91m 1.51237 [0m(+0.00467)
     | > avg_decoder_coarse_loss:[92m 2.03786 [0m(-0.04355)
     | > avg_decoder_ddc_loss:[92m 0.00091 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00234 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47902 [0m(-0.00102)
     | > avg_postnet_diff_spec_loss:[92m 0.82951 [0m(-0.00279)
     | > avg_decoder_ssim_loss:[92m 0.31363 [0m(-0.00078)
     | > avg_postnet_ssim_loss:[92m 0.33967 [0m(-0.00113)
     | > avg_loss:[92m 3.72518 [0m(-0.04527)
     | > avg_align_error:[91m 0.99278 [0m(+0.00001)


[4m[1m > EPOCH: 52/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:13:43) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 274600[0m
     | > decoder_loss: 1.96561  (1.92277)
     | > postnet_loss: 1.59212  (1.62801)
     | > stopnet_loss: 1.19762  (1.70554)
     | > decoder_coarse_loss: 1.81906  (1.83704)
     | > decoder_ddc_loss: 0.00118  (0.00119)
     | > ga_loss: 0.00240  (0.00243)
     | > decoder_diff_spec_loss: 0.48812  (0.49553)
     | > postnet_diff_spec_loss: 0.80526  (0.80974)
     | > decoder_ssim_loss: 0.39516  (0.31241)
     | > postnet_ssim_loss: 0.40680  (0.32495)
     | > loss: 3.07794  (3.55058)
     | > align_error: 0.99149  (0.99184)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.32919  (4.26812)
     | > current_lr: 0.00009 
     | > step_time: 3.87780  (3.87290)
     | > loader_time: 0.02440  (0.03787)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 274625[0m
     | > decoder_loss: 1.73688  (1.93868)
     | > postnet_loss: 1.45746  (1.63267)
     | > stopnet_loss: 1.64652  (1.65815)
     | > decoder_coarse_loss: 1.68052  (1.85645)
     | > decoder_ddc_loss: 0.00100  (0.00126)
     | > ga_loss: 0.00186  (0.00243)
     | > decoder_diff_spec_loss: 0.45252  (0.50295)
     | > postnet_diff_spec_loss: 0.78173  (0.81352)
     | > decoder_ssim_loss: 0.28609  (0.31634)
     | > postnet_ssim_loss: 0.30076  (0.32835)
     | > loss: 3.33006  (3.51784)
     | > align_error: 0.99311  (0.99149)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.46716  (4.12371)
     | > current_lr: 0.00009 
     | > step_time: 5.08770  (3.79122)
     | > loader_time: 0.02350  (0.03386)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 274650[0m
     | > decoder_loss: 2.02654  (1.92847)
     | > postnet_loss: 1.77172  (1.62574)
     | > stopnet_loss: 1.54159  (1.64674)
     | > decoder_coarse_loss: 1.93897  (1.84783)
     | > decoder_ddc_loss: 0.00112  (0.00129)
     | > ga_loss: 0.00211  (0.00248)
     | > decoder_diff_spec_loss: 0.51347  (0.50044)
     | > postnet_diff_spec_loss: 0.83353  (0.81080)
     | > decoder_ssim_loss: 0.32435  (0.31651)
     | > postnet_ssim_loss: 0.33523  (0.32876)
     | > loss: 3.48837  (3.49911)
     | > align_error: 0.99240  (0.99131)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.55872  (3.92875)
     | > current_lr: 0.00009 
     | > step_time: 3.43940  (3.63661)
     | > loader_time: 0.02210  (0.03268)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.98563 [0m(-0.13890)
     | > avg_decoder_loss:[91m 2.46537 [0m(+0.10473)
     | > avg_postnet_loss:[92m 2.43175 [0m(-0.01142)
     | > avg_stopnet_loss:[92m 1.50435 [0m(-0.00802)
     | > avg_decoder_coarse_loss:[91m 2.10825 [0m(+0.07039)
     | > avg_decoder_ddc_loss:[91m 0.00092 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00233 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.48122 [0m(+0.00220)
     | > avg_postnet_diff_spec_loss:[92m 0.82926 [0m(-0.00025)
     | > avg_decoder_ssim_loss:[92m 0.31340 [0m(-0.00023)
     | > avg_postnet_ssim_loss:[92m 0.33879 [0m(-0.00088)
     | > avg_loss:[91m 3.75824 [0m(+0.03306)
     | > avg_align_error:[92m 0.99271 [0m(-0.00007)


[4m[1m > EPOCH: 53/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:20:56) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 274675[0m
     | > decoder_loss: 1.66392  (1.85772)
     | > postnet_loss: 1.40340  (1.58960)
     | > stopnet_loss: 1.37711  (1.60053)
     | > decoder_coarse_loss: 1.58786  (1.78612)
     | > decoder_ddc_loss: 0.00087  (0.00135)
     | > ga_loss: 0.00201  (0.00250)
     | > decoder_diff_spec_loss: 0.43968  (0.49140)
     | > postnet_diff_spec_loss: 0.78392  (0.81032)
     | > decoder_ssim_loss: 0.35279  (0.32502)
     | > postnet_ssim_loss: 0.36947  (0.33898)
     | > loss: 3.03764  (3.41315)
     | > align_error: 0.99420  (0.99122)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.04973  (3.33450)
     | > current_lr: 0.00009 
     | > step_time: 4.41020  (4.04023)
     | > loader_time: 0.02190  (0.05354)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 274700[0m
     | > decoder_loss: 1.87987  (1.90022)
     | > postnet_loss: 1.61585  (1.60343)
     | > stopnet_loss: 1.21750  (1.62889)
     | > decoder_coarse_loss: 1.85072  (1.82548)
     | > decoder_ddc_loss: 0.00091  (0.00130)
     | > ga_loss: 0.00201  (0.00246)
     | > decoder_diff_spec_loss: 0.50749  (0.49544)
     | > postnet_diff_spec_loss: 0.82712  (0.80890)
     | > decoder_ssim_loss: 0.36044  (0.32126)
     | > postnet_ssim_loss: 0.36618  (0.33449)
     | > loss: 3.07971  (3.46382)
     | > align_error: 0.99382  (0.99137)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.33097  (4.04063)
     | > current_lr: 0.00009 
     | > step_time: 4.48730  (3.72454)
     | > loader_time: 0.01750  (0.04109)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 274725[0m
     | > decoder_loss: 1.85092  (1.91932)
     | > postnet_loss: 1.52696  (1.61407)
     | > stopnet_loss: 1.48108  (1.64788)
     | > decoder_coarse_loss: 1.78185  (1.84705)
     | > decoder_ddc_loss: 0.00184  (0.00131)
     | > ga_loss: 0.00302  (0.00249)
     | > decoder_diff_spec_loss: 0.48545  (0.50081)
     | > postnet_diff_spec_loss: 0.79416  (0.81174)
     | > decoder_ssim_loss: 0.33381  (0.31598)
     | > postnet_ssim_loss: 0.35152  (0.32875)
     | > loss: 3.27780  (3.49508)
     | > align_error: 0.98888  (0.99119)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.91275  (4.11214)
     | > current_lr: 0.00009 
     | > step_time: 2.55740  (3.65636)
     | > loader_time: 0.01680  (0.03808)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 274750[0m
     | > decoder_loss: 1.80867  (1.91654)
     | > postnet_loss: 1.49883  (1.60811)
     | > stopnet_loss: 1.33881  (1.65399)
     | > decoder_coarse_loss: 1.74221  (1.84142)
     | > decoder_ddc_loss: 0.00110  (0.00127)
     | > ga_loss: 0.00218  (0.00245)
     | > decoder_diff_spec_loss: 0.47998  (0.49997)
     | > postnet_diff_spec_loss: 0.79052  (0.81055)
     | > decoder_ssim_loss: 0.35186  (0.31437)
     | > postnet_ssim_loss: 0.36167  (0.32686)
     | > loss: 3.10841  (3.49603)
     | > align_error: 0.99232  (0.99134)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.97361  (3.85645)
     | > current_lr: 0.00009 
     | > step_time: 2.44600  (3.55298)
     | > loader_time: 0.01970  (0.03540)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.07656 [0m(+0.09093)
     | > avg_decoder_loss:[91m 2.54185 [0m(+0.07648)
     | > avg_postnet_loss:[91m 2.52918 [0m(+0.09744)
     | > avg_stopnet_loss:[92m 1.50269 [0m(-0.00166)
     | > avg_decoder_coarse_loss:[92m 2.06385 [0m(-0.04440)
     | > avg_decoder_ddc_loss:[92m 0.00084 [0m(-0.00008)
     | > avg_ga_loss:[91m 0.00234 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.48095 [0m(-0.00027)
     | > avg_postnet_diff_spec_loss:[91m 0.83013 [0m(+0.00087)
     | > avg_decoder_ssim_loss:[92m 0.31297 [0m(-0.00043)
     | > avg_postnet_ssim_loss:[91m 0.33912 [0m(+0.00034)
     | > avg_loss:[91m 3.78912 [0m(+0.03088)
     | > avg_align_error:[91m 0.99282 [0m(+0.00011)


[4m[1m > EPOCH: 54/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:28:04) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 274775[0m
     | > decoder_loss: 1.95242  (1.90122)
     | > postnet_loss: 1.66917  (1.59628)
     | > stopnet_loss: 1.70143  (1.71103)
     | > decoder_coarse_loss: 1.90896  (1.82346)
     | > decoder_ddc_loss: 0.00120  (0.00117)
     | > ga_loss: 0.00236  (0.00241)
     | > decoder_diff_spec_loss: 0.50196  (0.49571)
     | > postnet_diff_spec_loss: 0.81234  (0.80918)
     | > decoder_ssim_loss: 0.30126  (0.30740)
     | > postnet_ssim_loss: 0.30861  (0.32073)
     | > loss: 3.57720  (3.53689)
     | > align_error: 0.99188  (0.99188)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.61213  (4.09898)
     | > current_lr: 0.00009 
     | > step_time: 3.79030  (3.91730)
     | > loader_time: 0.04460  (0.04760)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 274800[0m
     | > decoder_loss: 2.04423  (1.92698)
     | > postnet_loss: 1.76010  (1.61379)
     | > stopnet_loss: 2.17992  (1.64463)
     | > decoder_coarse_loss: 1.97753  (1.84635)
     | > decoder_ddc_loss: 0.00085  (0.00127)
     | > ga_loss: 0.00214  (0.00243)
     | > decoder_diff_spec_loss: 0.52905  (0.50247)
     | > postnet_diff_spec_loss: 0.82880  (0.81345)
     | > decoder_ssim_loss: 0.23955  (0.31570)
     | > postnet_ssim_loss: 0.24836  (0.32832)
     | > loss: 4.09772  (3.49384)
     | > align_error: 0.99339  (0.99147)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.86906  (4.16282)
     | > current_lr: 0.00009 
     | > step_time: 3.94000  (3.73301)
     | > loader_time: 0.02810  (0.03737)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 274825[0m
     | > decoder_loss: 1.96488  (1.90994)
     | > postnet_loss: 1.57589  (1.59865)
     | > stopnet_loss: 1.53925  (1.63889)
     | > decoder_coarse_loss: 1.85149  (1.83409)
     | > decoder_ddc_loss: 0.00146  (0.00130)
     | > ga_loss: 0.00259  (0.00247)
     | > decoder_diff_spec_loss: 0.51105  (0.49896)
     | > postnet_diff_spec_loss: 0.81475  (0.80951)
     | > decoder_ssim_loss: 0.32647  (0.31515)
     | > postnet_ssim_loss: 0.33145  (0.32792)
     | > loss: 3.39656  (3.47513)
     | > align_error: 0.99126  (0.99127)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.13282  (4.06920)
     | > current_lr: 0.00009 
     | > step_time: 3.17050  (3.61774)
     | > loader_time: 0.03380  (0.03482)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.57313 [0m(-0.50343)
     | > avg_decoder_loss:[92m 2.42273 [0m(-0.11911)
     | > avg_postnet_loss:[92m 2.34695 [0m(-0.18223)
     | > avg_stopnet_loss:[91m 1.50354 [0m(+0.00085)
     | > avg_decoder_coarse_loss:[92m 1.99215 [0m(-0.07170)
     | > avg_decoder_ddc_loss:[91m 0.00088 [0m(+0.00005)
     | > avg_ga_loss:[92m 0.00233 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47910 [0m(-0.00184)
     | > avg_postnet_diff_spec_loss:[92m 0.82758 [0m(-0.00255)
     | > avg_decoder_ssim_loss:[92m 0.31217 [0m(-0.00080)
     | > avg_postnet_ssim_loss:[92m 0.33676 [0m(-0.00236)
     | > avg_loss:[92m 3.69476 [0m(-0.09436)
     | > avg_align_error:[92m 0.99277 [0m(-0.00005)


[4m[1m > EPOCH: 55/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:35:12) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 274850[0m
     | > decoder_loss: 2.00209  (1.87577)
     | > postnet_loss: 1.62001  (1.58935)
     | > stopnet_loss: 1.20649  (1.59574)
     | > decoder_coarse_loss: 1.92130  (1.79394)
     | > decoder_ddc_loss: 0.00195  (0.00141)
     | > ga_loss: 0.00324  (0.00252)
     | > decoder_diff_spec_loss: 0.51122  (0.49445)
     | > postnet_diff_spec_loss: 0.81739  (0.81287)
     | > decoder_ssim_loss: 0.41628  (0.32113)
     | > postnet_ssim_loss: 0.42746  (0.33504)
     | > loss: 3.15210  (3.41433)
     | > align_error: 0.98895  (0.99092)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.07026  (3.59912)
     | > current_lr: 0.00009 
     | > step_time: 2.63720  (4.00228)
     | > loader_time: 0.01550  (0.04472)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 274875[0m
     | > decoder_loss: 1.73895  (1.89176)
     | > postnet_loss: 1.51463  (1.58125)
     | > stopnet_loss: 1.24717  (1.62062)
     | > decoder_coarse_loss: 1.71305  (1.80741)
     | > decoder_ddc_loss: 0.00239  (0.00132)
     | > ga_loss: 0.00314  (0.00246)
     | > decoder_diff_spec_loss: 0.47012  (0.49405)
     | > postnet_diff_spec_loss: 0.80142  (0.80811)
     | > decoder_ssim_loss: 0.42026  (0.31918)
     | > postnet_ssim_loss: 0.43206  (0.33286)
     | > loss: 3.03612  (3.44190)
     | > align_error: 0.98677  (0.99128)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.35794  (3.97203)
     | > current_lr: 0.00009 
     | > step_time: 2.69250  (3.71982)
     | > loader_time: 0.04840  (0.03853)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 274900[0m
     | > decoder_loss: 1.79748  (1.91462)
     | > postnet_loss: 1.59468  (1.59712)
     | > stopnet_loss: 1.48738  (1.63540)
     | > decoder_coarse_loss: 1.74606  (1.83345)
     | > decoder_ddc_loss: 0.00203  (0.00131)
     | > ga_loss: 0.00320  (0.00246)
     | > decoder_diff_spec_loss: 0.46190  (0.50037)
     | > postnet_diff_spec_loss: 0.79756  (0.81169)
     | > decoder_ssim_loss: 0.35166  (0.31488)
     | > postnet_ssim_loss: 0.37046  (0.32772)
     | > loss: 3.28382  (3.47301)
     | > align_error: 0.98722  (0.99121)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.57891  (4.10773)
     | > current_lr: 0.00009 
     | > step_time: 3.03180  (3.66842)
     | > loader_time: 0.05350  (0.03600)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 274925[0m
     | > decoder_loss: 1.87178  (1.90971)
     | > postnet_loss: 1.63425  (1.59233)
     | > stopnet_loss: 2.14828  (1.64677)
     | > decoder_coarse_loss: 1.80884  (1.82966)
     | > decoder_ddc_loss: 0.00065  (0.00129)
     | > ga_loss: 0.00189  (0.00244)
     | > decoder_diff_spec_loss: 0.50915  (0.49968)
     | > postnet_diff_spec_loss: 0.80056  (0.81038)
     | > decoder_ssim_loss: 0.23304  (0.31316)
     | > postnet_ssim_loss: 0.24194  (0.32577)
     | > loss: 3.93279  (3.47946)
     | > align_error: 0.99349  (0.99129)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.35504  (3.82676)
     | > current_lr: 0.00009 
     | > step_time: 2.98900  (3.58153)
     | > loader_time: 0.01910  (0.03257)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.46328 [0m(-0.10985)
     | > avg_decoder_loss:[92m 2.38225 [0m(-0.04048)
     | > avg_postnet_loss:[91m 2.43704 [0m(+0.09009)
     | > avg_stopnet_loss:[92m 1.50084 [0m(-0.00270)
     | > avg_decoder_coarse_loss:[91m 2.01732 [0m(+0.02517)
     | > avg_decoder_ddc_loss:[92m 0.00085 [0m(-0.00004)
     | > avg_ga_loss:[91m 0.00233 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47722 [0m(-0.00189)
     | > avg_postnet_diff_spec_loss:[91m 0.82821 [0m(+0.00063)
     | > avg_decoder_ssim_loss:[92m 0.31164 [0m(-0.00053)
     | > avg_postnet_ssim_loss:[91m 0.33844 [0m(+0.00168)
     | > avg_loss:[91m 3.71073 [0m(+0.01597)
     | > avg_align_error:[92m 0.99276 [0m(-0.00001)


[4m[1m > EPOCH: 56/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:42:23) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 274950[0m
     | > decoder_loss: 1.86840  (1.89088)
     | > postnet_loss: 1.51240  (1.57378)
     | > stopnet_loss: 1.13942  (1.73176)
     | > decoder_coarse_loss: 1.81922  (1.81091)
     | > decoder_ddc_loss: 0.00116  (0.00122)
     | > ga_loss: 0.00184  (0.00239)
     | > decoder_diff_spec_loss: 0.51219  (0.49536)
     | > postnet_diff_spec_loss: 0.80152  (0.80872)
     | > decoder_ssim_loss: 0.38488  (0.30669)
     | > postnet_ssim_loss: 0.40405  (0.32055)
     | > loss: 2.97459  (3.54573)
     | > align_error: 0.99262  (0.99164)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.03287  (4.76636)
     | > current_lr: 0.00009 
     | > step_time: 3.70060  (3.90273)
     | > loader_time: 0.10020  (0.04239)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 274975[0m
     | > decoder_loss: 1.89668  (1.91029)
     | > postnet_loss: 1.59593  (1.58709)
     | > stopnet_loss: 1.16417  (1.64767)
     | > decoder_coarse_loss: 1.80588  (1.83244)
     | > decoder_ddc_loss: 0.00245  (0.00129)
     | > ga_loss: 0.00331  (0.00241)
     | > decoder_diff_spec_loss: 0.48711  (0.50225)
     | > postnet_diff_spec_loss: 0.80747  (0.81230)
     | > decoder_ssim_loss: 0.40159  (0.31641)
     | > postnet_ssim_loss: 0.41140  (0.32903)
     | > loss: 3.03286  (3.48251)
     | > align_error: 0.98618  (0.99123)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.59555  (4.17035)
     | > current_lr: 0.00009 
     | > step_time: 2.09210  (3.74598)
     | > loader_time: 0.02210  (0.03455)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 275000[0m
     | > decoder_loss: 1.95140  (1.89830)
     | > postnet_loss: 1.60226  (1.57801)
     | > stopnet_loss: 1.32000  (1.64780)
     | > decoder_coarse_loss: 1.87758  (1.82196)
     | > decoder_ddc_loss: 0.00153  (0.00129)
     | > ga_loss: 0.00266  (0.00246)
     | > decoder_diff_spec_loss: 0.50600  (0.49854)
     | > postnet_diff_spec_loss: 0.81496  (0.80885)
     | > decoder_ssim_loss: 0.39694  (0.31421)
     | > postnet_ssim_loss: 0.40758  (0.32702)
     | > loss: 3.22284  (3.47213)
     | > align_error: 0.99022  (0.99114)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.97838  (4.11264)
     | > current_lr: 0.00009 
     | > step_time: 2.82100  (3.65520)
     | > loader_time: 0.09930  (0.03449)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.49665 [0m(+0.03337)
     | > avg_decoder_loss:[92m 2.37829 [0m(-0.00396)
     | > avg_postnet_loss:[92m 2.32158 [0m(-0.11546)
     | > avg_stopnet_loss:[91m 1.50546 [0m(+0.00462)
     | > avg_decoder_coarse_loss:[92m 1.96811 [0m(-0.04921)
     | > avg_decoder_ddc_loss:[92m 0.00080 [0m(-0.00004)
     | > avg_ga_loss:[91m 0.00233 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47651 [0m(-0.00070)
     | > avg_postnet_diff_spec_loss:[92m 0.82702 [0m(-0.00119)
     | > avg_decoder_ssim_loss:[92m 0.31127 [0m(-0.00037)
     | > avg_postnet_ssim_loss:[92m 0.33742 [0m(-0.00103)
     | > avg_loss:[92m 3.67237 [0m(-0.03836)
     | > avg_align_error:[91m 0.99287 [0m(+0.00011)


[4m[1m > EPOCH: 57/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:49:35) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 275025[0m
     | > decoder_loss: 1.79414  (1.83453)
     | > postnet_loss: 1.45828  (1.56989)
     | > stopnet_loss: 1.26719  (1.62915)
     | > decoder_coarse_loss: 1.79151  (1.76843)
     | > decoder_ddc_loss: 0.00229  (0.00126)
     | > ga_loss: 0.00337  (0.00243)
     | > decoder_diff_spec_loss: 0.46842  (0.49357)
     | > postnet_diff_spec_loss: 0.78188  (0.81205)
     | > decoder_ssim_loss: 0.37961  (0.30983)
     | > postnet_ssim_loss: 0.39987  (0.32385)
     | > loss: 3.05302  (3.41965)
     | > align_error: 0.98620  (0.99110)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.27770  (3.67227)
     | > current_lr: 0.00009 
     | > step_time: 2.33720  (4.10457)
     | > loader_time: 0.01070  (0.04668)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 275050[0m
     | > decoder_loss: 1.75897  (1.87858)
     | > postnet_loss: 1.49382  (1.56506)
     | > stopnet_loss: 1.39837  (1.63650)
     | > decoder_coarse_loss: 1.70815  (1.80058)
     | > decoder_ddc_loss: 0.00212  (0.00122)
     | > ga_loss: 0.00282  (0.00243)
     | > decoder_diff_spec_loss: 0.44281  (0.49568)
     | > postnet_diff_spec_loss: 0.76665  (0.80784)
     | > decoder_ssim_loss: 0.33976  (0.31517)
     | > postnet_ssim_loss: 0.35492  (0.32938)
     | > loss: 3.12926  (3.44702)
     | > align_error: 0.98722  (0.99134)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.64757  (4.08662)
     | > current_lr: 0.00009 
     | > step_time: 3.07010  (3.63779)
     | > loader_time: 0.01860  (0.03606)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 275075[0m
     | > decoder_loss: 1.94934  (1.89849)
     | > postnet_loss: 1.65230  (1.57878)
     | > stopnet_loss: 1.79795  (1.63948)
     | > decoder_coarse_loss: 1.89089  (1.82369)
     | > decoder_ddc_loss: 0.00103  (0.00125)
     | > ga_loss: 0.00224  (0.00244)
     | > decoder_diff_spec_loss: 0.52028  (0.50111)
     | > postnet_diff_spec_loss: 0.84258  (0.81133)
     | > decoder_ssim_loss: 0.28446  (0.31310)
     | > postnet_ssim_loss: 0.29292  (0.32634)
     | > loss: 3.66759  (3.46520)
     | > align_error: 0.99259  (0.99119)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.71089  (4.23042)
     | > current_lr: 0.00009 
     | > step_time: 3.96670  (3.61419)
     | > loader_time: 0.02340  (0.03443)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 275100[0m
     | > decoder_loss: 1.92411  (1.89586)
     | > postnet_loss: 1.63737  (1.57297)
     | > stopnet_loss: 1.86118  (1.63508)
     | > decoder_coarse_loss: 1.86519  (1.82092)
     | > decoder_ddc_loss: 0.00107  (0.00124)
     | > ga_loss: 0.00240  (0.00244)
     | > decoder_diff_spec_loss: 0.50713  (0.49939)
     | > postnet_diff_spec_loss: 0.82912  (0.80982)
     | > decoder_ssim_loss: 0.26075  (0.31303)
     | > postnet_ssim_loss: 0.27168  (0.32614)
     | > loss: 3.69726  (3.45711)
     | > align_error: 0.99153  (0.99120)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.86581  (3.91209)
     | > current_lr: 0.00009 
     | > step_time: 2.93260  (3.54204)
     | > loader_time: 0.02120  (0.03389)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.40135 [0m(-0.09530)
     | > avg_decoder_loss:[92m 2.35427 [0m(-0.02402)
     | > avg_postnet_loss:[91m 2.34761 [0m(+0.02603)
     | > avg_stopnet_loss:[92m 1.50312 [0m(-0.00234)
     | > avg_decoder_coarse_loss:[91m 2.00986 [0m(+0.04175)
     | > avg_decoder_ddc_loss:[92m 0.00078 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00233 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47654 [0m(+0.00003)
     | > avg_postnet_diff_spec_loss:[92m 0.82559 [0m(-0.00143)
     | > avg_decoder_ssim_loss:[92m 0.31070 [0m(-0.00057)
     | > avg_postnet_ssim_loss:[92m 0.33612 [0m(-0.00129)
     | > avg_loss:[91m 3.68014 [0m(+0.00778)
     | > avg_align_error:[92m 0.99283 [0m(-0.00004)


[4m[1m > EPOCH: 58/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:56:41) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 275125[0m
     | > decoder_loss: 2.06346  (1.85783)
     | > postnet_loss: 1.72700  (1.55169)
     | > stopnet_loss: 1.31370  (1.71643)
     | > decoder_coarse_loss: 1.95554  (1.79570)
     | > decoder_ddc_loss: 0.00122  (0.00119)
     | > ga_loss: 0.00203  (0.00241)
     | > decoder_diff_spec_loss: 0.54976  (0.49306)
     | > postnet_diff_spec_loss: 0.84456  (0.80838)
     | > decoder_ssim_loss: 0.36520  (0.30184)
     | > postnet_ssim_loss: 0.38079  (0.31617)
     | > loss: 3.29574  (3.50995)
     | > align_error: 0.99196  (0.99157)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.61804  (3.99347)
     | > current_lr: 0.00009 
     | > step_time: 3.86440  (3.92874)
     | > loader_time: 0.04460  (0.03444)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 275150[0m
     | > decoder_loss: 2.05423  (1.89178)
     | > postnet_loss: 1.62097  (1.57035)
     | > stopnet_loss: 1.31890  (1.62927)
     | > decoder_coarse_loss: 1.96004  (1.82104)
     | > decoder_ddc_loss: 0.00124  (0.00123)
     | > ga_loss: 0.00235  (0.00238)
     | > decoder_diff_spec_loss: 0.52181  (0.50164)
     | > postnet_diff_spec_loss: 0.81128  (0.81204)
     | > decoder_ssim_loss: 0.33583  (0.31354)
     | > postnet_ssim_loss: 0.35401  (0.32698)
     | > loss: 3.24551  (3.45084)
     | > align_error: 0.99089  (0.99130)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.12024  (3.71421)
     | > current_lr: 0.00009 
     | > step_time: 3.48270  (3.77531)
     | > loader_time: 0.01990  (0.03609)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 275175[0m
     | > decoder_loss: 1.80770  (1.88039)
     | > postnet_loss: 1.46220  (1.56156)
     | > stopnet_loss: 1.63196  (1.63411)
     | > decoder_coarse_loss: 1.74669  (1.80804)
     | > decoder_ddc_loss: 0.00151  (0.00126)
     | > ga_loss: 0.00295  (0.00244)
     | > decoder_diff_spec_loss: 0.47578  (0.49767)
     | > postnet_diff_spec_loss: 0.79433  (0.80823)
     | > decoder_ssim_loss: 0.31846  (0.31199)
     | > postnet_ssim_loss: 0.33301  (0.32556)
     | > loss: 3.38165  (3.44500)
     | > align_error: 0.98899  (0.99109)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.63592  (3.72566)
     | > current_lr: 0.00009 
     | > step_time: 2.22700  (3.62177)
     | > loader_time: 0.01830  (0.03653)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.40655 [0m(+0.00520)
     | > avg_decoder_loss:[92m 2.35247 [0m(-0.00180)
     | > avg_postnet_loss:[92m 2.33580 [0m(-0.01181)
     | > avg_stopnet_loss:[92m 1.50266 [0m(-0.00046)
     | > avg_decoder_coarse_loss:[92m 1.99548 [0m(-0.01438)
     | > avg_decoder_ddc_loss:[92m 0.00078 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00233 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47767 [0m(+0.00113)
     | > avg_postnet_diff_spec_loss:[91m 0.82716 [0m(+0.00157)
     | > avg_decoder_ssim_loss:[92m 0.31022 [0m(-0.00048)
     | > avg_postnet_ssim_loss:[91m 0.33710 [0m(+0.00098)
     | > avg_loss:[92m 3.67346 [0m(-0.00669)
     | > avg_align_error:[91m 0.99288 [0m(+0.00005)


[4m[1m > EPOCH: 59/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:03:54) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 275200[0m
     | > decoder_loss: 1.69835  (1.84128)
     | > postnet_loss: 1.49807  (1.57211)
     | > stopnet_loss: 1.44407  (1.69231)
     | > decoder_coarse_loss: 1.67894  (1.77988)
     | > decoder_ddc_loss: 0.00186  (0.00109)
     | > ga_loss: 0.00291  (0.00230)
     | > decoder_diff_spec_loss: 0.47954  (0.49516)
     | > postnet_diff_spec_loss: 0.80844  (0.81519)
     | > decoder_ssim_loss: 0.34604  (0.30046)
     | > postnet_ssim_loss: 0.36238  (0.31426)
     | > loss: 3.17701  (3.48364)
     | > align_error: 0.98777  (0.99181)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.54646  (3.52117)
     | > current_lr: 0.00009 
     | > step_time: 2.26100  (4.43246)
     | > loader_time: 0.08720  (0.06229)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 275225[0m
     | > decoder_loss: 1.97464  (1.87353)
     | > postnet_loss: 1.61445  (1.54615)
     | > stopnet_loss: 1.33815  (1.63576)
     | > decoder_coarse_loss: 1.90131  (1.79456)
     | > decoder_ddc_loss: 0.00168  (0.00121)
     | > ga_loss: 0.00244  (0.00240)
     | > decoder_diff_spec_loss: 0.52677  (0.49620)
     | > postnet_diff_spec_loss: 0.82204  (0.80822)
     | > decoder_ssim_loss: 0.35667  (0.31354)
     | > postnet_ssim_loss: 0.36889  (0.32793)
     | > loss: 3.24198  (3.43812)
     | > align_error: 0.98923  (0.99141)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.12657  (3.98827)
     | > current_lr: 0.00009 
     | > step_time: 2.88250  (3.77936)
     | > loader_time: 0.01740  (0.03911)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 275250[0m
     | > decoder_loss: 1.91651  (1.88657)
     | > postnet_loss: 1.54512  (1.55733)
     | > stopnet_loss: 1.48635  (1.63467)
     | > decoder_coarse_loss: 1.87858  (1.81010)
     | > decoder_ddc_loss: 0.00120  (0.00126)
     | > ga_loss: 0.00229  (0.00243)
     | > decoder_diff_spec_loss: 0.51830  (0.49963)
     | > postnet_diff_spec_loss: 0.80585  (0.80997)
     | > decoder_ssim_loss: 0.32535  (0.31278)
     | > postnet_ssim_loss: 0.33643  (0.32640)
     | > loss: 3.32964  (3.44783)
     | > align_error: 0.99133  (0.99112)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.63881  (3.96741)
     | > current_lr: 0.00009 
     | > step_time: 3.80440  (3.68559)
     | > loader_time: 0.04930  (0.03428)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 275275[0m
     | > decoder_loss: 1.88603  (1.88456)
     | > postnet_loss: 1.49629  (1.55441)
     | > stopnet_loss: 1.85372  (1.62670)
     | > decoder_coarse_loss: 1.77557  (1.80901)
     | > decoder_ddc_loss: 0.00091  (0.00125)
     | > ga_loss: 0.00197  (0.00242)
     | > decoder_diff_spec_loss: 0.50655  (0.49858)
     | > postnet_diff_spec_loss: 0.81060  (0.80889)
     | > decoder_ssim_loss: 0.26214  (0.31284)
     | > postnet_ssim_loss: 0.27545  (0.32634)
     | > loss: 3.61697  (3.43779)
     | > align_error: 0.99279  (0.99112)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.51580  (3.84306)
     | > current_lr: 0.00009 
     | > step_time: 2.95010  (3.60915)
     | > loader_time: 0.04800  (0.03430)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.31818 [0m(-0.08837)
     | > avg_decoder_loss:[92m 2.30425 [0m(-0.04822)
     | > avg_postnet_loss:[92m 2.25750 [0m(-0.07830)
     | > avg_stopnet_loss:[92m 1.50180 [0m(-0.00086)
     | > avg_decoder_coarse_loss:[92m 1.95732 [0m(-0.03816)
     | > avg_decoder_ddc_loss:[91m 0.00079 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00232 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47612 [0m(-0.00155)
     | > avg_postnet_diff_spec_loss:[92m 0.82573 [0m(-0.00142)
     | > avg_decoder_ssim_loss:[92m 0.30957 [0m(-0.00066)
     | > avg_postnet_ssim_loss:[92m 0.33524 [0m(-0.00186)
     | > avg_loss:[92m 3.63002 [0m(-0.04343)
     | > avg_align_error:[92m 0.99278 [0m(-0.00010)


[4m[1m > EPOCH: 60/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:11:01) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 275300[0m
     | > decoder_loss: 1.91870  (1.84489)
     | > postnet_loss: 1.52502  (1.52653)
     | > stopnet_loss: 1.99502  (1.73772)
     | > decoder_coarse_loss: 1.81784  (1.77342)
     | > decoder_ddc_loss: 0.00102  (0.00108)
     | > ga_loss: 0.00251  (0.00243)
     | > decoder_diff_spec_loss: 0.51385  (0.49148)
     | > postnet_diff_spec_loss: 0.81242  (0.80596)
     | > decoder_ssim_loss: 0.25458  (0.29773)
     | > postnet_ssim_loss: 0.26806  (0.31219)
     | > loss: 3.78546  (3.51319)
     | > align_error: 0.99223  (0.99168)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.26719  (3.91413)
     | > current_lr: 0.00009 
     | > step_time: 3.30150  (3.92432)
     | > loader_time: 0.02390  (0.03950)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 275325[0m
     | > decoder_loss: 2.09747  (1.88087)
     | > postnet_loss: 1.62725  (1.55085)
     | > stopnet_loss: 2.14689  (1.62728)
     | > decoder_coarse_loss: 2.00123  (1.80657)
     | > decoder_ddc_loss: 0.00098  (0.00115)
     | > ga_loss: 0.00227  (0.00238)
     | > decoder_diff_spec_loss: 0.56120  (0.50124)
     | > postnet_diff_spec_loss: 0.85484  (0.81122)
     | > decoder_ssim_loss: 0.23828  (0.31214)
     | > postnet_ssim_loss: 0.24158  (0.32560)
     | > loss: 4.06394  (3.43660)
     | > align_error: 0.99147  (0.99139)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.91016  (3.71844)
     | > current_lr: 0.00009 
     | > step_time: 3.96960  (3.76225)
     | > loader_time: 0.04870  (0.03625)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 275350[0m
     | > decoder_loss: 1.89523  (1.87035)
     | > postnet_loss: 1.51542  (1.54128)
     | > stopnet_loss: 1.83330  (1.62581)
     | > decoder_coarse_loss: 1.82160  (1.79946)
     | > decoder_ddc_loss: 0.00118  (0.00120)
     | > ga_loss: 0.00233  (0.00243)
     | > decoder_diff_spec_loss: 0.48177  (0.49788)
     | > postnet_diff_spec_loss: 0.80103  (0.80760)
     | > decoder_ssim_loss: 0.27024  (0.31090)
     | > postnet_ssim_loss: 0.28279  (0.32468)
     | > loss: 3.61229  (3.42629)
     | > align_error: 0.99030  (0.99114)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.11829  (3.74260)
     | > current_lr: 0.00009 
     | > step_time: 4.11680  (3.66637)
     | > loader_time: 0.08650  (0.03391)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.80633 [0m(+0.48815)
     | > avg_decoder_loss:[91m 2.49694 [0m(+0.19269)
     | > avg_postnet_loss:[91m 2.56372 [0m(+0.30621)
     | > avg_stopnet_loss:[92m 1.49799 [0m(-0.00381)
     | > avg_decoder_coarse_loss:[91m 2.06616 [0m(+0.10884)
     | > avg_decoder_ddc_loss:[92m 0.00079 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00230 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47882 [0m(+0.00270)
     | > avg_postnet_diff_spec_loss:[91m 0.82862 [0m(+0.00288)
     | > avg_decoder_ssim_loss:[91m 0.31002 [0m(+0.00046)
     | > avg_postnet_ssim_loss:[91m 0.33837 [0m(+0.00313)
     | > avg_loss:[91m 3.78037 [0m(+0.15035)
     | > avg_align_error:[92m 0.99256 [0m(-0.00022)


[4m[1m > EPOCH: 61/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:18:12) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 275375[0m
     | > decoder_loss: 1.99133  (1.85092)
     | > postnet_loss: 1.65369  (1.55461)
     | > stopnet_loss: 1.25044  (1.67796)
     | > decoder_coarse_loss: 1.90523  (1.77917)
     | > decoder_ddc_loss: 0.00100  (0.00095)
     | > ga_loss: 0.00189  (0.00221)
     | > decoder_diff_spec_loss: 0.54203  (0.49868)
     | > postnet_diff_spec_loss: 0.82111  (0.81483)
     | > decoder_ssim_loss: 0.34556  (0.29325)
     | > postnet_ssim_loss: 0.36460  (0.30689)
     | > loss: 3.16603  (3.46382)
     | > align_error: 0.99240  (0.99229)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.46768  (3.36759)
     | > current_lr: 0.00009 
     | > step_time: 4.05960  (4.75430)
     | > loader_time: 0.02130  (0.05991)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 275400[0m
     | > decoder_loss: 1.91627  (1.86091)
     | > postnet_loss: 1.60841  (1.52424)
     | > stopnet_loss: 1.61824  (1.62459)
     | > decoder_coarse_loss: 1.81881  (1.78481)
     | > decoder_ddc_loss: 0.00086  (0.00112)
     | > ga_loss: 0.00196  (0.00240)
     | > decoder_diff_spec_loss: 0.47567  (0.49422)
     | > postnet_diff_spec_loss: 0.79506  (0.80708)
     | > decoder_ssim_loss: 0.27949  (0.31160)
     | > postnet_ssim_loss: 0.29854  (0.32590)
     | > loss: 3.42632  (3.41405)
     | > align_error: 0.99318  (0.99153)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.92689  (4.12139)
     | > current_lr: 0.00009 
     | > step_time: 4.77140  (3.73965)
     | > loader_time: 0.02740  (0.04066)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 275425[0m
     | > decoder_loss: 1.92982  (1.87543)
     | > postnet_loss: 1.56130  (1.53613)
     | > stopnet_loss: 1.52813  (1.61906)
     | > decoder_coarse_loss: 1.78908  (1.80280)
     | > decoder_ddc_loss: 0.00149  (0.00120)
     | > ga_loss: 0.00269  (0.00243)
     | > decoder_diff_spec_loss: 0.47584  (0.49865)
     | > postnet_diff_spec_loss: 0.79503  (0.80925)
     | > decoder_ssim_loss: 0.31065  (0.31195)
     | > postnet_ssim_loss: 0.32425  (0.32551)
     | > loss: 3.33845  (3.42142)
     | > align_error: 0.98853  (0.99113)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.31471  (4.03775)
     | > current_lr: 0.00009 
     | > step_time: 3.66980  (3.66886)
     | > loader_time: 0.01970  (0.03950)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 275450[0m
     | > decoder_loss: 1.95858  (1.87138)
     | > postnet_loss: 1.61440  (1.53483)
     | > stopnet_loss: 1.17623  (1.61588)
     | > decoder_coarse_loss: 1.90115  (1.79937)
     | > decoder_ddc_loss: 0.00098  (0.00120)
     | > ga_loss: 0.00190  (0.00242)
     | > decoder_diff_spec_loss: 0.54206  (0.49761)
     | > postnet_diff_spec_loss: 0.84146  (0.80815)
     | > decoder_ssim_loss: 0.37527  (0.31280)
     | > postnet_ssim_loss: 0.39680  (0.32630)
     | > loss: 3.09343  (3.41591)
     | > align_error: 0.99219  (0.99112)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.45303  (3.96767)
     | > current_lr: 0.00009 
     | > step_time: 3.51110  (3.59082)
     | > loader_time: 0.02290  (0.03604)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.51562 [0m(-0.29071)
     | > avg_decoder_loss:[92m 2.31036 [0m(-0.18658)
     | > avg_postnet_loss:[92m 2.30844 [0m(-0.25527)
     | > avg_stopnet_loss:[91m 1.50207 [0m(+0.00407)
     | > avg_decoder_coarse_loss:[92m 1.93744 [0m(-0.12871)
     | > avg_decoder_ddc_loss:[92m 0.00078 [0m(-0.00001)
     | > avg_ga_loss:[91m 0.00230 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47581 [0m(-0.00301)
     | > avg_postnet_diff_spec_loss:[92m 0.82516 [0m(-0.00346)
     | > avg_decoder_ssim_loss:[92m 0.30900 [0m(-0.00102)
     | > avg_postnet_ssim_loss:[92m 0.33555 [0m(-0.00282)
     | > avg_loss:[92m 3.63922 [0m(-0.14115)
     | > avg_align_error:[91m 0.99274 [0m(+0.00018)


[4m[1m > EPOCH: 62/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:25:19) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 275475[0m
     | > decoder_loss: 1.72997  (1.83618)
     | > postnet_loss: 1.45349  (1.50945)
     | > stopnet_loss: 2.17318  (1.71467)
     | > decoder_coarse_loss: 1.67207  (1.76287)
     | > decoder_ddc_loss: 0.00074  (0.00115)
     | > ga_loss: 0.00202  (0.00240)
     | > decoder_diff_spec_loss: 0.46114  (0.48889)
     | > postnet_diff_spec_loss: 0.78292  (0.80491)
     | > decoder_ssim_loss: 0.22662  (0.29946)
     | > postnet_ssim_loss: 0.24468  (0.31389)
     | > loss: 3.82618  (3.48088)
     | > align_error: 0.99443  (0.99148)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.82145  (4.29542)
     | > current_lr: 0.00009 
     | > step_time: 5.15190  (4.05911)
     | > loader_time: 0.02430  (0.03904)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 275500[0m
     | > decoder_loss: 1.91278  (1.86753)
     | > postnet_loss: 1.56126  (1.53119)
     | > stopnet_loss: 2.38179  (1.61201)
     | > decoder_coarse_loss: 1.84991  (1.79595)
     | > decoder_ddc_loss: 0.00088  (0.00119)
     | > ga_loss: 0.00212  (0.00237)
     | > decoder_diff_spec_loss: 0.54007  (0.49844)
     | > postnet_diff_spec_loss: 0.83670  (0.80940)
     | > decoder_ssim_loss: 0.21834  (0.31317)
     | > postnet_ssim_loss: 0.22471  (0.32693)
     | > loss: 4.17856  (3.40982)
     | > align_error: 0.99277  (0.99131)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.33828  (3.97944)
     | > current_lr: 0.00009 
     | > step_time: 4.54280  (3.82216)
     | > loader_time: 0.06870  (0.03112)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 275525[0m
     | > decoder_loss: 1.90805  (1.86190)
     | > postnet_loss: 1.45714  (1.52743)
     | > stopnet_loss: 2.07903  (1.61960)
     | > decoder_coarse_loss: 1.84065  (1.79235)
     | > decoder_ddc_loss: 0.00059  (0.00120)
     | > ga_loss: 0.00210  (0.00243)
     | > decoder_diff_spec_loss: 0.51237  (0.49680)
     | > postnet_diff_spec_loss: 0.79148  (0.80712)
     | > decoder_ssim_loss: 0.24424  (0.31080)
     | > postnet_ssim_loss: 0.25111  (0.32488)
     | > loss: 3.84095  (3.41236)
     | > align_error: 0.99437  (0.99115)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.01443  (3.94503)
     | > current_lr: 0.00009 
     | > step_time: 4.63110  (3.69520)
     | > loader_time: 0.01970  (0.03109)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.87412 [0m(+0.35850)
     | > avg_decoder_loss:[91m 2.35760 [0m(+0.04725)
     | > avg_postnet_loss:[91m 2.40133 [0m(+0.09289)
     | > avg_stopnet_loss:[92m 1.49995 [0m(-0.00212)
     | > avg_decoder_coarse_loss:[91m 1.97362 [0m(+0.03618)
     | > avg_decoder_ddc_loss:[92m 0.00077 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00230 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47572 [0m(-0.00008)
     | > avg_postnet_diff_spec_loss:[91m 0.82548 [0m(+0.00032)
     | > avg_decoder_ssim_loss:[92m 0.30892 [0m(-0.00008)
     | > avg_postnet_ssim_loss:[91m 0.33605 [0m(+0.00050)
     | > avg_loss:[91m 3.68131 [0m(+0.04209)
     | > avg_align_error:[92m 0.99270 [0m(-0.00003)


[4m[1m > EPOCH: 63/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:32:25) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 275550[0m
     | > decoder_loss: 1.81359  (1.81176)
     | > postnet_loss: 1.52760  (1.53956)
     | > stopnet_loss: 1.29023  (1.79460)
     | > decoder_coarse_loss: 1.74549  (1.75109)
     | > decoder_ddc_loss: 0.00116  (0.00091)
     | > ga_loss: 0.00221  (0.00226)
     | > decoder_diff_spec_loss: 0.48373  (0.48918)
     | > postnet_diff_spec_loss: 0.81029  (0.81297)
     | > decoder_ssim_loss: 0.36103  (0.28387)
     | > postnet_ssim_loss: 0.37350  (0.29665)
     | > loss: 3.08037  (3.55241)
     | > align_error: 0.99111  (0.99228)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.24023  (3.52869)
     | > current_lr: 0.00008 
     | > step_time: 3.53650  (4.82557)
     | > loader_time: 0.01810  (0.05547)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 275575[0m
     | > decoder_loss: 1.75326  (1.84736)
     | > postnet_loss: 1.43280  (1.51361)
     | > stopnet_loss: 2.23520  (1.63703)
     | > decoder_coarse_loss: 1.69153  (1.77564)
     | > decoder_ddc_loss: 0.00074  (0.00117)
     | > ga_loss: 0.00229  (0.00240)
     | > decoder_diff_spec_loss: 0.47684  (0.49378)
     | > postnet_diff_spec_loss: 0.78211  (0.80669)
     | > decoder_ssim_loss: 0.21964  (0.31158)
     | > postnet_ssim_loss: 0.23446  (0.32644)
     | > loss: 3.89450  (3.41811)
     | > align_error: 0.99335  (0.99133)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.41182  (4.16986)
     | > current_lr: 0.00008 
     | > step_time: 3.67470  (3.64491)
     | > loader_time: 0.06420  (0.04824)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 275600[0m
     | > decoder_loss: 1.86394  (1.86552)
     | > postnet_loss: 1.56141  (1.52865)
     | > stopnet_loss: 1.19823  (1.62700)
     | > decoder_coarse_loss: 1.81285  (1.79277)
     | > decoder_ddc_loss: 0.00128  (0.00119)
     | > ga_loss: 0.00243  (0.00242)
     | > decoder_diff_spec_loss: 0.51896  (0.49869)
     | > postnet_diff_spec_loss: 0.81810  (0.80888)
     | > decoder_ssim_loss: 0.37644  (0.31099)
     | > postnet_ssim_loss: 0.39647  (0.32518)
     | > loss: 3.04777  (3.42208)
     | > align_error: 0.99079  (0.99113)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.53120  (3.84913)
     | > current_lr: 0.00008 
     | > step_time: 3.19190  (3.60977)
     | > loader_time: 0.03660  (0.03873)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 275625[0m
     | > decoder_loss: 1.92908  (1.86150)
     | > postnet_loss: 1.48817  (1.52512)
     | > stopnet_loss: 1.88179  (1.61889)
     | > decoder_coarse_loss: 1.83753  (1.78946)
     | > decoder_ddc_loss: 0.00102  (0.00119)
     | > ga_loss: 0.00239  (0.00243)
     | > decoder_diff_spec_loss: 0.48594  (0.49668)
     | > postnet_diff_spec_loss: 0.78096  (0.80709)
     | > decoder_ssim_loss: 0.26835  (0.31117)
     | > postnet_ssim_loss: 0.28580  (0.32502)
     | > loss: 3.66296  (3.41035)
     | > align_error: 0.99135  (0.99108)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.40819  (3.73902)
     | > current_lr: 0.00008 
     | > step_time: 3.24950  (3.57073)
     | > loader_time: 0.01910  (0.03620)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.92047 [0m(+0.04635)
     | > avg_decoder_loss:[91m 2.36206 [0m(+0.00446)
     | > avg_postnet_loss:[92m 2.22024 [0m(-0.18110)
     | > avg_stopnet_loss:[92m 1.49861 [0m(-0.00134)
     | > avg_decoder_coarse_loss:[92m 1.94184 [0m(-0.03178)
     | > avg_decoder_ddc_loss:[92m 0.00077 [0m(-0.00001)
     | > avg_ga_loss:[91m 0.00230 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47781 [0m(+0.00208)
     | > avg_postnet_diff_spec_loss:[92m 0.82359 [0m(-0.00189)
     | > avg_decoder_ssim_loss:[92m 0.30852 [0m(-0.00040)
     | > avg_postnet_ssim_loss:[92m 0.33202 [0m(-0.00403)
     | > avg_loss:[92m 3.62682 [0m(-0.05448)
     | > avg_align_error:[91m 0.99270 [0m(+0.00000)


[4m[1m > EPOCH: 64/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:39:37) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 275650[0m
     | > decoder_loss: 1.86275  (1.82962)
     | > postnet_loss: 1.49098  (1.49948)
     | > stopnet_loss: 1.92256  (1.68486)
     | > decoder_coarse_loss: 1.78481  (1.75060)
     | > decoder_ddc_loss: 0.00072  (0.00113)
     | > ga_loss: 0.00198  (0.00243)
     | > decoder_diff_spec_loss: 0.49322  (0.49016)
     | > postnet_diff_spec_loss: 0.80043  (0.80566)
     | > decoder_ssim_loss: 0.25261  (0.30270)
     | > postnet_ssim_loss: 0.26796  (0.31734)
     | > loss: 3.67081  (3.44619)
     | > align_error: 0.99411  (0.99138)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.92833  (3.98935)
     | > current_lr: 0.00008 
     | > step_time: 4.28550  (3.84525)
     | > loader_time: 0.02050  (0.02908)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 275675[0m
     | > decoder_loss: 1.95158  (1.85937)
     | > postnet_loss: 1.55263  (1.52449)
     | > stopnet_loss: 1.11282  (1.58877)
     | > decoder_coarse_loss: 1.87770  (1.78419)
     | > decoder_ddc_loss: 0.00137  (0.00116)
     | > ga_loss: 0.00226  (0.00238)
     | > decoder_diff_spec_loss: 0.52704  (0.49730)
     | > postnet_diff_spec_loss: 0.82227  (0.80846)
     | > decoder_ssim_loss: 0.41249  (0.31473)
     | > postnet_ssim_loss: 0.41974  (0.32896)
     | > loss: 3.01534  (3.38032)
     | > align_error: 0.99027  (0.99130)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.39152  (3.73949)
     | > current_lr: 0.00008 
     | > step_time: 3.14070  (3.70256)
     | > loader_time: 0.01880  (0.03030)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 275700[0m
     | > decoder_loss: 1.72077  (1.85477)
     | > postnet_loss: 1.48113  (1.52187)
     | > stopnet_loss: 1.46918  (1.60439)
     | > decoder_coarse_loss: 1.64410  (1.78183)
     | > decoder_ddc_loss: 0.00151  (0.00119)
     | > ga_loss: 0.00255  (0.00242)
     | > decoder_diff_spec_loss: 0.46770  (0.49622)
     | > postnet_diff_spec_loss: 0.79598  (0.80686)
     | > decoder_ssim_loss: 0.32018  (0.31122)
     | > postnet_ssim_loss: 0.33873  (0.32557)
     | > loss: 3.17445  (3.39139)
     | > align_error: 0.98983  (0.99108)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.44681  (3.77466)
     | > current_lr: 0.00008 
     | > step_time: 2.74650  (3.61040)
     | > loader_time: 0.01930  (0.03310)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.86833 [0m(-0.05214)
     | > avg_decoder_loss:[91m 2.39527 [0m(+0.03321)
     | > avg_postnet_loss:[91m 2.36131 [0m(+0.14107)
     | > avg_stopnet_loss:[92m 1.49516 [0m(-0.00344)
     | > avg_decoder_coarse_loss:[91m 1.97074 [0m(+0.02890)
     | > avg_decoder_ddc_loss:[92m 0.00076 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00230 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47817 [0m(+0.00036)
     | > avg_postnet_diff_spec_loss:[92m 0.82266 [0m(-0.00093)
     | > avg_decoder_ssim_loss:[91m 0.30861 [0m(+0.00008)
     | > avg_postnet_ssim_loss:[91m 0.33354 [0m(+0.00152)
     | > avg_loss:[91m 3.67440 [0m(+0.04758)
     | > avg_align_error:[92m 0.99269 [0m(-0.00001)


[4m[1m > EPOCH: 65/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:46:41) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 275725[0m
     | > decoder_loss: 1.74319  (1.80039)
     | > postnet_loss: 1.51672  (1.52693)
     | > stopnet_loss: 1.78781  (1.87958)
     | > decoder_coarse_loss: 1.70076  (1.73024)
     | > decoder_ddc_loss: 0.00085  (0.00087)
     | > ga_loss: 0.00225  (0.00226)
     | > decoder_diff_spec_loss: 0.47992  (0.49232)
     | > postnet_diff_spec_loss: 0.81446  (0.81317)
     | > decoder_ssim_loss: 0.26872  (0.26794)
     | > postnet_ssim_loss: 0.28962  (0.28035)
     | > loss: 3.50262  (3.61893)
     | > align_error: 0.99304  (0.99249)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.11885  (3.98511)
     | > current_lr: 0.00008 
     | > step_time: 4.31590  (4.85413)
     | > loader_time: 0.02140  (0.05471)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 275750[0m
     | > decoder_loss: 1.85434  (1.83802)
     | > postnet_loss: 1.53691  (1.50793)
     | > stopnet_loss: 1.30740  (1.62535)
     | > decoder_coarse_loss: 1.79298  (1.76462)
     | > decoder_ddc_loss: 0.00112  (0.00115)
     | > ga_loss: 0.00222  (0.00240)
     | > decoder_diff_spec_loss: 0.52713  (0.49411)
     | > postnet_diff_spec_loss: 0.82395  (0.80701)
     | > decoder_ssim_loss: 0.35422  (0.31389)
     | > postnet_ssim_loss: 0.36555  (0.32890)
     | > loss: 3.13253  (3.40124)
     | > align_error: 0.99233  (0.99130)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.56251  (4.07531)
     | > current_lr: 0.00008 
     | > step_time: 3.83450  (3.66925)
     | > loader_time: 0.02750  (0.03715)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 275775[0m
     | > decoder_loss: 1.68579  (1.85282)
     | > postnet_loss: 1.46756  (1.51693)
     | > stopnet_loss: 1.96311  (1.64311)
     | > decoder_coarse_loss: 1.61228  (1.78188)
     | > decoder_ddc_loss: 0.00094  (0.00117)
     | > ga_loss: 0.00248  (0.00241)
     | > decoder_diff_spec_loss: 0.46107  (0.49758)
     | > postnet_diff_spec_loss: 0.79230  (0.80816)
     | > decoder_ssim_loss: 0.25983  (0.30903)
     | > postnet_ssim_loss: 0.27856  (0.32337)
     | > loss: 3.61510  (3.42790)
     | > align_error: 0.99224  (0.99115)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.06638  (3.75957)
     | > current_lr: 0.00008 
     | > step_time: 3.29860  (3.68258)
     | > loader_time: 0.02000  (0.03462)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 275800[0m
     | > decoder_loss: 2.11144  (1.84894)
     | > postnet_loss: 1.57320  (1.51410)
     | > stopnet_loss: 1.89252  (1.61931)
     | > decoder_coarse_loss: 2.04908  (1.77971)
     | > decoder_ddc_loss: 0.00078  (0.00119)
     | > ga_loss: 0.00198  (0.00242)
     | > decoder_diff_spec_loss: 0.50202  (0.49599)
     | > postnet_diff_spec_loss: 0.80188  (0.80686)
     | > decoder_ssim_loss: 0.25130  (0.31083)
     | > postnet_ssim_loss: 0.26285  (0.32495)
     | > loss: 3.79057  (3.40203)
     | > align_error: 0.99338  (0.99107)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.81066  (3.74315)
     | > current_lr: 0.00008 
     | > step_time: 3.72310  (3.61233)
     | > loader_time: 0.01880  (0.03357)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.55294 [0m(-0.31540)
     | > avg_decoder_loss:[91m 2.42004 [0m(+0.02477)
     | > avg_postnet_loss:[91m 2.41477 [0m(+0.05346)
     | > avg_stopnet_loss:[92m 1.49492 [0m(-0.00024)
     | > avg_decoder_coarse_loss:[91m 1.98490 [0m(+0.01415)
     | > avg_decoder_ddc_loss:[92m 0.00074 [0m(-0.00001)
     | > avg_ga_loss:[91m 0.00230 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47578 [0m(-0.00239)
     | > avg_postnet_diff_spec_loss:[91m 0.82337 [0m(+0.00071)
     | > avg_decoder_ssim_loss:[92m 0.30815 [0m(-0.00046)
     | > avg_postnet_ssim_loss:[92m 0.33325 [0m(-0.00028)
     | > avg_loss:[91m 3.69668 [0m(+0.02228)
     | > avg_align_error:[91m 0.99277 [0m(+0.00008)


[4m[1m > EPOCH: 66/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:53:55) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 275825[0m
     | > decoder_loss: 1.67369  (1.81436)
     | > postnet_loss: 1.34138  (1.48889)
     | > stopnet_loss: 1.57122  (1.68712)
     | > decoder_coarse_loss: 1.57250  (1.74975)
     | > decoder_ddc_loss: 0.00098  (0.00116)
     | > ga_loss: 0.00221  (0.00244)
     | > decoder_diff_spec_loss: 0.45418  (0.48926)
     | > postnet_diff_spec_loss: 0.76993  (0.80575)
     | > decoder_ssim_loss: 0.30980  (0.30534)
     | > postnet_ssim_loss: 0.32510  (0.32018)
     | > loss: 3.19416  (3.44301)
     | > align_error: 0.99233  (0.99114)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.34771  (4.12861)
     | > current_lr: 0.00008 
     | > step_time: 4.64080  (3.83147)
     | > loader_time: 0.07350  (0.03599)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 275850[0m
     | > decoder_loss: 1.84872  (1.84165)
     | > postnet_loss: 1.57500  (1.50394)
     | > stopnet_loss: 1.85787  (1.60373)
     | > decoder_coarse_loss: 1.76864  (1.77111)
     | > decoder_ddc_loss: 0.00084  (0.00114)
     | > ga_loss: 0.00189  (0.00237)
     | > decoder_diff_spec_loss: 0.50039  (0.49519)
     | > postnet_diff_spec_loss: 0.81651  (0.80738)
     | > decoder_ssim_loss: 0.26430  (0.31165)
     | > postnet_ssim_loss: 0.26937  (0.32619)
     | > loss: 3.62825  (3.38015)
     | > align_error: 0.99297  (0.99126)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.76931  (3.85348)
     | > current_lr: 0.00008 
     | > step_time: 4.95700  (3.71693)
     | > loader_time: 0.05020  (0.03284)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 275875[0m
     | > decoder_loss: 1.81303  (1.84220)
     | > postnet_loss: 1.42255  (1.50433)
     | > stopnet_loss: 1.77603  (1.60730)
     | > decoder_coarse_loss: 1.73455  (1.77449)
     | > decoder_ddc_loss: 0.00075  (0.00118)
     | > ga_loss: 0.00191  (0.00241)
     | > decoder_diff_spec_loss: 0.48875  (0.49600)
     | > postnet_diff_spec_loss: 0.79337  (0.80615)
     | > decoder_ssim_loss: 0.27419  (0.31031)
     | > postnet_ssim_loss: 0.28428  (0.32470)
     | > loss: 3.48846  (3.38420)
     | > align_error: 0.99408  (0.99102)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.55553  (3.80944)
     | > current_lr: 0.00008 
     | > step_time: 3.88780  (3.60896)
     | > loader_time: 0.04790  (0.03155)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.83346 [0m(+0.28052)
     | > avg_decoder_loss:[92m 2.38059 [0m(-0.03946)
     | > avg_postnet_loss:[92m 2.35936 [0m(-0.05541)
     | > avg_stopnet_loss:[91m 1.49539 [0m(+0.00047)
     | > avg_decoder_coarse_loss:[92m 1.95865 [0m(-0.02625)
     | > avg_decoder_ddc_loss:[91m 0.00077 [0m(+0.00003)
     | > avg_ga_loss:[92m 0.00229 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.47443 [0m(-0.00135)
     | > avg_postnet_diff_spec_loss:[92m 0.82324 [0m(-0.00012)
     | > avg_decoder_ssim_loss:[92m 0.30771 [0m(-0.00044)
     | > avg_postnet_ssim_loss:[92m 0.33291 [0m(-0.00034)
     | > avg_loss:[92m 3.66624 [0m(-0.03045)
     | > avg_align_error:[92m 0.99264 [0m(-0.00013)


[4m[1m > EPOCH: 67/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:01:03) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 275900[0m
     | > decoder_loss: 1.81410  (1.80914)
     | > postnet_loss: 1.51129  (1.50556)
     | > stopnet_loss: 2.29162  (1.88891)
     | > decoder_coarse_loss: 1.75060  (1.72607)
     | > decoder_ddc_loss: 0.00057  (0.00087)
     | > ga_loss: 0.00204  (0.00225)
     | > decoder_diff_spec_loss: 0.49884  (0.49408)
     | > postnet_diff_spec_loss: 0.82407  (0.81202)
     | > decoder_ssim_loss: 0.21402  (0.26771)
     | > postnet_ssim_loss: 0.22449  (0.27777)
     | > loss: 4.01133  (3.62346)
     | > align_error: 0.99436  (0.99232)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.08855  (3.71669)
     | > current_lr: 0.00008 
     | > step_time: 4.85020  (5.26740)
     | > loader_time: 0.11930  (0.08241)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 275925[0m
     | > decoder_loss: 2.01305  (1.82887)
     | > postnet_loss: 1.61926  (1.48414)
     | > stopnet_loss: 1.35160  (1.60555)
     | > decoder_coarse_loss: 1.91323  (1.76039)
     | > decoder_ddc_loss: 0.00175  (0.00116)
     | > ga_loss: 0.00314  (0.00239)
     | > decoder_diff_spec_loss: 0.54583  (0.49324)
     | > postnet_diff_spec_loss: 0.84731  (0.80598)
     | > decoder_ssim_loss: 0.37630  (0.31174)
     | > postnet_ssim_loss: 0.39323  (0.32695)
     | > loss: 3.29478  (3.37061)
     | > align_error: 0.98759  (0.99118)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.72945  (4.19356)
     | > current_lr: 0.00008 
     | > step_time: 2.87840  (3.70733)
     | > loader_time: 0.01980  (0.04229)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 275950[0m
     | > decoder_loss: 1.88349  (1.84642)
     | > postnet_loss: 1.37577  (1.49863)
     | > stopnet_loss: 2.03777  (1.61997)
     | > decoder_coarse_loss: 1.80657  (1.78039)
     | > decoder_ddc_loss: 0.00131  (0.00118)
     | > ga_loss: 0.00274  (0.00240)
     | > decoder_diff_spec_loss: 0.51014  (0.49782)
     | > postnet_diff_spec_loss: 0.78417  (0.80779)
     | > decoder_ssim_loss: 0.25129  (0.30921)
     | > postnet_ssim_loss: 0.26316  (0.32347)
     | > loss: 3.77046  (3.39818)
     | > align_error: 0.98914  (0.99104)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.09020  (3.85964)
     | > current_lr: 0.00008 
     | > step_time: 3.02890  (3.67755)
     | > loader_time: 0.10050  (0.03976)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 275975[0m
     | > decoder_loss: 1.64994  (1.83651)
     | > postnet_loss: 1.39319  (1.49472)
     | > stopnet_loss: 1.32285  (1.60313)
     | > decoder_coarse_loss: 1.63164  (1.77115)
     | > decoder_ddc_loss: 0.00142  (0.00119)
     | > ga_loss: 0.00273  (0.00241)
     | > decoder_diff_spec_loss: 0.47810  (0.49581)
     | > postnet_diff_spec_loss: 0.80431  (0.80630)
     | > decoder_ssim_loss: 0.36430  (0.31097)
     | > postnet_ssim_loss: 0.37799  (0.32516)
     | > loss: 3.01171  (3.37565)
     | > align_error: 0.98904  (0.99097)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.22405  (3.74614)
     | > current_lr: 0.00008 
     | > step_time: 2.61980  (3.60050)
     | > loader_time: 0.01720  (0.03625)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.05090 [0m(+0.21744)
     | > avg_decoder_loss:[92m 2.29037 [0m(-0.09022)
     | > avg_postnet_loss:[92m 2.35039 [0m(-0.00897)
     | > avg_stopnet_loss:[92m 1.49467 [0m(-0.00072)
     | > avg_decoder_coarse_loss:[92m 1.88553 [0m(-0.07312)
     | > avg_decoder_ddc_loss:[92m 0.00077 [0m(-0.00001)
     | > avg_ga_loss:[91m 0.00230 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47370 [0m(-0.00073)
     | > avg_postnet_diff_spec_loss:[92m 0.82275 [0m(-0.00049)
     | > avg_decoder_ssim_loss:[92m 0.30742 [0m(-0.00029)
     | > avg_postnet_ssim_loss:[91m 0.33298 [0m(+0.00006)
     | > avg_loss:[92m 3.62213 [0m(-0.04411)
     | > avg_align_error:[91m 0.99272 [0m(+0.00008)


[4m[1m > EPOCH: 68/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:08:07) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 276000[0m
     | > decoder_loss: 1.86479  (1.81861)
     | > postnet_loss: 1.52085  (1.48568)
     | > stopnet_loss: 1.74242  (1.69285)
     | > decoder_coarse_loss: 1.76815  (1.75700)
     | > decoder_ddc_loss: 0.00128  (0.00116)
     | > ga_loss: 0.00233  (0.00245)
     | > decoder_diff_spec_loss: 0.48871  (0.49191)
     | > postnet_diff_spec_loss: 0.79606  (0.80697)
     | > decoder_ssim_loss: 0.27309  (0.30429)
     | > postnet_ssim_loss: 0.28749  (0.31890)
     | > loss: 3.50420  (3.45124)
     | > align_error: 0.99104  (0.99096)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.63705  (4.21514)
     | > current_lr: 0.00008 
     | > step_time: 3.68910  (3.85399)
     | > loader_time: 0.02090  (0.02796)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 276025[0m
     | > decoder_loss: 1.84963  (1.83527)
     | > postnet_loss: 1.54881  (1.48884)
     | > stopnet_loss: 1.71096  (1.59868)
     | > decoder_coarse_loss: 1.78974  (1.76411)
     | > decoder_ddc_loss: 0.00115  (0.00114)
     | > ga_loss: 0.00256  (0.00238)
     | > decoder_diff_spec_loss: 0.51726  (0.49571)
     | > postnet_diff_spec_loss: 0.83377  (0.80641)
     | > decoder_ssim_loss: 0.28473  (0.31230)
     | > postnet_ssim_loss: 0.29803  (0.32695)
     | > loss: 3.50453  (3.36825)
     | > align_error: 0.98995  (0.99114)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.51556  (3.85175)
     | > current_lr: 0.00008 
     | > step_time: 3.22120  (3.75001)
     | > loader_time: 0.03270  (0.03416)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 276050[0m
     | > decoder_loss: 1.75335  (1.83693)
     | > postnet_loss: 1.43019  (1.49240)
     | > stopnet_loss: 1.78558  (1.60142)
     | > decoder_coarse_loss: 1.66622  (1.77031)
     | > decoder_ddc_loss: 0.00083  (0.00116)
     | > ga_loss: 0.00211  (0.00242)
     | > decoder_diff_spec_loss: 0.49291  (0.49575)
     | > postnet_diff_spec_loss: 0.80138  (0.80559)
     | > decoder_ssim_loss: 0.26639  (0.31032)
     | > postnet_ssim_loss: 0.27682  (0.32471)
     | > loss: 3.46817  (3.37279)
     | > align_error: 0.99249  (0.99096)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.55585  (4.03109)
     | > current_lr: 0.00008 
     | > step_time: 3.70910  (3.63969)
     | > loader_time: 0.03000  (0.03411)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.65785 [0m(-0.39305)
     | > avg_decoder_loss:[92m 2.27489 [0m(-0.01548)
     | > avg_postnet_loss:[92m 2.19072 [0m(-0.15966)
     | > avg_stopnet_loss:[92m 1.49397 [0m(-0.00070)
     | > avg_decoder_coarse_loss:[91m 1.89382 [0m(+0.00829)
     | > avg_decoder_ddc_loss:[92m 0.00075 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00230 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47634 [0m(+0.00264)
     | > avg_postnet_diff_spec_loss:[92m 0.81993 [0m(-0.00282)
     | > avg_decoder_ssim_loss:[92m 0.30714 [0m(-0.00028)
     | > avg_postnet_ssim_loss:[92m 0.33021 [0m(-0.00277)
     | > avg_loss:[92m 3.57893 [0m(-0.04320)
     | > avg_align_error:[91m 0.99286 [0m(+0.00014)


[4m[1m > EPOCH: 69/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:15:17) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 276075[0m
     | > decoder_loss: 1.83123  (1.78049)
     | > postnet_loss: 1.45364  (1.47958)
     | > stopnet_loss: 1.59577  (1.75388)
     | > decoder_coarse_loss: 1.75079  (1.72045)
     | > decoder_ddc_loss: 0.00079  (0.00097)
     | > ga_loss: 0.00194  (0.00231)
     | > decoder_diff_spec_loss: 0.49916  (0.49229)
     | > postnet_diff_spec_loss: 0.80806  (0.80725)
     | > decoder_ssim_loss: 0.28822  (0.28490)
     | > postnet_ssim_loss: 0.29746  (0.29421)
     | > loss: 3.33783  (3.48048)
     | > align_error: 0.99330  (0.99159)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.20652  (4.99741)
     | > current_lr: 0.00008 
     | > step_time: 5.90290  (5.65874)
     | > loader_time: 0.08790  (0.05248)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 276100[0m
     | > decoder_loss: 1.77375  (1.81775)
     | > postnet_loss: 1.41823  (1.46929)
     | > stopnet_loss: 1.69312  (1.60884)
     | > decoder_coarse_loss: 1.72726  (1.74289)
     | > decoder_ddc_loss: 0.00086  (0.00110)
     | > ga_loss: 0.00235  (0.00236)
     | > decoder_diff_spec_loss: 0.50192  (0.49086)
     | > postnet_diff_spec_loss: 0.80904  (0.80400)
     | > decoder_ssim_loss: 0.28185  (0.30918)
     | > postnet_ssim_loss: 0.29535  (0.32410)
     | > loss: 3.40691  (3.36045)
     | > align_error: 0.99266  (0.99133)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.64225  (3.99061)
     | > current_lr: 0.00008 
     | > step_time: 2.92350  (3.80403)
     | > loader_time: 0.02390  (0.03444)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 276125[0m
     | > decoder_loss: 1.74557  (1.84305)
     | > postnet_loss: 1.53353  (1.49025)
     | > stopnet_loss: 1.40853  (1.60810)
     | > decoder_coarse_loss: 1.72858  (1.76839)
     | > decoder_ddc_loss: 0.00136  (0.00114)
     | > ga_loss: 0.00303  (0.00239)
     | > decoder_diff_spec_loss: 0.46583  (0.49771)
     | > postnet_diff_spec_loss: 0.80961  (0.80772)
     | > decoder_ssim_loss: 0.33954  (0.31003)
     | > postnet_ssim_loss: 0.35546  (0.32420)
     | > loss: 3.16853  (3.38066)
     | > align_error: 0.98956  (0.99108)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.35490  (3.73099)
     | > current_lr: 0.00008 
     | > step_time: 2.19360  (3.72650)
     | > loader_time: 0.02000  (0.03428)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 276150[0m
     | > decoder_loss: 1.58360  (1.83531)
     | > postnet_loss: 1.50822  (1.48563)
     | > stopnet_loss: 2.71513  (1.60253)
     | > decoder_coarse_loss: 1.49466  (1.76263)
     | > decoder_ddc_loss: 0.00069  (0.00113)
     | > ga_loss: 0.00228  (0.00241)
     | > decoder_diff_spec_loss: 0.42862  (0.49585)
     | > postnet_diff_spec_loss: 0.80365  (0.80595)
     | > decoder_ssim_loss: 0.18973  (0.30995)
     | > postnet_ssim_loss: 0.20387  (0.32416)
     | > loss: 4.27978  (3.36972)
     | > align_error: 0.99278  (0.99101)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.38324  (3.76702)
     | > current_lr: 0.00008 
     | > step_time: 4.01570  (3.63097)
     | > loader_time: 0.02180  (0.03290)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.42132 [0m(-0.23653)
     | > avg_decoder_loss:[92m 2.24457 [0m(-0.03032)
     | > avg_postnet_loss:[92m 2.18988 [0m(-0.00084)
     | > avg_stopnet_loss:[92m 1.49345 [0m(-0.00052)
     | > avg_decoder_coarse_loss:[91m 1.95311 [0m(+0.05930)
     | > avg_decoder_ddc_loss:[92m 0.00074 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00230 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47383 [0m(-0.00251)
     | > avg_postnet_diff_spec_loss:[91m 0.82094 [0m(+0.00101)
     | > avg_decoder_ssim_loss:[92m 0.30708 [0m(-0.00006)
     | > avg_postnet_ssim_loss:[91m 0.33048 [0m(+0.00027)
     | > avg_loss:[91m 3.58510 [0m(+0.00618)
     | > avg_align_error:[92m 0.99283 [0m(-0.00003)


[4m[1m > EPOCH: 70/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:22:21) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 276175[0m
     | > decoder_loss: 1.98684  (1.80723)
     | > postnet_loss: 1.58896  (1.46715)
     | > stopnet_loss: 1.19995  (1.66914)
     | > decoder_coarse_loss: 1.91934  (1.74552)
     | > decoder_ddc_loss: 0.00121  (0.00109)
     | > ga_loss: 0.00246  (0.00246)
     | > decoder_diff_spec_loss: 0.51490  (0.48928)
     | > postnet_diff_spec_loss: 0.82876  (0.80704)
     | > decoder_ssim_loss: 0.37535  (0.30589)
     | > postnet_ssim_loss: 0.39088  (0.32050)
     | > loss: 3.11380  (3.41735)
     | > align_error: 0.99013  (0.99111)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.50219  (3.92582)
     | > current_lr: 0.00008 
     | > step_time: 3.47660  (3.91538)
     | > loader_time: 0.02040  (0.03673)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 276200[0m
     | > decoder_loss: 2.30009  (1.82843)
     | > postnet_loss: 1.80623  (1.47303)
     | > stopnet_loss: 2.12700  (1.57935)
     | > decoder_coarse_loss: 2.18932  (1.75502)
     | > decoder_ddc_loss: 0.00067  (0.00109)
     | > ga_loss: 0.00181  (0.00237)
     | > decoder_diff_spec_loss: 0.59396  (0.49366)
     | > postnet_diff_spec_loss: 0.87044  (0.80522)
     | > decoder_ssim_loss: 0.22872  (0.31239)
     | > postnet_ssim_loss: 0.23997  (0.32729)
     | > loss: 4.19340  (3.34022)
     | > align_error: 0.99349  (0.99126)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.47974  (3.89648)
     | > current_lr: 0.00008 
     | > step_time: 4.90170  (3.73533)
     | > loader_time: 0.02390  (0.03112)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 276225[0m
     | > decoder_loss: 1.81524  (1.83098)
     | > postnet_loss: 1.43728  (1.48168)
     | > stopnet_loss: 1.76418  (1.59799)
     | > decoder_coarse_loss: 1.77115  (1.76470)
     | > decoder_ddc_loss: 0.00066  (0.00110)
     | > ga_loss: 0.00196  (0.00242)
     | > decoder_diff_spec_loss: 0.50044  (0.49455)
     | > postnet_diff_spec_loss: 0.78541  (0.80528)
     | > decoder_ssim_loss: 0.27892  (0.31045)
     | > postnet_ssim_loss: 0.28873  (0.32511)
     | > loss: 3.49344  (3.36354)
     | > align_error: 0.99347  (0.99103)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.97763  (3.95228)
     | > current_lr: 0.00008 
     | > step_time: 4.19540  (3.60209)
     | > loader_time: 0.02110  (0.03361)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.98428 [0m(+0.56296)
     | > avg_decoder_loss:[92m 2.22921 [0m(-0.01536)
     | > avg_postnet_loss:[92m 2.16650 [0m(-0.02338)
     | > avg_stopnet_loss:[92m 1.49221 [0m(-0.00124)
     | > avg_decoder_coarse_loss:[92m 1.84379 [0m(-0.10932)
     | > avg_decoder_ddc_loss:[92m 0.00070 [0m(-0.00004)
     | > avg_ga_loss:[91m 0.00231 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47386 [0m(+0.00004)
     | > avg_postnet_diff_spec_loss:[92m 0.81999 [0m(-0.00095)
     | > avg_decoder_ssim_loss:[92m 0.30658 [0m(-0.00050)
     | > avg_postnet_ssim_loss:[91m 0.33077 [0m(+0.00029)
     | > avg_loss:[92m 3.54659 [0m(-0.03852)
     | > avg_align_error:[91m 0.99289 [0m(+0.00006)


[4m[1m > EPOCH: 71/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:29:25) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 276250[0m
     | > decoder_loss: 1.74297  (1.75383)
     | > postnet_loss: 1.47087  (1.49650)
     | > stopnet_loss: 1.64077  (1.80637)
     | > decoder_coarse_loss: 1.67145  (1.69674)
     | > decoder_ddc_loss: 0.00086  (0.00099)
     | > ga_loss: 0.00249  (0.00252)
     | > decoder_diff_spec_loss: 0.47342  (0.48171)
     | > postnet_diff_spec_loss: 0.79358  (0.80616)
     | > decoder_ssim_loss: 0.29874  (0.28243)
     | > postnet_ssim_loss: 0.30806  (0.29399)
     | > loss: 3.34321  (3.52206)
     | > align_error: 0.99175  (0.99082)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.96459  (4.75766)
     | > current_lr: 0.00008 
     | > step_time: 5.25340  (5.72686)
     | > loader_time: 0.08250  (0.08025)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 276275[0m
     | > decoder_loss: 1.69660  (1.81335)
     | > postnet_loss: 1.35078  (1.45327)
     | > stopnet_loss: 1.24231  (1.60989)
     | > decoder_coarse_loss: 1.64488  (1.73824)
     | > decoder_ddc_loss: 0.00132  (0.00103)
     | > ga_loss: 0.00251  (0.00237)
     | > decoder_diff_spec_loss: 0.46957  (0.48923)
     | > postnet_diff_spec_loss: 0.78538  (0.80336)
     | > decoder_ssim_loss: 0.36389  (0.30981)
     | > postnet_ssim_loss: 0.38184  (0.32477)
     | > loss: 2.92840  (3.35499)
     | > align_error: 0.98938  (0.99137)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.51540  (3.65685)
     | > current_lr: 0.00008 
     | > step_time: 3.80980  (3.80334)
     | > loader_time: 0.01760  (0.03652)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 276300[0m
     | > decoder_loss: 1.71281  (1.83408)
     | > postnet_loss: 1.36081  (1.47215)
     | > stopnet_loss: 1.96673  (1.60072)
     | > decoder_coarse_loss: 1.65815  (1.76142)
     | > decoder_ddc_loss: 0.00105  (0.00108)
     | > ga_loss: 0.00271  (0.00237)
     | > decoder_diff_spec_loss: 0.47434  (0.49689)
     | > postnet_diff_spec_loss: 0.79053  (0.80739)
     | > decoder_ssim_loss: 0.24680  (0.30878)
     | > postnet_ssim_loss: 0.25978  (0.32316)
     | > loss: 3.60637  (3.36383)
     | > align_error: 0.99106  (0.99113)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.11698  (3.42577)
     | > current_lr: 0.00008 
     | > step_time: 4.35930  (3.72793)
     | > loader_time: 0.04400  (0.03404)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 276325[0m
     | > decoder_loss: 2.00108  (1.82808)
     | > postnet_loss: 1.53646  (1.46919)
     | > stopnet_loss: 1.25211  (1.58074)
     | > decoder_coarse_loss: 1.93410  (1.75852)
     | > decoder_ddc_loss: 0.00111  (0.00112)
     | > ga_loss: 0.00199  (0.00240)
     | > decoder_diff_spec_loss: 0.54214  (0.49547)
     | > postnet_diff_spec_loss: 0.82962  (0.80548)
     | > decoder_ssim_loss: 0.35318  (0.31090)
     | > postnet_ssim_loss: 0.36446  (0.32525)
     | > loss: 3.15257  (3.34124)
     | > align_error: 0.99194  (0.99095)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.75355  (3.49336)
     | > current_lr: 0.00008 
     | > step_time: 4.50400  (3.62514)
     | > loader_time: 0.08470  (0.03449)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.65897 [0m(-0.32531)
     | > avg_decoder_loss:[92m 2.18753 [0m(-0.04168)
     | > avg_postnet_loss:[91m 2.29691 [0m(+0.13041)
     | > avg_stopnet_loss:[91m 1.49430 [0m(+0.00209)
     | > avg_decoder_coarse_loss:[91m 1.93579 [0m(+0.09200)
     | > avg_decoder_ddc_loss:[91m 0.00076 [0m(+0.00005)
     | > avg_ga_loss:[92m 0.00228 [0m(-0.00003)
     | > avg_decoder_diff_spec_loss:[92m 0.47344 [0m(-0.00042)
     | > avg_postnet_diff_spec_loss:[91m 0.82145 [0m(+0.00146)
     | > avg_decoder_ssim_loss:[92m 0.30578 [0m(-0.00081)
     | > avg_postnet_ssim_loss:[91m 0.33133 [0m(+0.00056)
     | > avg_loss:[91m 3.59393 [0m(+0.04734)
     | > avg_align_error:[92m 0.99268 [0m(-0.00021)


[4m[1m > EPOCH: 72/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:36:30) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 276350[0m
     | > decoder_loss: 1.89225  (1.78702)
     | > postnet_loss: 1.44736  (1.45395)
     | > stopnet_loss: 2.66448  (1.70887)
     | > decoder_coarse_loss: 1.79815  (1.73128)
     | > decoder_ddc_loss: 0.00109  (0.00107)
     | > ga_loss: 0.00318  (0.00246)
     | > decoder_diff_spec_loss: 0.48761  (0.48656)
     | > postnet_diff_spec_loss: 0.79500  (0.80465)
     | > decoder_ssim_loss: 0.20362  (0.30020)
     | > postnet_ssim_loss: 0.21238  (0.31482)
     | > loss: 4.38972  (3.44104)
     | > align_error: 0.98861  (0.99115)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.96421  (3.81694)
     | > current_lr: 0.00008 
     | > step_time: 3.45720  (3.84908)
     | > loader_time: 0.03920  (0.04699)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 276375[0m
     | > decoder_loss: 1.93679  (1.81099)
     | > postnet_loss: 1.45947  (1.45884)
     | > stopnet_loss: 1.24421  (1.56942)
     | > decoder_coarse_loss: 1.87776  (1.73963)
     | > decoder_ddc_loss: 0.00081  (0.00109)
     | > ga_loss: 0.00184  (0.00238)
     | > decoder_diff_spec_loss: 0.51405  (0.49109)
     | > postnet_diff_spec_loss: 0.79900  (0.80312)
     | > decoder_ssim_loss: 0.33841  (0.31396)
     | > postnet_ssim_loss: 0.35342  (0.32920)
     | > loss: 3.07335  (3.31830)
     | > align_error: 0.99279  (0.99119)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.15497  (3.80044)
     | > current_lr: 0.00008 
     | > step_time: 4.75740  (3.71641)
     | > loader_time: 0.02020  (0.03691)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 276400[0m
     | > decoder_loss: 1.70715  (1.82737)
     | > postnet_loss: 1.48916  (1.47413)
     | > stopnet_loss: 1.23795  (1.58745)
     | > decoder_coarse_loss: 1.66011  (1.75760)
     | > decoder_ddc_loss: 0.00149  (0.00112)
     | > ga_loss: 0.00265  (0.00242)
     | > decoder_diff_spec_loss: 0.44847  (0.49473)
     | > postnet_diff_spec_loss: 0.79231  (0.80520)
     | > decoder_ssim_loss: 0.36861  (0.31032)
     | > postnet_ssim_loss: 0.39310  (0.32532)
     | > loss: 2.96632  (3.34849)
     | > align_error: 0.98949  (0.99095)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.35271  (3.85559)
     | > current_lr: 0.00008 
     | > step_time: 2.76570  (3.64067)
     | > loader_time: 0.01410  (0.03440)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.77697 [0m(+0.11800)
     | > avg_decoder_loss:[91m 2.21497 [0m(+0.02744)
     | > avg_postnet_loss:[92m 2.24504 [0m(-0.05187)
     | > avg_stopnet_loss:[92m 1.49261 [0m(-0.00168)
     | > avg_decoder_coarse_loss:[92m 1.88873 [0m(-0.04706)
     | > avg_decoder_ddc_loss:[92m 0.00074 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00229 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47543 [0m(+0.00199)
     | > avg_postnet_diff_spec_loss:[92m 0.82124 [0m(-0.00021)
     | > avg_decoder_ssim_loss:[91m 0.30598 [0m(+0.00020)
     | > avg_postnet_ssim_loss:[91m 0.33228 [0m(+0.00095)
     | > avg_loss:[92m 3.57515 [0m(-0.01878)
     | > avg_align_error:[91m 0.99276 [0m(+0.00008)


[4m[1m > EPOCH: 73/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:43:43) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 276425[0m
     | > decoder_loss: 1.76093  (1.76093)
     | > postnet_loss: 1.50356  (1.50356)
     | > stopnet_loss: 1.93548  (1.93548)
     | > decoder_coarse_loss: 1.73960  (1.73960)
     | > decoder_ddc_loss: 0.00125  (0.00125)
     | > ga_loss: 0.00255  (0.00255)
     | > decoder_diff_spec_loss: 0.49467  (0.49467)
     | > postnet_diff_spec_loss: 0.81582  (0.81582)
     | > decoder_ssim_loss: 0.26628  (0.26628)
     | > postnet_ssim_loss: 0.27822  (0.27822)
     | > loss: 3.66332  (3.66332)
     | > align_error: 0.98955  (0.98955)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.95482  (8.95482)
     | > current_lr: 0.00008 
     | > step_time: 5.61560  (5.61560)
     | > loader_time: 0.12460  (0.12461)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 276450[0m
     | > decoder_loss: 1.89812  (1.80720)
     | > postnet_loss: 1.51088  (1.44770)
     | > stopnet_loss: 1.43200  (1.61763)
     | > decoder_coarse_loss: 1.76750  (1.72961)
     | > decoder_ddc_loss: 0.00126  (0.00107)
     | > ga_loss: 0.00279  (0.00234)
     | > decoder_diff_spec_loss: 0.51175  (0.48981)
     | > postnet_diff_spec_loss: 0.80720  (0.80309)
     | > decoder_ssim_loss: 0.33319  (0.30697)
     | > postnet_ssim_loss: 0.35230  (0.32194)
     | > loss: 3.24148  (3.35619)
     | > align_error: 0.98931  (0.99130)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.07489  (3.98608)
     | > current_lr: 0.00008 
     | > step_time: 3.19010  (3.71731)
     | > loader_time: 0.01590  (0.04422)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 276475[0m
     | > decoder_loss: 1.92401  (1.82971)
     | > postnet_loss: 1.58079  (1.46406)
     | > stopnet_loss: 1.28215  (1.58615)
     | > decoder_coarse_loss: 1.81174  (1.75757)
     | > decoder_ddc_loss: 0.00157  (0.00111)
     | > ga_loss: 0.00331  (0.00235)
     | > decoder_diff_spec_loss: 0.52730  (0.49688)
     | > postnet_diff_spec_loss: 0.81669  (0.80674)
     | > decoder_ssim_loss: 0.36152  (0.30947)
     | > postnet_ssim_loss: 0.37716  (0.32383)
     | > loss: 3.14890  (3.34526)
     | > align_error: 0.98825  (0.99107)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.47564  (3.62784)
     | > current_lr: 0.00008 
     | > step_time: 2.68200  (3.63730)
     | > loader_time: 0.02160  (0.03700)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 276500[0m
     | > decoder_loss: 1.84737  (1.81845)
     | > postnet_loss: 1.50541  (1.45651)
     | > stopnet_loss: 1.06491  (1.57573)
     | > decoder_coarse_loss: 1.81075  (1.75025)
     | > decoder_ddc_loss: 0.00204  (0.00112)
     | > ga_loss: 0.00323  (0.00239)
     | > decoder_diff_spec_loss: 0.52086  (0.49413)
     | > postnet_diff_spec_loss: 0.83558  (0.80430)
     | > decoder_ssim_loss: 0.41050  (0.30966)
     | > postnet_ssim_loss: 0.42968  (0.32407)
     | > loss: 2.92162  (3.32732)
     | > align_error: 0.98540  (0.99093)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.13788  (3.57241)
     | > current_lr: 0.00008 
     | > step_time: 2.37450  (3.51453)
     | > loader_time: 0.02350  (0.03423)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.50812 [0m(-0.26885)
     | > avg_decoder_loss:[91m 2.22660 [0m(+0.01163)
     | > avg_postnet_loss:[91m 2.36213 [0m(+0.11709)
     | > avg_stopnet_loss:[92m 1.49037 [0m(-0.00225)
     | > avg_decoder_coarse_loss:[91m 1.89577 [0m(+0.00704)
     | > avg_decoder_ddc_loss:[92m 0.00073 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00227 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.47633 [0m(+0.00091)
     | > avg_postnet_diff_spec_loss:[91m 0.82265 [0m(+0.00141)
     | > avg_decoder_ssim_loss:[92m 0.30579 [0m(-0.00019)
     | > avg_postnet_ssim_loss:[92m 0.33157 [0m(-0.00071)
     | > avg_loss:[91m 3.60711 [0m(+0.03196)
     | > avg_align_error:[92m 0.99272 [0m(-0.00004)


[4m[1m > EPOCH: 74/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:50:49) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 276525[0m
     | > decoder_loss: 1.82263  (1.76025)
     | > postnet_loss: 1.43020  (1.43171)
     | > stopnet_loss: 2.93459  (1.61930)
     | > decoder_coarse_loss: 1.74019  (1.70634)
     | > decoder_ddc_loss: 0.00059  (0.00108)
     | > ga_loss: 0.00219  (0.00238)
     | > decoder_diff_spec_loss: 0.51156  (0.48687)
     | > postnet_diff_spec_loss: 0.81234  (0.80562)
     | > decoder_ssim_loss: 0.17532  (0.30665)
     | > postnet_ssim_loss: 0.18474  (0.32233)
     | > loss: 4.61491  (3.33640)
     | > align_error: 0.99423  (0.99118)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.11900  (3.61429)
     | > current_lr: 0.00008 
     | > step_time: 4.52780  (3.98138)
     | > loader_time: 0.02560  (0.03556)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 276550[0m
     | > decoder_loss: 1.85464  (1.79385)
     | > postnet_loss: 1.44727  (1.44458)
     | > stopnet_loss: 1.53880  (1.56452)
     | > decoder_coarse_loss: 1.81158  (1.72587)
     | > decoder_ddc_loss: 0.00104  (0.00109)
     | > ga_loss: 0.00241  (0.00238)
     | > decoder_diff_spec_loss: 0.49265  (0.48977)
     | > postnet_diff_spec_loss: 0.80136  (0.80287)
     | > decoder_ssim_loss: 0.30462  (0.31248)
     | > postnet_ssim_loss: 0.31876  (0.32809)
     | > loss: 3.30881  (3.30105)
     | > align_error: 0.99143  (0.99106)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.77867  (3.98199)
     | > current_lr: 0.00008 
     | > step_time: 3.73090  (3.68629)
     | > loader_time: 0.01870  (0.03501)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 276575[0m
     | > decoder_loss: 1.92275  (1.81436)
     | > postnet_loss: 1.50898  (1.45836)
     | > stopnet_loss: 1.43665  (1.58288)
     | > decoder_coarse_loss: 1.86078  (1.74846)
     | > decoder_ddc_loss: 0.00123  (0.00110)
     | > ga_loss: 0.00278  (0.00240)
     | > decoder_diff_spec_loss: 0.49952  (0.49436)
     | > postnet_diff_spec_loss: 0.79721  (0.80484)
     | > decoder_ssim_loss: 0.32828  (0.30873)
     | > postnet_ssim_loss: 0.34034  (0.32380)
     | > loss: 3.26533  (3.33338)
     | > align_error: 0.99028  (0.99091)
     | > amp_scaler: 65536.00000  (33288.12698)
     | > grad_norm: 3.30240  (3.95851)
     | > current_lr: 0.00008 
     | > step_time: 2.39220  (3.65531)
     | > loader_time: 0.02460  (0.03398)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.54997 [0m(+0.04185)
     | > avg_decoder_loss:[92m 2.16025 [0m(-0.06635)
     | > avg_postnet_loss:[92m 2.19650 [0m(-0.16563)
     | > avg_stopnet_loss:[91m 1.49294 [0m(+0.00257)
     | > avg_decoder_coarse_loss:[92m 1.87671 [0m(-0.01906)
     | > avg_decoder_ddc_loss:[91m 0.00075 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00226 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47418 [0m(-0.00216)
     | > avg_postnet_diff_spec_loss:[92m 0.82081 [0m(-0.00184)
     | > avg_decoder_ssim_loss:[92m 0.30537 [0m(-0.00042)
     | > avg_postnet_ssim_loss:[92m 0.33013 [0m(-0.00144)
     | > avg_loss:[92m 3.54544 [0m(-0.06167)
     | > avg_align_error:[92m 0.99269 [0m(-0.00003)


[4m[1m > EPOCH: 75/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:57:55) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 276600[0m
     | > decoder_loss: 1.60582  (1.60582)
     | > postnet_loss: 1.33934  (1.33934)
     | > stopnet_loss: 0.96764  (0.96764)
     | > decoder_coarse_loss: 1.58826  (1.58826)
     | > decoder_ddc_loss: 0.00150  (0.00150)
     | > ga_loss: 0.00251  (0.00251)
     | > decoder_diff_spec_loss: 0.45946  (0.45946)
     | > postnet_diff_spec_loss: 0.78435  (0.78435)
     | > decoder_ssim_loss: 0.45135  (0.45135)
     | > postnet_ssim_loss: 0.47563  (0.47563)
     | > loss: 2.65659  (2.65659)
     | > align_error: 0.98940  (0.98940)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.51702  (3.51702)
     | > current_lr: 0.00008 
     | > step_time: 3.13160  (3.13163)
     | > loader_time: 10.35600  (10.35603)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 276625[0m
     | > decoder_loss: 1.71107  (1.79484)
     | > postnet_loss: 1.39369  (1.44064)
     | > stopnet_loss: 1.32110  (1.62384)
     | > decoder_coarse_loss: 1.62554  (1.73456)
     | > decoder_ddc_loss: 0.00129  (0.00101)
     | > ga_loss: 0.00230  (0.00233)
     | > decoder_diff_spec_loss: 0.46970  (0.48899)
     | > postnet_diff_spec_loss: 0.79561  (0.80271)
     | > decoder_ssim_loss: 0.34924  (0.30547)
     | > postnet_ssim_loss: 0.36200  (0.32082)
     | > loss: 3.00963  (3.35774)
     | > align_error: 0.98963  (0.99146)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.40836  (4.16966)
     | > current_lr: 0.00008 
     | > step_time: 3.69980  (3.80093)
     | > loader_time: 0.02310  (0.03530)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 276650[0m
     | > decoder_loss: 1.79716  (1.82107)
     | > postnet_loss: 1.36797  (1.45663)
     | > stopnet_loss: 1.51005  (1.59279)
     | > decoder_coarse_loss: 1.77719  (1.75614)
     | > decoder_ddc_loss: 0.00133  (0.00106)
     | > ga_loss: 0.00236  (0.00233)
     | > decoder_diff_spec_loss: 0.49314  (0.49642)
     | > postnet_diff_spec_loss: 0.79294  (0.80621)
     | > decoder_ssim_loss: 0.31952  (0.30804)
     | > postnet_ssim_loss: 0.33721  (0.32270)
     | > loss: 3.24348  (3.34653)
     | > align_error: 0.99008  (0.99116)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.14822  (3.81662)
     | > current_lr: 0.00008 
     | > step_time: 2.88520  (3.72930)
     | > loader_time: 0.11990  (0.03449)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 276675[0m
     | > decoder_loss: 1.74300  (1.80989)
     | > postnet_loss: 1.35314  (1.44966)
     | > stopnet_loss: 1.51995  (1.58810)
     | > decoder_coarse_loss: 1.70056  (1.74619)
     | > decoder_ddc_loss: 0.00079  (0.00109)
     | > ga_loss: 0.00205  (0.00238)
     | > decoder_diff_spec_loss: 0.51092  (0.49354)
     | > postnet_diff_spec_loss: 0.79692  (0.80357)
     | > decoder_ssim_loss: 0.30277  (0.30792)
     | > postnet_ssim_loss: 0.31037  (0.32252)
     | > loss: 3.20981  (3.33361)
     | > align_error: 0.99254  (0.99100)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.44317  (3.71076)
     | > current_lr: 0.00008 
     | > step_time: 4.12900  (3.58097)
     | > loader_time: 0.02830  (0.03444)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.98067 [0m(+0.43070)
     | > avg_decoder_loss:[92m 2.13294 [0m(-0.02731)
     | > avg_postnet_loss:[92m 2.11544 [0m(-0.08106)
     | > avg_stopnet_loss:[92m 1.48943 [0m(-0.00351)
     | > avg_decoder_coarse_loss:[91m 1.88317 [0m(+0.00646)
     | > avg_decoder_ddc_loss:[92m 0.00071 [0m(-0.00004)
     | > avg_ga_loss:[91m 0.00228 [0m(+0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.47419 [0m(+0.00001)
     | > avg_postnet_diff_spec_loss:[92m 0.81964 [0m(-0.00117)
     | > avg_decoder_ssim_loss:[92m 0.30522 [0m(-0.00016)
     | > avg_postnet_ssim_loss:[92m 0.32955 [0m(-0.00058)
     | > avg_loss:[92m 3.51604 [0m(-0.02939)
     | > avg_align_error:[91m 0.99281 [0m(+0.00012)


[4m[1m > EPOCH: 76/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:05:03) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 276700[0m
     | > decoder_loss: 1.81947  (1.76005)
     | > postnet_loss: 1.43465  (1.43517)
     | > stopnet_loss: 1.43952  (1.51105)
     | > decoder_coarse_loss: 1.73633  (1.69815)
     | > decoder_ddc_loss: 0.00102  (0.00109)
     | > ga_loss: 0.00244  (0.00240)
     | > decoder_diff_spec_loss: 0.49107  (0.48384)
     | > postnet_diff_spec_loss: 0.80617  (0.80475)
     | > decoder_ssim_loss: 0.32790  (0.31752)
     | > postnet_ssim_loss: 0.34593  (0.33404)
     | > loss: 3.19237  (3.23171)
     | > align_error: 0.99113  (0.99095)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.43728  (3.56373)
     | > current_lr: 0.00008 
     | > step_time: 2.92570  (3.91726)
     | > loader_time: 0.02620  (0.03312)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 276725[0m
     | > decoder_loss: 1.69276  (1.78972)
     | > postnet_loss: 1.36010  (1.44062)
     | > stopnet_loss: 1.59572  (1.56125)
     | > decoder_coarse_loss: 1.63831  (1.71750)
     | > decoder_ddc_loss: 0.00098  (0.00106)
     | > ga_loss: 0.00265  (0.00238)
     | > decoder_diff_spec_loss: 0.47633  (0.48848)
     | > postnet_diff_spec_loss: 0.79310  (0.80248)
     | > decoder_ssim_loss: 0.29479  (0.31237)
     | > postnet_ssim_loss: 0.31161  (0.32800)
     | > loss: 3.25095  (3.29319)
     | > align_error: 0.99081  (0.99105)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.01010  (4.07552)
     | > current_lr: 0.00008 
     | > step_time: 2.67590  (3.68237)
     | > loader_time: 0.02120  (0.03319)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 276750[0m
     | > decoder_loss: 1.68372  (1.80657)
     | > postnet_loss: 1.35069  (1.44755)
     | > stopnet_loss: 1.40716  (1.58191)
     | > decoder_coarse_loss: 1.64131  (1.74121)
     | > decoder_ddc_loss: 0.00103  (0.00108)
     | > ga_loss: 0.00232  (0.00239)
     | > decoder_diff_spec_loss: 0.45285  (0.49332)
     | > postnet_diff_spec_loss: 0.77116  (0.80446)
     | > decoder_ssim_loss: 0.32135  (0.30791)
     | > postnet_ssim_loss: 0.33911  (0.32309)
     | > loss: 3.05906  (3.32516)
     | > align_error: 0.99175  (0.99092)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.57055  (4.00198)
     | > current_lr: 0.00008 
     | > step_time: 3.97160  (3.63989)
     | > loader_time: 0.03510  (0.03610)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 276775[0m
     | > decoder_loss: 1.95001  (1.80665)
     | > postnet_loss: 1.44321  (1.44501)
     | > stopnet_loss: 0.80644  (1.58285)
     | > decoder_coarse_loss: 1.81947  (1.74232)
     | > decoder_ddc_loss: 0.00418  (0.00109)
     | > ga_loss: 0.00347  (0.00237)
     | > decoder_diff_spec_loss: 0.49764  (0.49299)
     | > postnet_diff_spec_loss: 0.78004  (0.80368)
     | > decoder_ssim_loss: 0.50463  (0.30854)
     | > postnet_ssim_loss: 0.54834  (0.32370)
     | > loss: 2.71065  (3.32571)
     | > align_error: 0.97867  (0.99091)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 11.29906  (3.86294)
     | > current_lr: 0.00008 
     | > step_time: 1.01340  (3.52214)
     | > loader_time: 0.00720  (0.03438)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.76806 [0m(-0.21261)
     | > avg_decoder_loss:[91m 2.18723 [0m(+0.05429)
     | > avg_postnet_loss:[91m 2.21604 [0m(+0.10060)
     | > avg_stopnet_loss:[91m 1.49303 [0m(+0.00360)
     | > avg_decoder_coarse_loss:[91m 1.90974 [0m(+0.02658)
     | > avg_decoder_ddc_loss:[91m 0.00072 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00227 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47391 [0m(-0.00028)
     | > avg_postnet_diff_spec_loss:[91m 0.82130 [0m(+0.00166)
     | > avg_decoder_ssim_loss:[91m 0.30536 [0m(+0.00014)
     | > avg_postnet_ssim_loss:[91m 0.33131 [0m(+0.00176)
     | > avg_loss:[91m 3.56578 [0m(+0.04973)
     | > avg_align_error:[92m 0.99270 [0m(-0.00011)


[4m[1m > EPOCH: 77/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:12:07) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 276800[0m
     | > decoder_loss: 1.78374  (1.79593)
     | > postnet_loss: 1.38696  (1.43312)
     | > stopnet_loss: 1.12282  (1.64611)
     | > decoder_coarse_loss: 1.71871  (1.73151)
     | > decoder_ddc_loss: 0.00104  (0.00105)
     | > ga_loss: 0.00227  (0.00231)
     | > decoder_diff_spec_loss: 0.48181  (0.48964)
     | > postnet_diff_spec_loss: 0.79598  (0.80250)
     | > decoder_ssim_loss: 0.38398  (0.30315)
     | > postnet_ssim_loss: 0.39836  (0.31844)
     | > loss: 2.87182  (3.37648)
     | > align_error: 0.99097  (0.99134)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.67038  (4.09327)
     | > current_lr: 0.00008 
     | > step_time: 3.45860  (3.83338)
     | > loader_time: 0.02130  (0.03747)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 276825[0m
     | > decoder_loss: 1.62012  (1.81408)
     | > postnet_loss: 1.35863  (1.45290)
     | > stopnet_loss: 1.66958  (1.59724)
     | > decoder_coarse_loss: 1.54131  (1.74777)
     | > decoder_ddc_loss: 0.00080  (0.00109)
     | > ga_loss: 0.00180  (0.00232)
     | > decoder_diff_spec_loss: 0.45047  (0.49565)
     | > postnet_diff_spec_loss: 0.77801  (0.80615)
     | > decoder_ssim_loss: 0.27587  (0.30709)
     | > postnet_ssim_loss: 0.29484  (0.32199)
     | > loss: 3.25858  (3.34551)
     | > align_error: 0.99267  (0.99100)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.00325  (3.78834)
     | > current_lr: 0.00008 
     | > step_time: 4.40890  (3.74493)
     | > loader_time: 0.02250  (0.03789)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 276850[0m
     | > decoder_loss: 1.88201  (1.80565)
     | > postnet_loss: 1.53513  (1.44523)
     | > stopnet_loss: 1.48394  (1.58664)
     | > decoder_coarse_loss: 1.83233  (1.74333)
     | > decoder_ddc_loss: 0.00094  (0.00110)
     | > ga_loss: 0.00205  (0.00238)
     | > decoder_diff_spec_loss: 0.50301  (0.49276)
     | > postnet_diff_spec_loss: 0.82572  (0.80322)
     | > decoder_ssim_loss: 0.31583  (0.30741)
     | > postnet_ssim_loss: 0.32961  (0.32235)
     | > loss: 3.30035  (3.32879)
     | > align_error: 0.99213  (0.99085)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.48502  (3.72343)
     | > current_lr: 0.00008 
     | > step_time: 3.57880  (3.59713)
     | > loader_time: 0.02010  (0.03716)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.08386 [0m(+0.31580)
     | > avg_decoder_loss:[92m 2.13330 [0m(-0.05393)
     | > avg_postnet_loss:[92m 2.15207 [0m(-0.06397)
     | > avg_stopnet_loss:[92m 1.49081 [0m(-0.00222)
     | > avg_decoder_coarse_loss:[92m 1.87555 [0m(-0.03420)
     | > avg_decoder_ddc_loss:[91m 0.00075 [0m(+0.00003)
     | > avg_ga_loss:[92m 0.00227 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47227 [0m(-0.00164)
     | > avg_postnet_diff_spec_loss:[92m 0.81919 [0m(-0.00211)
     | > avg_decoder_ssim_loss:[92m 0.30474 [0m(-0.00062)
     | > avg_postnet_ssim_loss:[92m 0.33031 [0m(-0.00100)
     | > avg_loss:[92m 3.52419 [0m(-0.04159)
     | > avg_align_error:[92m 0.99267 [0m(-0.00003)


[4m[1m > EPOCH: 78/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:19:17) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 276875[0m
     | > decoder_loss: 1.53191  (1.73681)
     | > postnet_loss: 1.27915  (1.41842)
     | > stopnet_loss: 1.26879  (1.52591)
     | > decoder_coarse_loss: 1.53295  (1.69807)
     | > decoder_ddc_loss: 0.00076  (0.00109)
     | > ga_loss: 0.00193  (0.00238)
     | > decoder_diff_spec_loss: 0.43316  (0.48087)
     | > postnet_diff_spec_loss: 0.77762  (0.80326)
     | > decoder_ssim_loss: 0.34330  (0.31597)
     | > postnet_ssim_loss: 0.36435  (0.33187)
     | > loss: 2.84426  (3.23438)
     | > align_error: 0.99379  (0.99090)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.93773  (3.61744)
     | > current_lr: 0.00008 
     | > step_time: 4.87470  (4.14313)
     | > loader_time: 0.02160  (0.03591)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 276900[0m
     | > decoder_loss: 1.82286  (1.78657)
     | > postnet_loss: 1.49923  (1.42803)
     | > stopnet_loss: 1.24455  (1.56467)
     | > decoder_coarse_loss: 1.72919  (1.71919)
     | > decoder_ddc_loss: 0.00076  (0.00110)
     | > ga_loss: 0.00195  (0.00235)
     | > decoder_diff_spec_loss: 0.50153  (0.48793)
     | > postnet_diff_spec_loss: 0.82266  (0.80169)
     | > decoder_ssim_loss: 0.35184  (0.31242)
     | > postnet_ssim_loss: 0.36101  (0.32787)
     | > loss: 3.02655  (3.29263)
     | > align_error: 0.99359  (0.99093)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.34562  (4.13906)
     | > current_lr: 0.00008 
     | > step_time: 4.68200  (3.69013)
     | > loader_time: 0.02260  (0.03923)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 276925[0m
     | > decoder_loss: 1.73985  (1.80702)
     | > postnet_loss: 1.40853  (1.44028)
     | > stopnet_loss: 1.50624  (1.59044)
     | > decoder_coarse_loss: 1.68557  (1.74030)
     | > decoder_ddc_loss: 0.00153  (0.00112)
     | > ga_loss: 0.00283  (0.00237)
     | > decoder_diff_spec_loss: 0.47673  (0.49332)
     | > postnet_diff_spec_loss: 0.78534  (0.80423)
     | > decoder_ssim_loss: 0.32599  (0.30743)
     | > postnet_ssim_loss: 0.34571  (0.32237)
     | > loss: 3.21269  (3.33133)
     | > align_error: 0.98832  (0.99073)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.33987  (4.03242)
     | > current_lr: 0.00008 
     | > step_time: 2.59250  (3.61359)
     | > loader_time: 0.03470  (0.03669)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 276950[0m
     | > decoder_loss: 1.70823  (1.80287)
     | > postnet_loss: 1.38293  (1.43757)
     | > stopnet_loss: 1.28927  (1.59110)
     | > decoder_coarse_loss: 1.64556  (1.73840)
     | > decoder_ddc_loss: 0.00092  (0.00108)
     | > ga_loss: 0.00211  (0.00235)
     | > decoder_diff_spec_loss: 0.46789  (0.49238)
     | > postnet_diff_spec_loss: 0.78471  (0.80313)
     | > decoder_ssim_loss: 0.34230  (0.30597)
     | > postnet_ssim_loss: 0.35720  (0.32063)
     | > loss: 2.97223  (3.32833)
     | > align_error: 0.99202  (0.99090)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.86540  (3.78767)
     | > current_lr: 0.00008 
     | > step_time: 2.53910  (3.55034)
     | > loader_time: 0.01980  (0.03383)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.87826 [0m(-0.20560)
     | > avg_decoder_loss:[92m 2.08068 [0m(-0.05262)
     | > avg_postnet_loss:[92m 2.13954 [0m(-0.01254)
     | > avg_stopnet_loss:[91m 1.49099 [0m(+0.00018)
     | > avg_decoder_coarse_loss:[91m 1.88494 [0m(+0.00939)
     | > avg_decoder_ddc_loss:[91m 0.00076 [0m(+0.00001)
     | > avg_ga_loss:[91m 0.00227 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47116 [0m(-0.00111)
     | > avg_postnet_diff_spec_loss:[92m 0.81909 [0m(-0.00010)
     | > avg_decoder_ssim_loss:[92m 0.30457 [0m(-0.00017)
     | > avg_postnet_ssim_loss:[92m 0.33027 [0m(-0.00004)
     | > avg_loss:[92m 3.51010 [0m(-0.01409)
     | > avg_align_error:[91m 0.99274 [0m(+0.00008)


[4m[1m > EPOCH: 79/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:26:26) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 276975[0m
     | > decoder_loss: 1.82709  (1.78245)
     | > postnet_loss: 1.48030  (1.42694)
     | > stopnet_loss: 1.60766  (1.65935)
     | > decoder_coarse_loss: 1.75096  (1.72557)
     | > decoder_ddc_loss: 0.00098  (0.00101)
     | > ga_loss: 0.00232  (0.00232)
     | > decoder_diff_spec_loss: 0.49581  (0.48697)
     | > postnet_diff_spec_loss: 0.80357  (0.80206)
     | > decoder_ssim_loss: 0.29364  (0.29897)
     | > postnet_ssim_loss: 0.30256  (0.31451)
     | > loss: 3.35799  (3.38057)
     | > align_error: 0.99162  (0.99138)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.36798  (4.21051)
     | > current_lr: 0.00008 
     | > step_time: 3.82860  (3.88355)
     | > loader_time: 0.02490  (0.03812)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 277000[0m
     | > decoder_loss: 1.91101  (1.81087)
     | > postnet_loss: 1.55827  (1.44565)
     | > stopnet_loss: 2.10294  (1.59211)
     | > decoder_coarse_loss: 1.86317  (1.74712)
     | > decoder_ddc_loss: 0.00067  (0.00105)
     | > ga_loss: 0.00208  (0.00234)
     | > decoder_diff_spec_loss: 0.52152  (0.49537)
     | > postnet_diff_spec_loss: 0.81927  (0.80606)
     | > decoder_ssim_loss: 0.23269  (0.30737)
     | > postnet_ssim_loss: 0.24279  (0.32207)
     | > loss: 3.90069  (3.33768)
     | > align_error: 0.99320  (0.99104)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.09478  (3.91274)
     | > current_lr: 0.00008 
     | > step_time: 4.00060  (3.73721)
     | > loader_time: 0.05670  (0.03240)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 277025[0m
     | > decoder_loss: 1.82443  (1.79829)
     | > postnet_loss: 1.44321  (1.43580)
     | > stopnet_loss: 1.51054  (1.58358)
     | > decoder_coarse_loss: 1.76322  (1.73394)
     | > decoder_ddc_loss: 0.00128  (0.00108)
     | > ga_loss: 0.00246  (0.00238)
     | > decoder_diff_spec_loss: 0.49862  (0.49126)
     | > postnet_diff_spec_loss: 0.80954  (0.80225)
     | > decoder_ssim_loss: 0.31649  (0.30682)
     | > postnet_ssim_loss: 0.32720  (0.32180)
     | > loss: 3.26885  (3.31830)
     | > align_error: 0.99049  (0.99085)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.79829  (3.95237)
     | > current_lr: 0.00008 
     | > step_time: 2.49830  (3.60083)
     | > loader_time: 0.03110  (0.03619)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.54157 [0m(-0.33669)
     | > avg_decoder_loss:[91m 2.10226 [0m(+0.02157)
     | > avg_postnet_loss:[91m 2.20046 [0m(+0.06092)
     | > avg_stopnet_loss:[91m 1.49228 [0m(+0.00129)
     | > avg_decoder_coarse_loss:[92m 1.79894 [0m(-0.08600)
     | > avg_decoder_ddc_loss:[92m 0.00073 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00227 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47337 [0m(+0.00221)
     | > avg_postnet_diff_spec_loss:[91m 0.81938 [0m(+0.00030)
     | > avg_decoder_ssim_loss:[92m 0.30451 [0m(-0.00006)
     | > avg_postnet_ssim_loss:[91m 0.33049 [0m(+0.00022)
     | > avg_loss:[91m 3.51118 [0m(+0.00108)
     | > avg_align_error:[91m 0.99275 [0m(+0.00000)


[4m[1m > EPOCH: 80/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:33:37) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 277050[0m
     | > decoder_loss: 1.90937  (1.75661)
     | > postnet_loss: 1.48762  (1.42591)
     | > stopnet_loss: 1.16513  (1.56674)
     | > decoder_coarse_loss: 1.83555  (1.70381)
     | > decoder_ddc_loss: 0.00161  (0.00109)
     | > ga_loss: 0.00311  (0.00243)
     | > decoder_diff_spec_loss: 0.51051  (0.48810)
     | > postnet_diff_spec_loss: 0.81105  (0.80560)
     | > decoder_ssim_loss: 0.40501  (0.31289)
     | > postnet_ssim_loss: 0.42160  (0.32850)
     | > loss: 3.02626  (3.28452)
     | > align_error: 0.98832  (0.99064)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.77071  (3.36212)
     | > current_lr: 0.00008 
     | > step_time: 2.91690  (3.85943)
     | > loader_time: 0.01690  (0.03362)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 277075[0m
     | > decoder_loss: 1.63804  (1.78147)
     | > postnet_loss: 1.38612  (1.42352)
     | > stopnet_loss: 1.15144  (1.57305)
     | > decoder_coarse_loss: 1.58550  (1.71310)
     | > decoder_ddc_loss: 0.00190  (0.00108)
     | > ga_loss: 0.00300  (0.00237)
     | > decoder_diff_spec_loss: 0.46042  (0.48761)
     | > postnet_diff_spec_loss: 0.79428  (0.80070)
     | > decoder_ssim_loss: 0.40814  (0.31074)
     | > postnet_ssim_loss: 0.42428  (0.32652)
     | > loss: 2.84114  (3.29607)
     | > align_error: 0.98613  (0.99091)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.09598  (3.85466)
     | > current_lr: 0.00008 
     | > step_time: 2.12440  (3.55025)
     | > loader_time: 0.02160  (0.03146)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 277100[0m
     | > decoder_loss: 1.69149  (1.80531)
     | > postnet_loss: 1.43002  (1.43700)
     | > stopnet_loss: 1.31542  (1.58972)
     | > decoder_coarse_loss: 1.67703  (1.73688)
     | > decoder_ddc_loss: 0.00173  (0.00110)
     | > ga_loss: 0.00303  (0.00236)
     | > decoder_diff_spec_loss: 0.45759  (0.49392)
     | > postnet_diff_spec_loss: 0.78785  (0.80404)
     | > decoder_ssim_loss: 0.34332  (0.30666)
     | > postnet_ssim_loss: 0.36376  (0.32166)
     | > loss: 3.01877  (3.32818)
     | > align_error: 0.98654  (0.99079)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.39443  (3.88144)
     | > current_lr: 0.00008 
     | > step_time: 2.89590  (3.58261)
     | > loader_time: 0.01550  (0.03215)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 277125[0m
     | > decoder_loss: 1.77776  (1.80120)
     | > postnet_loss: 1.39089  (1.43316)
     | > stopnet_loss: 2.17515  (1.59587)
     | > decoder_coarse_loss: 1.73666  (1.73406)
     | > decoder_ddc_loss: 0.00058  (0.00109)
     | > ga_loss: 0.00183  (0.00234)
     | > decoder_diff_spec_loss: 0.49528  (0.49259)
     | > postnet_diff_spec_loss: 0.79121  (0.80293)
     | > decoder_ssim_loss: 0.22797  (0.30507)
     | > postnet_ssim_loss: 0.23617  (0.31992)
     | > loss: 3.84841  (3.33008)
     | > align_error: 0.99330  (0.99087)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.64324  (3.70663)
     | > current_lr: 0.00007 
     | > step_time: 2.99270  (3.52342)
     | > loader_time: 0.02660  (0.03259)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.07937 [0m(+0.53780)
     | > avg_decoder_loss:[92m 2.07897 [0m(-0.02329)
     | > avg_postnet_loss:[92m 2.13757 [0m(-0.06288)
     | > avg_stopnet_loss:[92m 1.49143 [0m(-0.00085)
     | > avg_decoder_coarse_loss:[91m 1.81846 [0m(+0.01953)
     | > avg_decoder_ddc_loss:[91m 0.00075 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00227 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47370 [0m(+0.00032)
     | > avg_postnet_diff_spec_loss:[92m 0.81910 [0m(-0.00029)
     | > avg_decoder_ssim_loss:[92m 0.30409 [0m(-0.00042)
     | > avg_postnet_ssim_loss:[92m 0.32908 [0m(-0.00141)
     | > avg_loss:[92m 3.49323 [0m(-0.01796)
     | > avg_align_error:[92m 0.99268 [0m(-0.00007)


[4m[1m > EPOCH: 81/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:40:40) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 277150[0m
     | > decoder_loss: 1.80396  (1.78399)
     | > postnet_loss: 1.36935  (1.42068)
     | > stopnet_loss: 1.14866  (1.65690)
     | > decoder_coarse_loss: 1.70909  (1.71707)
     | > decoder_ddc_loss: 0.00096  (0.00100)
     | > ga_loss: 0.00181  (0.00231)
     | > decoder_diff_spec_loss: 0.50552  (0.48799)
     | > postnet_diff_spec_loss: 0.79438  (0.80169)
     | > decoder_ssim_loss: 0.37707  (0.29900)
     | > postnet_ssim_loss: 0.39631  (0.31459)
     | > loss: 2.89687  (3.37495)
     | > align_error: 0.99262  (0.99137)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.82650  (4.27413)
     | > current_lr: 0.00007 
     | > step_time: 3.69310  (3.81721)
     | > loader_time: 0.07040  (0.03715)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 277175[0m
     | > decoder_loss: 1.79085  (1.81055)
     | > postnet_loss: 1.45374  (1.43974)
     | > stopnet_loss: 1.15577  (1.57565)
     | > decoder_coarse_loss: 1.70285  (1.73964)
     | > decoder_ddc_loss: 0.00207  (0.00105)
     | > ga_loss: 0.00317  (0.00233)
     | > decoder_diff_spec_loss: 0.48918  (0.49408)
     | > postnet_diff_spec_loss: 0.80008  (0.80555)
     | > decoder_ssim_loss: 0.39090  (0.30857)
     | > postnet_ssim_loss: 0.40394  (0.32343)
     | > loss: 2.93001  (3.31797)
     | > align_error: 0.98542  (0.99098)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.28235  (3.83577)
     | > current_lr: 0.00007 
     | > step_time: 1.72510  (3.69258)
     | > loader_time: 0.01670  (0.03375)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 277200[0m
     | > decoder_loss: 1.81113  (1.79524)
     | > postnet_loss: 1.46312  (1.43095)
     | > stopnet_loss: 1.13306  (1.58003)
     | > decoder_coarse_loss: 1.73207  (1.72770)
     | > decoder_ddc_loss: 0.00126  (0.00105)
     | > ga_loss: 0.00259  (0.00238)
     | > decoder_diff_spec_loss: 0.49664  (0.49098)
     | > postnet_diff_spec_loss: 0.80505  (0.80194)
     | > decoder_ssim_loss: 0.38626  (0.30620)
     | > postnet_ssim_loss: 0.39864  (0.32139)
     | > loss: 2.91955  (3.31078)
     | > align_error: 0.98975  (0.99086)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.55557  (3.74944)
     | > current_lr: 0.00007 
     | > step_time: 2.60560  (3.58132)
     | > loader_time: 0.01720  (0.03340)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.82084 [0m(-0.25853)
     | > avg_decoder_loss:[92m 2.06487 [0m(-0.01409)
     | > avg_postnet_loss:[92m 2.07968 [0m(-0.05789)
     | > avg_stopnet_loss:[92m 1.48768 [0m(-0.00376)
     | > avg_decoder_coarse_loss:[92m 1.78280 [0m(-0.03566)
     | > avg_decoder_ddc_loss:[92m 0.00072 [0m(-0.00003)
     | > avg_ga_loss:[91m 0.00227 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47232 [0m(-0.00138)
     | > avg_postnet_diff_spec_loss:[92m 0.81806 [0m(-0.00104)
     | > avg_decoder_ssim_loss:[92m 0.30395 [0m(-0.00014)
     | > avg_postnet_ssim_loss:[91m 0.32929 [0m(+0.00021)
     | > avg_loss:[92m 3.46196 [0m(-0.03126)
     | > avg_align_error:[91m 0.99278 [0m(+0.00010)


[4m[1m > EPOCH: 82/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:47:47) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 277225[0m
     | > decoder_loss: 1.69939  (1.73574)
     | > postnet_loss: 1.30088  (1.41348)
     | > stopnet_loss: 1.19555  (1.59525)
     | > decoder_coarse_loss: 1.65294  (1.68788)
     | > decoder_ddc_loss: 0.00190  (0.00107)
     | > ga_loss: 0.00325  (0.00234)
     | > decoder_diff_spec_loss: 0.46334  (0.48501)
     | > postnet_diff_spec_loss: 0.77231  (0.80468)
     | > decoder_ssim_loss: 0.36785  (0.30251)
     | > postnet_ssim_loss: 0.38926  (0.31812)
     | > loss: 2.87377  (3.29409)
     | > align_error: 0.98539  (0.99069)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.53050  (3.30677)
     | > current_lr: 0.00007 
     | > step_time: 2.52710  (4.13060)
     | > loader_time: 0.01690  (0.04776)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 277250[0m
     | > decoder_loss: 1.62898  (1.77985)
     | > postnet_loss: 1.34304  (1.41819)
     | > stopnet_loss: 1.42632  (1.57990)
     | > decoder_coarse_loss: 1.61116  (1.70963)
     | > decoder_ddc_loss: 0.00178  (0.00107)
     | > ga_loss: 0.00266  (0.00234)
     | > decoder_diff_spec_loss: 0.43649  (0.48809)
     | > postnet_diff_spec_loss: 0.76014  (0.80053)
     | > decoder_ssim_loss: 0.33054  (0.30772)
     | > postnet_ssim_loss: 0.35097  (0.32330)
     | > loss: 3.05539  (3.29870)
     | > align_error: 0.98658  (0.99094)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.17475  (3.96186)
     | > current_lr: 0.00007 
     | > step_time: 2.78870  (3.69830)
     | > loader_time: 0.01760  (0.03910)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 277275[0m
     | > decoder_loss: 1.87634  (1.80130)
     | > postnet_loss: 1.57589  (1.43663)
     | > stopnet_loss: 1.71902  (1.58330)
     | > decoder_coarse_loss: 1.82642  (1.73464)
     | > decoder_ddc_loss: 0.00089  (0.00108)
     | > ga_loss: 0.00216  (0.00235)
     | > decoder_diff_spec_loss: 0.51170  (0.49320)
     | > postnet_diff_spec_loss: 0.83502  (0.80416)
     | > decoder_ssim_loss: 0.27867  (0.30576)
     | > postnet_ssim_loss: 0.29017  (0.32080)
     | > loss: 3.52862  (3.31946)
     | > align_error: 0.99216  (0.99085)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.45679  (4.08255)
     | > current_lr: 0.00007 
     | > step_time: 4.42160  (3.67920)
     | > loader_time: 0.01880  (0.03321)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 277300[0m
     | > decoder_loss: 1.81079  (1.79577)
     | > postnet_loss: 1.46938  (1.43159)
     | > stopnet_loss: 1.87688  (1.58078)
     | > decoder_coarse_loss: 1.73790  (1.72865)
     | > decoder_ddc_loss: 0.00107  (0.00108)
     | > ga_loss: 0.00229  (0.00235)
     | > decoder_diff_spec_loss: 0.49671  (0.49173)
     | > postnet_diff_spec_loss: 0.82171  (0.80287)
     | > decoder_ssim_loss: 0.25350  (0.30569)
     | > postnet_ssim_loss: 0.26817  (0.32069)
     | > loss: 3.60312  (3.31204)
     | > align_error: 0.99086  (0.99083)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.67032  (3.86071)
     | > current_lr: 0.00007 
     | > step_time: 3.17740  (3.59971)
     | > loader_time: 0.02250  (0.03143)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.01372 [0m(+0.19288)
     | > avg_decoder_loss:[91m 2.07934 [0m(+0.01447)
     | > avg_postnet_loss:[91m 2.08841 [0m(+0.00873)
     | > avg_stopnet_loss:[91m 1.48924 [0m(+0.00156)
     | > avg_decoder_coarse_loss:[91m 1.84330 [0m(+0.06050)
     | > avg_decoder_ddc_loss:[91m 0.00075 [0m(+0.00003)
     | > avg_ga_loss:[92m 0.00225 [0m(-0.00003)
     | > avg_decoder_diff_spec_loss:[92m 0.47142 [0m(-0.00089)
     | > avg_postnet_diff_spec_loss:[92m 0.81711 [0m(-0.00095)
     | > avg_decoder_ssim_loss:[92m 0.30387 [0m(-0.00008)
     | > avg_postnet_ssim_loss:[92m 0.32837 [0m(-0.00092)
     | > avg_loss:[91m 3.48362 [0m(+0.02166)
     | > avg_align_error:[92m 0.99260 [0m(-0.00018)


[4m[1m > EPOCH: 83/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:55:02) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 277325[0m
     | > decoder_loss: 2.00374  (1.77734)
     | > postnet_loss: 1.66774  (1.43153)
     | > stopnet_loss: 1.22441  (1.67035)
     | > decoder_coarse_loss: 1.87337  (1.70219)
     | > decoder_ddc_loss: 0.00101  (0.00102)
     | > ga_loss: 0.00197  (0.00232)
     | > decoder_diff_spec_loss: 0.54380  (0.48596)
     | > postnet_diff_spec_loss: 0.83659  (0.80148)
     | > decoder_ssim_loss: 0.35889  (0.29501)
     | > postnet_ssim_loss: 0.37433  (0.31081)
     | > loss: 3.14912  (3.38327)
     | > align_error: 0.99184  (0.99123)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.39665  (4.37364)
     | > current_lr: 0.00007 
     | > step_time: 3.82820  (3.88997)
     | > loader_time: 0.04600  (0.04056)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 277350[0m
     | > decoder_loss: 1.93832  (1.80481)
     | > postnet_loss: 1.42332  (1.44209)
     | > stopnet_loss: 1.30483  (1.57762)
     | > decoder_coarse_loss: 1.83245  (1.73094)
     | > decoder_ddc_loss: 0.00112  (0.00104)
     | > ga_loss: 0.00224  (0.00230)
     | > decoder_diff_spec_loss: 0.51643  (0.49451)
     | > postnet_diff_spec_loss: 0.80450  (0.80497)
     | > decoder_ssim_loss: 0.32860  (0.30639)
     | > postnet_ssim_loss: 0.34914  (0.32156)
     | > loss: 3.11452  (3.31571)
     | > align_error: 0.99039  (0.99106)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.53488  (3.90021)
     | > current_lr: 0.00007 
     | > step_time: 3.63350  (3.73602)
     | > loader_time: 0.02060  (0.03783)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 277375[0m
     | > decoder_loss: 1.76626  (1.79260)
     | > postnet_loss: 1.36919  (1.43402)
     | > stopnet_loss: 1.51149  (1.58080)
     | > decoder_coarse_loss: 1.67353  (1.72085)
     | > decoder_ddc_loss: 0.00125  (0.00107)
     | > ga_loss: 0.00285  (0.00236)
     | > decoder_diff_spec_loss: 0.47020  (0.49099)
     | > postnet_diff_spec_loss: 0.79087  (0.80133)
     | > decoder_ssim_loss: 0.31296  (0.30478)
     | > postnet_ssim_loss: 0.32875  (0.32007)
     | > loss: 3.20398  (3.30902)
     | > align_error: 0.98844  (0.99081)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.62742  (3.84179)
     | > current_lr: 0.00007 
     | > step_time: 2.77200  (3.59921)
     | > loader_time: 0.08490  (0.04113)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.44155 [0m(-0.57217)
     | > avg_decoder_loss:[92m 2.06086 [0m(-0.01848)
     | > avg_postnet_loss:[91m 2.12951 [0m(+0.04110)
     | > avg_stopnet_loss:[92m 1.48836 [0m(-0.00088)
     | > avg_decoder_coarse_loss:[91m 1.87070 [0m(+0.02740)
     | > avg_decoder_ddc_loss:[91m 0.00075 [0m(+0.00000)
     | > avg_ga_loss:[91m 0.00225 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47311 [0m(+0.00169)
     | > avg_postnet_diff_spec_loss:[91m 0.81904 [0m(+0.00193)
     | > avg_decoder_ssim_loss:[92m 0.30373 [0m(-0.00014)
     | > avg_postnet_ssim_loss:[91m 0.33057 [0m(+0.00220)
     | > avg_loss:[91m 3.49669 [0m(+0.01307)
     | > avg_align_error:[92m 0.99257 [0m(-0.00003)


[4m[1m > EPOCH: 84/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:02:07) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 277400[0m
     | > decoder_loss: 1.61751  (1.74010)
     | > postnet_loss: 1.37816  (1.42457)
     | > stopnet_loss: 1.42318  (1.63986)
     | > decoder_coarse_loss: 1.57758  (1.70746)
     | > decoder_ddc_loss: 0.00169  (0.00101)
     | > ga_loss: 0.00279  (0.00222)
     | > decoder_diff_spec_loss: 0.47045  (0.48674)
     | > postnet_diff_spec_loss: 0.79937  (0.80855)
     | > decoder_ssim_loss: 0.33737  (0.29352)
     | > postnet_ssim_loss: 0.35576  (0.30889)
     | > loss: 3.07159  (3.34364)
     | > align_error: 0.98680  (0.99126)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.46904  (3.75487)
     | > current_lr: 0.00007 
     | > step_time: 1.98600  (4.35367)
     | > loader_time: 0.06470  (0.04710)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 277425[0m
     | > decoder_loss: 1.95288  (1.78807)
     | > postnet_loss: 1.49438  (1.42085)
     | > stopnet_loss: 1.24910  (1.57940)
     | > decoder_coarse_loss: 1.81840  (1.71584)
     | > decoder_ddc_loss: 0.00145  (0.00104)
     | > ga_loss: 0.00236  (0.00232)
     | > decoder_diff_spec_loss: 0.53027  (0.48930)
     | > postnet_diff_spec_loss: 0.81519  (0.80122)
     | > decoder_ssim_loss: 0.35075  (0.30651)
     | > postnet_ssim_loss: 0.36380  (0.32200)
     | > loss: 3.09270  (3.30220)
     | > align_error: 0.98868  (0.99106)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.57464  (4.22719)
     | > current_lr: 0.00007 
     | > step_time: 3.36780  (3.80005)
     | > loader_time: 0.01810  (0.03762)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 277450[0m
     | > decoder_loss: 1.83779  (1.80187)
     | > postnet_loss: 1.45625  (1.43130)
     | > stopnet_loss: 1.44446  (1.57913)
     | > decoder_coarse_loss: 1.80909  (1.73436)
     | > decoder_ddc_loss: 0.00099  (0.00108)
     | > ga_loss: 0.00220  (0.00234)
     | > decoder_diff_spec_loss: 0.50377  (0.49335)
     | > postnet_diff_spec_loss: 0.79877  (0.80319)
     | > decoder_ssim_loss: 0.31719  (0.30583)
     | > postnet_ssim_loss: 0.33209  (0.32094)
     | > loss: 3.21945  (3.31383)
     | > align_error: 0.99109  (0.99077)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.59840  (4.01815)
     | > current_lr: 0.00007 
     | > step_time: 4.04500  (3.72089)
     | > loader_time: 0.02480  (0.03552)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 277475[0m
     | > decoder_loss: 1.75340  (1.79565)
     | > postnet_loss: 1.36521  (1.42869)
     | > stopnet_loss: 1.86571  (1.57642)
     | > decoder_coarse_loss: 1.73569  (1.72925)
     | > decoder_ddc_loss: 0.00074  (0.00107)
     | > ga_loss: 0.00189  (0.00234)
     | > decoder_diff_spec_loss: 0.49840  (0.49189)
     | > postnet_diff_spec_loss: 0.80075  (0.80216)
     | > decoder_ssim_loss: 0.25643  (0.30588)
     | > postnet_ssim_loss: 0.27030  (0.32095)
     | > loss: 3.54540  (3.30701)
     | > align_error: 0.99259  (0.99081)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.20047  (3.76815)
     | > current_lr: 0.00007 
     | > step_time: 2.88950  (3.61199)
     | > loader_time: 0.01810  (0.03473)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.62324 [0m(+0.18169)
     | > avg_decoder_loss:[92m 2.00653 [0m(-0.05433)
     | > avg_postnet_loss:[92m 2.11687 [0m(-0.01265)
     | > avg_stopnet_loss:[92m 1.48640 [0m(-0.00196)
     | > avg_decoder_coarse_loss:[92m 1.83942 [0m(-0.03129)
     | > avg_decoder_ddc_loss:[92m 0.00073 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00225 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47269 [0m(-0.00042)
     | > avg_postnet_diff_spec_loss:[92m 0.81904 [0m(-0.00000)
     | > avg_decoder_ssim_loss:[92m 0.30316 [0m(-0.00057)
     | > avg_postnet_ssim_loss:[92m 0.32995 [0m(-0.00062)
     | > avg_loss:[92m 3.46974 [0m(-0.02695)
     | > avg_align_error:[91m 0.99260 [0m(+0.00003)


[4m[1m > EPOCH: 85/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:09:15) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 277500[0m
     | > decoder_loss: 1.84620  (1.76898)
     | > postnet_loss: 1.39021  (1.41895)
     | > stopnet_loss: 1.98414  (1.69499)
     | > decoder_coarse_loss: 1.75509  (1.70422)
     | > decoder_ddc_loss: 0.00082  (0.00098)
     | > ga_loss: 0.00245  (0.00233)
     | > decoder_diff_spec_loss: 0.50730  (0.48370)
     | > postnet_diff_spec_loss: 0.80791  (0.79972)
     | > decoder_ssim_loss: 0.25054  (0.29122)
     | > postnet_ssim_loss: 0.26429  (0.30735)
     | > loss: 3.70196  (3.40043)
     | > align_error: 0.99218  (0.99123)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.06772  (4.29477)
     | > current_lr: 0.00007 
     | > step_time: 2.75890  (3.88338)
     | > loader_time: 0.06750  (0.03632)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 277525[0m
     | > decoder_loss: 1.96110  (1.80092)
     | > postnet_loss: 1.53484  (1.44034)
     | > stopnet_loss: 2.04564  (1.58444)
     | > decoder_coarse_loss: 1.94203  (1.73553)
     | > decoder_ddc_loss: 0.00088  (0.00101)
     | > ga_loss: 0.00222  (0.00230)
     | > decoder_diff_spec_loss: 0.55142  (0.49325)
     | > postnet_diff_spec_loss: 0.84907  (0.80480)
     | > decoder_ssim_loss: 0.23343  (0.30559)
     | > postnet_ssim_loss: 0.23902  (0.32069)
     | > loss: 3.88470  (3.32146)
     | > align_error: 0.99109  (0.99103)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.99685  (3.82394)
     | > current_lr: 0.00007 
     | > step_time: 3.78980  (3.76248)
     | > loader_time: 0.02180  (0.03351)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 277550[0m
     | > decoder_loss: 1.80565  (1.79065)
     | > postnet_loss: 1.39368  (1.43146)
     | > stopnet_loss: 1.79203  (1.58162)
     | > decoder_coarse_loss: 1.74807  (1.73117)
     | > decoder_ddc_loss: 0.00101  (0.00105)
     | > ga_loss: 0.00226  (0.00235)
     | > decoder_diff_spec_loss: 0.48276  (0.49019)
     | > postnet_diff_spec_loss: 0.79176  (0.80129)
     | > decoder_ssim_loss: 0.26351  (0.30441)
     | > postnet_ssim_loss: 0.27587  (0.31972)
     | > loss: 3.49391  (3.31084)
     | > align_error: 0.99028  (0.99084)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.96663  (3.69073)
     | > current_lr: 0.00007 
     | > step_time: 4.58690  (3.64646)
     | > loader_time: 0.06790  (0.03485)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.08713 [0m(+0.46389)
     | > avg_decoder_loss:[92m 1.95762 [0m(-0.04891)
     | > avg_postnet_loss:[92m 2.04940 [0m(-0.06746)
     | > avg_stopnet_loss:[91m 1.48708 [0m(+0.00068)
     | > avg_decoder_coarse_loss:[92m 1.76426 [0m(-0.07516)
     | > avg_decoder_ddc_loss:[91m 0.00076 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00224 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47200 [0m(-0.00070)
     | > avg_postnet_diff_spec_loss:[91m 0.81921 [0m(+0.00016)
     | > avg_decoder_ssim_loss:[92m 0.30296 [0m(-0.00020)
     | > avg_postnet_ssim_loss:[91m 0.33046 [0m(+0.00051)
     | > avg_loss:[92m 3.42246 [0m(-0.04728)
     | > avg_align_error:[92m 0.99257 [0m(-0.00003)


[4m[1m > EPOCH: 86/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:16:23) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 277575[0m
     | > decoder_loss: 1.85413  (1.74504)
     | > postnet_loss: 1.47402  (1.43369)
     | > stopnet_loss: 1.22149  (1.66707)
     | > decoder_coarse_loss: 1.79018  (1.69805)
     | > decoder_ddc_loss: 0.00096  (0.00086)
     | > ga_loss: 0.00182  (0.00215)
     | > decoder_diff_spec_loss: 0.52654  (0.48818)
     | > postnet_diff_spec_loss: 0.81469  (0.80936)
     | > decoder_ssim_loss: 0.33690  (0.28651)
     | > postnet_ssim_loss: 0.35728  (0.30172)
     | > loss: 3.01924  (3.36865)
     | > align_error: 0.99191  (0.99196)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.31781  (3.90530)
     | > current_lr: 0.00007 
     | > step_time: 3.56760  (4.33406)
     | > loader_time: 0.01990  (0.04872)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 277600[0m
     | > decoder_loss: 1.81486  (1.77313)
     | > postnet_loss: 1.48085  (1.42323)
     | > stopnet_loss: 1.62860  (1.59583)
     | > decoder_coarse_loss: 1.76062  (1.70817)
     | > decoder_ddc_loss: 0.00075  (0.00097)
     | > ga_loss: 0.00191  (0.00233)
     | > decoder_diff_spec_loss: 0.47117  (0.48727)
     | > postnet_diff_spec_loss: 0.78973  (0.80056)
     | > decoder_ssim_loss: 0.27258  (0.30451)
     | > postnet_ssim_loss: 0.29436  (0.32077)
     | > loss: 3.35939  (3.31212)
     | > align_error: 0.99316  (0.99127)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.82048  (4.37818)
     | > current_lr: 0.00007 
     | > step_time: 4.53440  (3.65011)
     | > loader_time: 0.02480  (0.03793)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 277625[0m
     | > decoder_loss: 1.77471  (1.79090)
     | > postnet_loss: 1.43803  (1.43154)
     | > stopnet_loss: 1.54023  (1.58298)
     | > decoder_coarse_loss: 1.74171  (1.73270)
     | > decoder_ddc_loss: 0.00123  (0.00102)
     | > ga_loss: 0.00259  (0.00235)
     | > decoder_diff_spec_loss: 0.47424  (0.49195)
     | > postnet_diff_spec_loss: 0.79035  (0.80278)
     | > decoder_ssim_loss: 0.30328  (0.30500)
     | > postnet_ssim_loss: 0.32004  (0.32056)
     | > loss: 3.26406  (3.31386)
     | > align_error: 0.98837  (0.99089)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.15042  (4.00521)
     | > current_lr: 0.00007 
     | > step_time: 3.29280  (3.61224)
     | > loader_time: 0.02300  (0.03473)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 277650[0m
     | > decoder_loss: 1.90257  (1.78950)
     | > postnet_loss: 1.50159  (1.43060)
     | > stopnet_loss: 1.10055  (1.56939)
     | > decoder_coarse_loss: 1.82193  (1.73033)
     | > decoder_ddc_loss: 0.00081  (0.00102)
     | > ga_loss: 0.00187  (0.00235)
     | > decoder_diff_spec_loss: 0.53379  (0.49101)
     | > postnet_diff_spec_loss: 0.83148  (0.80192)
     | > decoder_ssim_loss: 0.36723  (0.30596)
     | > postnet_ssim_loss: 0.38896  (0.32140)
     | > loss: 2.94699  (3.29908)
     | > align_error: 0.99213  (0.99086)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.17294  (3.95910)
     | > current_lr: 0.00007 
     | > step_time: 2.97490  (3.57979)
     | > loader_time: 0.02070  (0.03428)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.05622 [0m(-0.03091)
     | > avg_decoder_loss:[91m 2.00017 [0m(+0.04254)
     | > avg_postnet_loss:[91m 2.19871 [0m(+0.14931)
     | > avg_stopnet_loss:[91m 1.48903 [0m(+0.00195)
     | > avg_decoder_coarse_loss:[92m 1.71535 [0m(-0.04891)
     | > avg_decoder_ddc_loss:[92m 0.00071 [0m(-0.00005)
     | > avg_ga_loss:[91m 0.00225 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47214 [0m(+0.00014)
     | > avg_postnet_diff_spec_loss:[91m 0.82034 [0m(+0.00114)
     | > avg_decoder_ssim_loss:[91m 0.30314 [0m(+0.00018)
     | > avg_postnet_ssim_loss:[92m 0.33017 [0m(-0.00029)
     | > avg_loss:[91m 3.46048 [0m(+0.03802)
     | > avg_align_error:[91m 0.99272 [0m(+0.00015)


[4m[1m > EPOCH: 87/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:23:29) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 277675[0m
     | > decoder_loss: 1.65821  (1.75134)
     | > postnet_loss: 1.32114  (1.41200)
     | > stopnet_loss: 2.09034  (1.67113)
     | > decoder_coarse_loss: 1.59385  (1.68423)
     | > decoder_ddc_loss: 0.00056  (0.00094)
     | > ga_loss: 0.00198  (0.00234)
     | > decoder_diff_spec_loss: 0.45243  (0.48345)
     | > postnet_diff_spec_loss: 0.77531  (0.79888)
     | > decoder_ssim_loss: 0.22096  (0.29334)
     | > postnet_ssim_loss: 0.24035  (0.30945)
     | > loss: 3.66594  (3.36623)
     | > align_error: 0.99422  (0.99125)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.39474  (4.38325)
     | > current_lr: 0.00007 
     | > step_time: 4.18500  (3.92898)
     | > loader_time: 0.03080  (0.03862)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 277700[0m
     | > decoder_loss: 1.87814  (1.79381)
     | > postnet_loss: 1.46360  (1.43247)
     | > stopnet_loss: 2.29847  (1.56625)
     | > decoder_coarse_loss: 1.85747  (1.73220)
     | > decoder_ddc_loss: 0.00074  (0.00099)
     | > ga_loss: 0.00206  (0.00231)
     | > decoder_diff_spec_loss: 0.53079  (0.49157)
     | > postnet_diff_spec_loss: 0.82758  (0.80342)
     | > decoder_ssim_loss: 0.21492  (0.30701)
     | > postnet_ssim_loss: 0.22165  (0.32220)
     | > loss: 4.05747  (3.29871)
     | > align_error: 0.99260  (0.99107)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.11429  (3.97236)
     | > current_lr: 0.00007 
     | > step_time: 4.68930  (3.78006)
     | > loader_time: 0.06670  (0.03592)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 277725[0m
     | > decoder_loss: 1.81011  (1.78563)
     | > postnet_loss: 1.33903  (1.42303)
     | > stopnet_loss: 1.99605  (1.57243)
     | > decoder_coarse_loss: 1.72839  (1.73073)
     | > decoder_ddc_loss: 0.00052  (0.00101)
     | > ga_loss: 0.00204  (0.00236)
     | > decoder_diff_spec_loss: 0.50595  (0.48984)
     | > postnet_diff_spec_loss: 0.78511  (0.80098)
     | > decoder_ssim_loss: 0.23819  (0.30459)
     | > postnet_ssim_loss: 0.24601  (0.32008)
     | > loss: 3.66961  (3.29818)
     | > align_error: 0.99398  (0.99089)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.78290  (3.84354)
     | > current_lr: 0.00007 
     | > step_time: 4.80910  (3.68912)
     | > loader_time: 0.02260  (0.03480)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.59245 [0m(-0.46377)
     | > avg_decoder_loss:[92m 1.97627 [0m(-0.02390)
     | > avg_postnet_loss:[92m 1.98244 [0m(-0.21627)
     | > avg_stopnet_loss:[92m 1.48881 [0m(-0.00022)
     | > avg_decoder_coarse_loss:[92m 1.70622 [0m(-0.00913)
     | > avg_decoder_ddc_loss:[92m 0.00070 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00224 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47165 [0m(-0.00048)
     | > avg_postnet_diff_spec_loss:[92m 0.81802 [0m(-0.00233)
     | > avg_decoder_ssim_loss:[92m 0.30297 [0m(-0.00018)
     | > avg_postnet_ssim_loss:[92m 0.32888 [0m(-0.00128)
     | > avg_loss:[92m 3.39682 [0m(-0.06366)
     | > avg_align_error:[91m 0.99275 [0m(+0.00002)


[4m[1m > EPOCH: 88/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:30:39) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 277750[0m
     | > decoder_loss: 1.78009  (1.72935)
     | > postnet_loss: 1.46481  (1.42864)
     | > stopnet_loss: 1.26844  (1.74850)
     | > decoder_coarse_loss: 1.70083  (1.67390)
     | > decoder_ddc_loss: 0.00100  (0.00084)
     | > ga_loss: 0.00215  (0.00220)
     | > decoder_diff_spec_loss: 0.48290  (0.48435)
     | > postnet_diff_spec_loss: 0.80276  (0.80695)
     | > decoder_ssim_loss: 0.35267  (0.27814)
     | > postnet_ssim_loss: 0.36527  (0.29189)
     | > loss: 3.01679  (3.43299)
     | > align_error: 0.99054  (0.99197)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.72549  (4.03655)
     | > current_lr: 0.00007 
     | > step_time: 3.29070  (4.58832)
     | > loader_time: 0.05220  (0.03049)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 277775[0m
     | > decoder_loss: 1.66114  (1.76915)
     | > postnet_loss: 1.35237  (1.40693)
     | > stopnet_loss: 2.21128  (1.58182)
     | > decoder_coarse_loss: 1.61619  (1.70163)
     | > decoder_ddc_loss: 0.00068  (0.00101)
     | > ga_loss: 0.00222  (0.00233)
     | > decoder_diff_spec_loss: 0.46580  (0.48808)
     | > postnet_diff_spec_loss: 0.77440  (0.80033)
     | > decoder_ssim_loss: 0.21463  (0.30551)
     | > postnet_ssim_loss: 0.22964  (0.32124)
     | > loss: 3.80109  (3.29192)
     | > align_error: 0.99306  (0.99106)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.70683  (4.06179)
     | > current_lr: 0.00007 
     | > step_time: 4.38620  (3.74575)
     | > loader_time: 0.02540  (0.02740)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 277800[0m
     | > decoder_loss: 1.80913  (1.79025)
     | > postnet_loss: 1.41019  (1.42036)
     | > stopnet_loss: 1.12674  (1.57841)
     | > decoder_coarse_loss: 1.78706  (1.72449)
     | > decoder_ddc_loss: 0.00113  (0.00103)
     | > ga_loss: 0.00232  (0.00234)
     | > decoder_diff_spec_loss: 0.51845  (0.49211)
     | > postnet_diff_spec_loss: 0.81493  (0.80277)
     | > decoder_ssim_loss: 0.36985  (0.30495)
     | > postnet_ssim_loss: 0.39296  (0.32028)
     | > loss: 2.91426  (3.30418)
     | > align_error: 0.99067  (0.99086)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.77769  (3.78942)
     | > current_lr: 0.00007 
     | > step_time: 3.04610  (3.69193)
     | > loader_time: 0.04500  (0.02957)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 277825[0m
     | > decoder_loss: 1.85651  (1.78274)
     | > postnet_loss: 1.33854  (1.41659)
     | > stopnet_loss: 1.78856  (1.56988)
     | > decoder_coarse_loss: 1.75342  (1.72005)
     | > decoder_ddc_loss: 0.00092  (0.00104)
     | > ga_loss: 0.00232  (0.00235)
     | > decoder_diff_spec_loss: 0.48207  (0.49021)
     | > postnet_diff_spec_loss: 0.77439  (0.80115)
     | > decoder_ssim_loss: 0.26292  (0.30506)
     | > postnet_ssim_loss: 0.27986  (0.32028)
     | > loss: 3.48730  (3.29091)
     | > align_error: 0.99098  (0.99079)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.10348  (3.62946)
     | > current_lr: 0.00007 
     | > step_time: 2.56170  (3.62388)
     | > loader_time: 0.01920  (0.03289)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.47717 [0m(-0.11529)
     | > avg_decoder_loss:[91m 2.06617 [0m(+0.08991)
     | > avg_postnet_loss:[91m 2.09108 [0m(+0.10864)
     | > avg_stopnet_loss:[92m 1.48758 [0m(-0.00123)
     | > avg_decoder_coarse_loss:[91m 1.72273 [0m(+0.01651)
     | > avg_decoder_ddc_loss:[92m 0.00070 [0m(-0.00000)
     | > avg_ga_loss:[91m 0.00225 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47422 [0m(+0.00257)
     | > avg_postnet_diff_spec_loss:[91m 0.81962 [0m(+0.00160)
     | > avg_decoder_ssim_loss:[91m 0.30351 [0m(+0.00054)
     | > avg_postnet_ssim_loss:[91m 0.33013 [0m(+0.00124)
     | > avg_loss:[91m 3.45085 [0m(+0.05403)
     | > avg_align_error:[91m 0.99286 [0m(+0.00012)


[4m[1m > EPOCH: 89/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:37:54) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 277850[0m
     | > decoder_loss: 1.77420  (1.75265)
     | > postnet_loss: 1.38252  (1.40449)
     | > stopnet_loss: 1.85176  (1.64938)
     | > decoder_coarse_loss: 1.69600  (1.68651)
     | > decoder_ddc_loss: 0.00059  (0.00100)
     | > ga_loss: 0.00192  (0.00234)
     | > decoder_diff_spec_loss: 0.47787  (0.48464)
     | > postnet_diff_spec_loss: 0.79443  (0.79968)
     | > decoder_ssim_loss: 0.24685  (0.29688)
     | > postnet_ssim_loss: 0.26526  (0.31279)
     | > loss: 3.52079  (3.34574)
     | > align_error: 0.99394  (0.99097)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.45755  (4.19781)
     | > current_lr: 0.00007 
     | > step_time: 5.29850  (3.82933)
     | > loader_time: 0.02500  (0.04592)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 277875[0m
     | > decoder_loss: 1.87890  (1.78456)
     | > postnet_loss: 1.41192  (1.41716)
     | > stopnet_loss: 1.07601  (1.54846)
     | > decoder_coarse_loss: 1.81113  (1.71240)
     | > decoder_ddc_loss: 0.00113  (0.00102)
     | > ga_loss: 0.00217  (0.00229)
     | > decoder_diff_spec_loss: 0.51852  (0.49084)
     | > postnet_diff_spec_loss: 0.81504  (0.80233)
     | > decoder_ssim_loss: 0.40463  (0.30873)
     | > postnet_ssim_loss: 0.41344  (0.32401)
     | > loss: 2.90054  (3.27019)
     | > align_error: 0.99025  (0.99094)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.27810  (3.79481)
     | > current_lr: 0.00007 
     | > step_time: 3.63180  (3.70317)
     | > loader_time: 0.03580  (0.04381)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 277900[0m
     | > decoder_loss: 1.65440  (1.78135)
     | > postnet_loss: 1.35350  (1.41290)
     | > stopnet_loss: 1.48336  (1.56382)
     | > decoder_coarse_loss: 1.59383  (1.71221)
     | > decoder_ddc_loss: 0.00129  (0.00105)
     | > ga_loss: 0.00247  (0.00234)
     | > decoder_diff_spec_loss: 0.46444  (0.49043)
     | > postnet_diff_spec_loss: 0.79223  (0.80082)
     | > decoder_ssim_loss: 0.31411  (0.30527)
     | > postnet_ssim_loss: 0.33164  (0.32066)
     | > loss: 3.12208  (3.28169)
     | > align_error: 0.98945  (0.99074)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.74291  (3.78465)
     | > current_lr: 0.00007 
     | > step_time: 2.68190  (3.62574)
     | > loader_time: 0.01870  (0.03814)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.45004 [0m(-0.02713)
     | > avg_decoder_loss:[91m 2.09162 [0m(+0.02545)
     | > avg_postnet_loss:[91m 2.23181 [0m(+0.14073)
     | > avg_stopnet_loss:[92m 1.48611 [0m(-0.00147)
     | > avg_decoder_coarse_loss:[91m 1.74661 [0m(+0.02387)
     | > avg_decoder_ddc_loss:[91m 0.00072 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00223 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.47197 [0m(-0.00224)
     | > avg_postnet_diff_spec_loss:[91m 0.82018 [0m(+0.00056)
     | > avg_decoder_ssim_loss:[92m 0.30313 [0m(-0.00038)
     | > avg_postnet_ssim_loss:[91m 0.33063 [0m(+0.00050)
     | > avg_loss:[91m 3.49642 [0m(+0.04557)
     | > avg_align_error:[92m 0.99261 [0m(-0.00025)


[4m[1m > EPOCH: 90/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:45:02) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 277925[0m
     | > decoder_loss: 1.65179  (1.72325)
     | > postnet_loss: 1.41963  (1.41299)
     | > stopnet_loss: 1.68513  (1.82497)
     | > decoder_coarse_loss: 1.63720  (1.66389)
     | > decoder_ddc_loss: 0.00071  (0.00082)
     | > ga_loss: 0.00217  (0.00219)
     | > decoder_diff_spec_loss: 0.47004  (0.48278)
     | > postnet_diff_spec_loss: 0.80844  (0.80799)
     | > decoder_ssim_loss: 0.26267  (0.26333)
     | > postnet_ssim_loss: 0.28506  (0.27757)
     | > loss: 3.32986  (3.49408)
     | > align_error: 0.99283  (0.99216)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.60546  (3.66748)
     | > current_lr: 0.00007 
     | > step_time: 4.07610  (5.16661)
     | > loader_time: 0.04480  (0.08262)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 277950[0m
     | > decoder_loss: 1.75933  (1.76220)
     | > postnet_loss: 1.38130  (1.39716)
     | > stopnet_loss: 1.24995  (1.56503)
     | > decoder_coarse_loss: 1.70018  (1.69181)
     | > decoder_ddc_loss: 0.00089  (0.00101)
     | > ga_loss: 0.00216  (0.00233)
     | > decoder_diff_spec_loss: 0.51421  (0.48796)
     | > postnet_diff_spec_loss: 0.81538  (0.80103)
     | > decoder_ssim_loss: 0.34687  (0.30809)
     | > postnet_ssim_loss: 0.35803  (0.32405)
     | > loss: 2.97977  (3.26999)
     | > align_error: 0.99200  (0.99099)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.76465  (3.94933)
     | > current_lr: 0.00007 
     | > step_time: 3.91320  (3.79760)
     | > loader_time: 0.04680  (0.04228)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 277975[0m
     | > decoder_loss: 1.59451  (1.77969)
     | > postnet_loss: 1.37127  (1.41004)
     | > stopnet_loss: 1.85683  (1.59118)
     | > decoder_coarse_loss: 1.58584  (1.71130)
     | > decoder_ddc_loss: 0.00081  (0.00102)
     | > ga_loss: 0.00245  (0.00234)
     | > decoder_diff_spec_loss: 0.45492  (0.49100)
     | > postnet_diff_spec_loss: 0.78535  (0.80230)
     | > decoder_ssim_loss: 0.25381  (0.30313)
     | > postnet_ssim_loss: 0.27456  (0.31875)
     | > loss: 3.44936  (3.30717)
     | > align_error: 0.99206  (0.99081)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.23026  (3.50255)
     | > current_lr: 0.00007 
     | > step_time: 3.14580  (3.70338)
     | > loader_time: 0.02700  (0.04085)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 278000[0m
     | > decoder_loss: 2.04753  (1.77593)
     | > postnet_loss: 1.46266  (1.40913)
     | > stopnet_loss: 1.84858  (1.57263)
     | > decoder_coarse_loss: 1.91531  (1.71037)
     | > decoder_ddc_loss: 0.00071  (0.00103)
     | > ga_loss: 0.00195  (0.00234)
     | > decoder_diff_spec_loss: 0.51058  (0.48969)
     | > postnet_diff_spec_loss: 0.79826  (0.80112)
     | > decoder_ssim_loss: 0.24771  (0.30501)
     | > postnet_ssim_loss: 0.25983  (0.32047)
     | > loss: 3.66898  (3.28754)
     | > align_error: 0.99305  (0.99075)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.04824  (3.52206)
     | > current_lr: 0.00007 
     | > step_time: 3.62810  (3.61855)
     | > loader_time: 0.01730  (0.03797)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.35897 [0m(-0.09107)
     | > avg_decoder_loss:[92m 1.99481 [0m(-0.09681)
     | > avg_postnet_loss:[92m 2.04607 [0m(-0.18573)
     | > avg_stopnet_loss:[92m 1.48554 [0m(-0.00058)
     | > avg_decoder_coarse_loss:[92m 1.70344 [0m(-0.04317)
     | > avg_decoder_ddc_loss:[91m 0.00073 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00222 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47267 [0m(+0.00070)
     | > avg_postnet_diff_spec_loss:[92m 0.81908 [0m(-0.00110)
     | > avg_decoder_ssim_loss:[92m 0.30295 [0m(-0.00018)
     | > avg_postnet_ssim_loss:[92m 0.32925 [0m(-0.00138)
     | > avg_loss:[92m 3.41390 [0m(-0.08252)
     | > avg_align_error:[91m 0.99264 [0m(+0.00003)


[4m[1m > EPOCH: 91/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:52:14) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 278025[0m
     | > decoder_loss: 1.60212  (1.74697)
     | > postnet_loss: 1.29529  (1.40833)
     | > stopnet_loss: 1.48165  (1.64015)
     | > decoder_coarse_loss: 1.54945  (1.67609)
     | > decoder_ddc_loss: 0.00085  (0.00103)
     | > ga_loss: 0.00214  (0.00236)
     | > decoder_diff_spec_loss: 0.44385  (0.48410)
     | > postnet_diff_spec_loss: 0.76464  (0.80044)
     | > decoder_ssim_loss: 0.30277  (0.29949)
     | > postnet_ssim_loss: 0.32030  (0.31603)
     | > loss: 3.06215  (3.33508)
     | > align_error: 0.99179  (0.99078)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.37649  (4.32967)
     | > current_lr: 0.00007 
     | > step_time: 4.11530  (3.72345)
     | > loader_time: 0.02220  (0.04160)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 278050[0m
     | > decoder_loss: 1.79129  (1.77608)
     | > postnet_loss: 1.43306  (1.41465)
     | > stopnet_loss: 1.76914  (1.55981)
     | > decoder_coarse_loss: 1.73728  (1.70483)
     | > decoder_ddc_loss: 0.00069  (0.00102)
     | > ga_loss: 0.00182  (0.00229)
     | > decoder_diff_spec_loss: 0.49463  (0.48981)
     | > postnet_diff_spec_loss: 0.80999  (0.80189)
     | > decoder_ssim_loss: 0.25933  (0.30612)
     | > postnet_ssim_loss: 0.26664  (0.32197)
     | > loss: 3.47645  (3.27535)
     | > align_error: 0.99279  (0.99091)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.29389  (3.78126)
     | > current_lr: 0.00007 
     | > step_time: 5.02760  (3.70631)
     | > loader_time: 0.02980  (0.03735)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 278075[0m
     | > decoder_loss: 1.73632  (1.77453)
     | > postnet_loss: 1.33270  (1.41012)
     | > stopnet_loss: 1.72904  (1.56279)
     | > decoder_coarse_loss: 1.66480  (1.70869)
     | > decoder_ddc_loss: 0.00060  (0.00103)
     | > ga_loss: 0.00190  (0.00233)
     | > decoder_diff_spec_loss: 0.49423  (0.48981)
     | > postnet_diff_spec_loss: 0.78815  (0.80063)
     | > decoder_ssim_loss: 0.26939  (0.30468)
     | > postnet_ssim_loss: 0.27897  (0.32043)
     | > loss: 3.37982  (3.27694)
     | > align_error: 0.99382  (0.99074)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.40005  (3.73298)
     | > current_lr: 0.00007 
     | > step_time: 4.72760  (3.61609)
     | > loader_time: 0.07390  (0.03607)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.83134 [0m(+0.47237)
     | > avg_decoder_loss:[91m 2.04654 [0m(+0.05173)
     | > avg_postnet_loss:[91m 2.09770 [0m(+0.05163)
     | > avg_stopnet_loss:[92m 1.48528 [0m(-0.00026)
     | > avg_decoder_coarse_loss:[91m 1.72661 [0m(+0.02317)
     | > avg_decoder_ddc_loss:[92m 0.00072 [0m(-0.00000)
     | > avg_ga_loss:[91m 0.00223 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47273 [0m(+0.00006)
     | > avg_postnet_diff_spec_loss:[92m 0.81904 [0m(-0.00004)
     | > avg_decoder_ssim_loss:[92m 0.30287 [0m(-0.00008)
     | > avg_postnet_ssim_loss:[91m 0.32931 [0m(+0.00006)
     | > avg_loss:[91m 3.44531 [0m(+0.03141)
     | > avg_align_error:[92m 0.99257 [0m(-0.00007)


[4m[1m > EPOCH: 92/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:59:23) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 278100[0m
     | > decoder_loss: 1.74656  (1.72502)
     | > postnet_loss: 1.41083  (1.40484)
     | > stopnet_loss: 2.28170  (1.85772)
     | > decoder_coarse_loss: 1.70527  (1.67727)
     | > decoder_ddc_loss: 0.00056  (0.00084)
     | > ga_loss: 0.00200  (0.00219)
     | > decoder_diff_spec_loss: 0.49668  (0.48906)
     | > postnet_diff_spec_loss: 0.82137  (0.80748)
     | > decoder_ssim_loss: 0.21029  (0.26298)
     | > postnet_ssim_loss: 0.22218  (0.27457)
     | > loss: 3.94512  (3.52917)
     | > align_error: 0.99394  (0.99187)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.65605  (4.23503)
     | > current_lr: 0.00007 
     | > step_time: 4.88810  (5.09153)
     | > loader_time: 0.02710  (0.05507)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 278125[0m
     | > decoder_loss: 1.93550  (1.76366)
     | > postnet_loss: 1.50845  (1.39784)
     | > stopnet_loss: 1.23253  (1.57138)
     | > decoder_coarse_loss: 1.85073  (1.69782)
     | > decoder_ddc_loss: 0.00151  (0.00100)
     | > ga_loss: 0.00305  (0.00232)
     | > decoder_diff_spec_loss: 0.53258  (0.48692)
     | > postnet_diff_spec_loss: 0.84068  (0.80036)
     | > decoder_ssim_loss: 0.36892  (0.30653)
     | > postnet_ssim_loss: 0.38744  (0.32244)
     | > loss: 3.10422  (3.27713)
     | > align_error: 0.98744  (0.99089)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.16567  (4.05926)
     | > current_lr: 0.00007 
     | > step_time: 3.14080  (3.67445)
     | > loader_time: 0.01520  (0.03380)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 278150[0m
     | > decoder_loss: 1.78829  (1.78276)
     | > postnet_loss: 1.27513  (1.40867)
     | > stopnet_loss: 2.04688  (1.58069)
     | > decoder_coarse_loss: 1.76480  (1.71839)
     | > decoder_ddc_loss: 0.00114  (0.00101)
     | > ga_loss: 0.00267  (0.00233)
     | > decoder_diff_spec_loss: 0.50620  (0.49154)
     | > postnet_diff_spec_loss: 0.77650  (0.80244)
     | > decoder_ssim_loss: 0.24710  (0.30399)
     | > postnet_ssim_loss: 0.25936  (0.31928)
     | > loss: 3.71484  (3.29937)
     | > align_error: 0.98882  (0.99080)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.81338  (3.60236)
     | > current_lr: 0.00007 
     | > step_time: 2.97700  (3.58914)
     | > loader_time: 0.01840  (0.03627)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 278175[0m
     | > decoder_loss: 1.62701  (1.77156)
     | > postnet_loss: 1.38248  (1.40643)
     | > stopnet_loss: 1.23708  (1.56242)
     | > decoder_coarse_loss: 1.54848  (1.70760)
     | > decoder_ddc_loss: 0.00133  (0.00102)
     | > ga_loss: 0.00263  (0.00235)
     | > decoder_diff_spec_loss: 0.47463  (0.48883)
     | > postnet_diff_spec_loss: 0.79847  (0.80091)
     | > decoder_ssim_loss: 0.35735  (0.30559)
     | > postnet_ssim_loss: 0.37222  (0.32098)
     | > loss: 2.89071  (3.27488)
     | > align_error: 0.98821  (0.99071)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.76084  (3.67540)
     | > current_lr: 0.00007 
     | > step_time: 2.76270  (3.53412)
     | > loader_time: 0.02030  (0.03480)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.52605 [0m(-0.30529)
     | > avg_decoder_loss:[92m 2.02975 [0m(-0.01679)
     | > avg_postnet_loss:[91m 2.14595 [0m(+0.04824)
     | > avg_stopnet_loss:[91m 1.48552 [0m(+0.00024)
     | > avg_decoder_coarse_loss:[92m 1.71968 [0m(-0.00693)
     | > avg_decoder_ddc_loss:[92m 0.00072 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00223 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47443 [0m(+0.00170)
     | > avg_postnet_diff_spec_loss:[91m 0.82032 [0m(+0.00129)
     | > avg_decoder_ssim_loss:[92m 0.30255 [0m(-0.00032)
     | > avg_postnet_ssim_loss:[91m 0.32964 [0m(+0.00033)
     | > avg_loss:[91m 3.45242 [0m(+0.00711)
     | > avg_align_error:[92m 0.99256 [0m(-0.00001)


[4m[1m > EPOCH: 93/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:06:29) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 278200[0m
     | > decoder_loss: 1.84623  (1.74857)
     | > postnet_loss: 1.45219  (1.39459)
     | > stopnet_loss: 1.67890  (1.64539)
     | > decoder_coarse_loss: 1.72891  (1.67935)
     | > decoder_ddc_loss: 0.00123  (0.00102)
     | > ga_loss: 0.00226  (0.00236)
     | > decoder_diff_spec_loss: 0.48611  (0.48666)
     | > postnet_diff_spec_loss: 0.78871  (0.80123)
     | > decoder_ssim_loss: 0.26943  (0.29892)
     | > postnet_ssim_loss: 0.28228  (0.31430)
     | > loss: 3.40399  (3.33836)
     | > align_error: 0.99057  (0.99064)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.57132  (4.04922)
     | > current_lr: 0.00007 
     | > step_time: 3.93250  (3.82143)
     | > loader_time: 0.02100  (0.04461)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 278225[0m
     | > decoder_loss: 1.78982  (1.76842)
     | > postnet_loss: 1.43985  (1.39928)
     | > stopnet_loss: 1.63231  (1.55699)
     | > decoder_coarse_loss: 1.70698  (1.70113)
     | > decoder_ddc_loss: 0.00106  (0.00102)
     | > ga_loss: 0.00245  (0.00229)
     | > decoder_diff_spec_loss: 0.50870  (0.48889)
     | > postnet_diff_spec_loss: 0.82866  (0.80106)
     | > decoder_ssim_loss: 0.28072  (0.30691)
     | > postnet_ssim_loss: 0.29474  (0.32267)
     | > loss: 3.35719  (3.26580)
     | > align_error: 0.98936  (0.99077)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.21891  (3.65430)
     | > current_lr: 0.00007 
     | > step_time: 2.96700  (3.73155)
     | > loader_time: 0.02170  (0.03533)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 278250[0m
     | > decoder_loss: 1.68574  (1.77133)
     | > postnet_loss: 1.35460  (1.39903)
     | > stopnet_loss: 1.73960  (1.56240)
     | > decoder_coarse_loss: 1.63660  (1.70623)
     | > decoder_ddc_loss: 0.00075  (0.00103)
     | > ga_loss: 0.00207  (0.00233)
     | > decoder_diff_spec_loss: 0.48842  (0.48895)
     | > postnet_diff_spec_loss: 0.79478  (0.80025)
     | > decoder_ssim_loss: 0.26115  (0.30495)
     | > postnet_ssim_loss: 0.27304  (0.32053)
     | > loss: 3.37370  (3.27214)
     | > align_error: 0.99205  (0.99061)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.05603  (3.57619)
     | > current_lr: 0.00007 
     | > step_time: 4.09190  (3.65112)
     | > loader_time: 0.02280  (0.03539)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.64957 [0m(+0.12352)
     | > avg_decoder_loss:[91m 2.06663 [0m(+0.03688)
     | > avg_postnet_loss:[91m 2.15773 [0m(+0.01178)
     | > avg_stopnet_loss:[92m 1.48382 [0m(-0.00170)
     | > avg_decoder_coarse_loss:[92m 1.71879 [0m(-0.00088)
     | > avg_decoder_ddc_loss:[92m 0.00072 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00222 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47132 [0m(-0.00311)
     | > avg_postnet_diff_spec_loss:[92m 0.82002 [0m(-0.00030)
     | > avg_decoder_ssim_loss:[91m 0.30268 [0m(+0.00013)
     | > avg_postnet_ssim_loss:[91m 0.32984 [0m(+0.00020)
     | > avg_loss:[91m 3.46185 [0m(+0.00944)
     | > avg_align_error:[91m 0.99258 [0m(+0.00002)


[4m[1m > EPOCH: 94/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:13:38) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 278275[0m
     | > decoder_loss: 1.77090  (1.71365)
     | > postnet_loss: 1.36531  (1.38599)
     | > stopnet_loss: 1.56928  (1.69957)
     | > decoder_coarse_loss: 1.67916  (1.65909)
     | > decoder_ddc_loss: 0.00067  (0.00089)
     | > ga_loss: 0.00189  (0.00226)
     | > decoder_diff_spec_loss: 0.49246  (0.48241)
     | > postnet_diff_spec_loss: 0.80434  (0.80215)
     | > decoder_ssim_loss: 0.28335  (0.27959)
     | > postnet_ssim_loss: 0.29577  (0.29215)
     | > loss: 3.25171  (3.36483)
     | > align_error: 0.99314  (0.99135)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.00210  (4.76304)
     | > current_lr: 0.00007 
     | > step_time: 5.11110  (5.52746)
     | > loader_time: 0.05850  (0.04497)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 278300[0m
     | > decoder_loss: 1.74662  (1.74829)
     | > postnet_loss: 1.36177  (1.37909)
     | > stopnet_loss: 1.64778  (1.56762)
     | > decoder_coarse_loss: 1.66928  (1.67651)
     | > decoder_ddc_loss: 0.00083  (0.00101)
     | > ga_loss: 0.00228  (0.00228)
     | > decoder_diff_spec_loss: 0.49832  (0.48395)
     | > postnet_diff_spec_loss: 0.80617  (0.79858)
     | > decoder_ssim_loss: 0.27702  (0.30374)
     | > postnet_ssim_loss: 0.29166  (0.31986)
     | > loss: 3.32208  (3.25680)
     | > align_error: 0.99228  (0.99093)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.11845  (3.76508)
     | > current_lr: 0.00007 
     | > step_time: 3.42560  (3.75284)
     | > loader_time: 0.04480  (0.03716)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 278325[0m
     | > decoder_loss: 1.70432  (1.77411)
     | > postnet_loss: 1.41657  (1.39661)
     | > stopnet_loss: 1.42404  (1.56090)
     | > decoder_coarse_loss: 1.68166  (1.70328)
     | > decoder_ddc_loss: 0.00117  (0.00103)
     | > ga_loss: 0.00290  (0.00231)
     | > decoder_diff_spec_loss: 0.45503  (0.49031)
     | > postnet_diff_spec_loss: 0.80384  (0.80249)
     | > decoder_ssim_loss: 0.33161  (0.30463)
     | > postnet_ssim_loss: 0.34879  (0.31999)
     | > loss: 3.12429  (3.27055)
     | > align_error: 0.98924  (0.99071)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.06457  (3.50407)
     | > current_lr: 0.00007 
     | > step_time: 2.31200  (3.70079)
     | > loader_time: 0.02200  (0.03748)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 278350[0m
     | > decoder_loss: 1.50974  (1.76547)
     | > postnet_loss: 1.43876  (1.39443)
     | > stopnet_loss: 2.63605  (1.55695)
     | > decoder_coarse_loss: 1.45576  (1.69699)
     | > decoder_ddc_loss: 0.00061  (0.00103)
     | > ga_loss: 0.00221  (0.00233)
     | > decoder_diff_spec_loss: 0.42612  (0.48862)
     | > postnet_diff_spec_loss: 0.79857  (0.80060)
     | > decoder_ssim_loss: 0.18578  (0.30448)
     | > postnet_ssim_loss: 0.20111  (0.31996)
     | > loss: 4.15123  (3.26148)
     | > align_error: 0.99245  (0.99065)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.69250  (3.49735)
     | > current_lr: 0.00007 
     | > step_time: 4.04030  (3.60573)
     | > loader_time: 0.06890  (0.03640)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.69188 [0m(+0.04231)
     | > avg_decoder_loss:[92m 2.01806 [0m(-0.04857)
     | > avg_postnet_loss:[92m 2.05573 [0m(-0.10200)
     | > avg_stopnet_loss:[91m 1.48660 [0m(+0.00278)
     | > avg_decoder_coarse_loss:[92m 1.71280 [0m(-0.00599)
     | > avg_decoder_ddc_loss:[92m 0.00069 [0m(-0.00003)
     | > avg_ga_loss:[91m 0.00224 [0m(+0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.47089 [0m(-0.00043)
     | > avg_postnet_diff_spec_loss:[92m 0.81886 [0m(-0.00117)
     | > avg_decoder_ssim_loss:[92m 0.30236 [0m(-0.00032)
     | > avg_postnet_ssim_loss:[91m 0.33049 [0m(+0.00065)
     | > avg_loss:[92m 3.42526 [0m(-0.03659)
     | > avg_align_error:[91m 0.99281 [0m(+0.00024)


[4m[1m > EPOCH: 95/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:20:40) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 278375[0m
     | > decoder_loss: 1.89530  (1.73127)
     | > postnet_loss: 1.49604  (1.38744)
     | > stopnet_loss: 1.20607  (1.64213)
     | > decoder_coarse_loss: 1.83888  (1.67751)
     | > decoder_ddc_loss: 0.00112  (0.00099)
     | > ga_loss: 0.00235  (0.00237)
     | > decoder_diff_spec_loss: 0.51114  (0.48456)
     | > postnet_diff_spec_loss: 0.82228  (0.80128)
     | > decoder_ssim_loss: 0.36754  (0.30031)
     | > postnet_ssim_loss: 0.38603  (0.31592)
     | > loss: 3.04743  (3.32880)
     | > align_error: 0.98981  (0.99065)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.45788  (4.07023)
     | > current_lr: 0.00007 
     | > step_time: 3.40720  (3.94048)
     | > loader_time: 0.01710  (0.03905)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 278400[0m
     | > decoder_loss: 2.25730  (1.75860)
     | > postnet_loss: 1.71136  (1.39159)
     | > stopnet_loss: 2.13282  (1.55481)
     | > decoder_coarse_loss: 2.10901  (1.69139)
     | > decoder_ddc_loss: 0.00065  (0.00100)
     | > ga_loss: 0.00173  (0.00229)
     | > decoder_diff_spec_loss: 0.58869  (0.48751)
     | > postnet_diff_spec_loss: 0.86185  (0.79978)
     | > decoder_ssim_loss: 0.22486  (0.30697)
     | > postnet_ssim_loss: 0.23664  (0.32287)
     | > loss: 4.13908  (3.25617)
     | > align_error: 0.99314  (0.99085)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.09332  (3.77955)
     | > current_lr: 0.00007 
     | > step_time: 5.01720  (3.81051)
     | > loader_time: 0.06490  (0.03677)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 278425[0m
     | > decoder_loss: 1.76526  (1.76575)
     | > postnet_loss: 1.36092  (1.39433)
     | > stopnet_loss: 1.73614  (1.56378)
     | > decoder_coarse_loss: 1.68974  (1.69908)
     | > decoder_ddc_loss: 0.00060  (0.00102)
     | > ga_loss: 0.00192  (0.00233)
     | > decoder_diff_spec_loss: 0.49884  (0.48821)
     | > postnet_diff_spec_loss: 0.78175  (0.79997)
     | > decoder_ssim_loss: 0.27460  (0.30520)
     | > postnet_ssim_loss: 0.28529  (0.32096)
     | > loss: 3.40997  (3.26908)
     | > align_error: 0.99329  (0.99064)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.52344  (3.67496)
     | > current_lr: 0.00007 
     | > step_time: 5.04210  (3.68080)
     | > loader_time: 0.01910  (0.03423)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.98782 [0m(+0.29595)
     | > avg_decoder_loss:[91m 2.13468 [0m(+0.11663)
     | > avg_postnet_loss:[91m 2.16776 [0m(+0.11203)
     | > avg_stopnet_loss:[92m 1.48371 [0m(-0.00289)
     | > avg_decoder_coarse_loss:[91m 1.71996 [0m(+0.00715)
     | > avg_decoder_ddc_loss:[91m 0.00073 [0m(+0.00005)
     | > avg_ga_loss:[92m 0.00222 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.47419 [0m(+0.00330)
     | > avg_postnet_diff_spec_loss:[91m 0.82010 [0m(+0.00124)
     | > avg_decoder_ssim_loss:[91m 0.30281 [0m(+0.00045)
     | > avg_postnet_ssim_loss:[92m 0.32961 [0m(-0.00088)
     | > avg_loss:[91m 3.48226 [0m(+0.05699)
     | > avg_align_error:[92m 0.99254 [0m(-0.00027)


[4m[1m > EPOCH: 96/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:27:47) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 278450[0m
     | > decoder_loss: 1.68638  (1.70543)
     | > postnet_loss: 1.43611  (1.44281)
     | > stopnet_loss: 1.61310  (1.75777)
     | > decoder_coarse_loss: 1.63019  (1.65672)
     | > decoder_ddc_loss: 0.00086  (0.00105)
     | > ga_loss: 0.00240  (0.00242)
     | > decoder_diff_spec_loss: 0.46970  (0.48118)
     | > postnet_diff_spec_loss: 0.79055  (0.80298)
     | > decoder_ssim_loss: 0.29326  (0.27853)
     | > postnet_ssim_loss: 0.30446  (0.29083)
     | > loss: 3.27799  (3.43473)
     | > align_error: 0.99118  (0.99014)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.59580  (6.46363)
     | > current_lr: 0.00007 
     | > step_time: 4.72580  (5.45492)
     | > loader_time: 0.02060  (0.02135)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 278475[0m
     | > decoder_loss: 1.66591  (1.74122)
     | > postnet_loss: 1.32323  (1.38444)
     | > stopnet_loss: 1.19588  (1.57859)
     | > decoder_coarse_loss: 1.57718  (1.67576)
     | > decoder_ddc_loss: 0.00123  (0.00096)
     | > ga_loss: 0.00244  (0.00229)
     | > decoder_diff_spec_loss: 0.46180  (0.48491)
     | > postnet_diff_spec_loss: 0.77977  (0.79813)
     | > decoder_ssim_loss: 0.35724  (0.30451)
     | > postnet_ssim_loss: 0.37600  (0.32085)
     | > loss: 2.84367  (3.26775)
     | > align_error: 0.98898  (0.99096)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.44296  (4.17608)
     | > current_lr: 0.00007 
     | > step_time: 3.55770  (3.76788)
     | > loader_time: 0.01870  (0.02713)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 278500[0m
     | > decoder_loss: 1.68045  (1.76906)
     | > postnet_loss: 1.30142  (1.39934)
     | > stopnet_loss: 1.90630  (1.56893)
     | > decoder_coarse_loss: 1.60133  (1.70293)
     | > decoder_ddc_loss: 0.00091  (0.00100)
     | > ga_loss: 0.00264  (0.00230)
     | > decoder_diff_spec_loss: 0.47513  (0.49152)
     | > postnet_diff_spec_loss: 0.78758  (0.80217)
     | > decoder_ssim_loss: 0.24526  (0.30374)
     | > postnet_ssim_loss: 0.25674  (0.31912)
     | > loss: 3.50669  (3.27765)
     | > align_error: 0.99091  (0.99076)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.65816  (3.70200)
     | > current_lr: 0.00007 
     | > step_time: 3.94060  (3.77043)
     | > loader_time: 0.02480  (0.02805)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 278525[0m
     | > decoder_loss: 1.97270  (1.76259)
     | > postnet_loss: 1.47243  (1.39314)
     | > stopnet_loss: 1.18822  (1.54554)
     | > decoder_coarse_loss: 1.87247  (1.69925)
     | > decoder_ddc_loss: 0.00102  (0.00102)
     | > ga_loss: 0.00192  (0.00233)
     | > decoder_diff_spec_loss: 0.53461  (0.48939)
     | > postnet_diff_spec_loss: 0.82652  (0.80023)
     | > decoder_ssim_loss: 0.34683  (0.30558)
     | > postnet_ssim_loss: 0.36098  (0.32118)
     | > loss: 3.04473  (3.25029)
     | > align_error: 0.99153  (0.99060)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.87701  (3.65992)
     | > current_lr: 0.00007 
     | > step_time: 3.82400  (3.64372)
     | > loader_time: 0.02160  (0.02830)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.08117 [0m(+0.09335)
     | > avg_decoder_loss:[92m 2.08119 [0m(-0.05349)
     | > avg_postnet_loss:[92m 2.14016 [0m(-0.02760)
     | > avg_stopnet_loss:[92m 1.48324 [0m(-0.00047)
     | > avg_decoder_coarse_loss:[91m 1.73425 [0m(+0.01429)
     | > avg_decoder_ddc_loss:[92m 0.00071 [0m(-0.00003)
     | > avg_ga_loss:[91m 0.00222 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47350 [0m(-0.00069)
     | > avg_postnet_diff_spec_loss:[92m 0.81938 [0m(-0.00072)
     | > avg_decoder_ssim_loss:[92m 0.30239 [0m(-0.00042)
     | > avg_postnet_ssim_loss:[91m 0.32982 [0m(+0.00021)
     | > avg_loss:[92m 3.46468 [0m(-0.01758)
     | > avg_align_error:[91m 0.99260 [0m(+0.00006)


[4m[1m > EPOCH: 97/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:34:51) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 278550[0m
     | > decoder_loss: 1.83228  (1.72265)
     | > postnet_loss: 1.39073  (1.37140)
     | > stopnet_loss: 2.58509  (1.66262)
     | > decoder_coarse_loss: 1.73443  (1.65648)
     | > decoder_ddc_loss: 0.00104  (0.00096)
     | > ga_loss: 0.00303  (0.00237)
     | > decoder_diff_spec_loss: 0.48332  (0.48255)
     | > postnet_diff_spec_loss: 0.79109  (0.79995)
     | > decoder_ssim_loss: 0.19898  (0.29550)
     | > postnet_ssim_loss: 0.21018  (0.31073)
     | > loss: 4.26076  (3.33451)
     | > align_error: 0.98811  (0.99076)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 11.55775  (3.91484)
     | > current_lr: 0.00007 
     | > step_time: 2.56330  (3.89104)
     | > loader_time: 0.02540  (0.04670)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 278575[0m
     | > decoder_loss: 1.89113  (1.74494)
     | > postnet_loss: 1.37910  (1.37705)
     | > stopnet_loss: 1.25854  (1.53545)
     | > decoder_coarse_loss: 1.82626  (1.67912)
     | > decoder_ddc_loss: 0.00079  (0.00102)
     | > ga_loss: 0.00177  (0.00230)
     | > decoder_diff_spec_loss: 0.50454  (0.48458)
     | > postnet_diff_spec_loss: 0.79322  (0.79791)
     | > decoder_ssim_loss: 0.33291  (0.30881)
     | > postnet_ssim_loss: 0.34856  (0.32487)
     | > loss: 3.03651  (3.22651)
     | > align_error: 0.99254  (0.99072)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.36301  (3.73326)
     | > current_lr: 0.00007 
     | > step_time: 4.72270  (3.60176)
     | > loader_time: 0.02620  (0.03862)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 278600[0m
     | > decoder_loss: 1.64160  (1.76327)
     | > postnet_loss: 1.42401  (1.38685)
     | > stopnet_loss: 1.24613  (1.55127)
     | > decoder_coarse_loss: 1.58636  (1.69502)
     | > decoder_ddc_loss: 0.00129  (0.00103)
     | > ga_loss: 0.00256  (0.00233)
     | > decoder_diff_spec_loss: 0.43688  (0.48753)
     | > postnet_diff_spec_loss: 0.78793  (0.79967)
     | > decoder_ssim_loss: 0.36321  (0.30534)
     | > postnet_ssim_loss: 0.38862  (0.32109)
     | > loss: 2.91642  (3.25288)
     | > align_error: 0.98918  (0.99053)
     | > amp_scaler: 65536.00000  (33792.00000)
     | > grad_norm: 2.80330  (3.58046)
     | > current_lr: 0.00007 
     | > step_time: 2.79650  (3.51813)
     | > loader_time: 0.02280  (0.03554)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.77388 [0m(-0.30729)
     | > avg_decoder_loss:[91m 2.09332 [0m(+0.01213)
     | > avg_postnet_loss:[91m 2.24487 [0m(+0.10472)
     | > avg_stopnet_loss:[91m 1.48436 [0m(+0.00112)
     | > avg_decoder_coarse_loss:[92m 1.73224 [0m(-0.00201)
     | > avg_decoder_ddc_loss:[91m 0.00072 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00221 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47312 [0m(-0.00038)
     | > avg_postnet_diff_spec_loss:[91m 0.82046 [0m(+0.00108)
     | > avg_decoder_ssim_loss:[92m 0.30219 [0m(-0.00019)
     | > avg_postnet_ssim_loss:[92m 0.32956 [0m(-0.00026)
     | > avg_loss:[91m 3.49453 [0m(+0.02985)
     | > avg_align_error:[92m 0.99256 [0m(-0.00005)


[4m[1m > EPOCH: 98/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:42:04) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 278625[0m
     | > decoder_loss: 1.70866  (1.70866)
     | > postnet_loss: 1.41185  (1.41185)
     | > stopnet_loss: 1.90505  (1.90505)
     | > decoder_coarse_loss: 1.64158  (1.64158)
     | > decoder_ddc_loss: 0.00115  (0.00115)
     | > ga_loss: 0.00244  (0.00244)
     | > decoder_diff_spec_loss: 0.48999  (0.48999)
     | > postnet_diff_spec_loss: 0.81170  (0.81170)
     | > decoder_ssim_loss: 0.26315  (0.26315)
     | > postnet_ssim_loss: 0.27595  (0.27595)
     | > loss: 3.56825  (3.56825)
     | > align_error: 0.98946  (0.98946)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.50014  (9.50014)
     | > current_lr: 0.00007 
     | > step_time: 6.40680  (6.40682)
     | > loader_time: 0.02250  (0.02252)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 278650[0m
     | > decoder_loss: 1.80033  (1.73552)
     | > postnet_loss: 1.40400  (1.36716)
     | > stopnet_loss: 1.38278  (1.58447)
     | > decoder_coarse_loss: 1.75230  (1.67199)
     | > decoder_ddc_loss: 0.00116  (0.00094)
     | > ga_loss: 0.00268  (0.00227)
     | > decoder_diff_spec_loss: 0.50272  (0.48362)
     | > postnet_diff_spec_loss: 0.80350  (0.79790)
     | > decoder_ssim_loss: 0.32668  (0.30193)
     | > postnet_ssim_loss: 0.34742  (0.31824)
     | > loss: 3.13072  (3.26517)
     | > align_error: 0.98905  (0.99104)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.46175  (3.90423)
     | > current_lr: 0.00007 
     | > step_time: 2.67040  (3.74214)
     | > loader_time: 0.02070  (0.03559)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 278675[0m
     | > decoder_loss: 1.84560  (1.76162)
     | > postnet_loss: 1.47067  (1.38726)
     | > stopnet_loss: 1.31283  (1.55885)
     | > decoder_coarse_loss: 1.77598  (1.69648)
     | > decoder_ddc_loss: 0.00141  (0.00099)
     | > ga_loss: 0.00308  (0.00228)
     | > decoder_diff_spec_loss: 0.51130  (0.48987)
     | > postnet_diff_spec_loss: 0.81205  (0.80202)
     | > decoder_ssim_loss: 0.35540  (0.30438)
     | > postnet_ssim_loss: 0.37236  (0.32019)
     | > loss: 3.11441  (3.26094)
     | > align_error: 0.98786  (0.99075)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.32702  (3.49893)
     | > current_lr: 0.00007 
     | > step_time: 2.48410  (3.69164)
     | > loader_time: 0.01420  (0.03234)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 278700[0m
     | > decoder_loss: 1.76483  (1.75258)
     | > postnet_loss: 1.41737  (1.38232)
     | > stopnet_loss: 1.04618  (1.54847)
     | > decoder_coarse_loss: 1.69141  (1.68799)
     | > decoder_ddc_loss: 0.00183  (0.00101)
     | > ga_loss: 0.00311  (0.00232)
     | > decoder_diff_spec_loss: 0.51610  (0.48765)
     | > postnet_diff_spec_loss: 0.83135  (0.79966)
     | > decoder_ssim_loss: 0.40520  (0.30457)
     | > postnet_ssim_loss: 0.42572  (0.32041)
     | > loss: 2.82519  (3.24411)
     | > align_error: 0.98470  (0.99059)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.98775  (3.43644)
     | > current_lr: 0.00007 
     | > step_time: 2.74190  (3.58336)
     | > loader_time: 0.01900  (0.03464)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.54054 [0m(-0.23334)
     | > avg_decoder_loss:[92m 2.03636 [0m(-0.05696)
     | > avg_postnet_loss:[92m 2.16059 [0m(-0.08428)
     | > avg_stopnet_loss:[92m 1.48369 [0m(-0.00068)
     | > avg_decoder_coarse_loss:[91m 1.75006 [0m(+0.01781)
     | > avg_decoder_ddc_loss:[92m 0.00069 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00222 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47366 [0m(+0.00054)
     | > avg_postnet_diff_spec_loss:[92m 0.81903 [0m(-0.00143)
     | > avg_decoder_ssim_loss:[92m 0.30186 [0m(-0.00034)
     | > avg_postnet_ssim_loss:[92m 0.32831 [0m(-0.00126)
     | > avg_loss:[92m 3.46241 [0m(-0.03212)
     | > avg_align_error:[91m 0.99261 [0m(+0.00005)


[4m[1m > EPOCH: 99/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:49:09) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 278725[0m
     | > decoder_loss: 1.73885  (1.70322)
     | > postnet_loss: 1.33925  (1.36918)
     | > stopnet_loss: 2.89912  (1.60505)
     | > decoder_coarse_loss: 1.67718  (1.64340)
     | > decoder_ddc_loss: 0.00057  (0.00099)
     | > ga_loss: 0.00211  (0.00230)
     | > decoder_diff_spec_loss: 0.50642  (0.48293)
     | > postnet_diff_spec_loss: 0.80644  (0.80023)
     | > decoder_ssim_loss: 0.17192  (0.30220)
     | > postnet_ssim_loss: 0.18104  (0.31882)
     | > loss: 4.51507  (3.27179)
     | > align_error: 0.99392  (0.99084)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.59451  (3.64881)
     | > current_lr: 0.00007 
     | > step_time: 3.55280  (3.89711)
     | > loader_time: 0.06040  (0.03946)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 278750[0m
     | > decoder_loss: 1.81348  (1.73650)
     | > postnet_loss: 1.37742  (1.37236)
     | > stopnet_loss: 1.50103  (1.53703)
     | > decoder_coarse_loss: 1.72434  (1.66641)
     | > decoder_ddc_loss: 0.00096  (0.00100)
     | > ga_loss: 0.00234  (0.00230)
     | > decoder_diff_spec_loss: 0.48946  (0.48443)
     | > postnet_diff_spec_loss: 0.79850  (0.79771)
     | > decoder_ssim_loss: 0.30116  (0.30797)
     | > postnet_ssim_loss: 0.31488  (0.32414)
     | > loss: 3.21777  (3.22117)
     | > align_error: 0.99112  (0.99071)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.80024  (3.56330)
     | > current_lr: 0.00007 
     | > step_time: 3.29410  (3.62696)
     | > loader_time: 0.02930  (0.03429)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 278775[0m
     | > decoder_loss: 1.85931  (1.75973)
     | > postnet_loss: 1.43203  (1.38316)
     | > stopnet_loss: 1.44000  (1.55863)
     | > decoder_coarse_loss: 1.82213  (1.69105)
     | > decoder_ddc_loss: 0.00114  (0.00100)
     | > ga_loss: 0.00269  (0.00233)
     | > decoder_diff_spec_loss: 0.49428  (0.48895)
     | > postnet_diff_spec_loss: 0.79114  (0.79988)
     | > decoder_ssim_loss: 0.32324  (0.30429)
     | > postnet_ssim_loss: 0.33629  (0.32004)
     | > loss: 3.21836  (3.25730)
     | > align_error: 0.98983  (0.99060)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.55172  (3.63896)
     | > current_lr: 0.00007 
     | > step_time: 2.86620  (3.60754)
     | > loader_time: 0.01590  (0.03401)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.89236 [0m(+0.35183)
     | > avg_decoder_loss:[91m 2.08080 [0m(+0.04444)
     | > avg_postnet_loss:[91m 2.24450 [0m(+0.08391)
     | > avg_stopnet_loss:[92m 1.48275 [0m(-0.00094)
     | > avg_decoder_coarse_loss:[92m 1.73458 [0m(-0.01548)
     | > avg_decoder_ddc_loss:[91m 0.00070 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00221 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47455 [0m(+0.00089)
     | > avg_postnet_diff_spec_loss:[91m 0.82075 [0m(+0.00172)
     | > avg_decoder_ssim_loss:[91m 0.30219 [0m(+0.00033)
     | > avg_postnet_ssim_loss:[91m 0.32953 [0m(+0.00122)
     | > avg_loss:[91m 3.49072 [0m(+0.02831)
     | > avg_align_error:[92m 0.99257 [0m(-0.00004)

