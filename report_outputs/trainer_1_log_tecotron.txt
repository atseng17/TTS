 > Using CUDA:  True
 > Number of GPUs:  4
 > `speakers.json` is saved to /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf/speakers.json.
 > `speakers_file` is updated in the config.json.
 > Restoring from model_file.pth.tar ...
 > Restoring Model...
 > Partial model initialization...
 | > Layer missing in the model definition: encoder.convolutions.0.convolution1d.weight
 | > Layer missing in the model definition: encoder.convolutions.0.convolution1d.bias
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.weight
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.bias
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.running_mean
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.running_var
 | > Layer missing in the model definition: encoder.convolutions.0.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: encoder.convolutions.1.convolution1d.weight
 | > Layer missing in the model definition: encoder.convolutions.1.convolution1d.bias
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.weight
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.bias
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.running_mean
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.running_var
 | > Layer missing in the model definition: encoder.convolutions.1.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: encoder.convolutions.2.convolution1d.weight
 | > Layer missing in the model definition: encoder.convolutions.2.convolution1d.bias
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.weight
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.bias
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.running_mean
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.running_var
 | > Layer missing in the model definition: encoder.convolutions.2.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: encoder.lstm.weight_ih_l0
 | > Layer missing in the model definition: encoder.lstm.weight_hh_l0
 | > Layer missing in the model definition: encoder.lstm.bias_ih_l0
 | > Layer missing in the model definition: encoder.lstm.bias_hh_l0
 | > Layer missing in the model definition: encoder.lstm.weight_ih_l0_reverse
 | > Layer missing in the model definition: encoder.lstm.weight_hh_l0_reverse
 | > Layer missing in the model definition: encoder.lstm.bias_ih_l0_reverse
 | > Layer missing in the model definition: encoder.lstm.bias_hh_l0_reverse
 | > Layer missing in the model definition: decoder.attention.prior
 | > Layer missing in the model definition: decoder.attention.query_layer.weight
 | > Layer missing in the model definition: decoder.attention.query_layer.bias
 | > Layer missing in the model definition: decoder.attention.key_layer.weight
 | > Layer missing in the model definition: decoder.attention.static_filter_conv.weight
 | > Layer missing in the model definition: decoder.attention.static_filter_layer.weight
 | > Layer missing in the model definition: decoder.attention.dynamic_filter_layer.weight
 | > Layer missing in the model definition: decoder.attention.dynamic_filter_layer.bias
 | > Layer missing in the model definition: decoder.attention.v.weight
 | > Layer missing in the model definition: decoder.decoder_rnn.weight_ih
 | > Layer missing in the model definition: decoder.decoder_rnn.weight_hh
 | > Layer missing in the model definition: decoder.decoder_rnn.bias_ih
 | > Layer missing in the model definition: decoder.decoder_rnn.bias_hh
 | > Layer missing in the model definition: decoder.linear_projection.linear_layer.weight
 | > Layer missing in the model definition: decoder.linear_projection.linear_layer.bias
 | > Layer missing in the model definition: decoder.stopnet.1.linear_layer.weight
 | > Layer missing in the model definition: decoder.stopnet.1.linear_layer.bias
 | > Layer missing in the model definition: postnet.convolutions.0.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.0.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.0.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.1.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.1.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.1.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.2.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.2.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.2.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.3.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.3.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.3.batch_normalization.num_batches_tracked
 | > Layer missing in the model definition: postnet.convolutions.4.convolution1d.weight
 | > Layer missing in the model definition: postnet.convolutions.4.convolution1d.bias
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.weight
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.bias
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.running_mean
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.running_var
 | > Layer missing in the model definition: postnet.convolutions.4.batch_normalization.num_batches_tracked
 | > 1 / 281 layers are restored.
 > Model restored from step 270000

 > Model has 9749029 parameters
 > Restoring best loss from  ...
 > Starting with loaded last best loss 0.09947767853736877.

[4m[1m > EPOCH: 0/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 09:38:16) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 270000[0m
     | > decoder_loss: 33.01016  (33.01016)
     | > postnet_loss: 19.62464  (19.62464)
     | > stopnet_loss: 1.74442  (1.74442)
     | > decoder_coarse_loss: 33.13115  (33.13115)
     | > decoder_ddc_loss: 0.00062  (0.00062)
     | > ga_loss: 0.00341  (0.00341)
     | > decoder_diff_spec_loss: 0.42874  (0.42874)
     | > postnet_diff_spec_loss: 0.86152  (0.86152)
     | > decoder_ssim_loss: 0.42721  (0.42721)
     | > postnet_ssim_loss: 0.42717  (0.42717)
     | > loss: 23.73927  (23.73927)
     | > align_error: 0.99306  (0.99306)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.75615  (1.75615)
     | > current_lr: 2.5000000000000002e-08 
     | > step_time: 4.70290  (4.70293)
     | > loader_time: 8.14940  (8.14941)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 270025[0m
     | > decoder_loss: 34.35991  (33.65945)
     | > postnet_loss: 21.39996  (19.81795)
     | > stopnet_loss: 1.38524  (1.88848)
     | > decoder_coarse_loss: 34.50363  (33.77635)
     | > decoder_ddc_loss: 0.00059  (0.00055)
     | > ga_loss: 0.00270  (0.00262)
     | > decoder_diff_spec_loss: 0.44605  (0.43545)
     | > postnet_diff_spec_loss: 0.87446  (0.86866)
     | > decoder_ssim_loss: 0.54765  (0.40295)
     | > postnet_ssim_loss: 0.54758  (0.40291)
     | > loss: 24.56867  (24.24262)
     | > align_error: 0.99341  (0.99444)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.79788  (1.79166)
     | > current_lr: 6.5e-07 
     | > step_time: 2.81590  (3.99611)
     | > loader_time: 0.04510  (0.03572)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 270050[0m
     | > decoder_loss: 30.78279  (33.83642)
     | > postnet_loss: 17.82067  (20.14841)
     | > stopnet_loss: 1.49023  (1.84917)
     | > decoder_coarse_loss: 30.91906  (33.95819)
     | > decoder_ddc_loss: 0.00052  (0.00055)
     | > ga_loss: 0.00285  (0.00268)
     | > decoder_diff_spec_loss: 0.41801  (0.43351)
     | > postnet_diff_spec_loss: 0.85700  (0.86482)
     | > decoder_ssim_loss: 0.50438  (0.41057)
     | > postnet_ssim_loss: 0.50433  (0.41053)
     | > loss: 21.95617  (24.37831)
     | > align_error: 0.99373  (0.99434)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.75892  (1.79171)
     | > current_lr: 1.275e-06 
     | > step_time: 2.84270  (3.81747)
     | > loader_time: 0.02030  (0.03436)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 270075[0m
     | > decoder_loss: 33.22558  (33.86237)
     | > postnet_loss: 19.08966  (20.15227)
     | > stopnet_loss: 1.68351  (1.85118)
     | > decoder_coarse_loss: 33.35542  (33.98283)
     | > decoder_ddc_loss: 0.00058  (0.00055)
     | > ga_loss: 0.00291  (0.00270)
     | > decoder_diff_spec_loss: 0.43941  (0.43134)
     | > postnet_diff_spec_loss: 0.87043  (0.86368)
     | > decoder_ssim_loss: 0.44089  (0.41071)
     | > postnet_ssim_loss: 0.44085  (0.41067)
     | > loss: 23.66378  (24.39327)
     | > align_error: 0.99414  (0.99435)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.82820  (1.79314)
     | > current_lr: 1.9e-06 
     | > step_time: 3.56690  (3.78114)
     | > loader_time: 0.02730  (0.03536)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time: 5.79974 [0m(+0.00000)
     | > avg_decoder_loss: 32.83392 [0m(+0.00000)
     | > avg_postnet_loss: 19.04105 [0m(+0.00000)
     | > avg_stopnet_loss: 1.72958 [0m(+0.00000)
     | > avg_decoder_coarse_loss: 32.94556 [0m(+0.00000)
     | > avg_decoder_ddc_loss: 0.00044 [0m(+0.00000)
     | > avg_ga_loss: 0.00234 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss: 0.43754 [0m(+0.00000)
     | > avg_postnet_diff_spec_loss: 0.88391 [0m(+0.00000)
     | > avg_decoder_ssim_loss: 0.42548 [0m(+0.00000)
     | > avg_postnet_ssim_loss: 0.42542 [0m(+0.00000)
     | > avg_loss: 23.48958 [0m(+0.00000)
     | > avg_align_error: 0.99493 [0m(+0.00000)


[4m[1m > EPOCH: 1/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 09:46:10) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 270100[0m
     | > decoder_loss: 34.67686  (34.07715)
     | > postnet_loss: 19.56574  (20.38354)
     | > stopnet_loss: 2.19261  (1.85466)
     | > decoder_coarse_loss: 34.81317  (34.19752)
     | > decoder_ddc_loss: 0.00052  (0.00055)
     | > ga_loss: 0.00247  (0.00280)
     | > decoder_diff_spec_loss: 0.41586  (0.43998)
     | > postnet_diff_spec_loss: 0.85954  (0.87185)
     | > decoder_ssim_loss: 0.32716  (0.40358)
     | > postnet_ssim_loss: 0.32713  (0.40355)
     | > loss: 24.95147  (24.56310)
     | > align_error: 0.99536  (0.99423)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.76693  (1.78861)
     | > current_lr: 2.525e-06 
     | > step_time: 5.67830  (4.12178)
     | > loader_time: 0.02970  (0.04315)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 270125[0m
     | > decoder_loss: 33.25983  (33.69833)
     | > postnet_loss: 19.31446  (19.97443)
     | > stopnet_loss: 1.46655  (1.85346)
     | > decoder_coarse_loss: 33.37909  (33.81394)
     | > decoder_ddc_loss: 0.00053  (0.00053)
     | > ga_loss: 0.00282  (0.00263)
     | > decoder_diff_spec_loss: 0.42494  (0.43571)
     | > postnet_diff_spec_loss: 0.86140  (0.86687)
     | > decoder_ssim_loss: 0.49960  (0.41172)
     | > postnet_ssim_loss: 0.49955  (0.41168)
     | > loss: 23.54052  (24.26992)
     | > align_error: 0.99405  (0.99439)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.76854  (1.79799)
     | > current_lr: 3.1500000000000003e-06 
     | > step_time: 3.07150  (3.93098)
     | > loader_time: 0.04020  (0.03893)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 270150[0m
     | > decoder_loss: 32.65532  (33.86864)
     | > postnet_loss: 19.32024  (20.21200)
     | > stopnet_loss: 1.78188  (1.84685)
     | > decoder_coarse_loss: 32.78041  (33.98514)
     | > decoder_ddc_loss: 0.00039  (0.00053)
     | > ga_loss: 0.00184  (0.00268)
     | > decoder_diff_spec_loss: 0.39628  (0.43180)
     | > postnet_diff_spec_loss: 0.84221  (0.86354)
     | > decoder_ssim_loss: 0.42256  (0.41279)
     | > postnet_ssim_loss: 0.42252  (0.41275)
     | > loss: 23.50107  (24.40708)
     | > align_error: 0.99576  (0.99435)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.98987  (1.81105)
     | > current_lr: 3.7750000000000003e-06 
     | > step_time: 4.81920  (3.79989)
     | > loader_time: 0.02220  (0.03545)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 270175[0m
     | > decoder_loss: 28.53727  (33.68541)
     | > postnet_loss: 13.15859  (20.07255)
     | > stopnet_loss: 1.57386  (1.85849)
     | > decoder_coarse_loss: 28.59112  (33.79671)
     | > decoder_ddc_loss: 0.00103  (0.00054)
     | > ga_loss: 0.00464  (0.00275)
     | > decoder_diff_spec_loss: 0.35683  (0.43075)
     | > postnet_diff_spec_loss: 0.76526  (0.86258)
     | > decoder_ssim_loss: 0.48624  (0.40988)
     | > postnet_ssim_loss: 0.48621  (0.40985)
     | > loss: 19.69270  (24.28930)
     | > align_error: 0.98751  (0.99422)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 1.77758  (1.81914)
     | > current_lr: 4.4e-06 
     | > step_time: 1.02030  (3.67420)
     | > loader_time: 0.00520  (0.03349)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.47838 [0m(-0.32136)
     | > avg_decoder_loss:[92m 32.72975 [0m(-0.10416)
     | > avg_postnet_loss:[92m 18.97413 [0m(-0.06692)
     | > avg_stopnet_loss:[91m 1.73497 [0m(+0.00539)
     | > avg_decoder_coarse_loss:[92m 32.73830 [0m(-0.20726)
     | > avg_decoder_ddc_loss:[92m 0.00042 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00233 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.43847 [0m(+0.00094)
     | > avg_postnet_diff_spec_loss:[92m 0.88373 [0m(-0.00018)
     | > avg_decoder_ssim_loss:[92m 0.42547 [0m(-0.00001)
     | > avg_postnet_ssim_loss:[92m 0.42541 [0m(-0.00001)
     | > avg_loss:[92m 23.40056 [0m(-0.08902)
     | > avg_align_error:[91m 0.99494 [0m(+0.00001)


[4m[1m > EPOCH: 2/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 09:53:52) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 270200[0m
     | > decoder_loss: 33.84975  (33.39883)
     | > postnet_loss: 18.84440  (19.65243)
     | > stopnet_loss: 1.47607  (1.92107)
     | > decoder_coarse_loss: 33.97687  (33.50720)
     | > decoder_ddc_loss: 0.00041  (0.00049)
     | > ga_loss: 0.00230  (0.00261)
     | > decoder_diff_spec_loss: 0.42619  (0.43710)
     | > postnet_diff_spec_loss: 0.86958  (0.86831)
     | > decoder_ssim_loss: 0.48996  (0.39691)
     | > postnet_ssim_loss: 0.48992  (0.39688)
     | > loss: 23.72433  (24.09864)
     | > align_error: 0.99481  (0.99452)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.01865  (1.95395)
     | > current_lr: 0.00001 
     | > step_time: 3.98570  (3.91860)
     | > loader_time: 0.07620  (0.03681)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 270225[0m
     | > decoder_loss: 34.08186  (33.61274)
     | > postnet_loss: 21.84275  (20.07682)
     | > stopnet_loss: 1.57209  (1.86744)
     | > decoder_coarse_loss: 34.22886  (33.72703)
     | > decoder_ddc_loss: 0.00032  (0.00048)
     | > ga_loss: 0.00220  (0.00267)
     | > decoder_diff_spec_loss: 0.44282  (0.43755)
     | > postnet_diff_spec_loss: 0.86454  (0.86479)
     | > decoder_ssim_loss: 0.47878  (0.40863)
     | > postnet_ssim_loss: 0.47880  (0.40861)
     | > loss: 24.68777  (24.26496)
     | > align_error: 0.99575  (0.99439)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.36655  (2.03612)
     | > current_lr: 0.00001 
     | > step_time: 4.41590  (3.69941)
     | > loader_time: 0.04380  (0.03591)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 270250[0m
     | > decoder_loss: 32.28986  (33.51669)
     | > postnet_loss: 17.56863  (20.02462)
     | > stopnet_loss: 1.58813  (1.86489)
     | > decoder_coarse_loss: 32.45286  (33.63502)
     | > decoder_ddc_loss: 0.00041  (0.00047)
     | > ga_loss: 0.00255  (0.00269)
     | > decoder_diff_spec_loss: 0.45283  (0.43764)
     | > postnet_diff_spec_loss: 0.88438  (0.86328)
     | > decoder_ssim_loss: 0.47190  (0.41027)
     | > postnet_ssim_loss: 0.47190  (0.41025)
     | > loss: 22.74906  (24.20289)
     | > align_error: 0.99468  (0.99441)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 2.69475  (2.15712)
     | > current_lr: 0.00001 
     | > step_time: 3.38260  (3.67268)
     | > loader_time: 0.02140  (0.03693)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.90922 [0m(+1.43084)
     | > avg_decoder_loss:[92m 32.37328 [0m(-0.35648)
     | > avg_postnet_loss:[92m 18.82662 [0m(-0.14751)
     | > avg_stopnet_loss:[91m 1.74199 [0m(+0.00702)
     | > avg_decoder_coarse_loss:[92m 32.18095 [0m(-0.55735)
     | > avg_decoder_ddc_loss:[92m 0.00038 [0m(-0.00003)
     | > avg_ga_loss:[92m 0.00233 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.44860 [0m(+0.01013)
     | > avg_postnet_diff_spec_loss:[92m 0.88280 [0m(-0.00093)
     | > avg_decoder_ssim_loss:[92m 0.42543 [0m(-0.00004)
     | > avg_postnet_ssim_loss:[92m 0.42540 [0m(-0.00001)
     | > avg_loss:[92m 23.14450 [0m(-0.25606)
     | > avg_align_error:[91m 0.99495 [0m(+0.00001)


[4m[1m > EPOCH: 3/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:01:25) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 270275[0m
     | > decoder_loss: 29.94513  (33.23674)
     | > postnet_loss: 16.71458  (20.19062)
     | > stopnet_loss: 2.25707  (1.83367)
     | > decoder_coarse_loss: 30.07209  (33.39587)
     | > decoder_ddc_loss: 0.00044  (0.00043)
     | > ga_loss: 0.00311  (0.00282)
     | > decoder_diff_spec_loss: 0.48603  (0.46873)
     | > postnet_diff_spec_loss: 0.88057  (0.87252)
     | > decoder_ssim_loss: 0.32938  (0.41044)
     | > postnet_ssim_loss: 0.32943  (0.41047)
     | > loss: 21.96205  (24.09421)
     | > align_error: 0.99447  (0.99422)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 3.00861  (2.96540)
     | > current_lr: 0.00001 
     | > step_time: 3.61340  (3.90560)
     | > loader_time: 0.01600  (0.03425)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 270300[0m
     | > decoder_loss: 33.08929  (32.74310)
     | > postnet_loss: 20.29279  (19.68657)
     | > stopnet_loss: 1.61672  (1.87261)
     | > decoder_coarse_loss: 33.26651  (32.92468)
     | > decoder_ddc_loss: 0.00033  (0.00040)
     | > ga_loss: 0.00223  (0.00261)
     | > decoder_diff_spec_loss: 0.47834  (0.47489)
     | > postnet_diff_spec_loss: 0.84329  (0.86640)
     | > decoder_ssim_loss: 0.46212  (0.40915)
     | > postnet_ssim_loss: 0.46228  (0.40922)
     | > loss: 23.85163  (23.76427)
     | > align_error: 0.99444  (0.99449)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 3.94170  (3.35257)
     | > current_lr: 0.00001 
     | > step_time: 4.02550  (3.86895)
     | > loader_time: 0.01750  (0.03319)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 270325[0m
     | > decoder_loss: 31.95064  (32.64423)
     | > postnet_loss: 20.08348  (19.87056)
     | > stopnet_loss: 1.58511  (1.85671)
     | > decoder_coarse_loss: 32.25444  (32.87270)
     | > decoder_ddc_loss: 0.00063  (0.00040)
     | > ga_loss: 0.00487  (0.00268)
     | > decoder_diff_spec_loss: 0.54911  (0.49116)
     | > postnet_diff_spec_loss: 0.87584  (0.86322)
     | > decoder_ssim_loss: 0.48675  (0.41244)
     | > postnet_ssim_loss: 0.48712  (0.41256)
     | > loss: 23.28146  (23.76194)
     | > align_error: 0.98970  (0.99442)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 4.35512  (3.86413)
     | > current_lr: 0.00001 
     | > step_time: 2.31650  (3.71611)
     | > loader_time: 0.01380  (0.03068)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 270350[0m
     | > decoder_loss: 30.57135  (32.13882)
     | > postnet_loss: 19.82821  (19.74072)
     | > stopnet_loss: 1.70314  (1.86936)
     | > decoder_coarse_loss: 31.03277  (32.42569)
     | > decoder_ddc_loss: 0.00037  (0.00040)
     | > ga_loss: 0.00291  (0.00271)
     | > decoder_diff_spec_loss: 0.64580  (0.52135)
     | > postnet_diff_spec_loss: 0.88032  (0.86297)
     | > decoder_ssim_loss: 0.43236  (0.40871)
     | > postnet_ssim_loss: 0.43312  (0.40893)
     | > loss: 22.67377  (23.50979)
     | > align_error: 0.99399  (0.99440)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 6.57574  (4.51458)
     | > current_lr: 0.00001 
     | > step_time: 2.18390  (3.63748)
     | > loader_time: 0.02270  (0.03011)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.95672 [0m(-0.95249)
     | > avg_decoder_loss:[92m 30.71505 [0m(-1.65822)
     | > avg_postnet_loss:[92m 18.67969 [0m(-0.14692)
     | > avg_stopnet_loss:[92m 1.73574 [0m(-0.00626)
     | > avg_decoder_coarse_loss:[92m 30.23808 [0m(-1.94287)
     | > avg_decoder_ddc_loss:[92m 0.00037 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00231 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.53603 [0m(+0.08743)
     | > avg_postnet_diff_spec_loss:[92m 0.88184 [0m(-0.00097)
     | > avg_decoder_ssim_loss:[92m 0.42514 [0m(-0.00029)
     | > avg_postnet_ssim_loss:[92m 0.42539 [0m(-0.00001)
     | > avg_loss:[92m 22.22271 [0m(-0.92179)
     | > avg_align_error:[92m 0.99494 [0m(-0.00001)


[4m[1m > EPOCH: 4/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:09:00) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 270375[0m
     | > decoder_loss: 27.92345  (29.66409)
     | > postnet_loss: 16.99198  (18.99426)
     | > stopnet_loss: 2.79415  (1.92665)
     | > decoder_coarse_loss: 28.71739  (30.30727)
     | > decoder_ddc_loss: 0.00038  (0.00039)
     | > ga_loss: 0.00218  (0.00258)
     | > decoder_diff_spec_loss: 0.81917  (0.72733)
     | > postnet_diff_spec_loss: 0.83836  (0.86731)
     | > decoder_ssim_loss: 0.25829  (0.39183)
     | > postnet_ssim_loss: 0.25907  (0.39277)
     | > loss: 21.75709  (22.27587)
     | > align_error: 0.99538  (0.99458)
     | > amp_scaler: 65536.00000  (65536.00000)
     | > grad_norm: 9.14475  (8.02545)
     | > current_lr: 0.00001 
     | > step_time: 5.01330  (3.96914)
     | > loader_time: 0.11440  (0.04324)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 270400[0m
     | > decoder_loss: 28.43628  (29.21638)
     | > postnet_loss: 18.31024  (19.28360)
     | > stopnet_loss: 1.75444  (1.84752)
     | > decoder_coarse_loss: 29.40019  (29.96362)
     | > decoder_ddc_loss: 0.00053  (0.00041)
     | > ga_loss: 0.00296  (0.00263)
     | > decoder_diff_spec_loss: 0.92880  (0.79580)
     | > postnet_diff_spec_loss: 0.87515  (0.86383)
     | > decoder_ssim_loss: 0.40236  (0.40573)
     | > postnet_ssim_loss: 0.40458  (0.40708)
     | > loss: 21.45878  (22.09479)
     | > align_error: 0.99375  (0.99440)
     | > amp_scaler: 32768.00000  (50517.33333)
     | > grad_norm: 10.13224  (8.54810)
     | > current_lr: 0.00001 
     | > step_time: 3.52990  (3.74929)
     | > loader_time: 0.05910  (0.04014)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 270425[0m
     | > decoder_loss: 23.63681  (28.39345)
     | > postnet_loss: 16.56100  (19.22314)
     | > stopnet_loss: 2.46455  (1.82272)
     | > decoder_coarse_loss: 24.80955  (29.23884)
     | > decoder_ddc_loss: 0.00036  (0.00044)
     | > ga_loss: 0.00256  (0.00263)
     | > decoder_diff_spec_loss: 1.21427  (0.87813)
     | > postnet_diff_spec_loss: 0.84566  (0.86205)
     | > decoder_ssim_loss: 0.28338  (0.40747)
     | > postnet_ssim_loss: 0.28603  (0.40932)
     | > loss: 19.38660  (21.68911)
     | > align_error: 0.99585  (0.99441)
     | > amp_scaler: 32768.00000  (44438.79452)
     | > grad_norm: 10.63656  (9.33026)
     | > current_lr: 0.00001 
     | > step_time: 4.40060  (3.75510)
     | > loader_time: 0.02220  (0.03931)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.71720 [0m(-0.23952)
     | > avg_decoder_loss:[92m 25.68106 [0m(-5.03400)
     | > avg_postnet_loss:[92m 18.10059 [0m(-0.57911)
     | > avg_stopnet_loss:[92m 1.57352 [0m(-0.16222)
     | > avg_decoder_coarse_loss:[92m 25.49369 [0m(-4.74439)
     | > avg_decoder_ddc_loss:[91m 0.00048 [0m(+0.00011)
     | > avg_ga_loss:[92m 0.00227 [0m(-0.00004)
     | > avg_decoder_diff_spec_loss:[91m 0.91418 [0m(+0.37815)
     | > avg_postnet_diff_spec_loss:[92m 0.88164 [0m(-0.00020)
     | > avg_decoder_ssim_loss:[92m 0.42272 [0m(-0.00243)
     | > avg_postnet_ssim_loss:[92m 0.42532 [0m(-0.00007)
     | > avg_loss:[92m 19.56479 [0m(-2.65792)
     | > avg_align_error:[92m 0.99484 [0m(-0.00010)


[4m[1m > EPOCH: 5/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:16:27) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 270450[0m
     | > decoder_loss: 24.25331  (24.54568)
     | > postnet_loss: 18.43381  (19.23303)
     | > stopnet_loss: 1.68819  (1.61513)
     | > decoder_coarse_loss: 25.50496  (25.76295)
     | > decoder_ddc_loss: 0.00062  (0.00062)
     | > ga_loss: 0.00261  (0.00268)
     | > decoder_diff_spec_loss: 1.38015  (1.28645)
     | > postnet_diff_spec_loss: 0.92341  (0.87117)
     | > decoder_ssim_loss: 0.38137  (0.41328)
     | > postnet_ssim_loss: 0.38616  (0.41840)
     | > loss: 19.51719  (19.76142)
     | > align_error: 0.99442  (0.99397)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 11.02355  (11.10799)
     | > current_lr: 0.00001 
     | > step_time: 3.46740  (3.98818)
     | > loader_time: 0.04430  (0.04800)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 270475[0m
     | > decoder_loss: 21.20668  (22.76082)
     | > postnet_loss: 18.36211  (18.19989)
     | > stopnet_loss: 1.66065  (1.66745)
     | > decoder_coarse_loss: 22.50181  (23.99050)
     | > decoder_ddc_loss: 0.00073  (0.00063)
     | > ga_loss: 0.00252  (0.00252)
     | > decoder_diff_spec_loss: 1.53372  (1.37104)
     | > postnet_diff_spec_loss: 0.90230  (0.86644)
     | > decoder_ssim_loss: 0.37379  (0.40127)
     | > postnet_ssim_loss: 0.38088  (0.40751)
     | > loss: 17.98874  (18.67957)
     | > align_error: 0.99420  (0.99419)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.55738  (10.52460)
     | > current_lr: 0.00001 
     | > step_time: 3.59380  (3.87373)
     | > loader_time: 0.03990  (0.03423)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 270500[0m
     | > decoder_loss: 17.97153  (21.45016)
     | > postnet_loss: 16.94923  (18.13053)
     | > stopnet_loss: 1.01140  (1.61223)
     | > decoder_coarse_loss: 19.24102  (22.71115)
     | > decoder_ddc_loss: 0.00096  (0.00067)
     | > ga_loss: 0.00263  (0.00253)
     | > decoder_diff_spec_loss: 1.51029  (1.44622)
     | > postnet_diff_spec_loss: 0.83774  (0.86246)
     | > decoder_ssim_loss: 0.54491  (0.40309)
     | > postnet_ssim_loss: 0.56305  (0.41107)
     | > loss: 15.42923  (17.97873)
     | > align_error: 0.99307  (0.99410)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.17296  (9.35354)
     | > current_lr: 0.00001 
     | > step_time: 2.73720  (3.73048)
     | > loader_time: 0.04100  (0.03392)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 270525[0m
     | > decoder_loss: 13.80037  (19.73127)
     | > postnet_loss: 15.82929  (17.65564)
     | > stopnet_loss: 1.83450  (1.60772)
     | > decoder_coarse_loss: 15.06391  (20.98709)
     | > decoder_ddc_loss: 0.00080  (0.00072)
     | > ga_loss: 0.00292  (0.00257)
     | > decoder_diff_spec_loss: 1.65253  (1.49379)
     | > postnet_diff_spec_loss: 0.87119  (0.86225)
     | > decoder_ssim_loss: 0.34800  (0.39840)
     | > postnet_ssim_loss: 0.36273  (0.40828)
     | > loss: 13.83129  (17.00495)
     | > align_error: 0.99346  (0.99387)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.27004  (8.48411)
     | > current_lr: 0.00001 
     | > step_time: 2.50720  (3.62999)
     | > loader_time: 0.04280  (0.03260)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.08911 [0m(+0.37191)
     | > avg_decoder_loss:[92m 15.37658 [0m(-10.30447)
     | > avg_postnet_loss:[92m 15.50625 [0m(-2.59434)
     | > avg_stopnet_loss:[92m 1.33638 [0m(-0.23714)
     | > avg_decoder_coarse_loss:[92m 15.58862 [0m(-9.90506)
     | > avg_decoder_ddc_loss:[91m 0.00083 [0m(+0.00035)
     | > avg_ga_loss:[92m 0.00222 [0m(-0.00005)
     | > avg_decoder_diff_spec_loss:[91m 1.24401 [0m(+0.32983)
     | > avg_postnet_diff_spec_loss:[92m 0.88157 [0m(-0.00007)
     | > avg_decoder_ssim_loss:[92m 0.41078 [0m(-0.01194)
     | > avg_postnet_ssim_loss:[92m 0.42461 [0m(-0.00071)
     | > avg_loss:[92m 13.70578 [0m(-5.85901)
     | > avg_align_error:[92m 0.99427 [0m(-0.00057)


[4m[1m > EPOCH: 6/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:23:56) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 270550[0m
     | > decoder_loss: 10.98399  (12.22781)
     | > postnet_loss: 14.33558  (15.21066)
     | > stopnet_loss: 1.80807  (1.62616)
     | > decoder_coarse_loss: 12.22798  (13.41111)
     | > decoder_ddc_loss: 0.00055  (0.00081)
     | > ga_loss: 0.00230  (0.00244)
     | > decoder_diff_spec_loss: 1.48297  (1.52953)
     | > postnet_diff_spec_loss: 0.84721  (0.86837)
     | > decoder_ssim_loss: 0.33209  (0.37836)
     | > postnet_ssim_loss: 0.35205  (0.39776)
     | > loss: 11.96015  (12.64448)
     | > align_error: 0.99498  (0.99354)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.22624  (7.12771)
     | > current_lr: 0.00001 
     | > step_time: 3.77970  (4.01000)
     | > loader_time: 0.01590  (0.03474)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 270575[0m
     | > decoder_loss: 8.06859  (10.98327)
     | > postnet_loss: 13.17591  (14.95510)
     | > stopnet_loss: 1.52295  (1.61957)
     | > decoder_coarse_loss: 9.15977  (12.13865)
     | > decoder_ddc_loss: 0.00089  (0.00084)
     | > ga_loss: 0.00269  (0.00247)
     | > decoder_diff_spec_loss: 1.27669  (1.43791)
     | > postnet_diff_spec_loss: 0.88849  (0.86344)
     | > decoder_ssim_loss: 0.43306  (0.38390)
     | > postnet_ssim_loss: 0.46274  (0.40576)
     | > loss: 9.90291  (11.92414)
     | > align_error: 0.99240  (0.99325)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.34627  (7.13753)
     | > current_lr: 0.00001 
     | > step_time: 2.75990  (3.81098)
     | > loader_time: 0.01510  (0.03308)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 270600[0m
     | > decoder_loss: 7.54725  (9.84915)
     | > postnet_loss: 13.76932  (14.51415)
     | > stopnet_loss: 1.14688  (1.61134)
     | > decoder_coarse_loss: 8.58219  (10.97362)
     | > decoder_ddc_loss: 0.00100  (0.00088)
     | > ga_loss: 0.00181  (0.00248)
     | > decoder_diff_spec_loss: 1.01101  (1.33861)
     | > postnet_diff_spec_loss: 0.83905  (0.86216)
     | > decoder_ssim_loss: 0.45639  (0.38529)
     | > postnet_ssim_loss: 0.48923  (0.40939)
     | > loss: 9.32981  (11.20705)
     | > align_error: 0.99393  (0.99308)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.19159  (6.64001)
     | > current_lr: 0.00002 
     | > step_time: 4.71220  (3.75878)
     | > loader_time: 0.02020  (0.03296)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.21169 [0m(+0.12258)
     | > avg_decoder_loss:[92m 8.45290 [0m(-6.92368)
     | > avg_postnet_loss:[92m 12.14297 [0m(-3.36328)
     | > avg_stopnet_loss:[92m 1.33272 [0m(-0.00366)
     | > avg_decoder_coarse_loss:[92m 8.48488 [0m(-7.10375)
     | > avg_decoder_ddc_loss:[91m 0.00126 [0m(+0.00043)
     | > avg_ga_loss:[92m 0.00221 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.73666 [0m(-0.50735)
     | > avg_postnet_diff_spec_loss:[91m 0.88169 [0m(+0.00011)
     | > avg_decoder_ssim_loss:[92m 0.39711 [0m(-0.01367)
     | > avg_postnet_ssim_loss:[92m 0.42271 [0m(-0.00191)
     | > avg_loss:[92m 9.22383 [0m(-4.48196)
     | > avg_align_error:[92m 0.99301 [0m(-0.00126)


[4m[1m > EPOCH: 7/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:31:22) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 270625[0m
     | > decoder_loss: 5.28337  (5.62318)
     | > postnet_loss: 12.14077  (12.91403)
     | > stopnet_loss: 1.40183  (1.57563)
     | > decoder_coarse_loss: 6.18054  (6.52899)
     | > decoder_ddc_loss: 0.00106  (0.00101)
     | > ga_loss: 0.00261  (0.00254)
     | > decoder_diff_spec_loss: 0.84135  (0.85871)
     | > postnet_diff_spec_loss: 0.88976  (0.86497)
     | > decoder_ssim_loss: 0.43145  (0.38490)
     | > postnet_ssim_loss: 0.47232  (0.41881)
     | > loss: 7.97506  (8.48696)
     | > align_error: 0.99106  (0.99202)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.54322  (4.54569)
     | > current_lr: 0.00002 
     | > step_time: 3.13770  (3.84067)
     | > loader_time: 0.02070  (0.03889)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 270650[0m
     | > decoder_loss: 4.59033  (4.88240)
     | > postnet_loss: 12.79078  (11.84561)
     | > stopnet_loss: 1.17660  (1.67752)
     | > decoder_coarse_loss: 5.28034  (5.70006)
     | > decoder_ddc_loss: 0.00116  (0.00101)
     | > ga_loss: 0.00218  (0.00239)
     | > decoder_diff_spec_loss: 0.65654  (0.76864)
     | > postnet_diff_spec_loss: 0.84746  (0.86509)
     | > decoder_ssim_loss: 0.44391  (0.37065)
     | > postnet_ssim_loss: 0.48601  (0.40506)
     | > loss: 7.46164  (7.89911)
     | > align_error: 0.99176  (0.99241)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.58238  (4.67588)
     | > current_lr: 0.00002 
     | > step_time: 3.49150  (3.84321)
     | > loader_time: 0.02010  (0.03095)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 270675[0m
     | > decoder_loss: 3.29068  (4.52195)
     | > postnet_loss: 9.86599  (11.67677)
     | > stopnet_loss: 1.42194  (1.69124)
     | > decoder_coarse_loss: 3.85698  (5.26195)
     | > decoder_ddc_loss: 0.00116  (0.00104)
     | > ga_loss: 0.00240  (0.00242)
     | > decoder_diff_spec_loss: 0.52976  (0.69484)
     | > postnet_diff_spec_loss: 0.83539  (0.86258)
     | > decoder_ssim_loss: 0.46367  (0.36911)
     | > postnet_ssim_loss: 0.51264  (0.40498)
     | > loss: 6.27300  (7.65164)
     | > align_error: 0.99200  (0.99236)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.73499  (4.46767)
     | > current_lr: 0.00002 
     | > step_time: 2.57280  (3.74045)
     | > loader_time: 0.02030  (0.03169)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 270700[0m
     | > decoder_loss: 3.50378  (4.26631)
     | > postnet_loss: 11.39894  (11.31647)
     | > stopnet_loss: 1.75340  (1.70303)
     | > decoder_coarse_loss: 3.88492  (4.92189)
     | > decoder_ddc_loss: 0.00113  (0.00107)
     | > ga_loss: 0.00288  (0.00247)
     | > decoder_diff_spec_loss: 0.50782  (0.63842)
     | > postnet_diff_spec_loss: 0.88485  (0.86185)
     | > decoder_ssim_loss: 0.36031  (0.36793)
     | > postnet_ssim_loss: 0.40170  (0.40512)
     | > loss: 7.00365  (7.41014)
     | > align_error: 0.99011  (0.99213)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.62378  (4.37382)
     | > current_lr: 0.00002 
     | > step_time: 2.11670  (3.65361)
     | > loader_time: 0.02320  (0.03039)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 6.01053 [0m(-0.20116)
     | > avg_decoder_loss:[92m 5.16551 [0m(-3.28740)
     | > avg_postnet_loss:[92m 9.80419 [0m(-2.33877)
     | > avg_stopnet_loss:[91m 1.33863 [0m(+0.00591)
     | > avg_decoder_coarse_loss:[92m 5.16799 [0m(-3.31689)
     | > avg_decoder_ddc_loss:[91m 0.00163 [0m(+0.00037)
     | > avg_ga_loss:[92m 0.00214 [0m(-0.00007)
     | > avg_decoder_diff_spec_loss:[92m 0.47468 [0m(-0.26198)
     | > avg_postnet_diff_spec_loss:[91m 0.88171 [0m(+0.00002)
     | > avg_decoder_ssim_loss:[92m 0.38520 [0m(-0.01190)
     | > avg_postnet_ssim_loss:[92m 0.42054 [0m(-0.00217)
     | > avg_loss:[92m 6.92469 [0m(-2.29914)
     | > avg_align_error:[92m 0.99209 [0m(-0.00093)


[4m[1m > EPOCH: 8/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:38:55) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 270725[0m
     | > decoder_loss: 3.22685  (3.50942)
     | > postnet_loss: 9.19336  (9.80249)
     | > stopnet_loss: 1.44353  (1.75749)
     | > decoder_coarse_loss: 3.51061  (3.80965)
     | > decoder_ddc_loss: 0.00153  (0.00110)
     | > ga_loss: 0.00292  (0.00241)
     | > decoder_diff_spec_loss: 0.46177  (0.45909)
     | > postnet_diff_spec_loss: 0.88673  (0.86896)
     | > decoder_ssim_loss: 0.44536  (0.35416)
     | > postnet_ssim_loss: 0.49931  (0.39593)
     | > loss: 6.01451  (6.56972)
     | > align_error: 0.98800  (0.99206)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.50418  (4.77139)
     | > current_lr: 0.00002 
     | > step_time: 2.81110  (4.06578)
     | > loader_time: 0.03470  (0.02970)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 270750[0m
     | > decoder_loss: 3.56281  (3.40612)
     | > postnet_loss: 10.25619  (9.71462)
     | > stopnet_loss: 1.69467  (1.75852)
     | > decoder_coarse_loss: 3.75853  (3.65633)
     | > decoder_ddc_loss: 0.00110  (0.00114)
     | > ga_loss: 0.00247  (0.00245)
     | > decoder_diff_spec_loss: 0.43138  (0.44329)
     | > postnet_diff_spec_loss: 0.87057  (0.86244)
     | > decoder_ssim_loss: 0.35241  (0.35743)
     | > postnet_ssim_loss: 0.39510  (0.40044)
     | > loss: 6.61402  (6.48120)
     | > align_error: 0.99112  (0.99195)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.28895  (4.14260)
     | > current_lr: 0.00002 
     | > step_time: 3.54860  (3.82275)
     | > loader_time: 0.02130  (0.03578)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 270775[0m
     | > decoder_loss: 3.51142  (3.38339)
     | > postnet_loss: 9.26932  (9.48828)
     | > stopnet_loss: 1.98509  (1.74455)
     | > decoder_coarse_loss: 3.62130  (3.59190)
     | > decoder_ddc_loss: 0.00116  (0.00115)
     | > ga_loss: 0.00330  (0.00248)
     | > decoder_diff_spec_loss: 0.41930  (0.43401)
     | > postnet_diff_spec_loss: 0.87151  (0.86204)
     | > decoder_ssim_loss: 0.35485  (0.36027)
     | > postnet_ssim_loss: 0.40228  (0.40417)
     | > loss: 6.61438  (6.38823)
     | > align_error: 0.99076  (0.99187)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.94565  (3.88956)
     | > current_lr: 0.00002 
     | > step_time: 2.40780  (3.74094)
     | > loader_time: 0.02870  (0.03559)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.36891 [0m(-0.64162)
     | > avg_decoder_loss:[92m 4.39986 [0m(-0.76565)
     | > avg_postnet_loss:[92m 8.23740 [0m(-1.56680)
     | > avg_stopnet_loss:[91m 1.34455 [0m(+0.00592)
     | > avg_decoder_coarse_loss:[92m 4.32078 [0m(-0.84721)
     | > avg_decoder_ddc_loss:[91m 0.00168 [0m(+0.00005)
     | > avg_ga_loss:[91m 0.00214 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.43236 [0m(-0.04232)
     | > avg_postnet_diff_spec_loss:[92m 0.88163 [0m(-0.00007)
     | > avg_decoder_ssim_loss:[92m 0.37829 [0m(-0.00691)
     | > avg_postnet_ssim_loss:[92m 0.41884 [0m(-0.00170)
     | > avg_loss:[92m 6.12297 [0m(-0.80172)
     | > avg_align_error:[92m 0.99188 [0m(-0.00020)


[4m[1m > EPOCH: 9/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:46:15) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 270800[0m
     | > decoder_loss: 3.83813  (3.39362)
     | > postnet_loss: 9.64968  (8.93236)
     | > stopnet_loss: 2.14767  (1.69384)
     | > decoder_coarse_loss: 3.91802  (3.46508)
     | > decoder_ddc_loss: 0.00071  (0.00119)
     | > ga_loss: 0.00197  (0.00250)
     | > decoder_diff_spec_loss: 0.44799  (0.41346)
     | > postnet_diff_spec_loss: 0.90610  (0.86138)
     | > decoder_ssim_loss: 0.28425  (0.36268)
     | > postnet_ssim_loss: 0.31952  (0.40854)
     | > loss: 6.99862  (6.16590)
     | > align_error: 0.99462  (0.99163)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.74715  (4.41203)
     | > current_lr: 0.00002 
     | > step_time: 4.59090  (4.25471)
     | > loader_time: 0.02440  (0.04369)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 270825[0m
     | > decoder_loss: 3.01313  (3.27816)
     | > postnet_loss: 7.56490  (8.11258)
     | > stopnet_loss: 2.16955  (1.77405)
     | > decoder_coarse_loss: 3.05291  (3.33257)
     | > decoder_ddc_loss: 0.00076  (0.00117)
     | > ga_loss: 0.00174  (0.00241)
     | > decoder_diff_spec_loss: 0.40319  (0.41312)
     | > postnet_diff_spec_loss: 0.84410  (0.86521)
     | > decoder_ssim_loss: 0.27913  (0.35441)
     | > postnet_ssim_loss: 0.31620  (0.39922)
     | > loss: 6.04684  (5.97520)
     | > align_error: 0.99487  (0.99196)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.88302  (3.87486)
     | > current_lr: 0.00002 
     | > step_time: 4.86780  (4.01683)
     | > loader_time: 0.05590  (0.03607)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 270850[0m
     | > decoder_loss: 3.64333  (3.26375)
     | > postnet_loss: 8.46998  (8.09630)
     | > stopnet_loss: 1.89529  (1.75580)
     | > decoder_coarse_loss: 3.66659  (3.30955)
     | > decoder_ddc_loss: 0.00093  (0.00116)
     | > ga_loss: 0.00188  (0.00244)
     | > decoder_diff_spec_loss: 0.44816  (0.40989)
     | > postnet_diff_spec_loss: 0.90034  (0.86259)
     | > decoder_ssim_loss: 0.30755  (0.35481)
     | > postnet_ssim_loss: 0.34445  (0.39981)
     | > loss: 6.35001  (5.94244)
     | > align_error: 0.99392  (0.99197)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.95478  (3.79675)
     | > current_lr: 0.00002 
     | > step_time: 4.65860  (3.87809)
     | > loader_time: 0.05910  (0.03242)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 270875[0m
     | > decoder_loss: 3.28438  (3.26674)
     | > postnet_loss: 8.85785  (7.86528)
     | > stopnet_loss: 1.67311  (1.75460)
     | > decoder_coarse_loss: 3.30027  (3.30497)
     | > decoder_ddc_loss: 0.00132  (0.00117)
     | > ga_loss: 0.00212  (0.00248)
     | > decoder_diff_spec_loss: 0.39980  (0.40751)
     | > postnet_diff_spec_loss: 0.83224  (0.86113)
     | > decoder_ssim_loss: 0.33154  (0.35662)
     | > postnet_ssim_loss: 0.37232  (0.40190)
     | > loss: 6.02864  (5.88332)
     | > align_error: 0.99113  (0.99183)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.89185  (3.81428)
     | > current_lr: 0.00002 
     | > step_time: 3.42030  (3.78627)
     | > loader_time: 0.02950  (0.03253)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.93822 [0m(+0.56931)
     | > avg_decoder_loss:[92m 4.24635 [0m(-0.15351)
     | > avg_postnet_loss:[92m 7.05629 [0m(-1.18111)
     | > avg_stopnet_loss:[91m 1.34830 [0m(+0.00375)
     | > avg_decoder_coarse_loss:[92m 4.12971 [0m(-0.19107)
     | > avg_decoder_ddc_loss:[92m 0.00165 [0m(-0.00003)
     | > avg_ga_loss:[92m 0.00212 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.42880 [0m(-0.00356)
     | > avg_postnet_diff_spec_loss:[92m 0.88147 [0m(-0.00016)
     | > avg_decoder_ssim_loss:[92m 0.37623 [0m(-0.00207)
     | > avg_postnet_ssim_loss:[92m 0.41756 [0m(-0.00129)
     | > avg_loss:[92m 5.74343 [0m(-0.37953)
     | > avg_align_error:[91m 0.99195 [0m(+0.00006)


[4m[1m > EPOCH: 10/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 10:53:52) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 270900[0m
     | > decoder_loss: 2.85720  (3.32777)
     | > postnet_loss: 6.02232  (7.01321)
     | > stopnet_loss: 2.25562  (1.77690)
     | > decoder_coarse_loss: 2.86187  (3.34334)
     | > decoder_ddc_loss: 0.00096  (0.00107)
     | > ga_loss: 0.00319  (0.00242)
     | > decoder_diff_spec_loss: 0.41201  (0.41090)
     | > postnet_diff_spec_loss: 0.85874  (0.86779)
     | > decoder_ssim_loss: 0.28861  (0.34503)
     | > postnet_ssim_loss: 0.32809  (0.38808)
     | > loss: 5.67901  (5.71329)
     | > align_error: 0.99164  (0.99221)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.54516  (4.46972)
     | > current_lr: 0.00002 
     | > step_time: 2.99540  (4.09056)
     | > loader_time: 0.02050  (0.03851)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 270925[0m
     | > decoder_loss: 2.82777  (3.23838)
     | > postnet_loss: 6.61646  (6.91756)
     | > stopnet_loss: 2.32808  (1.75812)
     | > decoder_coarse_loss: 2.84172  (3.25297)
     | > decoder_ddc_loss: 0.00097  (0.00112)
     | > ga_loss: 0.00249  (0.00246)
     | > decoder_diff_spec_loss: 0.40517  (0.40757)
     | > postnet_diff_spec_loss: 0.85540  (0.86200)
     | > decoder_ssim_loss: 0.26166  (0.35360)
     | > postnet_ssim_loss: 0.29580  (0.39784)
     | > loss: 5.86676  (5.62818)
     | > align_error: 0.99398  (0.99194)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.03005  (3.78825)
     | > current_lr: 0.00002 
     | > step_time: 4.41600  (3.82032)
     | > loader_time: 0.02450  (0.03822)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 270950[0m
     | > decoder_loss: 3.18241  (3.24126)
     | > postnet_loss: 6.50107  (6.79091)
     | > stopnet_loss: 1.66994  (1.73478)
     | > decoder_coarse_loss: 3.19785  (3.25572)
     | > decoder_ddc_loss: 0.00117  (0.00111)
     | > ga_loss: 0.00246  (0.00248)
     | > decoder_diff_spec_loss: 0.37238  (0.40600)
     | > postnet_diff_spec_loss: 0.83151  (0.86165)
     | > decoder_ssim_loss: 0.32860  (0.35685)
     | > postnet_ssim_loss: 0.36931  (0.40151)
     | > loss: 5.37832  (5.57594)
     | > align_error: 0.99104  (0.99188)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.71602  (3.77149)
     | > current_lr: 0.00002 
     | > step_time: 4.31050  (3.74899)
     | > loader_time: 0.06220  (0.03788)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.67423 [0m(-0.26399)
     | > avg_decoder_loss:[92m 3.75087 [0m(-0.49548)
     | > avg_postnet_loss:[92m 6.13671 [0m(-0.91958)
     | > avg_stopnet_loss:[91m 1.35880 [0m(+0.01050)
     | > avg_decoder_coarse_loss:[92m 3.74123 [0m(-0.38848)
     | > avg_decoder_ddc_loss:[92m 0.00145 [0m(-0.00020)
     | > avg_ga_loss:[91m 0.00213 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.42088 [0m(-0.00793)
     | > avg_postnet_diff_spec_loss:[92m 0.88129 [0m(-0.00018)
     | > avg_decoder_ssim_loss:[92m 0.37355 [0m(-0.00268)
     | > avg_postnet_ssim_loss:[92m 0.41656 [0m(-0.00100)
     | > avg_loss:[92m 5.30006 [0m(-0.44337)
     | > avg_align_error:[92m 0.99182 [0m(-0.00013)


[4m[1m > EPOCH: 11/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:01:32) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 270975[0m
     | > decoder_loss: 2.90529  (3.26465)
     | > postnet_loss: 5.18560  (6.43150)
     | > stopnet_loss: 1.68068  (1.64889)
     | > decoder_coarse_loss: 2.91457  (3.27763)
     | > decoder_ddc_loss: 0.00105  (0.00112)
     | > ga_loss: 0.00238  (0.00264)
     | > decoder_diff_spec_loss: 0.42055  (0.40309)
     | > postnet_diff_spec_loss: 0.88251  (0.85492)
     | > decoder_ssim_loss: 0.35138  (0.37269)
     | > postnet_ssim_loss: 0.39454  (0.41875)
     | > loss: 4.95644  (5.41818)
     | > align_error: 0.99197  (0.99125)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.40073  (3.01911)
     | > current_lr: 0.00002 
     | > step_time: 4.21930  (3.99624)
     | > loader_time: 0.01460  (0.04319)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 271000[0m
     | > decoder_loss: 2.77971  (3.22895)
     | > postnet_loss: 5.67908  (5.92329)
     | > stopnet_loss: 1.59625  (1.74121)
     | > decoder_coarse_loss: 2.78886  (3.24253)
     | > decoder_ddc_loss: 0.00140  (0.00108)
     | > ga_loss: 0.00301  (0.00245)
     | > decoder_diff_spec_loss: 0.39484  (0.40888)
     | > postnet_diff_spec_loss: 0.84097  (0.86568)
     | > decoder_ssim_loss: 0.36799  (0.35591)
     | > postnet_ssim_loss: 0.41315  (0.39953)
     | > loss: 4.92779  (5.35994)
     | > align_error: 0.99092  (0.99201)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.85424  (3.30665)
     | > current_lr: 0.00003 
     | > step_time: 2.79060  (3.79963)
     | > loader_time: 0.01540  (0.03367)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 271025[0m
     | > decoder_loss: 3.03496  (3.19646)
     | > postnet_loss: 5.87228  (5.90145)
     | > stopnet_loss: 1.99546  (1.74139)
     | > decoder_coarse_loss: 3.06237  (3.21160)
     | > decoder_ddc_loss: 0.00088  (0.00104)
     | > ga_loss: 0.00243  (0.00248)
     | > decoder_diff_spec_loss: 0.38620  (0.40532)
     | > postnet_diff_spec_loss: 0.83723  (0.86180)
     | > decoder_ssim_loss: 0.30152  (0.35486)
     | > postnet_ssim_loss: 0.34056  (0.39853)
     | > loss: 5.46658  (5.33655)
     | > align_error: 0.99358  (0.99210)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.69738  (3.37987)
     | > current_lr: 0.00003 
     | > step_time: 3.59620  (3.73035)
     | > loader_time: 0.05300  (0.03274)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 271050[0m
     | > decoder_loss: 3.37856  (3.20335)
     | > postnet_loss: 5.30323  (5.75592)
     | > stopnet_loss: 2.37399  (1.74631)
     | > decoder_coarse_loss: 3.40524  (3.22023)
     | > decoder_ddc_loss: 0.00101  (0.00104)
     | > ga_loss: 0.00268  (0.00252)
     | > decoder_diff_spec_loss: 0.41988  (0.40412)
     | > postnet_diff_spec_loss: 0.88606  (0.86137)
     | > decoder_ssim_loss: 0.27132  (0.35616)
     | > postnet_ssim_loss: 0.30018  (0.40002)
     | > loss: 5.87878  (5.30946)
     | > align_error: 0.99282  (0.99205)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.63010  (3.43655)
     | > current_lr: 0.00003 
     | > step_time: 3.16140  (3.67677)
     | > loader_time: 0.05500  (0.03080)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.41380 [0m(-0.26043)
     | > avg_decoder_loss:[92m 3.64104 [0m(-0.10983)
     | > avg_postnet_loss:[92m 5.44169 [0m(-0.69502)
     | > avg_stopnet_loss:[91m 1.36195 [0m(+0.00315)
     | > avg_decoder_coarse_loss:[92m 3.67495 [0m(-0.06628)
     | > avg_decoder_ddc_loss:[91m 0.00153 [0m(+0.00008)
     | > avg_ga_loss:[91m 0.00215 [0m(+0.00003)
     | > avg_decoder_diff_spec_loss:[92m 0.41963 [0m(-0.00124)
     | > avg_postnet_diff_spec_loss:[92m 0.88120 [0m(-0.00009)
     | > avg_decoder_ssim_loss:[92m 0.37295 [0m(-0.00060)
     | > avg_postnet_ssim_loss:[92m 0.41579 [0m(-0.00077)
     | > avg_loss:[92m 5.08492 [0m(-0.21514)
     | > avg_align_error:[91m 0.99201 [0m(+0.00019)


[4m[1m > EPOCH: 12/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:09:05) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 271075[0m
     | > decoder_loss: 2.95170  (3.28420)
     | > postnet_loss: 4.68024  (5.31120)
     | > stopnet_loss: 1.66134  (1.75344)
     | > decoder_coarse_loss: 2.98992  (3.30868)
     | > decoder_ddc_loss: 0.00078  (0.00099)
     | > ga_loss: 0.00206  (0.00239)
     | > decoder_diff_spec_loss: 0.37344  (0.40908)
     | > postnet_diff_spec_loss: 0.82107  (0.86809)
     | > decoder_ssim_loss: 0.33785  (0.34748)
     | > postnet_ssim_loss: 0.37754  (0.38934)
     | > loss: 4.80476  (5.24517)
     | > align_error: 0.99418  (0.99250)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.61933  (3.50283)
     | > current_lr: 0.00003 
     | > step_time: 3.83660  (4.08844)
     | > loader_time: 0.05670  (0.03948)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 271100[0m
     | > decoder_loss: 2.70041  (3.18177)
     | > postnet_loss: 4.08614  (5.18788)
     | > stopnet_loss: 1.45647  (1.74426)
     | > decoder_coarse_loss: 2.72707  (3.20989)
     | > decoder_ddc_loss: 0.00094  (0.00102)
     | > ga_loss: 0.00267  (0.00249)
     | > decoder_diff_spec_loss: 0.38975  (0.40601)
     | > postnet_diff_spec_loss: 0.84759  (0.86193)
     | > decoder_ssim_loss: 0.38440  (0.35515)
     | > postnet_ssim_loss: 0.43302  (0.39821)
     | > loss: 4.36216  (5.15720)
     | > align_error: 0.99198  (0.99223)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.97813  (3.36532)
     | > current_lr: 0.00003 
     | > step_time: 3.11590  (3.81167)
     | > loader_time: 0.01630  (0.03778)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 271125[0m
     | > decoder_loss: 3.03206  (3.16832)
     | > postnet_loss: 4.03901  (5.11300)
     | > stopnet_loss: 2.31316  (1.74407)
     | > decoder_coarse_loss: 3.08638  (3.20114)
     | > decoder_ddc_loss: 0.00105  (0.00102)
     | > ga_loss: 0.00205  (0.00252)
     | > decoder_diff_spec_loss: 0.35993  (0.40510)
     | > postnet_diff_spec_loss: 0.81745  (0.86194)
     | > decoder_ssim_loss: 0.25656  (0.35667)
     | > postnet_ssim_loss: 0.28824  (0.40004)
     | > loss: 5.29359  (5.13346)
     | > align_error: 0.99341  (0.99227)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.02339  (3.63188)
     | > current_lr: 0.00003 
     | > step_time: 5.37780  (3.78303)
     | > loader_time: 0.06510  (0.03539)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.66929 [0m(+0.25549)
     | > avg_decoder_loss:[92m 3.45842 [0m(-0.18262)
     | > avg_postnet_loss:[92m 4.93950 [0m(-0.50219)
     | > avg_stopnet_loss:[91m 1.36352 [0m(+0.00157)
     | > avg_decoder_coarse_loss:[92m 3.54689 [0m(-0.12806)
     | > avg_decoder_ddc_loss:[91m 0.00169 [0m(+0.00015)
     | > avg_ga_loss:[91m 0.00224 [0m(+0.00009)
     | > avg_decoder_diff_spec_loss:[92m 0.41909 [0m(-0.00054)
     | > avg_postnet_diff_spec_loss:[92m 0.88113 [0m(-0.00007)
     | > avg_decoder_ssim_loss:[92m 0.37215 [0m(-0.00080)
     | > avg_postnet_ssim_loss:[92m 0.41515 [0m(-0.00064)
     | > avg_loss:[92m 4.88322 [0m(-0.20170)
     | > avg_align_error:[91m 0.99204 [0m(+0.00003)


[4m[1m > EPOCH: 13/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:16:33) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 271150[0m
     | > decoder_loss: 3.45617  (3.22169)
     | > postnet_loss: 6.52151  (5.11229)
     | > stopnet_loss: 1.40743  (1.65649)
     | > decoder_coarse_loss: 3.51907  (3.27536)
     | > decoder_ddc_loss: 0.00095  (0.00110)
     | > ga_loss: 0.00234  (0.00278)
     | > decoder_diff_spec_loss: 0.38960  (0.40025)
     | > postnet_diff_spec_loss: 0.80804  (0.84994)
     | > decoder_ssim_loss: 0.41712  (0.37558)
     | > postnet_ssim_loss: 0.46707  (0.42095)
     | > loss: 5.31403  (5.08466)
     | > align_error: 0.99298  (0.99165)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.04229  (5.36588)
     | > current_lr: 0.00003 
     | > step_time: 3.13370  (4.08297)
     | > loader_time: 0.02350  (0.03845)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 271175[0m
     | > decoder_loss: 2.86797  (3.13838)
     | > postnet_loss: 4.03735  (4.62942)
     | > stopnet_loss: 1.80301  (1.76994)
     | > decoder_coarse_loss: 2.94245  (3.19953)
     | > decoder_ddc_loss: 0.00097  (0.00101)
     | > ga_loss: 0.00258  (0.00250)
     | > decoder_diff_spec_loss: 0.39542  (0.40983)
     | > postnet_diff_spec_loss: 0.83809  (0.86635)
     | > decoder_ssim_loss: 0.33696  (0.35483)
     | > postnet_ssim_loss: 0.37913  (0.39743)
     | > loss: 4.76551  (5.03163)
     | > align_error: 0.99288  (0.99254)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.60485  (3.83386)
     | > current_lr: 0.00003 
     | > step_time: 4.23480  (3.91534)
     | > loader_time: 0.01800  (0.03855)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 271200[0m
     | > decoder_loss: 3.27063  (3.08752)
     | > postnet_loss: 4.21736  (4.61412)
     | > stopnet_loss: 1.58286  (1.75169)
     | > decoder_coarse_loss: 3.37275  (3.15610)
     | > decoder_ddc_loss: 0.00135  (0.00102)
     | > ga_loss: 0.00295  (0.00251)
     | > decoder_diff_spec_loss: 0.42162  (0.40672)
     | > postnet_diff_spec_loss: 0.88713  (0.86210)
     | > decoder_ssim_loss: 0.38559  (0.35506)
     | > postnet_ssim_loss: 0.43155  (0.39792)
     | > loss: 4.84462  (4.98440)
     | > align_error: 0.99011  (0.99255)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.12493  (3.81412)
     | > current_lr: 0.00003 
     | > step_time: 2.88020  (3.77418)
     | > loader_time: 0.03790  (0.03376)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 271225[0m
     | > decoder_loss: 2.82698  (3.07483)
     | > postnet_loss: 4.37269  (4.53778)
     | > stopnet_loss: 2.30412  (1.74407)
     | > decoder_coarse_loss: 2.95689  (3.15467)
     | > decoder_ddc_loss: 0.00118  (0.00106)
     | > ga_loss: 0.00268  (0.00257)
     | > decoder_diff_spec_loss: 0.37503  (0.40571)
     | > postnet_diff_spec_loss: 0.82946  (0.86095)
     | > decoder_ssim_loss: 0.27032  (0.35643)
     | > postnet_ssim_loss: 0.30440  (0.39962)
     | > loss: 5.30176  (4.95468)
     | > align_error: 0.99206  (0.99250)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.80305  (3.71889)
     | > current_lr: 0.00003 
     | > step_time: 3.30740  (3.68720)
     | > loader_time: 0.02050  (0.03225)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.16403 [0m(+0.49473)
     | > avg_decoder_loss:[92m 3.27739 [0m(-0.18103)
     | > avg_postnet_loss:[92m 4.59190 [0m(-0.34760)
     | > avg_stopnet_loss:[91m 1.37580 [0m(+0.01228)
     | > avg_decoder_coarse_loss:[92m 3.42383 [0m(-0.12306)
     | > avg_decoder_ddc_loss:[91m 0.00191 [0m(+0.00022)
     | > avg_ga_loss:[91m 0.00243 [0m(+0.00019)
     | > avg_decoder_diff_spec_loss:[91m 0.42780 [0m(+0.00871)
     | > avg_postnet_diff_spec_loss:[92m 0.88109 [0m(-0.00004)
     | > avg_decoder_ssim_loss:[92m 0.37176 [0m(-0.00039)
     | > avg_postnet_ssim_loss:[92m 0.41461 [0m(-0.00054)
     | > avg_loss:[92m 4.73550 [0m(-0.14772)
     | > avg_align_error:[92m 0.99171 [0m(-0.00033)


[4m[1m > EPOCH: 14/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:24:00) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 271250[0m
     | > decoder_loss: 2.81998  (3.10713)
     | > postnet_loss: 3.70628  (4.37588)
     | > stopnet_loss: 1.77343  (1.73694)
     | > decoder_coarse_loss: 2.98208  (3.23749)
     | > decoder_ddc_loss: 0.00143  (0.00130)
     | > ga_loss: 0.00197  (0.00250)
     | > decoder_diff_spec_loss: 0.39042  (0.41777)
     | > postnet_diff_spec_loss: 0.86329  (0.87073)
     | > decoder_ssim_loss: 0.31653  (0.34714)
     | > postnet_ssim_loss: 0.35424  (0.38860)
     | > loss: 4.64185  (4.93597)
     | > align_error: 0.99349  (0.99247)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.97967  (3.26394)
     | > current_lr: 0.00003 
     | > step_time: 4.44180  (4.15417)
     | > loader_time: 0.02500  (0.03599)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 271275[0m
     | > decoder_loss: 3.32891  (2.98683)
     | > postnet_loss: 5.77751  (4.26247)
     | > stopnet_loss: 1.92605  (1.75369)
     | > decoder_coarse_loss: 3.53311  (3.12958)
     | > decoder_ddc_loss: 0.00176  (0.00158)
     | > ga_loss: 0.00233  (0.00260)
     | > decoder_diff_spec_loss: 0.43545  (0.41670)
     | > postnet_diff_spec_loss: 0.85310  (0.86228)
     | > decoder_ssim_loss: 0.33451  (0.35343)
     | > postnet_ssim_loss: 0.37445  (0.39597)
     | > loss: 5.59741  (4.86891)
     | > align_error: 0.99231  (0.99193)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.10943  (3.26900)
     | > current_lr: 0.00003 
     | > step_time: 4.50910  (3.83560)
     | > loader_time: 0.01940  (0.03480)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 271300[0m
     | > decoder_loss: 2.69261  (2.93425)
     | > postnet_loss: 4.21089  (4.21441)
     | > stopnet_loss: 1.23103  (1.73697)
     | > decoder_coarse_loss: 2.79057  (3.08786)
     | > decoder_ddc_loss: 0.00339  (0.00177)
     | > ga_loss: 0.00341  (0.00265)
     | > decoder_diff_spec_loss: 0.44143  (0.42122)
     | > postnet_diff_spec_loss: 0.82994  (0.86260)
     | > decoder_ssim_loss: 0.47887  (0.35700)
     | > postnet_ssim_loss: 0.53216  (0.40023)
     | > loss: 4.24304  (4.82007)
     | > align_error: 0.98622  (0.99159)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.01216  (3.45332)
     | > current_lr: 0.00003 
     | > step_time: 2.56630  (3.73324)
     | > loader_time: 0.02280  (0.03397)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 9.42024 [0m(+3.25621)
     | > avg_decoder_loss:[92m 2.99642 [0m(-0.28097)
     | > avg_postnet_loss:[92m 4.24444 [0m(-0.34746)
     | > avg_stopnet_loss:[91m 1.38641 [0m(+0.01061)
     | > avg_decoder_coarse_loss:[92m 3.19506 [0m(-0.22878)
     | > avg_decoder_ddc_loss:[92m 0.00175 [0m(-0.00015)
     | > avg_ga_loss:[91m 0.00244 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.46949 [0m(+0.04169)
     | > avg_postnet_diff_spec_loss:[92m 0.88053 [0m(-0.00056)
     | > avg_decoder_ssim_loss:[92m 0.37082 [0m(-0.00094)
     | > avg_postnet_ssim_loss:[92m 0.41274 [0m(-0.00187)
     | > avg_loss:[92m 4.54140 [0m(-0.19410)
     | > avg_align_error:[92m 0.99058 [0m(-0.00113)


[4m[1m > EPOCH: 15/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:31:42) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 271325[0m
     | > decoder_loss: 2.93183  (2.87176)
     | > postnet_loss: 3.94861  (4.07406)
     | > stopnet_loss: 1.69795  (1.63154)
     | > decoder_coarse_loss: 3.09885  (3.00503)
     | > decoder_ddc_loss: 0.00161  (0.00165)
     | > ga_loss: 0.00287  (0.00297)
     | > decoder_diff_spec_loss: 0.39996  (0.43009)
     | > postnet_diff_spec_loss: 0.84300  (0.85802)
     | > decoder_ssim_loss: 0.34638  (0.36593)
     | > postnet_ssim_loss: 0.38995  (0.40983)
     | > loss: 4.70233  (4.65050)
     | > align_error: 0.98941  (0.98944)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.57940  (4.54431)
     | > current_lr: 0.00003 
     | > step_time: 4.12190  (4.32840)
     | > loader_time: 0.06240  (0.05189)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 271350[0m
     | > decoder_loss: 2.55750  (2.82544)
     | > postnet_loss: 3.65027  (3.94253)
     | > stopnet_loss: 1.78435  (1.74266)
     | > decoder_coarse_loss: 2.66185  (2.95218)
     | > decoder_ddc_loss: 0.00149  (0.00145)
     | > ga_loss: 0.00242  (0.00259)
     | > decoder_diff_spec_loss: 0.42174  (0.44282)
     | > postnet_diff_spec_loss: 0.84283  (0.86680)
     | > decoder_ssim_loss: 0.32693  (0.35406)
     | > postnet_ssim_loss: 0.36466  (0.39592)
     | > loss: 4.50328  (4.70091)
     | > align_error: 0.99009  (0.99066)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.76597  (4.02214)
     | > current_lr: 0.00003 
     | > step_time: 5.67160  (3.94201)
     | > loader_time: 0.02320  (0.03876)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 271375[0m
     | > decoder_loss: 2.44358  (2.77346)
     | > postnet_loss: 3.29606  (3.90738)
     | > stopnet_loss: 1.72992  (1.73765)
     | > decoder_coarse_loss: 2.54100  (2.87837)
     | > decoder_ddc_loss: 0.00141  (0.00152)
     | > ga_loss: 0.00229  (0.00261)
     | > decoder_diff_spec_loss: 0.41231  (0.43790)
     | > postnet_diff_spec_loss: 0.84129  (0.86079)
     | > decoder_ssim_loss: 0.33334  (0.35318)
     | > postnet_ssim_loss: 0.37522  (0.39494)
     | > loss: 4.30242  (4.65258)
     | > align_error: 0.99223  (0.99065)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.76012  (3.67018)
     | > current_lr: 0.00003 
     | > step_time: 3.25470  (3.77891)
     | > loader_time: 0.02310  (0.03375)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 271400[0m
     | > decoder_loss: 2.59664  (2.76027)
     | > postnet_loss: 3.76011  (3.83985)
     | > stopnet_loss: 1.67430  (1.72593)
     | > decoder_coarse_loss: 2.68161  (2.85360)
     | > decoder_ddc_loss: 0.00225  (0.00161)
     | > ga_loss: 0.00357  (0.00267)
     | > decoder_diff_spec_loss: 0.45191  (0.43791)
     | > postnet_diff_spec_loss: 0.85626  (0.85996)
     | > decoder_ssim_loss: 0.37372  (0.35621)
     | > postnet_ssim_loss: 0.41519  (0.39779)
     | > loss: 4.47659  (4.61606)
     | > align_error: 0.98716  (0.99043)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.37253  (3.68310)
     | > current_lr: 0.00004 
     | > step_time: 2.27430  (3.69660)
     | > loader_time: 0.01920  (0.03257)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.54194 [0m(-3.87830)
     | > avg_decoder_loss:[92m 2.91491 [0m(-0.08151)
     | > avg_postnet_loss:[91m 4.38776 [0m(+0.14332)
     | > avg_stopnet_loss:[92m 1.38401 [0m(-0.00240)
     | > avg_decoder_coarse_loss:[92m 3.13598 [0m(-0.05908)
     | > avg_decoder_ddc_loss:[91m 0.00200 [0m(+0.00025)
     | > avg_ga_loss:[92m 0.00243 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.46536 [0m(-0.00413)
     | > avg_postnet_diff_spec_loss:[92m 0.87106 [0m(-0.00947)
     | > avg_decoder_ssim_loss:[92m 0.37025 [0m(-0.00057)
     | > avg_postnet_ssim_loss:[92m 0.40415 [0m(-0.00859)
     | > avg_loss:[92m 4.53402 [0m(-0.00739)
     | > avg_align_error:[92m 0.99032 [0m(-0.00026)


[4m[1m > EPOCH: 16/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:39:11) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 271425[0m
     | > decoder_loss: 2.47763  (2.82827)
     | > postnet_loss: 3.49905  (3.76365)
     | > stopnet_loss: 1.01454  (1.72771)
     | > decoder_coarse_loss: 2.51353  (2.86342)
     | > decoder_ddc_loss: 0.00158  (0.00186)
     | > ga_loss: 0.00185  (0.00256)
     | > decoder_diff_spec_loss: 0.43486  (0.44848)
     | > postnet_diff_spec_loss: 0.83732  (0.86664)
     | > decoder_ssim_loss: 0.48224  (0.34745)
     | > postnet_ssim_loss: 0.53642  (0.38493)
     | > loss: 3.71946  (4.61671)
     | > align_error: 0.99094  (0.99037)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.58309  (3.91590)
     | > current_lr: 0.00004 
     | > step_time: 4.83570  (4.11587)
     | > loader_time: 0.02350  (0.03198)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 271450[0m
     | > decoder_loss: 3.11341  (2.72297)
     | > postnet_loss: 4.22653  (3.58316)
     | > stopnet_loss: 2.24115  (1.74528)
     | > decoder_coarse_loss: 3.14461  (2.75573)
     | > decoder_ddc_loss: 0.00186  (0.00189)
     | > ga_loss: 0.00263  (0.00260)
     | > decoder_diff_spec_loss: 0.47103  (0.44257)
     | > postnet_diff_spec_loss: 0.87824  (0.85708)
     | > decoder_ssim_loss: 0.27271  (0.35248)
     | > postnet_ssim_loss: 0.30034  (0.38963)
     | > loss: 5.35650  (4.53467)
     | > align_error: 0.99007  (0.99007)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.76520  (3.76617)
     | > current_lr: 0.00004 
     | > step_time: 3.18340  (3.85320)
     | > loader_time: 0.02450  (0.03032)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 271475[0m
     | > decoder_loss: 2.44320  (2.71190)
     | > postnet_loss: 3.45969  (3.55376)
     | > stopnet_loss: 1.79220  (1.73744)
     | > decoder_coarse_loss: 2.47215  (2.73598)
     | > decoder_ddc_loss: 0.00156  (0.00190)
     | > ga_loss: 0.00249  (0.00263)
     | > decoder_diff_spec_loss: 0.44548  (0.44250)
     | > postnet_diff_spec_loss: 0.86767  (0.85730)
     | > decoder_ssim_loss: 0.33418  (0.35391)
     | > postnet_ssim_loss: 0.36635  (0.39084)
     | > loss: 4.40224  (4.51263)
     | > align_error: 0.99079  (0.99007)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.78849  (3.74150)
     | > current_lr: 0.00004 
     | > step_time: 3.32820  (3.76190)
     | > loader_time: 0.02720  (0.03109)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.67420 [0m(+1.13226)
     | > avg_decoder_loss:[92m 2.84570 [0m(-0.06921)
     | > avg_postnet_loss:[92m 3.84914 [0m(-0.53863)
     | > avg_stopnet_loss:[92m 1.37765 [0m(-0.00636)
     | > avg_decoder_coarse_loss:[92m 3.11593 [0m(-0.02005)
     | > avg_decoder_ddc_loss:[91m 0.00205 [0m(+0.00005)
     | > avg_ga_loss:[92m 0.00238 [0m(-0.00005)
     | > avg_decoder_diff_spec_loss:[92m 0.46169 [0m(-0.00367)
     | > avg_postnet_diff_spec_loss:[92m 0.86559 [0m(-0.00547)
     | > avg_decoder_ssim_loss:[92m 0.36943 [0m(-0.00082)
     | > avg_postnet_ssim_loss:[92m 0.39793 [0m(-0.00622)
     | > avg_loss:[92m 4.36640 [0m(-0.16762)
     | > avg_align_error:[92m 0.99014 [0m(-0.00018)


[4m[1m > EPOCH: 17/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:46:52) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 271500[0m
     | > decoder_loss: 2.54526  (2.69122)
     | > postnet_loss: 3.56165  (3.44738)
     | > stopnet_loss: 1.60037  (1.67276)
     | > decoder_coarse_loss: 2.55352  (2.69939)
     | > decoder_ddc_loss: 0.00153  (0.00222)
     | > ga_loss: 0.00246  (0.00293)
     | > decoder_diff_spec_loss: 0.43663  (0.44330)
     | > postnet_diff_spec_loss: 0.81724  (0.85328)
     | > decoder_ssim_loss: 0.36597  (0.36913)
     | > postnet_ssim_loss: 0.40256  (0.40325)
     | > loss: 4.28376  (4.41471)
     | > align_error: 0.99164  (0.98832)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.43288  (3.86596)
     | > current_lr: 0.00004 
     | > step_time: 4.83320  (4.07174)
     | > loader_time: 0.02090  (0.04053)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 271525[0m
     | > decoder_loss: 2.82791  (2.70886)
     | > postnet_loss: 3.50381  (3.31775)
     | > stopnet_loss: 1.52796  (1.72567)
     | > decoder_coarse_loss: 2.81386  (2.70154)
     | > decoder_ddc_loss: 0.00215  (0.00193)
     | > ga_loss: 0.00289  (0.00257)
     | > decoder_diff_spec_loss: 0.45825  (0.44943)
     | > postnet_diff_spec_loss: 0.86647  (0.85766)
     | > decoder_ssim_loss: 0.39133  (0.35352)
     | > postnet_ssim_loss: 0.42886  (0.38513)
     | > loss: 4.36559  (4.43246)
     | > align_error: 0.98890  (0.98982)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.42129  (4.93621)
     | > current_lr: 0.00004 
     | > step_time: 2.62270  (3.83298)
     | > loader_time: 0.01490  (0.03611)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 271550[0m
     | > decoder_loss: 2.85361  (2.66800)
     | > postnet_loss: 4.16365  (3.26918)
     | > stopnet_loss: 1.96669  (1.73260)
     | > decoder_coarse_loss: 2.80456  (2.65315)
     | > decoder_ddc_loss: 0.00137  (0.00192)
     | > ga_loss: 0.00210  (0.00258)
     | > decoder_diff_spec_loss: 0.44018  (0.44404)
     | > postnet_diff_spec_loss: 0.83496  (0.85166)
     | > decoder_ssim_loss: 0.28488  (0.35205)
     | > postnet_ssim_loss: 0.31126  (0.38347)
     | > loss: 4.90079  (4.40138)
     | > align_error: 0.99243  (0.98980)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.60298  (4.23822)
     | > current_lr: 0.00004 
     | > step_time: 3.92180  (3.77493)
     | > loader_time: 0.02040  (0.03579)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 271575[0m
     | > decoder_loss: 2.60673  (2.65830)
     | > postnet_loss: 3.20281  (3.20680)
     | > stopnet_loss: 1.41694  (1.72161)
     | > decoder_coarse_loss: 2.58240  (2.64107)
     | > decoder_ddc_loss: 0.00175  (0.00194)
     | > ga_loss: 0.00231  (0.00261)
     | > decoder_diff_spec_loss: 0.42396  (0.44405)
     | > postnet_diff_spec_loss: 0.82195  (0.85051)
     | > decoder_ssim_loss: 0.38002  (0.35458)
     | > postnet_ssim_loss: 0.40814  (0.38562)
     | > loss: 4.03541  (4.37040)
     | > align_error: 0.99074  (0.98970)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.96178  (4.19634)
     | > current_lr: 0.00004 
     | > step_time: 3.45530  (3.74925)
     | > loader_time: 0.02400  (0.03345)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.63719 [0m(-1.03701)
     | > avg_decoder_loss:[91m 2.88580 [0m(+0.04010)
     | > avg_postnet_loss:[92m 3.32674 [0m(-0.52240)
     | > avg_stopnet_loss:[92m 1.36871 [0m(-0.00894)
     | > avg_decoder_coarse_loss:[91m 3.20954 [0m(+0.09361)
     | > avg_decoder_ddc_loss:[91m 0.00210 [0m(+0.00004)
     | > avg_ga_loss:[92m 0.00233 [0m(-0.00004)
     | > avg_decoder_diff_spec_loss:[92m 0.45407 [0m(-0.00762)
     | > avg_postnet_diff_spec_loss:[92m 0.85940 [0m(-0.00619)
     | > avg_decoder_ssim_loss:[91m 0.36968 [0m(+0.00025)
     | > avg_postnet_ssim_loss:[92m 0.39280 [0m(-0.00513)
     | > avg_loss:[92m 4.25541 [0m(-0.11099)
     | > avg_align_error:[91m 0.99021 [0m(+0.00007)


[4m[1m > EPOCH: 18/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 11:54:33) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 271600[0m
     | > decoder_loss: 2.57955  (2.75575)
     | > postnet_loss: 2.90584  (3.19506)
     | > stopnet_loss: 1.79430  (1.78895)
     | > decoder_coarse_loss: 2.56395  (2.71334)
     | > decoder_ddc_loss: 0.00126  (0.00198)
     | > ga_loss: 0.00175  (0.00256)
     | > decoder_diff_spec_loss: 0.43586  (0.45426)
     | > postnet_diff_spec_loss: 0.85268  (0.85863)
     | > decoder_ssim_loss: 0.30127  (0.33813)
     | > postnet_ssim_loss: 0.32444  (0.36366)
     | > loss: 4.29426  (4.47194)
     | > align_error: 0.99202  (0.98978)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.35490  (4.53418)
     | > current_lr: 0.00004 
     | > step_time: 4.75120  (4.11628)
     | > loader_time: 0.02420  (0.03459)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 271625[0m
     | > decoder_loss: 2.38143  (2.64124)
     | > postnet_loss: 2.73091  (3.00933)
     | > stopnet_loss: 2.02876  (1.74153)
     | > decoder_coarse_loss: 2.35290  (2.60694)
     | > decoder_ddc_loss: 0.00235  (0.00194)
     | > ga_loss: 0.00353  (0.00256)
     | > decoder_diff_spec_loss: 0.41462  (0.44659)
     | > postnet_diff_spec_loss: 0.82052  (0.84708)
     | > decoder_ssim_loss: 0.31929  (0.35363)
     | > postnet_ssim_loss: 0.34843  (0.38020)
     | > loss: 4.38900  (4.32607)
     | > align_error: 0.98637  (0.98955)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.45928  (4.51753)
     | > current_lr: 0.00004 
     | > step_time: 3.07730  (3.86592)
     | > loader_time: 0.02680  (0.03416)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 271650[0m
     | > decoder_loss: 3.25912  (2.64855)
     | > postnet_loss: 3.51285  (3.01533)
     | > stopnet_loss: 1.62620  (1.72574)
     | > decoder_coarse_loss: 3.12925  (2.61046)
     | > decoder_ddc_loss: 0.00138  (0.00192)
     | > ga_loss: 0.00197  (0.00259)
     | > decoder_diff_spec_loss: 0.46112  (0.44668)
     | > postnet_diff_spec_loss: 0.85816  (0.84812)
     | > decoder_ssim_loss: 0.34430  (0.35350)
     | > postnet_ssim_loss: 0.36658  (0.37999)
     | > loss: 4.61926  (4.31482)
     | > align_error: 0.99210  (0.98957)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.98680  (4.29105)
     | > current_lr: 0.00004 
     | > step_time: 5.02080  (3.78680)
     | > loader_time: 0.05280  (0.03157)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.86060 [0m(+0.22341)
     | > avg_decoder_loss:[92m 2.80972 [0m(-0.07607)
     | > avg_postnet_loss:[92m 3.02591 [0m(-0.30083)
     | > avg_stopnet_loss:[92m 1.36427 [0m(-0.00444)
     | > avg_decoder_coarse_loss:[92m 3.16420 [0m(-0.04534)
     | > avg_decoder_ddc_loss:[92m 0.00181 [0m(-0.00028)
     | > avg_ga_loss:[92m 0.00229 [0m(-0.00004)
     | > avg_decoder_diff_spec_loss:[92m 0.45303 [0m(-0.00104)
     | > avg_postnet_diff_spec_loss:[92m 0.85865 [0m(-0.00075)
     | > avg_decoder_ssim_loss:[92m 0.36931 [0m(-0.00037)
     | > avg_postnet_ssim_loss:[92m 0.39053 [0m(-0.00227)
     | > avg_loss:[92m 4.14401 [0m(-0.11140)
     | > avg_align_error:[91m 0.99032 [0m(+0.00010)


[4m[1m > EPOCH: 19/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:02:27) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 271675[0m
     | > decoder_loss: 2.66791  (2.67268)
     | > postnet_loss: 3.27531  (2.98718)
     | > stopnet_loss: 1.75457  (1.56683)
     | > decoder_coarse_loss: 2.64038  (2.63176)
     | > decoder_ddc_loss: 0.00190  (0.00222)
     | > ga_loss: 0.00294  (0.00304)
     | > decoder_diff_spec_loss: 0.43569  (0.44715)
     | > postnet_diff_spec_loss: 0.83230  (0.85548)
     | > decoder_ssim_loss: 0.33336  (0.36889)
     | > postnet_ssim_loss: 0.35736  (0.39415)
     | > loss: 4.40534  (4.17192)
     | > align_error: 0.98778  (0.98681)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.15498  (2.86100)
     | > current_lr: 0.00004 
     | > step_time: 4.75160  (3.97789)
     | > loader_time: 0.02360  (0.01715)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 271700[0m
     | > decoder_loss: 2.52260  (2.63670)
     | > postnet_loss: 3.18716  (2.88975)
     | > stopnet_loss: 1.08959  (1.73873)
     | > decoder_coarse_loss: 2.50210  (2.59881)
     | > decoder_ddc_loss: 0.00228  (0.00177)
     | > ga_loss: 0.00289  (0.00252)
     | > decoder_diff_spec_loss: 0.44422  (0.45465)
     | > postnet_diff_spec_loss: 0.83242  (0.84896)
     | > decoder_ssim_loss: 0.54490  (0.35183)
     | > postnet_ssim_loss: 0.58644  (0.37449)
     | > loss: 3.75957  (4.29058)
     | > align_error: 0.98719  (0.98948)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.85440  (4.14993)
     | > current_lr: 0.00004 
     | > step_time: 2.27990  (3.86031)
     | > loader_time: 0.06460  (0.03980)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 271725[0m
     | > decoder_loss: 2.72615  (2.60175)
     | > postnet_loss: 3.12504  (2.83966)
     | > stopnet_loss: 1.82878  (1.71904)
     | > decoder_coarse_loss: 2.57765  (2.55602)
     | > decoder_ddc_loss: 0.00192  (0.00178)
     | > ga_loss: 0.00237  (0.00256)
     | > decoder_diff_spec_loss: 0.45775  (0.44925)
     | > postnet_diff_spec_loss: 0.84453  (0.84421)
     | > decoder_ssim_loss: 0.33266  (0.35296)
     | > postnet_ssim_loss: 0.35089  (0.37622)
     | > loss: 4.44481  (4.23729)
     | > align_error: 0.99010  (0.98943)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.33611  (3.69232)
     | > current_lr: 0.00004 
     | > step_time: 4.55420  (3.77024)
     | > loader_time: 0.06090  (0.03897)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 271750[0m
     | > decoder_loss: 2.68905  (2.59438)
     | > postnet_loss: 2.72805  (2.80240)
     | > stopnet_loss: 1.34486  (1.72128)
     | > decoder_coarse_loss: 2.60235  (2.55388)
     | > decoder_ddc_loss: 0.00205  (0.00179)
     | > ga_loss: 0.00292  (0.00258)
     | > decoder_diff_spec_loss: 0.44898  (0.44858)
     | > postnet_diff_spec_loss: 0.84757  (0.84310)
     | > decoder_ssim_loss: 0.41011  (0.35385)
     | > postnet_ssim_loss: 0.43059  (0.37674)
     | > loss: 3.89916  (4.22788)
     | > align_error: 0.98665  (0.98938)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.78770  (3.91323)
     | > current_lr: 0.00004 
     | > step_time: 2.81550  (3.69836)
     | > loader_time: 0.04310  (0.03639)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.59097 [0m(-0.26963)
     | > avg_decoder_loss:[92m 2.77955 [0m(-0.03017)
     | > avg_postnet_loss:[92m 2.87934 [0m(-0.14656)
     | > avg_stopnet_loss:[92m 1.35391 [0m(-0.01036)
     | > avg_decoder_coarse_loss:[91m 3.23494 [0m(+0.07075)
     | > avg_decoder_ddc_loss:[91m 0.00184 [0m(+0.00003)
     | > avg_ga_loss:[92m 0.00227 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.45750 [0m(+0.00447)
     | > avg_postnet_diff_spec_loss:[92m 0.85330 [0m(-0.00536)
     | > avg_decoder_ssim_loss:[92m 0.36902 [0m(-0.00029)
     | > avg_postnet_ssim_loss:[92m 0.38515 [0m(-0.00537)
     | > avg_loss:[92m 4.10541 [0m(-0.03859)
     | > avg_align_error:[92m 0.99012 [0m(-0.00019)


[4m[1m > EPOCH: 20/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:10:06) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 271775[0m
     | > decoder_loss: 2.42284  (2.68437)
     | > postnet_loss: 2.38678  (2.85925)
     | > stopnet_loss: 2.23363  (1.75209)
     | > decoder_coarse_loss: 2.37580  (2.62711)
     | > decoder_ddc_loss: 0.00118  (0.00175)
     | > ga_loss: 0.00203  (0.00261)
     | > decoder_diff_spec_loss: 0.46009  (0.46170)
     | > postnet_diff_spec_loss: 0.86058  (0.85097)
     | > decoder_ssim_loss: 0.26185  (0.33993)
     | > postnet_ssim_loss: 0.27099  (0.35812)
     | > loss: 4.50379  (4.31092)
     | > align_error: 0.99138  (0.98931)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.07809  (4.51155)
     | > current_lr: 0.00004 
     | > step_time: 4.83600  (4.10500)
     | > loader_time: 0.03550  (0.04244)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 271800[0m
     | > decoder_loss: 2.33986  (2.56896)
     | > postnet_loss: 2.51833  (2.68104)
     | > stopnet_loss: 2.11142  (1.71359)
     | > decoder_coarse_loss: 2.25783  (2.52417)
     | > decoder_ddc_loss: 0.00111  (0.00172)
     | > ga_loss: 0.00215  (0.00252)
     | > decoder_diff_spec_loss: 0.43581  (0.45173)
     | > postnet_diff_spec_loss: 0.82471  (0.84113)
     | > decoder_ssim_loss: 0.28274  (0.35346)
     | > postnet_ssim_loss: 0.29925  (0.37312)
     | > loss: 4.36208  (4.17501)
     | > align_error: 0.99261  (0.98940)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.22640  (4.17203)
     | > current_lr: 0.00005 
     | > step_time: 4.61200  (3.89207)
     | > loader_time: 0.01790  (0.03552)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 271825[0m
     | > decoder_loss: 2.72444  (2.56581)
     | > postnet_loss: 2.94537  (2.67850)
     | > stopnet_loss: 1.77253  (1.72793)
     | > decoder_coarse_loss: 2.75114  (2.52093)
     | > decoder_ddc_loss: 0.00169  (0.00173)
     | > ga_loss: 0.00276  (0.00258)
     | > decoder_diff_spec_loss: 0.47477  (0.45196)
     | > postnet_diff_spec_loss: 0.84042  (0.84120)
     | > decoder_ssim_loss: 0.36567  (0.35271)
     | > postnet_ssim_loss: 0.38178  (0.37259)
     | > loss: 4.40765  (4.18716)
     | > align_error: 0.98904  (0.98931)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.02738  (4.11661)
     | > current_lr: 0.00005 
     | > step_time: 2.89590  (3.73513)
     | > loader_time: 0.01880  (0.03362)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.69858 [0m(+0.10761)
     | > avg_decoder_loss:[92m 2.73827 [0m(-0.04128)
     | > avg_postnet_loss:[92m 2.72234 [0m(-0.15701)
     | > avg_stopnet_loss:[92m 1.35025 [0m(-0.00365)
     | > avg_decoder_coarse_loss:[91m 3.31745 [0m(+0.08251)
     | > avg_decoder_ddc_loss:[92m 0.00183 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00225 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.45752 [0m(+0.00003)
     | > avg_postnet_diff_spec_loss:[92m 0.85000 [0m(-0.00330)
     | > avg_decoder_ssim_loss:[92m 0.36858 [0m(-0.00043)
     | > avg_postnet_ssim_loss:[92m 0.38032 [0m(-0.00483)
     | > avg_loss:[92m 4.07061 [0m(-0.03481)
     | > avg_align_error:[91m 0.99015 [0m(+0.00003)


[4m[1m > EPOCH: 21/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:17:39) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 271850[0m
     | > decoder_loss: 2.82768  (2.62113)
     | > postnet_loss: 2.84426  (2.57208)
     | > stopnet_loss: 1.53960  (1.60916)
     | > decoder_coarse_loss: 2.72990  (2.55031)
     | > decoder_ddc_loss: 0.00201  (0.00214)
     | > ga_loss: 0.00309  (0.00309)
     | > decoder_diff_spec_loss: 0.47443  (0.46089)
     | > postnet_diff_spec_loss: 0.88485  (0.85939)
     | > decoder_ssim_loss: 0.39195  (0.38631)
     | > postnet_ssim_loss: 0.40651  (0.40340)
     | > loss: 4.19547  (4.08854)
     | > align_error: 0.98690  (0.98625)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.27099  (2.60052)
     | > current_lr: 0.00005 
     | > step_time: 4.14470  (4.39854)
     | > loader_time: 0.22390  (0.11751)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 271875[0m
     | > decoder_loss: 2.80941  (2.57265)
     | > postnet_loss: 2.66250  (2.60742)
     | > stopnet_loss: 1.78933  (1.75888)
     | > decoder_coarse_loss: 2.74391  (2.52407)
     | > decoder_ddc_loss: 0.00158  (0.00161)
     | > ga_loss: 0.00242  (0.00251)
     | > decoder_diff_spec_loss: 0.48307  (0.45845)
     | > postnet_diff_spec_loss: 0.87429  (0.84424)
     | > decoder_ssim_loss: 0.33535  (0.34361)
     | > postnet_ssim_loss: 0.34952  (0.36036)
     | > loss: 4.36633  (4.19952)
     | > align_error: 0.98965  (0.98949)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.65320  (4.30266)
     | > current_lr: 0.00005 
     | > step_time: 3.83920  (3.95250)
     | > loader_time: 0.01920  (0.04286)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 271900[0m
     | > decoder_loss: 2.62106  (2.53402)
     | > postnet_loss: 2.48041  (2.56604)
     | > stopnet_loss: 1.93575  (1.70421)
     | > decoder_coarse_loss: 2.55874  (2.48102)
     | > decoder_ddc_loss: 0.00123  (0.00163)
     | > ga_loss: 0.00233  (0.00255)
     | > decoder_diff_spec_loss: 0.44022  (0.45368)
     | > postnet_diff_spec_loss: 0.85134  (0.83890)
     | > decoder_ssim_loss: 0.28634  (0.35239)
     | > postnet_ssim_loss: 0.30036  (0.37017)
     | > loss: 4.33234  (4.11644)
     | > align_error: 0.99196  (0.98932)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.80464  (3.91252)
     | > current_lr: 0.00005 
     | > step_time: 4.92560  (3.78108)
     | > loader_time: 0.02330  (0.04009)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 271925[0m
     | > decoder_loss: 2.66394  (2.53266)
     | > postnet_loss: 2.50933  (2.54538)
     | > stopnet_loss: 1.75662  (1.72127)
     | > decoder_coarse_loss: 2.59799  (2.47799)
     | > decoder_ddc_loss: 0.00210  (0.00163)
     | > ga_loss: 0.00313  (0.00257)
     | > decoder_diff_spec_loss: 0.47288  (0.45290)
     | > postnet_diff_spec_loss: 0.84583  (0.83782)
     | > decoder_ssim_loss: 0.36769  (0.35216)
     | > postnet_ssim_loss: 0.38146  (0.36967)
     | > loss: 4.23257  (4.12666)
     | > align_error: 0.98625  (0.98936)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.59491  (3.95893)
     | > current_lr: 0.00005 
     | > step_time: 2.74450  (3.73492)
     | > loader_time: 0.01610  (0.03716)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.63684 [0m(-0.06174)
     | > avg_decoder_loss:[91m 2.79878 [0m(+0.06051)
     | > avg_postnet_loss:[92m 2.64185 [0m(-0.08048)
     | > avg_stopnet_loss:[91m 1.35350 [0m(+0.00324)
     | > avg_decoder_coarse_loss:[91m 3.38018 [0m(+0.06272)
     | > avg_decoder_ddc_loss:[92m 0.00168 [0m(-0.00015)
     | > avg_ga_loss:[92m 0.00225 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.45722 [0m(-0.00030)
     | > avg_postnet_diff_spec_loss:[92m 0.84792 [0m(-0.00208)
     | > avg_decoder_ssim_loss:[91m 0.36880 [0m(+0.00022)
     | > avg_postnet_ssim_loss:[92m 0.37730 [0m(-0.00302)
     | > avg_loss:[91m 4.08317 [0m(+0.01256)
     | > avg_align_error:[91m 0.99045 [0m(+0.00030)


[4m[1m > EPOCH: 22/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:25:26) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 271950[0m
     | > decoder_loss: 2.61031  (2.63752)
     | > postnet_loss: 2.92639  (2.66094)
     | > stopnet_loss: 1.79824  (1.70734)
     | > decoder_coarse_loss: 2.57026  (2.56156)
     | > decoder_ddc_loss: 0.00125  (0.00163)
     | > ga_loss: 0.00174  (0.00263)
     | > decoder_diff_spec_loss: 0.48585  (0.46792)
     | > postnet_diff_spec_loss: 0.83757  (0.84550)
     | > decoder_ssim_loss: 0.32820  (0.34479)
     | > postnet_ssim_loss: 0.34187  (0.35895)
     | > loss: 4.33237  (4.19017)
     | > align_error: 0.99211  (0.98911)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.59991  (5.37148)
     | > current_lr: 0.00005 
     | > step_time: 5.21930  (3.88488)
     | > loader_time: 0.02210  (0.04697)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 271975[0m
     | > decoder_loss: 2.49928  (2.52255)
     | > postnet_loss: 2.38501  (2.47583)
     | > stopnet_loss: 1.85928  (1.69096)
     | > decoder_coarse_loss: 2.37291  (2.46048)
     | > decoder_ddc_loss: 0.00252  (0.00159)
     | > ga_loss: 0.00348  (0.00252)
     | > decoder_diff_spec_loss: 0.41833  (0.45771)
     | > postnet_diff_spec_loss: 0.82498  (0.83708)
     | > decoder_ssim_loss: 0.36228  (0.35451)
     | > postnet_ssim_loss: 0.37981  (0.36938)
     | > loss: 4.18793  (4.07332)
     | > align_error: 0.98409  (0.98929)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.46304  (4.55705)
     | > current_lr: 0.00005 
     | > step_time: 2.71050  (3.75258)
     | > loader_time: 0.03780  (0.03442)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 272000[0m
     | > decoder_loss: 2.37779  (2.51049)
     | > postnet_loss: 2.28413  (2.46684)
     | > stopnet_loss: 2.00952  (1.70598)
     | > decoder_coarse_loss: 2.32907  (2.44975)
     | > decoder_ddc_loss: 0.00175  (0.00160)
     | > ga_loss: 0.00323  (0.00256)
     | > decoder_diff_spec_loss: 0.43651  (0.45598)
     | > postnet_diff_spec_loss: 0.83714  (0.83658)
     | > decoder_ssim_loss: 0.30857  (0.35154)
     | > postnet_ssim_loss: 0.32100  (0.36678)
     | > loss: 4.24967  (4.07867)
     | > align_error: 0.98829  (0.98933)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.40250  (4.15721)
     | > current_lr: 0.00005 
     | > step_time: 3.94970  (3.70265)
     | > loader_time: 0.01990  (0.03207)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.92811 [0m(+0.29126)
     | > avg_decoder_loss:[92m 2.72720 [0m(-0.07159)
     | > avg_postnet_loss:[92m 2.50639 [0m(-0.13547)
     | > avg_stopnet_loss:[91m 1.35414 [0m(+0.00064)
     | > avg_decoder_coarse_loss:[92m 3.37998 [0m(-0.00020)
     | > avg_decoder_ddc_loss:[91m 0.00172 [0m(+0.00004)
     | > avg_ga_loss:[92m 0.00225 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.45811 [0m(+0.00089)
     | > avg_postnet_diff_spec_loss:[91m 0.85005 [0m(+0.00213)
     | > avg_decoder_ssim_loss:[92m 0.36788 [0m(-0.00092)
     | > avg_postnet_ssim_loss:[92m 0.37717 [0m(-0.00013)
     | > avg_loss:[92m 4.03250 [0m(-0.05067)
     | > avg_align_error:[92m 0.99024 [0m(-0.00020)


[4m[1m > EPOCH: 23/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:33:13) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 272025[0m
     | > decoder_loss: 2.34094  (2.34094)
     | > postnet_loss: 2.21404  (2.21404)
     | > stopnet_loss: 1.61461  (1.61461)
     | > decoder_coarse_loss: 2.31494  (2.31494)
     | > decoder_ddc_loss: 0.00227  (0.00227)
     | > ga_loss: 0.00305  (0.00305)
     | > decoder_diff_spec_loss: 0.44981  (0.44981)
     | > postnet_diff_spec_loss: 0.82721  (0.82721)
     | > decoder_ssim_loss: 0.37858  (0.37858)
     | > postnet_ssim_loss: 0.39473  (0.39473)
     | > loss: 3.86048  (3.86048)
     | > align_error: 0.98552  (0.98552)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.53074  (4.53074)
     | > current_lr: 0.00005 
     | > step_time: 3.44210  (3.44211)
     | > loader_time: 0.02280  (0.02277)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 272050[0m
     | > decoder_loss: 2.50501  (2.51229)
     | > postnet_loss: 2.27059  (2.43635)
     | > stopnet_loss: 2.07374  (1.75171)
     | > decoder_coarse_loss: 2.41695  (2.44412)
     | > decoder_ddc_loss: 0.00176  (0.00152)
     | > ga_loss: 0.00281  (0.00249)
     | > decoder_diff_spec_loss: 0.49546  (0.46289)
     | > postnet_diff_spec_loss: 0.85182  (0.83893)
     | > decoder_ssim_loss: 0.29114  (0.34309)
     | > postnet_ssim_loss: 0.29868  (0.35601)
     | > loss: 4.37064  (4.11296)
     | > align_error: 0.98797  (0.98949)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.66024  (4.99257)
     | > current_lr: 0.00005 
     | > step_time: 4.06820  (3.91873)
     | > loader_time: 0.01680  (0.04592)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 272075[0m
     | > decoder_loss: 2.33659  (2.47967)
     | > postnet_loss: 2.24883  (2.39978)
     | > stopnet_loss: 1.36444  (1.70012)
     | > decoder_coarse_loss: 2.21574  (2.41191)
     | > decoder_ddc_loss: 0.00171  (0.00156)
     | > ga_loss: 0.00292  (0.00254)
     | > decoder_diff_spec_loss: 0.41262  (0.45746)
     | > postnet_diff_spec_loss: 0.81820  (0.83477)
     | > decoder_ssim_loss: 0.41770  (0.35255)
     | > postnet_ssim_loss: 0.44125  (0.36659)
     | > loss: 3.60219  (4.03892)
     | > align_error: 0.98818  (0.98934)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.00893  (4.33067)
     | > current_lr: 0.00005 
     | > step_time: 3.02690  (3.72057)
     | > loader_time: 0.01710  (0.03720)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 272100[0m
     | > decoder_loss: 2.36584  (2.47983)
     | > postnet_loss: 2.07821  (2.38178)
     | > stopnet_loss: 1.61443  (1.70812)
     | > decoder_coarse_loss: 2.23352  (2.41345)
     | > decoder_ddc_loss: 0.00125  (0.00155)
     | > ga_loss: 0.00231  (0.00255)
     | > decoder_diff_spec_loss: 0.45884  (0.45688)
     | > postnet_diff_spec_loss: 0.82999  (0.83393)
     | > decoder_ssim_loss: 0.32976  (0.35089)
     | > postnet_ssim_loss: 0.34354  (0.36479)
     | > loss: 3.78620  (4.04166)
     | > align_error: 0.99180  (0.98948)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.31426  (4.32332)
     | > current_lr: 0.00005 
     | > step_time: 4.03130  (3.71747)
     | > loader_time: 0.02210  (0.03444)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.92821 [0m(+0.00010)
     | > avg_decoder_loss:[92m 2.70199 [0m(-0.02521)
     | > avg_postnet_loss:[92m 2.39750 [0m(-0.10889)
     | > avg_stopnet_loss:[91m 1.35479 [0m(+0.00065)
     | > avg_decoder_coarse_loss:[91m 3.39688 [0m(+0.01690)
     | > avg_decoder_ddc_loss:[92m 0.00164 [0m(-0.00008)
     | > avg_ga_loss:[92m 0.00224 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.45956 [0m(+0.00145)
     | > avg_postnet_diff_spec_loss:[92m 0.84675 [0m(-0.00330)
     | > avg_decoder_ssim_loss:[92m 0.36726 [0m(-0.00062)
     | > avg_postnet_ssim_loss:[92m 0.37511 [0m(-0.00207)
     | > avg_loss:[92m 4.00268 [0m(-0.02981)
     | > avg_align_error:[91m 0.99027 [0m(+0.00003)


[4m[1m > EPOCH: 24/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:40:52) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 272125[0m
     | > decoder_loss: 2.71838  (2.58386)
     | > postnet_loss: 2.47345  (2.49014)
     | > stopnet_loss: 1.81172  (1.72556)
     | > decoder_coarse_loss: 2.61578  (2.48845)
     | > decoder_ddc_loss: 0.00213  (0.00159)
     | > ga_loss: 0.00333  (0.00270)
     | > decoder_diff_spec_loss: 0.49995  (0.46790)
     | > postnet_diff_spec_loss: 0.89093  (0.84384)
     | > decoder_ssim_loss: 0.34134  (0.34493)
     | > postnet_ssim_loss: 0.35233  (0.35650)
     | > loss: 4.30194  (4.13335)
     | > align_error: 0.98642  (0.98903)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.65197  (5.65744)
     | > current_lr: 0.00005 
     | > step_time: 2.14940  (3.88423)
     | > loader_time: 0.01700  (0.04555)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 272150[0m
     | > decoder_loss: 2.40143  (2.47179)
     | > postnet_loss: 2.13549  (2.33968)
     | > stopnet_loss: 1.39407  (1.68828)
     | > decoder_coarse_loss: 2.29063  (2.39506)
     | > decoder_ddc_loss: 0.00127  (0.00150)
     | > ga_loss: 0.00240  (0.00249)
     | > decoder_diff_spec_loss: 0.42686  (0.46315)
     | > postnet_diff_spec_loss: 0.79978  (0.83414)
     | > decoder_ssim_loss: 0.39255  (0.35316)
     | > postnet_ssim_loss: 0.40509  (0.36543)
     | > loss: 3.61933  (4.00669)
     | > align_error: 0.99134  (0.98951)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.47864  (4.84726)
     | > current_lr: 0.00005 
     | > step_time: 3.59190  (3.85911)
     | > loader_time: 0.02210  (0.03378)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 272175[0m
     | > decoder_loss: 2.66627  (2.46142)
     | > postnet_loss: 2.31141  (2.33702)
     | > stopnet_loss: 2.41056  (1.71616)
     | > decoder_coarse_loss: 2.64210  (2.39058)
     | > decoder_ddc_loss: 0.00146  (0.00153)
     | > ga_loss: 0.00294  (0.00255)
     | > decoder_diff_spec_loss: 0.53450  (0.46097)
     | > postnet_diff_spec_loss: 0.89844  (0.83321)
     | > decoder_ssim_loss: 0.26512  (0.35102)
     | > postnet_ssim_loss: 0.26911  (0.36376)
     | > loss: 4.82236  (4.02879)
     | > align_error: 0.99004  (0.98942)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.26738  (4.52565)
     | > current_lr: 0.00005 
     | > step_time: 3.94240  (3.75882)
     | > loader_time: 0.02650  (0.03249)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.73307 [0m(-0.19514)
     | > avg_decoder_loss:[92m 2.68461 [0m(-0.01738)
     | > avg_postnet_loss:[91m 2.41075 [0m(+0.01325)
     | > avg_stopnet_loss:[92m 1.35259 [0m(-0.00221)
     | > avg_decoder_coarse_loss:[91m 3.46508 [0m(+0.06820)
     | > avg_decoder_ddc_loss:[92m 0.00163 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00223 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.46319 [0m(+0.00363)
     | > avg_postnet_diff_spec_loss:[92m 0.84523 [0m(-0.00152)
     | > avg_decoder_ssim_loss:[92m 0.36638 [0m(-0.00088)
     | > avg_postnet_ssim_loss:[92m 0.37451 [0m(-0.00060)
     | > avg_loss:[91m 4.01658 [0m(+0.01390)
     | > avg_align_error:[92m 0.99027 [0m(-0.00000)


[4m[1m > EPOCH: 25/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:48:28) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 272200[0m
     | > decoder_loss: 2.34540  (2.34540)
     | > postnet_loss: 2.14741  (2.14741)
     | > stopnet_loss: 1.70091  (1.70091)
     | > decoder_coarse_loss: 2.28795  (2.28795)
     | > decoder_ddc_loss: 0.00183  (0.00183)
     | > ga_loss: 0.00317  (0.00317)
     | > decoder_diff_spec_loss: 0.46196  (0.46196)
     | > postnet_diff_spec_loss: 0.82914  (0.82914)
     | > decoder_ssim_loss: 0.36397  (0.36397)
     | > postnet_ssim_loss: 0.37404  (0.37404)
     | > loss: 3.91968  (3.91968)
     | > align_error: 0.98731  (0.98731)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.19532  (3.19532)
     | > current_lr: 0.00006 
     | > step_time: 4.22580  (4.22582)
     | > loader_time: 7.32120  (7.32122)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 272225[0m
     | > decoder_loss: 2.51573  (2.44861)
     | > postnet_loss: 2.56673  (2.31641)
     | > stopnet_loss: 1.18154  (1.74845)
     | > decoder_coarse_loss: 2.42613  (2.38751)
     | > decoder_ddc_loss: 0.00178  (0.00147)
     | > ga_loss: 0.00251  (0.00246)
     | > decoder_diff_spec_loss: 0.47535  (0.46677)
     | > postnet_diff_spec_loss: 0.83882  (0.83443)
     | > decoder_ssim_loss: 0.46909  (0.34406)
     | > postnet_ssim_loss: 0.48601  (0.35501)
     | > loss: 3.63900  (4.04934)
     | > align_error: 0.98766  (0.98963)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.23881  (5.25511)
     | > current_lr: 0.00006 
     | > step_time: 2.52030  (3.85813)
     | > loader_time: 0.05040  (0.04984)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 272250[0m
     | > decoder_loss: 2.18646  (2.42536)
     | > postnet_loss: 2.11503  (2.28165)
     | > stopnet_loss: 1.36511  (1.71490)
     | > decoder_coarse_loss: 2.11747  (2.35493)
     | > decoder_ddc_loss: 0.00167  (0.00152)
     | > ga_loss: 0.00273  (0.00252)
     | > decoder_diff_spec_loss: 0.43439  (0.46444)
     | > postnet_diff_spec_loss: 0.82832  (0.83104)
     | > decoder_ssim_loss: 0.43177  (0.35002)
     | > postnet_ssim_loss: 0.44681  (0.36155)
     | > loss: 3.51925  (3.99515)
     | > align_error: 0.98861  (0.98944)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.32002  (4.46039)
     | > current_lr: 0.00006 
     | > step_time: 3.09540  (3.72518)
     | > loader_time: 0.02860  (0.04073)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 272275[0m
     | > decoder_loss: 2.27193  (2.42041)
     | > postnet_loss: 2.03405  (2.26833)
     | > stopnet_loss: 1.59546  (1.71431)
     | > decoder_coarse_loss: 2.23678  (2.34856)
     | > decoder_ddc_loss: 0.00156  (0.00153)
     | > ga_loss: 0.00277  (0.00254)
     | > decoder_diff_spec_loss: 0.47577  (0.46299)
     | > postnet_diff_spec_loss: 0.83715  (0.82989)
     | > decoder_ssim_loss: 0.37580  (0.34972)
     | > postnet_ssim_loss: 0.38685  (0.36138)
     | > loss: 3.76428  (3.98771)
     | > align_error: 0.98925  (0.98950)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.44474  (4.30374)
     | > current_lr: 0.00006 
     | > step_time: 3.55300  (3.76517)
     | > loader_time: 0.02360  (0.03996)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.86862 [0m(+0.13555)
     | > avg_decoder_loss:[91m 2.73300 [0m(+0.04839)
     | > avg_postnet_loss:[92m 2.36184 [0m(-0.04891)
     | > avg_stopnet_loss:[91m 1.35331 [0m(+0.00072)
     | > avg_decoder_coarse_loss:[91m 3.67713 [0m(+0.21204)
     | > avg_decoder_ddc_loss:[92m 0.00159 [0m(-0.00005)
     | > avg_ga_loss:[91m 0.00223 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.46941 [0m(+0.00622)
     | > avg_postnet_diff_spec_loss:[92m 0.84494 [0m(-0.00029)
     | > avg_decoder_ssim_loss:[92m 0.36575 [0m(-0.00063)
     | > avg_postnet_ssim_loss:[92m 0.37440 [0m(-0.00011)
     | > avg_loss:[91m 4.07147 [0m(+0.05489)
     | > avg_align_error:[91m 0.99041 [0m(+0.00014)


[4m[1m > EPOCH: 26/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 12:56:05) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 272300[0m
     | > decoder_loss: 2.56887  (2.49958)
     | > postnet_loss: 2.30015  (2.38810)
     | > stopnet_loss: 2.05091  (1.73102)
     | > decoder_coarse_loss: 2.41886  (2.42547)
     | > decoder_ddc_loss: 0.00105  (0.00151)
     | > ga_loss: 0.00235  (0.00264)
     | > decoder_diff_spec_loss: 0.44858  (0.47420)
     | > postnet_diff_spec_loss: 0.82572  (0.83592)
     | > decoder_ssim_loss: 0.27875  (0.34301)
     | > postnet_ssim_loss: 0.28627  (0.35339)
     | > loss: 4.34473  (4.07452)
     | > align_error: 0.99151  (0.98924)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.11212  (5.66522)
     | > current_lr: 0.00006 
     | > step_time: 5.28700  (4.05725)
     | > loader_time: 0.01880  (0.03015)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 272325[0m
     | > decoder_loss: 2.34131  (2.39876)
     | > postnet_loss: 2.02477  (2.23176)
     | > stopnet_loss: 1.39639  (1.70181)
     | > decoder_coarse_loss: 2.27968  (2.34010)
     | > decoder_ddc_loss: 0.00159  (0.00149)
     | > ga_loss: 0.00265  (0.00249)
     | > decoder_diff_spec_loss: 0.45630  (0.47294)
     | > postnet_diff_spec_loss: 0.82664  (0.83106)
     | > decoder_ssim_loss: 0.41942  (0.34994)
     | > postnet_ssim_loss: 0.43580  (0.36110)
     | > loss: 3.60601  (3.96104)
     | > align_error: 0.98892  (0.98953)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.52306  (4.85071)
     | > current_lr: 0.00006 
     | > step_time: 2.78790  (3.88766)
     | > loader_time: 0.01970  (0.02924)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 272350[0m
     | > decoder_loss: 2.50499  (2.38241)
     | > postnet_loss: 2.42609  (2.21969)
     | > stopnet_loss: 1.50005  (1.70363)
     | > decoder_coarse_loss: 2.42033  (2.32061)
     | > decoder_ddc_loss: 0.00107  (0.00152)
     | > ga_loss: 0.00179  (0.00254)
     | > decoder_diff_spec_loss: 0.43902  (0.46854)
     | > postnet_diff_spec_loss: 0.81204  (0.82813)
     | > decoder_ssim_loss: 0.36063  (0.35037)
     | > postnet_ssim_loss: 0.37531  (0.36179)
     | > loss: 3.84385  (3.94958)
     | > align_error: 0.99209  (0.98950)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.18292  (4.61466)
     | > current_lr: 0.00006 
     | > step_time: 4.95460  (3.79961)
     | > loader_time: 0.04760  (0.02819)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 272375[0m
     | > decoder_loss: 1.59334  (2.36528)
     | > postnet_loss: 2.09024  (2.20150)
     | > stopnet_loss: 1.98492  (1.72278)
     | > decoder_coarse_loss: 1.62656  (2.30505)
     | > decoder_ddc_loss: 0.00304  (0.00154)
     | > ga_loss: 0.00420  (0.00260)
     | > decoder_diff_spec_loss: 0.37961  (0.46767)
     | > postnet_diff_spec_loss: 0.74796  (0.82682)
     | > decoder_ssim_loss: 0.40284  (0.34758)
     | > postnet_ssim_loss: 0.42474  (0.35861)
     | > loss: 3.82299  (3.95429)
     | > align_error: 0.97788  (0.98930)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 22.76603  (4.70598)
     | > current_lr: 0.00006 
     | > step_time: 1.07950  (3.64629)
     | > loader_time: 0.00510  (0.03028)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.00765 [0m(+0.13903)
     | > avg_decoder_loss:[92m 2.67867 [0m(-0.05433)
     | > avg_postnet_loss:[92m 2.28883 [0m(-0.07301)
     | > avg_stopnet_loss:[91m 1.35578 [0m(+0.00248)
     | > avg_decoder_coarse_loss:[92m 3.40932 [0m(-0.26780)
     | > avg_decoder_ddc_loss:[92m 0.00151 [0m(-0.00007)
     | > avg_ga_loss:[92m 0.00223 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47405 [0m(+0.00464)
     | > avg_postnet_diff_spec_loss:[92m 0.84076 [0m(-0.00418)
     | > avg_decoder_ssim_loss:[92m 0.36402 [0m(-0.00173)
     | > avg_postnet_ssim_loss:[92m 0.37020 [0m(-0.00420)
     | > avg_loss:[92m 3.97376 [0m(-0.09772)
     | > avg_align_error:[91m 0.99051 [0m(+0.00010)


[4m[1m > EPOCH: 27/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:03:44) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 272400[0m
     | > decoder_loss: 2.37055  (2.35697)
     | > postnet_loss: 2.15599  (2.18830)
     | > stopnet_loss: 1.26714  (1.76436)
     | > decoder_coarse_loss: 2.30432  (2.30648)
     | > decoder_ddc_loss: 0.00131  (0.00146)
     | > ga_loss: 0.00223  (0.00247)
     | > decoder_diff_spec_loss: 0.46530  (0.47582)
     | > postnet_diff_spec_loss: 0.83113  (0.83015)
     | > decoder_ssim_loss: 0.41602  (0.33649)
     | > postnet_ssim_loss: 0.43030  (0.34652)
     | > loss: 3.52201  (3.98724)
     | > align_error: 0.98993  (0.98983)
     | > amp_scaler: 32768.00000  (55978.66667)
     | > grad_norm: 1.48298  (4.80059)
     | > current_lr: 0.00006 
     | > step_time: 4.53900  (4.02874)
     | > loader_time: 0.03310  (0.03388)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 272425[0m
     | > decoder_loss: 2.44632  (2.33191)
     | > postnet_loss: 2.25394  (2.15298)
     | > stopnet_loss: 1.22025  (1.71586)
     | > decoder_coarse_loss: 2.36986  (2.28638)
     | > decoder_ddc_loss: 0.00115  (0.00151)
     | > ga_loss: 0.00210  (0.00254)
     | > decoder_diff_spec_loss: 0.47564  (0.47554)
     | > postnet_diff_spec_loss: 0.82373  (0.82656)
     | > decoder_ssim_loss: 0.40286  (0.34561)
     | > postnet_ssim_loss: 0.41776  (0.35610)
     | > loss: 3.52857  (3.92268)
     | > align_error: 0.99174  (0.98956)
     | > amp_scaler: 32768.00000  (44136.48980)
     | > grad_norm: 7.38723  (4.38154)
     | > current_lr: 0.00006 
     | > step_time: 4.01230  (3.80032)
     | > loader_time: 0.02340  (0.03128)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 272450[0m
     | > decoder_loss: 2.28552  (2.32341)
     | > postnet_loss: 2.07111  (2.13501)
     | > stopnet_loss: 1.35662  (1.71221)
     | > decoder_coarse_loss: 2.24698  (2.28083)
     | > decoder_ddc_loss: 0.00135  (0.00152)
     | > ga_loss: 0.00241  (0.00255)
     | > decoder_diff_spec_loss: 0.48080  (0.47380)
     | > postnet_diff_spec_loss: 0.84176  (0.82526)
     | > decoder_ssim_loss: 0.40286  (0.34667)
     | > postnet_ssim_loss: 0.41107  (0.35714)
     | > loss: 3.55404  (3.91087)
     | > align_error: 0.99025  (0.98959)
     | > amp_scaler: 32768.00000  (40295.78378)
     | > grad_norm: 2.76030  (4.28480)
     | > current_lr: 0.00006 
     | > step_time: 4.04590  (3.79069)
     | > loader_time: 0.02150  (0.03205)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.66228 [0m(-0.34537)
     | > avg_decoder_loss:[91m 2.69402 [0m(+0.01535)
     | > avg_postnet_loss:[91m 2.50537 [0m(+0.21654)
     | > avg_stopnet_loss:[91m 1.35777 [0m(+0.00198)
     | > avg_decoder_coarse_loss:[91m 3.47857 [0m(+0.06924)
     | > avg_decoder_ddc_loss:[91m 0.00152 [0m(+0.00000)
     | > avg_ga_loss:[91m 0.00223 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.48411 [0m(+0.01006)
     | > avg_postnet_diff_spec_loss:[92m 0.83929 [0m(-0.00147)
     | > avg_decoder_ssim_loss:[92m 0.36245 [0m(-0.00158)
     | > avg_postnet_ssim_loss:[92m 0.36891 [0m(-0.00129)
     | > avg_loss:[91m 4.05247 [0m(+0.07871)
     | > avg_align_error:[91m 0.99062 [0m(+0.00011)


[4m[1m > EPOCH: 28/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:11:28) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 272475[0m
     | > decoder_loss: 2.29156  (2.39596)
     | > postnet_loss: 2.14406  (2.25679)
     | > stopnet_loss: 2.08159  (1.68228)
     | > decoder_coarse_loss: 2.22812  (2.34614)
     | > decoder_ddc_loss: 0.00136  (0.00155)
     | > ga_loss: 0.00297  (0.00267)
     | > decoder_diff_spec_loss: 0.51297  (0.49028)
     | > postnet_diff_spec_loss: 0.83833  (0.83210)
     | > decoder_ssim_loss: 0.27898  (0.34604)
     | > postnet_ssim_loss: 0.28208  (0.35604)
     | > loss: 4.24079  (3.95185)
     | > align_error: 0.98977  (0.98916)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.97214  (5.06710)
     | > current_lr: 0.00006 
     | > step_time: 4.14120  (4.02576)
     | > loader_time: 0.01790  (0.04156)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 272500[0m
     | > decoder_loss: 2.21961  (2.29328)
     | > postnet_loss: 1.84304  (2.10211)
     | > stopnet_loss: 1.40332  (1.70440)
     | > decoder_coarse_loss: 2.18976  (2.27282)
     | > decoder_ddc_loss: 0.00148  (0.00147)
     | > ga_loss: 0.00217  (0.00248)
     | > decoder_diff_spec_loss: 0.47887  (0.48441)
     | > postnet_diff_spec_loss: 0.80272  (0.82691)
     | > decoder_ssim_loss: 0.39091  (0.34498)
     | > postnet_ssim_loss: 0.39858  (0.35499)
     | > loss: 3.49539  (3.88703)
     | > align_error: 0.98938  (0.98965)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.96953  (4.24939)
     | > current_lr: 0.00006 
     | > step_time: 3.84470  (3.90034)
     | > loader_time: 0.03690  (0.03250)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 272525[0m
     | > decoder_loss: 2.30057  (2.27170)
     | > postnet_loss: 1.88699  (2.07929)
     | > stopnet_loss: 1.57924  (1.68688)
     | > decoder_coarse_loss: 2.29305  (2.24998)
     | > decoder_ddc_loss: 0.00314  (0.00152)
     | > ga_loss: 0.00453  (0.00254)
     | > decoder_diff_spec_loss: 0.49515  (0.48055)
     | > postnet_diff_spec_loss: 0.82822  (0.82393)
     | > decoder_ssim_loss: 0.40322  (0.34697)
     | > postnet_ssim_loss: 0.40823  (0.35715)
     | > loss: 3.75652  (3.85237)
     | > align_error: 0.98155  (0.98955)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 12.45906  (4.43793)
     | > current_lr: 0.00006 
     | > step_time: 1.77250  (3.72322)
     | > loader_time: 0.02610  (0.03343)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 272550[0m
     | > decoder_loss: 2.13083  (2.26408)
     | > postnet_loss: 1.92645  (2.06837)
     | > stopnet_loss: 1.58036  (1.70087)
     | > decoder_coarse_loss: 2.12240  (2.24599)
     | > decoder_ddc_loss: 0.00164  (0.00151)
     | > ga_loss: 0.00276  (0.00257)
     | > decoder_diff_spec_loss: 0.49521  (0.48057)
     | > postnet_diff_spec_loss: 0.84246  (0.82331)
     | > decoder_ssim_loss: 0.36253  (0.34364)
     | > postnet_ssim_loss: 0.36789  (0.35351)
     | > loss: 3.65651  (3.85897)
     | > align_error: 0.98889  (0.98952)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.85438  (4.30290)
     | > current_lr: 0.00006 
     | > step_time: 2.14390  (3.65481)
     | > loader_time: 0.02330  (0.03346)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.17144 [0m(-0.49084)
     | > avg_decoder_loss:[92m 2.68097 [0m(-0.01305)
     | > avg_postnet_loss:[92m 2.49660 [0m(-0.00878)
     | > avg_stopnet_loss:[92m 1.35298 [0m(-0.00479)
     | > avg_decoder_coarse_loss:[91m 3.55254 [0m(+0.07397)
     | > avg_decoder_ddc_loss:[92m 0.00148 [0m(-0.00003)
     | > avg_ga_loss:[92m 0.00223 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.48963 [0m(+0.00552)
     | > avg_postnet_diff_spec_loss:[92m 0.83671 [0m(-0.00258)
     | > avg_decoder_ssim_loss:[92m 0.36033 [0m(-0.00212)
     | > avg_postnet_ssim_loss:[92m 0.36600 [0m(-0.00291)
     | > avg_loss:[91m 4.06018 [0m(+0.00772)
     | > avg_align_error:[91m 0.99071 [0m(+0.00009)


[4m[1m > EPOCH: 29/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:19:06) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 272575[0m
     | > decoder_loss: 2.10051  (2.24141)
     | > postnet_loss: 1.83029  (2.05653)
     | > stopnet_loss: 2.68651  (1.76598)
     | > decoder_coarse_loss: 2.08664  (2.25156)
     | > decoder_ddc_loss: 0.00118  (0.00140)
     | > ga_loss: 0.00209  (0.00248)
     | > decoder_diff_spec_loss: 0.47479  (0.48836)
     | > postnet_diff_spec_loss: 0.79520  (0.82534)
     | > decoder_ssim_loss: 0.21518  (0.32938)
     | > postnet_ssim_loss: 0.21923  (0.33865)
     | > loss: 4.62769  (3.91151)
     | > align_error: 0.99157  (0.98987)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.83362  (4.78678)
     | > current_lr: 0.00006 
     | > step_time: 5.37670  (4.03059)
     | > loader_time: 0.02580  (0.04104)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 272600[0m
     | > decoder_loss: 2.19381  (2.21606)
     | > postnet_loss: 1.93725  (2.03104)
     | > stopnet_loss: 1.64271  (1.70773)
     | > decoder_coarse_loss: 2.23415  (2.22598)
     | > decoder_ddc_loss: 0.00167  (0.00147)
     | > ga_loss: 0.00290  (0.00253)
     | > decoder_diff_spec_loss: 0.50026  (0.48587)
     | > postnet_diff_spec_loss: 0.82456  (0.82266)
     | > decoder_ssim_loss: 0.34153  (0.34071)
     | > postnet_ssim_loss: 0.34457  (0.35071)
     | > loss: 3.75165  (3.83900)
     | > align_error: 0.98802  (0.98955)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.75240  (4.03095)
     | > current_lr: 0.00006 
     | > step_time: 3.43290  (3.78836)
     | > loader_time: 0.01890  (0.03711)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 272625[0m
     | > decoder_loss: 1.96369  (2.21477)
     | > postnet_loss: 1.73683  (2.02242)
     | > stopnet_loss: 2.37957  (1.69566)
     | > decoder_coarse_loss: 1.99832  (2.22116)
     | > decoder_ddc_loss: 0.00100  (0.00146)
     | > ga_loss: 0.00252  (0.00254)
     | > decoder_diff_spec_loss: 0.45757  (0.48381)
     | > postnet_diff_spec_loss: 0.80731  (0.82126)
     | > decoder_ssim_loss: 0.23789  (0.34226)
     | > postnet_ssim_loss: 0.24343  (0.35242)
     | > loss: 4.25370  (3.82327)
     | > align_error: 0.99244  (0.98961)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.59049  (4.17404)
     | > current_lr: 0.00007 
     | > step_time: 4.62370  (3.78192)
     | > loader_time: 0.02290  (0.03669)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.58006 [0m(+1.40863)
     | > avg_decoder_loss:[92m 2.59089 [0m(-0.09007)
     | > avg_postnet_loss:[92m 2.40903 [0m(-0.08757)
     | > avg_stopnet_loss:[92m 1.34330 [0m(-0.00967)
     | > avg_decoder_coarse_loss:[92m 3.33026 [0m(-0.22227)
     | > avg_decoder_ddc_loss:[92m 0.00141 [0m(-0.00007)
     | > avg_ga_loss:[92m 0.00223 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.49050 [0m(+0.00087)
     | > avg_postnet_diff_spec_loss:[91m 0.83750 [0m(+0.00079)
     | > avg_decoder_ssim_loss:[92m 0.35834 [0m(-0.00199)
     | > avg_postnet_ssim_loss:[92m 0.36547 [0m(-0.00053)
     | > avg_loss:[92m 3.95029 [0m(-0.10990)
     | > avg_align_error:[92m 0.99062 [0m(-0.00009)


[4m[1m > EPOCH: 30/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:26:45) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 272650[0m
     | > decoder_loss: 2.44316  (2.29350)
     | > postnet_loss: 2.10025  (2.17484)
     | > stopnet_loss: 1.63391  (1.64050)
     | > decoder_coarse_loss: 2.44074  (2.28317)
     | > decoder_ddc_loss: 0.00143  (0.00148)
     | > ga_loss: 0.00250  (0.00263)
     | > decoder_diff_spec_loss: 0.54427  (0.49287)
     | > postnet_diff_spec_loss: 0.86821  (0.82786)
     | > decoder_ssim_loss: 0.32483  (0.34946)
     | > postnet_ssim_loss: 0.32824  (0.36207)
     | > loss: 3.90919  (3.84998)
     | > align_error: 0.98980  (0.98908)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.61397  (5.59080)
     | > current_lr: 0.00007 
     | > step_time: 3.67960  (3.90518)
     | > loader_time: 0.04980  (0.04550)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 272675[0m
     | > decoder_loss: 2.37784  (2.19344)
     | > postnet_loss: 2.02712  (2.02076)
     | > stopnet_loss: 1.76340  (1.71151)
     | > decoder_coarse_loss: 2.40255  (2.19873)
     | > decoder_ddc_loss: 0.00140  (0.00140)
     | > ga_loss: 0.00244  (0.00248)
     | > decoder_diff_spec_loss: 0.53430  (0.49126)
     | > postnet_diff_spec_loss: 0.85481  (0.82457)
     | > decoder_ssim_loss: 0.31958  (0.34024)
     | > postnet_ssim_loss: 0.32542  (0.35096)
     | > loss: 3.98638  (3.82925)
     | > align_error: 0.98967  (0.98961)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.05924  (4.16815)
     | > current_lr: 0.00007 
     | > step_time: 3.75010  (3.89167)
     | > loader_time: 0.04250  (0.03264)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 272700[0m
     | > decoder_loss: 2.00425  (2.17658)
     | > postnet_loss: 1.75792  (1.99705)
     | > stopnet_loss: 1.02070  (1.69311)
     | > decoder_coarse_loss: 2.02111  (2.18051)
     | > decoder_ddc_loss: 0.00163  (0.00143)
     | > ga_loss: 0.00259  (0.00250)
     | > decoder_diff_spec_loss: 0.45772  (0.48706)
     | > postnet_diff_spec_loss: 0.80030  (0.82067)
     | > decoder_ssim_loss: 0.46832  (0.34282)
     | > postnet_ssim_loss: 0.48874  (0.35351)
     | > loss: 3.03366  (3.79552)
     | > align_error: 0.98862  (0.98963)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.66616  (4.10382)
     | > current_lr: 0.00007 
     | > step_time: 2.95190  (3.78381)
     | > loader_time: 0.02020  (0.03265)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 272725[0m
     | > decoder_loss: 2.22999  (2.17392)
     | > postnet_loss: 1.89326  (1.98958)
     | > stopnet_loss: 1.94343  (1.70537)
     | > decoder_coarse_loss: 2.21148  (2.17784)
     | > decoder_ddc_loss: 0.00144  (0.00145)
     | > ga_loss: 0.00290  (0.00256)
     | > decoder_diff_spec_loss: 0.51181  (0.48690)
     | > postnet_diff_spec_loss: 0.82679  (0.82040)
     | > decoder_ssim_loss: 0.30201  (0.34033)
     | > postnet_ssim_loss: 0.30636  (0.35079)
     | > loss: 4.02873  (3.80344)
     | > align_error: 0.98916  (0.98947)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.94527  (4.20110)
     | > current_lr: 0.00007 
     | > step_time: 2.33010  (3.68993)
     | > loader_time: 0.01830  (0.03144)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.98948 [0m(-0.59058)
     | > avg_decoder_loss:[92m 2.53107 [0m(-0.05983)
     | > avg_postnet_loss:[92m 2.27683 [0m(-0.13220)
     | > avg_stopnet_loss:[92m 1.33699 [0m(-0.00632)
     | > avg_decoder_coarse_loss:[92m 3.23342 [0m(-0.09684)
     | > avg_decoder_ddc_loss:[92m 0.00139 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00222 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.49134 [0m(+0.00083)
     | > avg_postnet_diff_spec_loss:[92m 0.83563 [0m(-0.00186)
     | > avg_decoder_ssim_loss:[92m 0.35681 [0m(-0.00154)
     | > avg_postnet_ssim_loss:[92m 0.36491 [0m(-0.00056)
     | > avg_loss:[92m 3.87092 [0m(-0.07937)
     | > avg_align_error:[92m 0.99043 [0m(-0.00018)


[4m[1m > EPOCH: 31/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:34:20) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 272750[0m
     | > decoder_loss: 2.00958  (2.17410)
     | > postnet_loss: 1.74090  (1.99151)
     | > stopnet_loss: 2.00117  (1.73402)
     | > decoder_coarse_loss: 2.03325  (2.17810)
     | > decoder_ddc_loss: 0.00099  (0.00136)
     | > ga_loss: 0.00233  (0.00248)
     | > decoder_diff_spec_loss: 0.47784  (0.49475)
     | > postnet_diff_spec_loss: 0.80535  (0.82431)
     | > decoder_ssim_loss: 0.29239  (0.33209)
     | > postnet_ssim_loss: 0.30347  (0.34221)
     | > loss: 3.92876  (3.83101)
     | > align_error: 0.99174  (0.98967)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.07247  (5.02185)
     | > current_lr: 0.00007 
     | > step_time: 4.09820  (4.01715)
     | > loader_time: 0.02250  (0.03497)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 272775[0m
     | > decoder_loss: 2.11646  (2.14952)
     | > postnet_loss: 1.97011  (1.96347)
     | > stopnet_loss: 1.43151  (1.71867)
     | > decoder_coarse_loss: 2.15194  (2.15482)
     | > decoder_ddc_loss: 0.00161  (0.00142)
     | > ga_loss: 0.00267  (0.00250)
     | > decoder_diff_spec_loss: 0.50040  (0.49080)
     | > postnet_diff_spec_loss: 0.83457  (0.82027)
     | > decoder_ssim_loss: 0.38455  (0.33835)
     | > postnet_ssim_loss: 0.39148  (0.34884)
     | > loss: 3.53266  (3.79805)
     | > align_error: 0.98875  (0.98949)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.96240  (4.59152)
     | > current_lr: 0.00007 
     | > step_time: 2.48740  (3.80555)
     | > loader_time: 0.04250  (0.03335)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 272800[0m
     | > decoder_loss: 2.20503  (2.15208)
     | > postnet_loss: 1.97954  (1.96002)
     | > stopnet_loss: 1.22462  (1.69033)
     | > decoder_coarse_loss: 2.20666  (2.15462)
     | > decoder_ddc_loss: 0.00121  (0.00143)
     | > ga_loss: 0.00183  (0.00252)
     | > decoder_diff_spec_loss: 0.47265  (0.48863)
     | > postnet_diff_spec_loss: 0.80215  (0.81913)
     | > decoder_ssim_loss: 0.41119  (0.34144)
     | > postnet_ssim_loss: 0.42713  (0.35196)
     | > loss: 3.36018  (3.77025)
     | > align_error: 0.99140  (0.98950)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.43881  (4.40528)
     | > current_lr: 0.00007 
     | > step_time: 4.77930  (3.79317)
     | > loader_time: 0.02310  (0.03369)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.24702 [0m(-0.74246)
     | > avg_decoder_loss:[91m 2.64268 [0m(+0.11161)
     | > avg_postnet_loss:[91m 2.46287 [0m(+0.18604)
     | > avg_stopnet_loss:[92m 1.33417 [0m(-0.00282)
     | > avg_decoder_coarse_loss:[91m 3.35018 [0m(+0.11676)
     | > avg_decoder_ddc_loss:[92m 0.00134 [0m(-0.00005)
     | > avg_ga_loss:[92m 0.00221 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.49272 [0m(+0.00139)
     | > avg_postnet_diff_spec_loss:[92m 0.83370 [0m(-0.00193)
     | > avg_decoder_ssim_loss:[92m 0.35634 [0m(-0.00046)
     | > avg_postnet_ssim_loss:[92m 0.36366 [0m(-0.00125)
     | > avg_loss:[91m 3.97110 [0m(+0.10018)
     | > avg_align_error:[91m 0.99058 [0m(+0.00015)


[4m[1m > EPOCH: 32/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:42:04) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 272825[0m
     | > decoder_loss: 2.35015  (2.21885)
     | > postnet_loss: 2.14678  (2.10056)
     | > stopnet_loss: 1.41212  (1.60370)
     | > decoder_coarse_loss: 2.27227  (2.18383)
     | > decoder_ddc_loss: 0.00177  (0.00147)
     | > ga_loss: 0.00274  (0.00262)
     | > decoder_diff_spec_loss: 0.51666  (0.49099)
     | > postnet_diff_spec_loss: 0.84801  (0.81991)
     | > decoder_ssim_loss: 0.39713  (0.34974)
     | > postnet_ssim_loss: 0.41158  (0.36274)
     | > loss: 3.66189  (3.74882)
     | > align_error: 0.98799  (0.98902)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.32745  (5.03066)
     | > current_lr: 0.00007 
     | > step_time: 3.10620  (3.84784)
     | > loader_time: 0.04820  (0.04395)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 272850[0m
     | > decoder_loss: 2.10322  (2.14422)
     | > postnet_loss: 2.07753  (1.95995)
     | > stopnet_loss: 1.19822  (1.69086)
     | > decoder_coarse_loss: 2.09008  (2.13865)
     | > decoder_ddc_loss: 0.00147  (0.00137)
     | > ga_loss: 0.00222  (0.00246)
     | > decoder_diff_spec_loss: 0.49221  (0.49400)
     | > postnet_diff_spec_loss: 0.80847  (0.82105)
     | > decoder_ssim_loss: 0.40616  (0.33893)
     | > postnet_ssim_loss: 0.42494  (0.34953)
     | > loss: 3.31033  (3.76506)
     | > align_error: 0.98912  (0.98957)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.10850  (4.09680)
     | > current_lr: 0.00007 
     | > step_time: 3.65050  (3.81816)
     | > loader_time: 0.02170  (0.03336)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 272875[0m
     | > decoder_loss: 1.94883  (2.13138)
     | > postnet_loss: 1.71383  (1.94435)
     | > stopnet_loss: 1.43306  (1.68470)
     | > decoder_coarse_loss: 1.94155  (2.12002)
     | > decoder_ddc_loss: 0.00140  (0.00139)
     | > ga_loss: 0.00243  (0.00248)
     | > decoder_diff_spec_loss: 0.47619  (0.49070)
     | > postnet_diff_spec_loss: 0.79319  (0.81859)
     | > decoder_ssim_loss: 0.42802  (0.33870)
     | > postnet_ssim_loss: 0.43411  (0.34904)
     | > loss: 3.37950  (3.74562)
     | > align_error: 0.98969  (0.98960)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.05919  (4.02937)
     | > current_lr: 0.00007 
     | > step_time: 3.39680  (3.75712)
     | > loader_time: 0.01950  (0.03418)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 272900[0m
     | > decoder_loss: 2.27053  (2.12427)
     | > postnet_loss: 2.15757  (1.93396)
     | > stopnet_loss: 1.62430  (1.69308)
     | > decoder_coarse_loss: 2.23274  (2.11229)
     | > decoder_ddc_loss: 0.00192  (0.00141)
     | > ga_loss: 0.00317  (0.00253)
     | > decoder_diff_spec_loss: 0.53255  (0.48942)
     | > postnet_diff_spec_loss: 0.83289  (0.81766)
     | > decoder_ssim_loss: 0.33407  (0.33878)
     | > postnet_ssim_loss: 0.34196  (0.34913)
     | > loss: 3.81618  (3.74745)
     | > align_error: 0.98701  (0.98943)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.05598  (4.07376)
     | > current_lr: 0.00007 
     | > step_time: 2.12510  (3.64474)
     | > loader_time: 0.02280  (0.03269)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.66992 [0m(+0.42290)
     | > avg_decoder_loss:[92m 2.52866 [0m(-0.11402)
     | > avg_postnet_loss:[92m 2.29449 [0m(-0.16838)
     | > avg_stopnet_loss:[92m 1.33146 [0m(-0.00271)
     | > avg_decoder_coarse_loss:[92m 3.21079 [0m(-0.13939)
     | > avg_decoder_ddc_loss:[92m 0.00129 [0m(-0.00005)
     | > avg_ga_loss:[91m 0.00221 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.49271 [0m(-0.00001)
     | > avg_postnet_diff_spec_loss:[92m 0.83263 [0m(-0.00107)
     | > avg_decoder_ssim_loss:[92m 0.35460 [0m(-0.00175)
     | > avg_postnet_ssim_loss:[92m 0.36186 [0m(-0.00180)
     | > avg_loss:[92m 3.86178 [0m(-0.10932)
     | > avg_align_error:[92m 0.99048 [0m(-0.00010)


[4m[1m > EPOCH: 33/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:49:43) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 272925[0m
     | > decoder_loss: 2.10454  (2.15586)
     | > postnet_loss: 1.82826  (1.97475)
     | > stopnet_loss: 1.35608  (1.71944)
     | > decoder_coarse_loss: 2.07576  (2.13241)
     | > decoder_ddc_loss: 0.00205  (0.00133)
     | > ga_loss: 0.00292  (0.00247)
     | > decoder_diff_spec_loss: 0.51010  (0.49852)
     | > postnet_diff_spec_loss: 0.84023  (0.82385)
     | > decoder_ssim_loss: 0.41943  (0.33215)
     | > postnet_ssim_loss: 0.43365  (0.34244)
     | > loss: 3.42418  (3.79712)
     | > align_error: 0.98534  (0.98963)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.68354  (4.72918)
     | > current_lr: 0.00007 
     | > step_time: 2.70180  (4.02151)
     | > loader_time: 0.04780  (0.05199)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 272950[0m
     | > decoder_loss: 2.17844  (2.11292)
     | > postnet_loss: 1.85439  (1.92968)
     | > stopnet_loss: 1.68126  (1.71032)
     | > decoder_coarse_loss: 2.12679  (2.09485)
     | > decoder_ddc_loss: 0.00157  (0.00137)
     | > ga_loss: 0.00268  (0.00248)
     | > decoder_diff_spec_loss: 0.50414  (0.49316)
     | > postnet_diff_spec_loss: 0.82828  (0.81830)
     | > decoder_ssim_loss: 0.33335  (0.33554)
     | > postnet_ssim_loss: 0.34192  (0.34650)
     | > loss: 3.73687  (3.75582)
     | > align_error: 0.98840  (0.98950)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.57560  (4.19177)
     | > current_lr: 0.00007 
     | > step_time: 3.79170  (3.85634)
     | > loader_time: 0.02730  (0.04219)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 272975[0m
     | > decoder_loss: 2.17558  (2.11305)
     | > postnet_loss: 1.88931  (1.92361)
     | > stopnet_loss: 1.60990  (1.68271)
     | > decoder_coarse_loss: 2.17254  (2.09284)
     | > decoder_ddc_loss: 0.00159  (0.00139)
     | > ga_loss: 0.00343  (0.00252)
     | > decoder_diff_spec_loss: 0.49253  (0.49132)
     | > postnet_diff_spec_loss: 0.82375  (0.81755)
     | > decoder_ssim_loss: 0.33701  (0.33858)
     | > postnet_ssim_loss: 0.34499  (0.34925)
     | > loss: 3.68640  (3.72720)
     | > align_error: 0.98802  (0.98946)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.77277  (4.17792)
     | > current_lr: 0.00007 
     | > step_time: 2.85620  (3.79626)
     | > loader_time: 0.02550  (0.03921)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.04763 [0m(+0.37771)
     | > avg_decoder_loss:[91m 2.65126 [0m(+0.12261)
     | > avg_postnet_loss:[91m 2.43454 [0m(+0.14006)
     | > avg_stopnet_loss:[92m 1.33079 [0m(-0.00067)
     | > avg_decoder_coarse_loss:[91m 3.30937 [0m(+0.09858)
     | > avg_decoder_ddc_loss:[92m 0.00124 [0m(-0.00005)
     | > avg_ga_loss:[92m 0.00221 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.48969 [0m(-0.00302)
     | > avg_postnet_diff_spec_loss:[91m 0.83265 [0m(+0.00001)
     | > avg_decoder_ssim_loss:[92m 0.35405 [0m(-0.00055)
     | > avg_postnet_ssim_loss:[92m 0.36178 [0m(-0.00009)
     | > avg_loss:[91m 3.95046 [0m(+0.08868)
     | > avg_align_error:[91m 0.99063 [0m(+0.00014)


[4m[1m > EPOCH: 34/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 13:57:21) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 273000[0m
     | > decoder_loss: 2.39101  (2.16810)
     | > postnet_loss: 2.06477  (2.06206)
     | > stopnet_loss: 2.07189  (1.62959)
     | > decoder_coarse_loss: 2.31845  (2.09452)
     | > decoder_ddc_loss: 0.00089  (0.00139)
     | > ga_loss: 0.00204  (0.00258)
     | > decoder_diff_spec_loss: 0.55004  (0.48872)
     | > postnet_diff_spec_loss: 0.84997  (0.81543)
     | > decoder_ssim_loss: 0.26738  (0.34198)
     | > postnet_ssim_loss: 0.27505  (0.35507)
     | > loss: 4.26146  (3.72428)
     | > align_error: 0.99247  (0.98910)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.60779  (6.93734)
     | > current_lr: 0.00007 
     | > step_time: 4.50210  (4.01572)
     | > loader_time: 0.02460  (0.06962)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 273025[0m
     | > decoder_loss: 1.96953  (2.09858)
     | > postnet_loss: 1.70208  (1.91428)
     | > stopnet_loss: 2.04128  (1.68045)
     | > decoder_coarse_loss: 1.92596  (2.06537)
     | > decoder_ddc_loss: 0.00085  (0.00132)
     | > ga_loss: 0.00179  (0.00245)
     | > decoder_diff_spec_loss: 0.47309  (0.49461)
     | > postnet_diff_spec_loss: 0.80581  (0.81966)
     | > decoder_ssim_loss: 0.26487  (0.33503)
     | > postnet_ssim_loss: 0.27345  (0.34580)
     | > loss: 3.90416  (3.71139)
     | > align_error: 0.99281  (0.98955)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.06444  (4.63992)
     | > current_lr: 0.00008 
     | > step_time: 5.35170  (3.89988)
     | > loader_time: 0.02500  (0.04254)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 273050[0m
     | > decoder_loss: 2.38584  (2.09133)
     | > postnet_loss: 2.00335  (1.90727)
     | > stopnet_loss: 1.92872  (1.67747)
     | > decoder_coarse_loss: 2.31231  (2.04939)
     | > decoder_ddc_loss: 0.00109  (0.00134)
     | > ga_loss: 0.00183  (0.00247)
     | > decoder_diff_spec_loss: 0.54246  (0.49244)
     | > postnet_diff_spec_loss: 0.84715  (0.81764)
     | > decoder_ssim_loss: 0.29194  (0.33520)
     | > postnet_ssim_loss: 0.29598  (0.34627)
     | > loss: 4.10791  (3.70002)
     | > align_error: 0.99168  (0.98957)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.15899  (4.42158)
     | > current_lr: 0.00008 
     | > step_time: 5.42240  (3.81890)
     | > loader_time: 0.02550  (0.03795)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 273075[0m
     | > decoder_loss: 2.03173  (2.08366)
     | > postnet_loss: 2.13256  (1.89202)
     | > stopnet_loss: 1.67946  (1.67336)
     | > decoder_coarse_loss: 2.02265  (2.04099)
     | > decoder_ddc_loss: 0.00144  (0.00137)
     | > ga_loss: 0.00221  (0.00251)
     | > decoder_diff_spec_loss: 0.48754  (0.49064)
     | > postnet_diff_spec_loss: 0.79252  (0.81600)
     | > decoder_ssim_loss: 0.31139  (0.33702)
     | > postnet_ssim_loss: 0.32488  (0.34788)
     | > loss: 3.71669  (3.68830)
     | > align_error: 0.98873  (0.98940)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.57364  (4.34676)
     | > current_lr: 0.00008 
     | > step_time: 3.57250  (3.73353)
     | > loader_time: 0.02140  (0.03943)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.29771 [0m(+0.25008)
     | > avg_decoder_loss:[92m 2.60518 [0m(-0.04608)
     | > avg_postnet_loss:[92m 2.34829 [0m(-0.08625)
     | > avg_stopnet_loss:[92m 1.32964 [0m(-0.00115)
     | > avg_decoder_coarse_loss:[92m 3.24414 [0m(-0.06523)
     | > avg_decoder_ddc_loss:[92m 0.00123 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00220 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.49153 [0m(+0.00184)
     | > avg_postnet_diff_spec_loss:[92m 0.83126 [0m(-0.00139)
     | > avg_decoder_ssim_loss:[92m 0.35286 [0m(-0.00119)
     | > avg_postnet_ssim_loss:[91m 0.36244 [0m(+0.00066)
     | > avg_loss:[92m 3.89989 [0m(-0.05058)
     | > avg_align_error:[92m 0.99048 [0m(-0.00015)


[4m[1m > EPOCH: 35/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:05:02) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 273100[0m
     | > decoder_loss: 1.95737  (2.10564)
     | > postnet_loss: 1.61912  (1.93813)
     | > stopnet_loss: 2.18989  (1.70812)
     | > decoder_coarse_loss: 1.89011  (2.05320)
     | > decoder_ddc_loss: 0.00144  (0.00127)
     | > ga_loss: 0.00322  (0.00243)
     | > decoder_diff_spec_loss: 0.50006  (0.49818)
     | > postnet_diff_spec_loss: 0.80623  (0.82102)
     | > decoder_ssim_loss: 0.27319  (0.32573)
     | > postnet_ssim_loss: 0.27695  (0.33658)
     | > loss: 4.03713  (3.74020)
     | > align_error: 0.98855  (0.98976)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 12.65199  (5.01864)
     | > current_lr: 0.00008 
     | > step_time: 2.49480  (3.88195)
     | > loader_time: 0.02300  (0.03635)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 273125[0m
     | > decoder_loss: 1.86004  (2.06599)
     | > postnet_loss: 1.66843  (1.88439)
     | > stopnet_loss: 2.32325  (1.70152)
     | > decoder_coarse_loss: 1.86756  (2.02283)
     | > decoder_ddc_loss: 0.00103  (0.00131)
     | > ga_loss: 0.00249  (0.00246)
     | > decoder_diff_spec_loss: 0.48593  (0.49475)
     | > postnet_diff_spec_loss: 0.81122  (0.81623)
     | > decoder_ssim_loss: 0.24841  (0.33367)
     | > postnet_ssim_loss: 0.25485  (0.34497)
     | > loss: 4.13507  (3.70488)
     | > align_error: 0.99186  (0.98947)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.22651  (4.30812)
     | > current_lr: 0.00008 
     | > step_time: 4.12630  (3.61966)
     | > loader_time: 0.02290  (0.03475)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 273150[0m
     | > decoder_loss: 1.95630  (2.06937)
     | > postnet_loss: 1.71922  (1.88604)
     | > stopnet_loss: 1.65019  (1.67404)
     | > decoder_coarse_loss: 1.89966  (2.02326)
     | > decoder_ddc_loss: 0.00138  (0.00133)
     | > ga_loss: 0.00231  (0.00249)
     | > decoder_diff_spec_loss: 0.45686  (0.49282)
     | > postnet_diff_spec_loss: 0.79284  (0.81589)
     | > decoder_ssim_loss: 0.30840  (0.33668)
     | > postnet_ssim_loss: 0.32188  (0.34794)
     | > loss: 3.52585  (3.67981)
     | > align_error: 0.98848  (0.98945)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.34544  (4.16646)
     | > current_lr: 0.00008 
     | > step_time: 4.57240  (3.63366)
     | > loader_time: 0.14610  (0.03649)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.25821 [0m(-1.03950)
     | > avg_decoder_loss:[91m 2.67327 [0m(+0.06809)
     | > avg_postnet_loss:[91m 2.51099 [0m(+0.16269)
     | > avg_stopnet_loss:[91m 1.33062 [0m(+0.00099)
     | > avg_decoder_coarse_loss:[92m 3.10403 [0m(-0.14011)
     | > avg_decoder_ddc_loss:[92m 0.00115 [0m(-0.00008)
     | > avg_ga_loss:[92m 0.00220 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.48976 [0m(-0.00176)
     | > avg_postnet_diff_spec_loss:[92m 0.83016 [0m(-0.00109)
     | > avg_decoder_ssim_loss:[92m 0.35239 [0m(-0.00047)
     | > avg_postnet_ssim_loss:[91m 0.36291 [0m(+0.00047)
     | > avg_loss:[91m 3.92277 [0m(+0.02288)
     | > avg_align_error:[91m 0.99064 [0m(+0.00016)


[4m[1m > EPOCH: 36/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:12:41) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 273175[0m
     | > decoder_loss: 2.10378  (2.10493)
     | > postnet_loss: 1.93711  (2.01399)
     | > stopnet_loss: 1.58295  (1.52765)
     | > decoder_coarse_loss: 2.06409  (2.01591)
     | > decoder_ddc_loss: 0.00125  (0.00142)
     | > ga_loss: 0.00233  (0.00262)
     | > decoder_diff_spec_loss: 0.49388  (0.48158)
     | > postnet_diff_spec_loss: 0.83618  (0.80909)
     | > decoder_ssim_loss: 0.33227  (0.35084)
     | > postnet_ssim_loss: 0.34418  (0.36590)
     | > loss: 3.62276  (3.57668)
     | > align_error: 0.98978  (0.98855)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.49093  (6.95316)
     | > current_lr: 0.00008 
     | > step_time: 4.79900  (3.97068)
     | > loader_time: 0.02070  (0.04157)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 273200[0m
     | > decoder_loss: 1.87988  (2.07752)
     | > postnet_loss: 1.80906  (1.89356)
     | > stopnet_loss: 1.68153  (1.68255)
     | > decoder_coarse_loss: 1.82769  (2.02112)
     | > decoder_ddc_loss: 0.00156  (0.00131)
     | > ga_loss: 0.00294  (0.00246)
     | > decoder_diff_spec_loss: 0.47126  (0.49581)
     | > postnet_diff_spec_loss: 0.79981  (0.81927)
     | > decoder_ssim_loss: 0.34502  (0.33582)
     | > postnet_ssim_loss: 0.35802  (0.34715)
     | > loss: 3.56928  (3.69272)
     | > align_error: 0.98785  (0.98941)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.02850  (4.93715)
     | > current_lr: 0.00008 
     | > step_time: 3.37800  (3.84114)
     | > loader_time: 0.01770  (0.03446)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 273225[0m
     | > decoder_loss: 1.96811  (2.05303)
     | > postnet_loss: 1.75881  (1.87848)
     | > stopnet_loss: 1.98493  (1.67693)
     | > decoder_coarse_loss: 1.90247  (2.00287)
     | > decoder_ddc_loss: 0.00109  (0.00133)
     | > ga_loss: 0.00242  (0.00246)
     | > decoder_diff_spec_loss: 0.46944  (0.49176)
     | > postnet_diff_spec_loss: 0.80196  (0.81592)
     | > decoder_ssim_loss: 0.28468  (0.33452)
     | > postnet_ssim_loss: 0.29895  (0.34627)
     | > loss: 3.86840  (3.67027)
     | > align_error: 0.99110  (0.98947)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.79024  (4.53267)
     | > current_lr: 0.00008 
     | > step_time: 4.23330  (3.78140)
     | > loader_time: 0.01910  (0.03243)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 273250[0m
     | > decoder_loss: 2.13119  (2.05267)
     | > postnet_loss: 1.95781  (1.86564)
     | > stopnet_loss: 2.28676  (1.67576)
     | > decoder_coarse_loss: 2.05708  (2.00058)
     | > decoder_ddc_loss: 0.00121  (0.00135)
     | > ga_loss: 0.00271  (0.00250)
     | > decoder_diff_spec_loss: 0.50949  (0.49109)
     | > postnet_diff_spec_loss: 0.82621  (0.81531)
     | > decoder_ssim_loss: 0.25445  (0.33592)
     | > postnet_ssim_loss: 0.25645  (0.34735)
     | > loss: 4.29878  (3.66572)
     | > align_error: 0.98986  (0.98936)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.32946  (4.41030)
     | > current_lr: 0.00008 
     | > step_time: 3.07300  (3.68719)
     | > loader_time: 0.02090  (0.03268)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.77052 [0m(+0.51230)
     | > avg_decoder_loss:[92m 2.62373 [0m(-0.04954)
     | > avg_postnet_loss:[92m 2.26476 [0m(-0.24623)
     | > avg_stopnet_loss:[92m 1.32897 [0m(-0.00166)
     | > avg_decoder_coarse_loss:[92m 2.97962 [0m(-0.12441)
     | > avg_decoder_ddc_loss:[92m 0.00113 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00219 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.48722 [0m(-0.00255)
     | > avg_postnet_diff_spec_loss:[91m 0.83031 [0m(+0.00014)
     | > avg_decoder_ssim_loss:[92m 0.35160 [0m(-0.00079)
     | > avg_postnet_ssim_loss:[92m 0.36066 [0m(-0.00225)
     | > avg_loss:[92m 3.81470 [0m(-0.10807)
     | > avg_align_error:[91m 0.99066 [0m(+0.00002)


[4m[1m > EPOCH: 37/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:20:19) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 273275[0m
     | > decoder_loss: 1.90918  (2.09492)
     | > postnet_loss: 1.68986  (1.93173)
     | > stopnet_loss: 1.63938  (1.67797)
     | > decoder_coarse_loss: 1.83523  (2.02361)
     | > decoder_ddc_loss: 0.00096  (0.00124)
     | > ga_loss: 0.00198  (0.00237)
     | > decoder_diff_spec_loss: 0.46643  (0.49838)
     | > postnet_diff_spec_loss: 0.78330  (0.82070)
     | > decoder_ssim_loss: 0.32042  (0.32730)
     | > postnet_ssim_loss: 0.33350  (0.33922)
     | > loss: 3.48399  (3.69909)
     | > align_error: 0.99212  (0.98979)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.43684  (4.46283)
     | > current_lr: 0.00008 
     | > step_time: 4.04090  (4.17326)
     | > loader_time: 0.02590  (0.03136)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 273300[0m
     | > decoder_loss: 1.87130  (2.05182)
     | > postnet_loss: 1.70976  (1.87240)
     | > stopnet_loss: 1.53919  (1.67011)
     | > decoder_coarse_loss: 1.80003  (1.99951)
     | > decoder_ddc_loss: 0.00148  (0.00132)
     | > ga_loss: 0.00262  (0.00245)
     | > decoder_diff_spec_loss: 0.47562  (0.49418)
     | > postnet_diff_spec_loss: 0.79986  (0.81551)
     | > decoder_ssim_loss: 0.36271  (0.33435)
     | > postnet_ssim_loss: 0.37338  (0.34656)
     | > loss: 3.40083  (3.66126)
     | > align_error: 0.98871  (0.98936)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.55527  (4.53347)
     | > current_lr: 0.00008 
     | > step_time: 2.69530  (3.81636)
     | > loader_time: 0.08970  (0.03308)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 273325[0m
     | > decoder_loss: 1.86716  (2.05084)
     | > postnet_loss: 1.65910  (1.86597)
     | > stopnet_loss: 2.26006  (1.66408)
     | > decoder_coarse_loss: 1.79406  (1.99846)
     | > decoder_ddc_loss: 0.00100  (0.00133)
     | > ga_loss: 0.00203  (0.00248)
     | > decoder_diff_spec_loss: 0.44342  (0.49326)
     | > postnet_diff_spec_loss: 0.77387  (0.81540)
     | > decoder_ssim_loss: 0.24110  (0.33562)
     | > postnet_ssim_loss: 0.24993  (0.34769)
     | > loss: 4.02763  (3.65359)
     | > align_error: 0.99087  (0.98940)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.47808  (4.41735)
     | > current_lr: 0.00008 
     | > step_time: 4.87180  (3.72489)
     | > loader_time: 0.02600  (0.03245)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.97137 [0m(+0.20085)
     | > avg_decoder_loss:[91m 2.62379 [0m(+0.00006)
     | > avg_postnet_loss:[91m 2.32734 [0m(+0.06258)
     | > avg_stopnet_loss:[91m 1.33037 [0m(+0.00140)
     | > avg_decoder_coarse_loss:[92m 2.93529 [0m(-0.04434)
     | > avg_decoder_ddc_loss:[91m 0.00115 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00219 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.48808 [0m(+0.00086)
     | > avg_postnet_diff_spec_loss:[91m 0.83062 [0m(+0.00032)
     | > avg_decoder_ssim_loss:[92m 0.35082 [0m(-0.00078)
     | > avg_postnet_ssim_loss:[92m 0.35950 [0m(-0.00116)
     | > avg_loss:[91m 3.82047 [0m(+0.00577)
     | > avg_align_error:[92m 0.99061 [0m(-0.00005)


[4m[1m > EPOCH: 38/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:27:52) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 273350[0m
     | > decoder_loss: 2.11618  (2.09031)
     | > postnet_loss: 2.48092  (2.01223)
     | > stopnet_loss: 1.28201  (1.53638)
     | > decoder_coarse_loss: 1.93535  (1.96184)
     | > decoder_ddc_loss: 0.00134  (0.00143)
     | > ga_loss: 0.00229  (0.00268)
     | > decoder_diff_spec_loss: 0.47894  (0.48152)
     | > postnet_diff_spec_loss: 0.77355  (0.80335)
     | > decoder_ssim_loss: 0.38800  (0.35251)
     | > postnet_ssim_loss: 0.41675  (0.36858)
     | > loss: 3.44122  (3.56770)
     | > align_error: 0.99035  (0.98834)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.60189  (9.30986)
     | > current_lr: 0.00008 
     | > step_time: 3.10970  (4.14167)
     | > loader_time: 0.02240  (0.04021)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 273375[0m
     | > decoder_loss: 1.94963  (2.05454)
     | > postnet_loss: 1.73435  (1.86828)
     | > stopnet_loss: 1.66669  (1.66783)
     | > decoder_coarse_loss: 1.88411  (1.98388)
     | > decoder_ddc_loss: 0.00133  (0.00129)
     | > ga_loss: 0.00263  (0.00243)
     | > decoder_diff_spec_loss: 0.47263  (0.49757)
     | > postnet_diff_spec_loss: 0.80054  (0.81903)
     | > decoder_ssim_loss: 0.31628  (0.33410)
     | > postnet_ssim_loss: 0.32786  (0.34602)
     | > loss: 3.55153  (3.65615)
     | > align_error: 0.98985  (0.98941)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.06641  (5.16133)
     | > current_lr: 0.00008 
     | > step_time: 4.06780  (3.90122)
     | > loader_time: 0.02250  (0.03915)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 273400[0m
     | > decoder_loss: 2.19872  (2.03090)
     | > postnet_loss: 1.91923  (1.85398)
     | > stopnet_loss: 1.48656  (1.65566)
     | > decoder_coarse_loss: 2.09414  (1.96416)
     | > decoder_ddc_loss: 0.00176  (0.00131)
     | > ga_loss: 0.00295  (0.00244)
     | > decoder_diff_spec_loss: 0.52136  (0.49317)
     | > postnet_diff_spec_loss: 0.83816  (0.81543)
     | > decoder_ssim_loss: 0.36364  (0.33410)
     | > postnet_ssim_loss: 0.37286  (0.34622)
     | > loss: 3.57876  (3.62768)
     | > align_error: 0.98626  (0.98940)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.29619  (4.69791)
     | > current_lr: 0.00008 
     | > step_time: 3.11670  (3.78147)
     | > loader_time: 0.01850  (0.03358)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 273425[0m
     | > decoder_loss: 1.80699  (2.02591)
     | > postnet_loss: 1.59214  (1.83362)
     | > stopnet_loss: 2.18264  (1.64800)
     | > decoder_coarse_loss: 1.72942  (1.96180)
     | > decoder_ddc_loss: 0.00129  (0.00133)
     | > ga_loss: 0.00252  (0.00248)
     | > decoder_diff_spec_loss: 0.45955  (0.49159)
     | > postnet_diff_spec_loss: 0.79234  (0.81413)
     | > decoder_ssim_loss: 0.25606  (0.33563)
     | > postnet_ssim_loss: 0.26556  (0.34743)
     | > loss: 3.92109  (3.61326)
     | > align_error: 0.98841  (0.98931)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.98459  (4.67201)
     | > current_lr: 0.00009 
     | > step_time: 3.56770  (3.71447)
     | > loader_time: 0.01800  (0.03341)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.57452 [0m(-0.39685)
     | > avg_decoder_loss:[91m 2.67915 [0m(+0.05536)
     | > avg_postnet_loss:[91m 2.65372 [0m(+0.32638)
     | > avg_stopnet_loss:[91m 1.33099 [0m(+0.00062)
     | > avg_decoder_coarse_loss:[91m 3.03799 [0m(+0.10271)
     | > avg_decoder_ddc_loss:[91m 0.00119 [0m(+0.00004)
     | > avg_ga_loss:[92m 0.00218 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.48858 [0m(+0.00050)
     | > avg_postnet_diff_spec_loss:[92m 0.82728 [0m(-0.00334)
     | > avg_decoder_ssim_loss:[92m 0.35019 [0m(-0.00063)
     | > avg_postnet_ssim_loss:[91m 0.36121 [0m(+0.00171)
     | > avg_loss:[91m 3.94174 [0m(+0.12127)
     | > avg_align_error:[92m 0.99054 [0m(-0.00007)


[4m[1m > EPOCH: 39/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:35:22) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 273450[0m
     | > decoder_loss: 1.97084  (2.07698)
     | > postnet_loss: 1.89162  (1.90622)
     | > stopnet_loss: 1.74110  (1.66405)
     | > decoder_coarse_loss: 1.93561  (1.99417)
     | > decoder_ddc_loss: 0.00102  (0.00122)
     | > ga_loss: 0.00186  (0.00238)
     | > decoder_diff_spec_loss: 0.47327  (0.49885)
     | > postnet_diff_spec_loss: 0.82067  (0.82193)
     | > decoder_ssim_loss: 0.29821  (0.32660)
     | > postnet_ssim_loss: 0.31097  (0.33857)
     | > loss: 3.67594  (3.66708)
     | > align_error: 0.99127  (0.98965)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.97810  (6.21135)
     | > current_lr: 0.00009 
     | > step_time: 4.82630  (4.10049)
     | > loader_time: 0.01910  (0.03609)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 273475[0m
     | > decoder_loss: 2.24909  (2.02978)
     | > postnet_loss: 2.50190  (1.84180)
     | > stopnet_loss: 1.74861  (1.66667)
     | > decoder_coarse_loss: 2.09236  (1.95701)
     | > decoder_ddc_loss: 0.00119  (0.00129)
     | > ga_loss: 0.00218  (0.00242)
     | > decoder_diff_spec_loss: 0.51686  (0.49457)
     | > postnet_diff_spec_loss: 0.80935  (0.81497)
     | > decoder_ssim_loss: 0.31382  (0.33260)
     | > postnet_ssim_loss: 0.33042  (0.34496)
     | > loss: 3.96327  (3.63303)
     | > align_error: 0.99024  (0.98933)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.48009  (5.09999)
     | > current_lr: 0.00009 
     | > step_time: 3.77510  (3.80851)
     | > loader_time: 0.09710  (0.03993)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 273500[0m
     | > decoder_loss: 1.79752  (2.02882)
     | > postnet_loss: 1.79106  (1.83856)
     | > stopnet_loss: 1.08900  (1.64498)
     | > decoder_coarse_loss: 1.73135  (1.95617)
     | > decoder_ddc_loss: 0.00208  (0.00132)
     | > ga_loss: 0.00296  (0.00246)
     | > decoder_diff_spec_loss: 0.47588  (0.49389)
     | > postnet_diff_spec_loss: 0.79051  (0.81509)
     | > decoder_ssim_loss: 0.44526  (0.33605)
     | > postnet_ssim_loss: 0.46891  (0.34823)
     | > loss: 2.97942  (3.61183)
     | > align_error: 0.98498  (0.98931)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.77827  (4.72569)
     | > current_lr: 0.00009 
     | > step_time: 2.82020  (3.71161)
     | > loader_time: 0.02390  (0.03847)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.59109 [0m(+0.01657)
     | > avg_decoder_loss:[91m 2.74126 [0m(+0.06212)
     | > avg_postnet_loss:[92m 2.29728 [0m(-0.35644)
     | > avg_stopnet_loss:[92m 1.32915 [0m(-0.00184)
     | > avg_decoder_coarse_loss:[92m 2.95265 [0m(-0.08535)
     | > avg_decoder_ddc_loss:[92m 0.00116 [0m(-0.00003)
     | > avg_ga_loss:[92m 0.00218 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.48392 [0m(-0.00466)
     | > avg_postnet_diff_spec_loss:[91m 0.82901 [0m(+0.00172)
     | > avg_decoder_ssim_loss:[92m 0.34995 [0m(-0.00024)
     | > avg_postnet_ssim_loss:[92m 0.35788 [0m(-0.00333)
     | > avg_loss:[92m 3.84330 [0m(-0.09844)
     | > avg_align_error:[91m 0.99068 [0m(+0.00014)


[4m[1m > EPOCH: 40/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:42:44) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 273525[0m
     | > decoder_loss: 2.03501  (2.05298)
     | > postnet_loss: 1.73104  (1.87565)
     | > stopnet_loss: 1.70410  (1.64372)
     | > decoder_coarse_loss: 1.89254  (1.93519)
     | > decoder_ddc_loss: 0.00145  (0.00147)
     | > ga_loss: 0.00273  (0.00274)
     | > decoder_diff_spec_loss: 0.44802  (0.47711)
     | > postnet_diff_spec_loss: 0.79695  (0.80952)
     | > decoder_ssim_loss: 0.32654  (0.34437)
     | > postnet_ssim_loss: 0.34011  (0.35797)
     | > loss: 3.61066  (3.62098)
     | > align_error: 0.98781  (0.98793)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.31019  (7.55152)
     | > current_lr: 0.00009 
     | > step_time: 3.61110  (4.12304)
     | > loader_time: 0.01780  (0.05153)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 273550[0m
     | > decoder_loss: 1.90209  (2.04233)
     | > postnet_loss: 1.63760  (1.84816)
     | > stopnet_loss: 1.61498  (1.67287)
     | > decoder_coarse_loss: 1.83906  (1.98133)
     | > decoder_ddc_loss: 0.00121  (0.00130)
     | > ga_loss: 0.00225  (0.00241)
     | > decoder_diff_spec_loss: 0.47437  (0.49820)
     | > postnet_diff_spec_loss: 0.79697  (0.81910)
     | > decoder_ssim_loss: 0.30980  (0.33350)
     | > postnet_ssim_loss: 0.31514  (0.34603)
     | > loss: 3.44527  (3.65239)
     | > align_error: 0.98877  (0.98927)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.69661  (4.80579)
     | > current_lr: 0.00009 
     | > step_time: 4.28510  (3.84956)
     | > loader_time: 0.05770  (0.03987)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 273575[0m
     | > decoder_loss: 1.81952  (2.00859)
     | > postnet_loss: 1.66201  (1.82535)
     | > stopnet_loss: 1.66953  (1.65757)
     | > decoder_coarse_loss: 1.73128  (1.94870)
     | > decoder_ddc_loss: 0.00097  (0.00128)
     | > ga_loss: 0.00219  (0.00242)
     | > decoder_diff_spec_loss: 0.46395  (0.49337)
     | > postnet_diff_spec_loss: 0.79973  (0.81443)
     | > decoder_ssim_loss: 0.31484  (0.33235)
     | > postnet_ssim_loss: 0.32902  (0.34518)
     | > loss: 3.46080  (3.61199)
     | > align_error: 0.99100  (0.98936)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.84216  (4.47710)
     | > current_lr: 0.00009 
     | > step_time: 3.49460  (3.72021)
     | > loader_time: 0.02090  (0.03381)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 273600[0m
     | > decoder_loss: 1.93713  (2.00901)
     | > postnet_loss: 1.86474  (1.81092)
     | > stopnet_loss: 1.61081  (1.63832)
     | > decoder_coarse_loss: 1.87304  (1.94948)
     | > decoder_ddc_loss: 0.00186  (0.00130)
     | > ga_loss: 0.00328  (0.00247)
     | > decoder_diff_spec_loss: 0.49066  (0.49252)
     | > postnet_diff_spec_loss: 0.81348  (0.81370)
     | > decoder_ssim_loss: 0.35520  (0.33541)
     | > postnet_ssim_loss: 0.36828  (0.34786)
     | > loss: 3.55330  (3.59071)
     | > align_error: 0.98625  (0.98926)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.75885  (4.48783)
     | > current_lr: 0.00009 
     | > step_time: 1.90220  (3.63197)
     | > loader_time: 0.01400  (0.03207)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.91730 [0m(+0.32621)
     | > avg_decoder_loss:[92m 2.69504 [0m(-0.04622)
     | > avg_postnet_loss:[91m 2.55046 [0m(+0.25318)
     | > avg_stopnet_loss:[91m 1.33123 [0m(+0.00208)
     | > avg_decoder_coarse_loss:[92m 2.93707 [0m(-0.01558)
     | > avg_decoder_ddc_loss:[91m 0.00116 [0m(+0.00001)
     | > avg_ga_loss:[91m 0.00218 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.48748 [0m(+0.00356)
     | > avg_postnet_diff_spec_loss:[92m 0.82716 [0m(-0.00184)
     | > avg_decoder_ssim_loss:[92m 0.34916 [0m(-0.00079)
     | > avg_postnet_ssim_loss:[91m 0.36012 [0m(+0.00224)
     | > avg_loss:[91m 3.89406 [0m(+0.05076)
     | > avg_align_error:[92m 0.99059 [0m(-0.00009)


[4m[1m > EPOCH: 41/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:49:58) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 273625[0m
     | > decoder_loss: 1.88107  (2.05834)
     | > postnet_loss: 1.67456  (1.86970)
     | > stopnet_loss: 0.94779  (1.65320)
     | > decoder_coarse_loss: 1.88434  (1.97669)
     | > decoder_ddc_loss: 0.00115  (0.00124)
     | > ga_loss: 0.00182  (0.00240)
     | > decoder_diff_spec_loss: 0.48302  (0.50147)
     | > postnet_diff_spec_loss: 0.80004  (0.82164)
     | > decoder_ssim_loss: 0.45492  (0.32714)
     | > postnet_ssim_loss: 0.47846  (0.33938)
     | > loss: 2.87126  (3.63912)
     | > align_error: 0.99035  (0.98958)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.92620  (6.19239)
     | > current_lr: 0.00009 
     | > step_time: 4.45270  (4.12646)
     | > loader_time: 0.02170  (0.04086)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 273650[0m
     | > decoder_loss: 2.16804  (1.99859)
     | > postnet_loss: 2.00578  (1.79196)
     | > stopnet_loss: 1.98668  (1.64766)
     | > decoder_coarse_loss: 2.09613  (1.93515)
     | > decoder_ddc_loss: 0.00117  (0.00129)
     | > ga_loss: 0.00249  (0.00242)
     | > decoder_diff_spec_loss: 0.54199  (0.49467)
     | > postnet_diff_spec_loss: 0.82628  (0.81446)
     | > decoder_ssim_loss: 0.25541  (0.33166)
     | > postnet_ssim_loss: 0.26462  (0.34450)
     | > loss: 4.03898  (3.58785)
     | > align_error: 0.98935  (0.98931)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.07436  (4.97399)
     | > current_lr: 0.00009 
     | > step_time: 3.74900  (3.79422)
     | > loader_time: 0.05350  (0.03840)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 273675[0m
     | > decoder_loss: 1.92321  (2.00653)
     | > postnet_loss: 1.89014  (1.80354)
     | > stopnet_loss: 1.64162  (1.63148)
     | > decoder_coarse_loss: 1.84969  (1.93902)
     | > decoder_ddc_loss: 0.00115  (0.00130)
     | > ga_loss: 0.00234  (0.00245)
     | > decoder_diff_spec_loss: 0.49431  (0.49492)
     | > postnet_diff_spec_loss: 0.82766  (0.81466)
     | > decoder_ssim_loss: 0.31398  (0.33302)
     | > postnet_ssim_loss: 0.32893  (0.34570)
     | > loss: 3.56059  (3.57840)
     | > align_error: 0.99063  (0.98935)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.46544  (4.74910)
     | > current_lr: 0.00009 
     | > step_time: 3.12540  (3.65622)
     | > loader_time: 0.01720  (0.03642)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.17206 [0m(-0.74524)
     | > avg_decoder_loss:[92m 2.65676 [0m(-0.03828)
     | > avg_postnet_loss:[92m 2.38541 [0m(-0.16506)
     | > avg_stopnet_loss:[92m 1.33028 [0m(-0.00095)
     | > avg_decoder_coarse_loss:[92m 2.81536 [0m(-0.12171)
     | > avg_decoder_ddc_loss:[92m 0.00114 [0m(-0.00003)
     | > avg_ga_loss:[92m 0.00218 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.48568 [0m(-0.00179)
     | > avg_postnet_diff_spec_loss:[92m 0.82516 [0m(-0.00200)
     | > avg_decoder_ssim_loss:[92m 0.34811 [0m(-0.00105)
     | > avg_postnet_ssim_loss:[92m 0.35944 [0m(-0.00068)
     | > avg_loss:[92m 3.81044 [0m(-0.08362)
     | > avg_align_error:[91m 0.99060 [0m(+0.00001)


[4m[1m > EPOCH: 42/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 14:57:32) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 273700[0m
     | > decoder_loss: 1.99794  (2.02862)
     | > postnet_loss: 1.78982  (1.84571)
     | > stopnet_loss: 1.57937  (1.64150)
     | > decoder_coarse_loss: 1.86471  (1.93195)
     | > decoder_ddc_loss: 0.00109  (0.00146)
     | > ga_loss: 0.00227  (0.00271)
     | > decoder_diff_spec_loss: 0.47892  (0.48756)
     | > postnet_diff_spec_loss: 0.77950  (0.81042)
     | > decoder_ssim_loss: 0.34336  (0.34642)
     | > postnet_ssim_loss: 0.36167  (0.36051)
     | > loss: 3.49498  (3.60823)
     | > align_error: 0.99131  (0.98790)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.65011  (9.04862)
     | > current_lr: 0.00009 
     | > step_time: 3.96210  (4.30395)
     | > loader_time: 0.02650  (0.04188)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 273725[0m
     | > decoder_loss: 2.05165  (2.02226)
     | > postnet_loss: 1.79107  (1.80433)
     | > stopnet_loss: 1.28031  (1.66131)
     | > decoder_coarse_loss: 1.97730  (1.95406)
     | > decoder_ddc_loss: 0.00147  (0.00128)
     | > ga_loss: 0.00260  (0.00240)
     | > decoder_diff_spec_loss: 0.49897  (0.49839)
     | > postnet_diff_spec_loss: 0.82494  (0.81843)
     | > decoder_ssim_loss: 0.36431  (0.33296)
     | > postnet_ssim_loss: 0.38118  (0.34563)
     | > loss: 3.26602  (3.61763)
     | > align_error: 0.98814  (0.98931)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.54912  (5.09831)
     | > current_lr: 0.00009 
     | > step_time: 2.41000  (3.92838)
     | > loader_time: 0.01660  (0.03242)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 273750[0m
     | > decoder_loss: 2.07373  (1.99182)
     | > postnet_loss: 2.08673  (1.78444)
     | > stopnet_loss: 1.95521  (1.65207)
     | > decoder_coarse_loss: 1.98303  (1.92111)
     | > decoder_ddc_loss: 0.00090  (0.00129)
     | > ga_loss: 0.00197  (0.00241)
     | > decoder_diff_spec_loss: 0.50610  (0.49428)
     | > postnet_diff_spec_loss: 0.80065  (0.81365)
     | > decoder_ssim_loss: 0.26751  (0.33160)
     | > postnet_ssim_loss: 0.28538  (0.34444)
     | > loss: 3.96604  (3.58478)
     | > align_error: 0.99190  (0.98931)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.05760  (4.61415)
     | > current_lr: 0.00009 
     | > step_time: 5.85160  (3.85721)
     | > loader_time: 0.15660  (0.03292)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 273775[0m
     | > decoder_loss: 1.94023  (1.99185)
     | > postnet_loss: 1.75902  (1.77042)
     | > stopnet_loss: 1.38515  (1.63586)
     | > decoder_coarse_loss: 1.89486  (1.92223)
     | > decoder_ddc_loss: 0.00112  (0.00131)
     | > ga_loss: 0.00217  (0.00244)
     | > decoder_diff_spec_loss: 0.48182  (0.49297)
     | > postnet_diff_spec_loss: 0.78870  (0.81283)
     | > decoder_ssim_loss: 0.35623  (0.33403)
     | > postnet_ssim_loss: 0.37030  (0.34663)
     | > loss: 3.29406  (3.56612)
     | > align_error: 0.99050  (0.98923)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.86107  (4.69569)
     | > current_lr: 0.00009 
     | > step_time: 3.52730  (3.80811)
     | > loader_time: 0.02430  (0.03417)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.32183 [0m(+1.14978)
     | > avg_decoder_loss:[92m 2.61947 [0m(-0.03729)
     | > avg_postnet_loss:[92m 2.19640 [0m(-0.18900)
     | > avg_stopnet_loss:[92m 1.32809 [0m(-0.00219)
     | > avg_decoder_coarse_loss:[92m 2.71786 [0m(-0.09750)
     | > avg_decoder_ddc_loss:[92m 0.00114 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00217 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.48534 [0m(-0.00034)
     | > avg_postnet_diff_spec_loss:[92m 0.82500 [0m(-0.00016)
     | > avg_decoder_ssim_loss:[92m 0.34742 [0m(-0.00069)
     | > avg_postnet_ssim_loss:[92m 0.35663 [0m(-0.00282)
     | > avg_loss:[92m 3.72626 [0m(-0.08417)
     | > avg_align_error:[92m 0.99059 [0m(-0.00001)


[4m[1m > EPOCH: 43/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:05:23) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 273800[0m
     | > decoder_loss: 1.89736  (2.04900)
     | > postnet_loss: 1.65383  (1.82147)
     | > stopnet_loss: 1.71512  (1.68901)
     | > decoder_coarse_loss: 1.79680  (1.95746)
     | > decoder_ddc_loss: 0.00085  (0.00125)
     | > ga_loss: 0.00164  (0.00242)
     | > decoder_diff_spec_loss: 0.49692  (0.50367)
     | > postnet_diff_spec_loss: 0.81750  (0.82149)
     | > decoder_ssim_loss: 0.28255  (0.31802)
     | > postnet_ssim_loss: 0.29580  (0.33000)
     | > loss: 3.53374  (3.65170)
     | > align_error: 0.99158  (0.98940)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.45036  (5.61998)
     | > current_lr: 0.00009 
     | > step_time: 4.56960  (4.03545)
     | > loader_time: 0.02170  (0.03537)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 273825[0m
     | > decoder_loss: 1.77808  (1.97963)
     | > postnet_loss: 1.64500  (1.75019)
     | > stopnet_loss: 1.92544  (1.63575)
     | > decoder_coarse_loss: 1.70929  (1.90752)
     | > decoder_ddc_loss: 0.00180  (0.00131)
     | > ga_loss: 0.00322  (0.00240)
     | > decoder_diff_spec_loss: 0.45353  (0.49433)
     | > postnet_diff_spec_loss: 0.79663  (0.81330)
     | > decoder_ssim_loss: 0.29903  (0.33245)
     | > postnet_ssim_loss: 0.32319  (0.34578)
     | > loss: 3.69317  (3.55387)
     | > align_error: 0.98595  (0.98921)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.22184  (4.66218)
     | > current_lr: 0.00010 
     | > step_time: 2.89030  (3.77389)
     | > loader_time: 0.01720  (0.03816)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 273850[0m
     | > decoder_loss: 2.29924  (1.98860)
     | > postnet_loss: 1.90170  (1.76395)
     | > stopnet_loss: 1.63513  (1.63281)
     | > decoder_coarse_loss: 2.20146  (1.91940)
     | > decoder_ddc_loss: 0.00095  (0.00133)
     | > ga_loss: 0.00187  (0.00242)
     | > decoder_diff_spec_loss: 0.51194  (0.49534)
     | > postnet_diff_spec_loss: 0.81955  (0.81351)
     | > decoder_ssim_loss: 0.32374  (0.33210)
     | > postnet_ssim_loss: 0.33732  (0.34516)
     | > loss: 3.74344  (3.55976)
     | > align_error: 0.99192  (0.98922)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.74132  (4.60404)
     | > current_lr: 0.00010 
     | > step_time: 4.75770  (3.73645)
     | > loader_time: 0.01880  (0.03446)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 6.12836 [0m(-0.19348)
     | > avg_decoder_loss:[91m 2.65928 [0m(+0.03982)
     | > avg_postnet_loss:[91m 2.34799 [0m(+0.15159)
     | > avg_stopnet_loss:[92m 1.32610 [0m(-0.00198)
     | > avg_decoder_coarse_loss:[91m 2.72651 [0m(+0.00865)
     | > avg_decoder_ddc_loss:[92m 0.00113 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00216 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.48549 [0m(+0.00015)
     | > avg_postnet_diff_spec_loss:[92m 0.82482 [0m(-0.00018)
     | > avg_decoder_ssim_loss:[92m 0.34678 [0m(-0.00064)
     | > avg_postnet_ssim_loss:[92m 0.35636 [0m(-0.00027)
     | > avg_loss:[91m 3.77400 [0m(+0.04774)
     | > avg_align_error:[92m 0.99058 [0m(-0.00001)


[4m[1m > EPOCH: 44/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:13:10) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 273875[0m
     | > decoder_loss: 2.03353  (2.03138)
     | > postnet_loss: 1.93160  (1.82711)
     | > stopnet_loss: 1.68622  (1.54192)
     | > decoder_coarse_loss: 1.92940  (1.93047)
     | > decoder_ddc_loss: 0.00142  (0.00155)
     | > ga_loss: 0.00268  (0.00282)
     | > decoder_diff_spec_loss: 0.48328  (0.49038)
     | > postnet_diff_spec_loss: 0.80186  (0.82044)
     | > decoder_ssim_loss: 0.31647  (0.34749)
     | > postnet_ssim_loss: 0.33100  (0.36023)
     | > loss: 3.65676  (3.50830)
     | > align_error: 0.98733  (0.98652)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.80515  (6.93067)
     | > current_lr: 0.00010 
     | > step_time: 5.64060  (3.73155)
     | > loader_time: 0.10700  (0.05112)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 273900[0m
     | > decoder_loss: 1.92466  (2.01096)
     | > postnet_loss: 1.92927  (1.77358)
     | > stopnet_loss: 0.85942  (1.64206)
     | > decoder_coarse_loss: 1.85690  (1.93261)
     | > decoder_ddc_loss: 0.00178  (0.00125)
     | > ga_loss: 0.00265  (0.00236)
     | > decoder_diff_spec_loss: 0.50606  (0.49952)
     | > postnet_diff_spec_loss: 0.80549  (0.81769)
     | > decoder_ssim_loss: 0.51044  (0.33062)
     | > postnet_ssim_loss: 0.53707  (0.34351)
     | > loss: 2.89057  (3.58131)
     | > align_error: 0.98641  (0.98927)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.15628  (4.82612)
     | > current_lr: 0.00010 
     | > step_time: 2.79300  (3.75150)
     | > loader_time: 0.03600  (0.04219)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 273925[0m
     | > decoder_loss: 2.07178  (1.97734)
     | > postnet_loss: 1.87979  (1.74616)
     | > stopnet_loss: 1.60694  (1.62997)
     | > decoder_coarse_loss: 2.03625  (1.90144)
     | > decoder_ddc_loss: 0.00123  (0.00127)
     | > ga_loss: 0.00220  (0.00240)
     | > decoder_diff_spec_loss: 0.49085  (0.49454)
     | > postnet_diff_spec_loss: 0.81017  (0.81316)
     | > decoder_ssim_loss: 0.31236  (0.33154)
     | > postnet_ssim_loss: 0.32185  (0.34471)
     | > loss: 3.59902  (3.54449)
     | > align_error: 0.98992  (0.98922)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.75333  (4.31148)
     | > current_lr: 0.00010 
     | > step_time: 3.30990  (3.62368)
     | > loader_time: 0.01900  (0.03820)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 273950[0m
     | > decoder_loss: 1.98326  (1.97643)
     | > postnet_loss: 1.70698  (1.73943)
     | > stopnet_loss: 1.35600  (1.62158)
     | > decoder_coarse_loss: 1.93275  (1.90244)
     | > decoder_ddc_loss: 0.00162  (0.00129)
     | > ga_loss: 0.00272  (0.00242)
     | > decoder_diff_spec_loss: 0.49386  (0.49324)
     | > postnet_diff_spec_loss: 0.81648  (0.81244)
     | > decoder_ssim_loss: 0.38191  (0.33253)
     | > postnet_ssim_loss: 0.39578  (0.34548)
     | > loss: 3.29776  (3.53451)
     | > align_error: 0.98618  (0.98919)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.89253  (4.33329)
     | > current_lr: 0.00010 
     | > step_time: 3.10540  (3.55517)
     | > loader_time: 0.01640  (0.03540)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.83198 [0m(-1.29638)
     | > avg_decoder_loss:[92m 2.64318 [0m(-0.01610)
     | > avg_postnet_loss:[92m 2.22556 [0m(-0.12243)
     | > avg_stopnet_loss:[92m 1.32610 [0m(-0.00000)
     | > avg_decoder_coarse_loss:[92m 2.66239 [0m(-0.06412)
     | > avg_decoder_ddc_loss:[92m 0.00108 [0m(-0.00006)
     | > avg_ga_loss:[91m 0.00217 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.48280 [0m(-0.00269)
     | > avg_postnet_diff_spec_loss:[92m 0.82424 [0m(-0.00058)
     | > avg_decoder_ssim_loss:[92m 0.34601 [0m(-0.00077)
     | > avg_postnet_ssim_loss:[92m 0.35567 [0m(-0.00069)
     | > avg_loss:[92m 3.72217 [0m(-0.05184)
     | > avg_align_error:[91m 0.99070 [0m(+0.00012)


[4m[1m > EPOCH: 45/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:20:20) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 273975[0m
     | > decoder_loss: 1.87054  (2.03502)
     | > postnet_loss: 1.63404  (1.78654)
     | > stopnet_loss: 2.22134  (1.65748)
     | > decoder_coarse_loss: 1.81521  (1.94343)
     | > decoder_ddc_loss: 0.00084  (0.00123)
     | > ga_loss: 0.00196  (0.00246)
     | > decoder_diff_spec_loss: 0.50143  (0.50358)
     | > postnet_diff_spec_loss: 0.83166  (0.82101)
     | > decoder_ssim_loss: 0.24920  (0.31914)
     | > postnet_ssim_loss: 0.25037  (0.33095)
     | > loss: 4.01944  (3.60501)
     | > align_error: 0.99157  (0.98928)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.13772  (4.67126)
     | > current_lr: 0.00010 
     | > step_time: 4.38920  (3.94302)
     | > loader_time: 0.02780  (0.04002)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 274000[0m
     | > decoder_loss: 1.82572  (1.96628)
     | > postnet_loss: 1.52592  (1.71796)
     | > stopnet_loss: 1.93875  (1.60602)
     | > decoder_coarse_loss: 1.78265  (1.89473)
     | > decoder_ddc_loss: 0.00075  (0.00126)
     | > ga_loss: 0.00207  (0.00237)
     | > decoder_diff_spec_loss: 0.48521  (0.49376)
     | > postnet_diff_spec_loss: 0.79421  (0.81298)
     | > decoder_ssim_loss: 0.26459  (0.33213)
     | > postnet_ssim_loss: 0.27764  (0.34552)
     | > loss: 3.68827  (3.50903)
     | > align_error: 0.99249  (0.98927)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.10991  (4.30125)
     | > current_lr: 0.00010 
     | > step_time: 5.19000  (3.88808)
     | > loader_time: 0.02460  (0.03818)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 274025[0m
     | > decoder_loss: 2.11744  (1.96439)
     | > postnet_loss: 1.80841  (1.72307)
     | > stopnet_loss: 1.44200  (1.61805)
     | > decoder_coarse_loss: 2.00456  (1.89459)
     | > decoder_ddc_loss: 0.00140  (0.00128)
     | > ga_loss: 0.00260  (0.00242)
     | > decoder_diff_spec_loss: 0.52711  (0.49450)
     | > postnet_diff_spec_loss: 0.81214  (0.81256)
     | > decoder_ssim_loss: 0.34056  (0.33102)
     | > postnet_ssim_loss: 0.35723  (0.34438)
     | > loss: 3.44723  (3.52160)
     | > align_error: 0.98834  (0.98917)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.89670  (4.13380)
     | > current_lr: 0.00010 
     | > step_time: 2.72490  (3.75656)
     | > loader_time: 0.06730  (0.03533)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.85394 [0m(+2.02197)
     | > avg_decoder_loss:[92m 2.59357 [0m(-0.04961)
     | > avg_postnet_loss:[91m 2.39394 [0m(+0.16838)
     | > avg_stopnet_loss:[92m 1.32485 [0m(-0.00125)
     | > avg_decoder_coarse_loss:[92m 2.56825 [0m(-0.09415)
     | > avg_decoder_ddc_loss:[92m 0.00106 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00216 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.48267 [0m(-0.00012)
     | > avg_postnet_diff_spec_loss:[91m 0.82434 [0m(+0.00010)
     | > avg_decoder_ssim_loss:[92m 0.34521 [0m(-0.00080)
     | > avg_postnet_ssim_loss:[91m 0.35678 [0m(+0.00111)
     | > avg_loss:[91m 3.72712 [0m(+0.00495)
     | > avg_align_error:[92m 0.99063 [0m(-0.00007)


[4m[1m > EPOCH: 46/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:28:03) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 274050[0m
     | > decoder_loss: 2.14121  (2.01502)
     | > postnet_loss: 1.90077  (1.76648)
     | > stopnet_loss: 1.50582  (1.47014)
     | > decoder_coarse_loss: 2.00280  (1.89693)
     | > decoder_ddc_loss: 0.00144  (0.00155)
     | > ga_loss: 0.00287  (0.00288)
     | > decoder_diff_spec_loss: 0.51885  (0.49427)
     | > postnet_diff_spec_loss: 0.85091  (0.83017)
     | > decoder_ssim_loss: 0.36602  (0.36100)
     | > postnet_ssim_loss: 0.37683  (0.37375)
     | > loss: 3.55987  (3.41934)
     | > align_error: 0.98681  (0.98631)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.06915  (5.05389)
     | > current_lr: 0.00010 
     | > step_time: 4.43310  (3.36724)
     | > loader_time: 0.02480  (0.02126)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 274075[0m
     | > decoder_loss: 2.13187  (1.98919)
     | > postnet_loss: 1.85610  (1.73571)
     | > stopnet_loss: 1.61334  (1.64230)
     | > decoder_coarse_loss: 2.13616  (1.91678)
     | > decoder_ddc_loss: 0.00114  (0.00121)
     | > ga_loss: 0.00229  (0.00235)
     | > decoder_diff_spec_loss: 0.53573  (0.49839)
     | > postnet_diff_spec_loss: 0.84670  (0.81737)
     | > decoder_ssim_loss: 0.31222  (0.32281)
     | > postnet_ssim_loss: 0.32205  (0.33567)
     | > loss: 3.66030  (3.55833)
     | > align_error: 0.98968  (0.98943)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.80540  (4.68226)
     | > current_lr: 0.00010 
     | > step_time: 4.00840  (3.86940)
     | > loader_time: 0.04740  (0.03444)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 274100[0m
     | > decoder_loss: 1.96730  (1.95318)
     | > postnet_loss: 1.72531  (1.70867)
     | > stopnet_loss: 1.95716  (1.60748)
     | > decoder_coarse_loss: 1.92377  (1.88531)
     | > decoder_ddc_loss: 0.00096  (0.00126)
     | > ga_loss: 0.00220  (0.00239)
     | > decoder_diff_spec_loss: 0.48097  (0.49335)
     | > postnet_diff_spec_loss: 0.82227  (0.81256)
     | > decoder_ssim_loss: 0.26576  (0.33069)
     | > postnet_ssim_loss: 0.28122  (0.34465)
     | > loss: 3.83503  (3.50187)
     | > align_error: 0.99184  (0.98921)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.15527  (4.24043)
     | > current_lr: 0.00010 
     | > step_time: 4.65870  (3.66034)
     | > loader_time: 0.01880  (0.03432)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 274125[0m
     | > decoder_loss: 2.08577  (1.95239)
     | > postnet_loss: 1.73290  (1.70085)
     | > stopnet_loss: 1.48803  (1.61385)
     | > decoder_coarse_loss: 2.03908  (1.88749)
     | > decoder_ddc_loss: 0.00174  (0.00127)
     | > ga_loss: 0.00286  (0.00240)
     | > decoder_diff_spec_loss: 0.51290  (0.49243)
     | > postnet_diff_spec_loss: 0.81743  (0.81151)
     | > decoder_ssim_loss: 0.34466  (0.33059)
     | > postnet_ssim_loss: 0.35537  (0.34420)
     | > loss: 3.47477  (3.50605)
     | > align_error: 0.98617  (0.98922)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.60081  (4.22462)
     | > current_lr: 0.00010 
     | > step_time: 2.44530  (3.60285)
     | > loader_time: 0.01490  (0.03342)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 9.16309 [0m(+2.30915)
     | > avg_decoder_loss:[91m 2.61462 [0m(+0.02104)
     | > avg_postnet_loss:[92m 2.33118 [0m(-0.06276)
     | > avg_stopnet_loss:[91m 1.32509 [0m(+0.00024)
     | > avg_decoder_coarse_loss:[92m 2.51306 [0m(-0.05519)
     | > avg_decoder_ddc_loss:[92m 0.00105 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00216 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.48182 [0m(-0.00085)
     | > avg_postnet_diff_spec_loss:[91m 0.82444 [0m(+0.00010)
     | > avg_decoder_ssim_loss:[92m 0.34443 [0m(-0.00078)
     | > avg_postnet_ssim_loss:[91m 0.35744 [0m(+0.00066)
     | > avg_loss:[92m 3.70289 [0m(-0.02423)
     | > avg_align_error:[91m 0.99069 [0m(+0.00006)


[4m[1m > EPOCH: 47/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:35:28) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 274150[0m
     | > decoder_loss: 2.00547  (2.03092)
     | > postnet_loss: 1.81992  (1.76679)
     | > stopnet_loss: 1.60697  (1.63590)
     | > decoder_coarse_loss: 1.91913  (1.93237)
     | > decoder_ddc_loss: 0.00093  (0.00127)
     | > ga_loss: 0.00161  (0.00249)
     | > decoder_diff_spec_loss: 0.53308  (0.50359)
     | > postnet_diff_spec_loss: 0.81063  (0.81968)
     | > decoder_ssim_loss: 0.30806  (0.32258)
     | > postnet_ssim_loss: 0.32105  (0.33632)
     | > loss: 3.54457  (3.57673)
     | > align_error: 0.99210  (0.98911)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.91666  (5.57789)
     | > current_lr: 0.00010 
     | > step_time: 5.41910  (3.91450)
     | > loader_time: 0.02180  (0.04563)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 274175[0m
     | > decoder_loss: 1.85355  (1.95118)
     | > postnet_loss: 1.66380  (1.69196)
     | > stopnet_loss: 1.93712  (1.60947)
     | > decoder_coarse_loss: 1.78863  (1.87555)
     | > decoder_ddc_loss: 0.00204  (0.00126)
     | > ga_loss: 0.00321  (0.00237)
     | > decoder_diff_spec_loss: 0.45502  (0.49535)
     | > postnet_diff_spec_loss: 0.80223  (0.81318)
     | > decoder_ssim_loss: 0.34090  (0.33257)
     | > postnet_ssim_loss: 0.35640  (0.34659)
     | > loss: 3.76884  (3.49820)
     | > align_error: 0.98378  (0.98917)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 14.95445  (4.76309)
     | > current_lr: 0.00010 
     | > step_time: 3.27090  (3.79814)
     | > loader_time: 0.02210  (0.03855)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 274200[0m
     | > decoder_loss: 1.84831  (1.94403)
     | > postnet_loss: 1.63757  (1.68995)
     | > stopnet_loss: 1.84101  (1.61771)
     | > decoder_coarse_loss: 1.79813  (1.87221)
     | > decoder_ddc_loss: 0.00151  (0.00127)
     | > ga_loss: 0.00303  (0.00240)
     | > decoder_diff_spec_loss: 0.47143  (0.49395)
     | > postnet_diff_spec_loss: 0.81472  (0.81223)
     | > decoder_ssim_loss: 0.28745  (0.32966)
     | > postnet_ssim_loss: 0.30190  (0.34359)
     | > loss: 3.64642  (3.50145)
     | > align_error: 0.98780  (0.98916)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.61404  (4.50201)
     | > current_lr: 0.00010 
     | > step_time: 3.43170  (3.71478)
     | > loader_time: 0.02120  (0.03677)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 6.83356 [0m(-2.32953)
     | > avg_decoder_loss:[91m 2.68207 [0m(+0.06745)
     | > avg_postnet_loss:[91m 2.49040 [0m(+0.15922)
     | > avg_stopnet_loss:[92m 1.32460 [0m(-0.00050)
     | > avg_decoder_coarse_loss:[91m 2.62033 [0m(+0.10727)
     | > avg_decoder_ddc_loss:[91m 0.00111 [0m(+0.00006)
     | > avg_ga_loss:[92m 0.00214 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.48103 [0m(-0.00079)
     | > avg_postnet_diff_spec_loss:[92m 0.82328 [0m(-0.00116)
     | > avg_decoder_ssim_loss:[92m 0.34401 [0m(-0.00042)
     | > avg_postnet_ssim_loss:[91m 0.35748 [0m(+0.00004)
     | > avg_loss:[91m 3.78523 [0m(+0.08234)
     | > avg_align_error:[92m 0.99064 [0m(-0.00005)


[4m[1m > EPOCH: 48/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:43:09) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 274225[0m
     | > decoder_loss: 1.87174  (1.87174)
     | > postnet_loss: 1.59557  (1.59557)
     | > stopnet_loss: 1.42991  (1.42991)
     | > decoder_coarse_loss: 1.78199  (1.78199)
     | > decoder_ddc_loss: 0.00174  (0.00174)
     | > ga_loss: 0.00289  (0.00289)
     | > decoder_diff_spec_loss: 0.47332  (0.47332)
     | > postnet_diff_spec_loss: 0.80644  (0.80644)
     | > decoder_ssim_loss: 0.35536  (0.35536)
     | > postnet_ssim_loss: 0.36991  (0.36991)
     | > loss: 3.25838  (3.25838)
     | > align_error: 0.98569  (0.98569)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.13865  (6.13865)
     | > current_lr: 0.00010 
     | > step_time: 3.83230  (3.83233)
     | > loader_time: 0.01830  (0.01827)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 274250[0m
     | > decoder_loss: 1.98596  (1.95597)
     | > postnet_loss: 1.73705  (1.69311)
     | > stopnet_loss: 1.87855  (1.65008)
     | > decoder_coarse_loss: 1.92225  (1.87983)
     | > decoder_ddc_loss: 0.00134  (0.00121)
     | > ga_loss: 0.00262  (0.00234)
     | > decoder_diff_spec_loss: 0.52435  (0.49740)
     | > postnet_diff_spec_loss: 0.83090  (0.81560)
     | > decoder_ssim_loss: 0.27471  (0.32199)
     | > postnet_ssim_loss: 0.28218  (0.33584)
     | > loss: 3.78133  (3.53701)
     | > align_error: 0.98762  (0.98936)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.18773  (5.01862)
     | > current_lr: 0.00010 
     | > step_time: 3.60970  (3.96764)
     | > loader_time: 0.02010  (0.04700)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 274275[0m
     | > decoder_loss: 1.80685  (1.92657)
     | > postnet_loss: 1.64697  (1.67002)
     | > stopnet_loss: 1.24248  (1.60131)
     | > decoder_coarse_loss: 1.72966  (1.85781)
     | > decoder_ddc_loss: 0.00163  (0.00126)
     | > ga_loss: 0.00272  (0.00238)
     | > decoder_diff_spec_loss: 0.44623  (0.49380)
     | > postnet_diff_spec_loss: 0.79786  (0.81130)
     | > decoder_ssim_loss: 0.39125  (0.33051)
     | > postnet_ssim_loss: 0.41190  (0.34505)
     | > loss: 3.06417  (3.47228)
     | > align_error: 0.98775  (0.98912)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.07940  (4.36614)
     | > current_lr: 0.00010 
     | > step_time: 3.44060  (3.73393)
     | > loader_time: 0.02070  (0.03773)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 274300[0m
     | > decoder_loss: 1.83207  (1.92588)
     | > postnet_loss: 1.54424  (1.66556)
     | > stopnet_loss: 1.60233  (1.61002)
     | > decoder_coarse_loss: 1.80234  (1.86221)
     | > decoder_ddc_loss: 0.00105  (0.00126)
     | > ga_loss: 0.00219  (0.00238)
     | > decoder_diff_spec_loss: 0.48940  (0.49220)
     | > postnet_diff_spec_loss: 0.80822  (0.81059)
     | > decoder_ssim_loss: 0.31020  (0.32901)
     | > postnet_ssim_loss: 0.32308  (0.34339)
     | > loss: 3.39095  (3.47946)
     | > align_error: 0.99140  (0.98922)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.33480  (4.37802)
     | > current_lr: 0.00010 
     | > step_time: 3.73790  (3.76808)
     | > loader_time: 0.02000  (0.03762)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.86740 [0m(-0.96616)
     | > avg_decoder_loss:[92m 2.61780 [0m(-0.06426)
     | > avg_postnet_loss:[92m 2.38631 [0m(-0.10409)
     | > avg_stopnet_loss:[92m 1.32392 [0m(-0.00067)
     | > avg_decoder_coarse_loss:[92m 2.48843 [0m(-0.13190)
     | > avg_decoder_ddc_loss:[91m 0.00112 [0m(+0.00001)
     | > avg_ga_loss:[91m 0.00214 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.48212 [0m(+0.00109)
     | > avg_postnet_diff_spec_loss:[92m 0.82306 [0m(-0.00022)
     | > avg_decoder_ssim_loss:[92m 0.34291 [0m(-0.00109)
     | > avg_postnet_ssim_loss:[92m 0.35589 [0m(-0.00159)
     | > avg_loss:[92m 3.70904 [0m(-0.07619)
     | > avg_align_error:[92m 0.99046 [0m(-0.00018)


[4m[1m > EPOCH: 49/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:50:38) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 274325[0m
     | > decoder_loss: 2.07464  (2.00747)
     | > postnet_loss: 1.79569  (1.73026)
     | > stopnet_loss: 1.78000  (1.63594)
     | > decoder_coarse_loss: 2.06038  (1.91721)
     | > decoder_ddc_loss: 0.00166  (0.00132)
     | > ga_loss: 0.00313  (0.00254)
     | > decoder_diff_spec_loss: 0.52506  (0.50028)
     | > postnet_diff_spec_loss: 0.86119  (0.82016)
     | > decoder_ssim_loss: 0.31976  (0.32284)
     | > postnet_ssim_loss: 0.33086  (0.33730)
     | > loss: 3.78798  (3.55784)
     | > align_error: 0.98632  (0.98874)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 11.53255  (6.01246)
     | > current_lr: 0.00010 
     | > step_time: 2.22580  (3.76299)
     | > loader_time: 0.06380  (0.04836)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 274350[0m
     | > decoder_loss: 1.87487  (1.92846)
     | > postnet_loss: 1.51753  (1.65460)
     | > stopnet_loss: 1.30770  (1.58554)
     | > decoder_coarse_loss: 1.76312  (1.85067)
     | > decoder_ddc_loss: 0.00118  (0.00126)
     | > ga_loss: 0.00214  (0.00233)
     | > decoder_diff_spec_loss: 0.46373  (0.49339)
     | > postnet_diff_spec_loss: 0.78066  (0.81242)
     | > decoder_ssim_loss: 0.37104  (0.33097)
     | > postnet_ssim_loss: 0.38459  (0.34542)
     | > loss: 3.10755  (3.45149)
     | > align_error: 0.99096  (0.98923)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.29094  (4.35164)
     | > current_lr: 0.00010 
     | > step_time: 3.40060  (3.75929)
     | > loader_time: 0.02090  (0.03645)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 274375[0m
     | > decoder_loss: 2.14354  (1.92685)
     | > postnet_loss: 1.73781  (1.65661)
     | > stopnet_loss: 2.20023  (1.60140)
     | > decoder_coarse_loss: 2.04115  (1.84868)
     | > decoder_ddc_loss: 0.00108  (0.00128)
     | > ga_loss: 0.00264  (0.00237)
     | > decoder_diff_spec_loss: 0.57084  (0.49227)
     | > postnet_diff_spec_loss: 0.87031  (0.81118)
     | > decoder_ssim_loss: 0.24959  (0.32898)
     | > postnet_ssim_loss: 0.25320  (0.34347)
     | > loss: 4.18032  (3.46561)
     | > align_error: 0.98974  (0.98912)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.58706  (4.56419)
     | > current_lr: 0.00010 
     | > step_time: 4.08810  (3.69514)
     | > loader_time: 0.03500  (0.03293)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.82373 [0m(-0.04366)
     | > avg_decoder_loss:[92m 2.52842 [0m(-0.08939)
     | > avg_postnet_loss:[92m 2.36161 [0m(-0.02470)
     | > avg_stopnet_loss:[92m 1.32201 [0m(-0.00192)
     | > avg_decoder_coarse_loss:[92m 2.44943 [0m(-0.03899)
     | > avg_decoder_ddc_loss:[92m 0.00110 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00214 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47965 [0m(-0.00247)
     | > avg_postnet_diff_spec_loss:[91m 0.82308 [0m(+0.00003)
     | > avg_decoder_ssim_loss:[92m 0.34215 [0m(-0.00076)
     | > avg_postnet_ssim_loss:[91m 0.35605 [0m(+0.00016)
     | > avg_loss:[92m 3.66806 [0m(-0.04098)
     | > avg_align_error:[91m 0.99051 [0m(+0.00005)


[4m[1m > EPOCH: 50/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 15:58:32) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 274400[0m
     | > decoder_loss: 1.85785  (1.85785)
     | > postnet_loss: 1.58391  (1.58391)
     | > stopnet_loss: 1.52195  (1.52195)
     | > decoder_coarse_loss: 1.80410  (1.80410)
     | > decoder_ddc_loss: 0.00156  (0.00156)
     | > ga_loss: 0.00298  (0.00298)
     | > decoder_diff_spec_loss: 0.48444  (0.48444)
     | > postnet_diff_spec_loss: 0.80657  (0.80657)
     | > decoder_ssim_loss: 0.34087  (0.34087)
     | > postnet_ssim_loss: 0.35040  (0.35040)
     | > loss: 3.34429  (3.34429)
     | > align_error: 0.98682  (0.98682)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.96274  (4.96274)
     | > current_lr: 0.00010 
     | > step_time: 4.23800  (4.23799)
     | > loader_time: 6.69970  (6.69973)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 274425[0m
     | > decoder_loss: 1.98963  (1.93756)
     | > postnet_loss: 1.76613  (1.66043)
     | > stopnet_loss: 1.07830  (1.62203)
     | > decoder_coarse_loss: 1.89567  (1.86100)
     | > decoder_ddc_loss: 0.00159  (0.00120)
     | > ga_loss: 0.00239  (0.00232)
     | > decoder_diff_spec_loss: 0.51159  (0.49620)
     | > postnet_diff_spec_loss: 0.81937  (0.81379)
     | > decoder_ssim_loss: 0.43763  (0.32264)
     | > postnet_ssim_loss: 0.45893  (0.33663)
     | > loss: 3.06038  (3.49098)
     | > align_error: 0.98717  (0.98947)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.36922  (4.85643)
     | > current_lr: 0.00010 
     | > step_time: 2.90790  (3.95469)
     | > loader_time: 0.03020  (0.04070)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 274450[0m
     | > decoder_loss: 1.76973  (1.90952)
     | > postnet_loss: 1.70066  (1.64040)
     | > stopnet_loss: 1.14084  (1.58593)
     | > decoder_coarse_loss: 1.69361  (1.84065)
     | > decoder_ddc_loss: 0.00150  (0.00125)
     | > ga_loss: 0.00257  (0.00236)
     | > decoder_diff_spec_loss: 0.46303  (0.49436)
     | > postnet_diff_spec_loss: 0.81191  (0.81100)
     | > decoder_ssim_loss: 0.40312  (0.32791)
     | > postnet_ssim_loss: 0.42435  (0.34288)
     | > loss: 2.97065  (3.43972)
     | > align_error: 0.98775  (0.98913)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.62732  (4.19079)
     | > current_lr: 0.00009 
     | > step_time: 3.13480  (3.72018)
     | > loader_time: 0.02190  (0.03429)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 274475[0m
     | > decoder_loss: 1.82611  (1.91176)
     | > postnet_loss: 1.54981  (1.63941)
     | > stopnet_loss: 1.43893  (1.59090)
     | > decoder_coarse_loss: 1.77542  (1.84119)
     | > decoder_ddc_loss: 0.00128  (0.00126)
     | > ga_loss: 0.00255  (0.00237)
     | > decoder_diff_spec_loss: 0.49204  (0.49171)
     | > postnet_diff_spec_loss: 0.81640  (0.80998)
     | > decoder_ssim_loss: 0.35422  (0.32802)
     | > postnet_ssim_loss: 0.36741  (0.34275)
     | > loss: 3.24734  (3.44426)
     | > align_error: 0.98881  (0.98915)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.36120  (4.15199)
     | > current_lr: 0.00009 
     | > step_time: 2.79050  (3.69343)
     | > loader_time: 0.01870  (0.03483)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 6.14841 [0m(+0.32467)
     | > avg_decoder_loss:[91m 2.59659 [0m(+0.06818)
     | > avg_postnet_loss:[92m 2.04353 [0m(-0.31808)
     | > avg_stopnet_loss:[92m 1.32191 [0m(-0.00009)
     | > avg_decoder_coarse_loss:[91m 2.50151 [0m(+0.05208)
     | > avg_decoder_ddc_loss:[92m 0.00107 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00212 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47877 [0m(-0.00088)
     | > avg_postnet_diff_spec_loss:[92m 0.82216 [0m(-0.00092)
     | > avg_decoder_ssim_loss:[92m 0.34177 [0m(-0.00038)
     | > avg_postnet_ssim_loss:[92m 0.35248 [0m(-0.00357)
     | > avg_loss:[92m 3.61700 [0m(-0.05105)
     | > avg_align_error:[91m 0.99058 [0m(+0.00007)


[4m[1m > EPOCH: 51/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:06:15) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 274500[0m
     | > decoder_loss: 2.00174  (1.97583)
     | > postnet_loss: 1.70051  (1.67673)
     | > stopnet_loss: 2.04164  (1.60852)
     | > decoder_coarse_loss: 1.86088  (1.89091)
     | > decoder_ddc_loss: 0.00091  (0.00124)
     | > ga_loss: 0.00218  (0.00244)
     | > decoder_diff_spec_loss: 0.46626  (0.49693)
     | > postnet_diff_spec_loss: 0.80704  (0.81550)
     | > decoder_ssim_loss: 0.26151  (0.32216)
     | > postnet_ssim_loss: 0.27164  (0.33700)
     | > loss: 3.89518  (3.49982)
     | > align_error: 0.99119  (0.98894)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.20527  (6.09118)
     | > current_lr: 0.00009 
     | > step_time: 4.77220  (4.05843)
     | > loader_time: 0.02320  (0.04080)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 274525[0m
     | > decoder_loss: 1.83899  (1.91213)
     | > postnet_loss: 1.55967  (1.62334)
     | > stopnet_loss: 1.26707  (1.59354)
     | > decoder_coarse_loss: 1.76242  (1.84711)
     | > decoder_ddc_loss: 0.00149  (0.00122)
     | > ga_loss: 0.00245  (0.00231)
     | > decoder_diff_spec_loss: 0.48273  (0.49463)
     | > postnet_diff_spec_loss: 0.80849  (0.81212)
     | > decoder_ssim_loss: 0.39478  (0.32867)
     | > postnet_ssim_loss: 0.41268  (0.34343)
     | > loss: 3.09463  (3.44574)
     | > align_error: 0.98837  (0.98918)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.25642  (4.64724)
     | > current_lr: 0.00009 
     | > step_time: 2.96900  (3.92244)
     | > loader_time: 0.09100  (0.03781)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 274550[0m
     | > decoder_loss: 2.05234  (1.90150)
     | > postnet_loss: 1.74679  (1.62267)
     | > stopnet_loss: 1.42765  (1.58687)
     | > decoder_coarse_loss: 1.95475  (1.83726)
     | > decoder_ddc_loss: 0.00090  (0.00124)
     | > ga_loss: 0.00168  (0.00235)
     | > decoder_diff_spec_loss: 0.46879  (0.49100)
     | > postnet_diff_spec_loss: 0.79117  (0.80925)
     | > decoder_ssim_loss: 0.33761  (0.32894)
     | > postnet_ssim_loss: 0.35588  (0.34403)
     | > loss: 3.36313  (3.43261)
     | > align_error: 0.99166  (0.98911)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.17403  (4.46779)
     | > current_lr: 0.00009 
     | > step_time: 4.70820  (3.82593)
     | > loader_time: 0.04240  (0.03383)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 274575[0m
     | > decoder_loss: 1.36140  (1.89379)
     | > postnet_loss: 1.46634  (1.61823)
     | > stopnet_loss: 1.30616  (1.59953)
     | > decoder_coarse_loss: 1.34143  (1.82699)
     | > decoder_ddc_loss: 0.00251  (0.00126)
     | > ga_loss: 0.00372  (0.00240)
     | > decoder_diff_spec_loss: 0.38085  (0.49012)
     | > postnet_diff_spec_loss: 0.75102  (0.80855)
     | > decoder_ssim_loss: 0.38592  (0.32666)
     | > postnet_ssim_loss: 0.41077  (0.34145)
     | > loss: 2.84983  (3.43832)
     | > align_error: 0.97722  (0.98889)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 15.04090  (4.41159)
     | > current_lr: 0.00009 
     | > step_time: 0.89170  (3.65404)
     | > loader_time: 0.00470  (0.03261)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.19353 [0m(-0.95487)
     | > avg_decoder_loss:[91m 2.66109 [0m(+0.06450)
     | > avg_postnet_loss:[91m 2.23738 [0m(+0.19385)
     | > avg_stopnet_loss:[91m 1.32214 [0m(+0.00023)
     | > avg_decoder_coarse_loss:[92m 2.43480 [0m(-0.06671)
     | > avg_decoder_ddc_loss:[92m 0.00105 [0m(-0.00002)
     | > avg_ga_loss:[91m 0.00213 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47940 [0m(+0.00064)
     | > avg_postnet_diff_spec_loss:[92m 0.82029 [0m(-0.00187)
     | > avg_decoder_ssim_loss:[92m 0.34134 [0m(-0.00043)
     | > avg_postnet_ssim_loss:[91m 0.35322 [0m(+0.00074)
     | > avg_loss:[91m 3.66492 [0m(+0.04791)
     | > avg_align_error:[91m 0.99061 [0m(+0.00003)


[4m[1m > EPOCH: 52/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:13:43) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 274600[0m
     | > decoder_loss: 1.98118  (1.91850)
     | > postnet_loss: 1.69099  (1.63255)
     | > stopnet_loss: 1.11776  (1.63858)
     | > decoder_coarse_loss: 1.93018  (1.84290)
     | > decoder_ddc_loss: 0.00116  (0.00115)
     | > ga_loss: 0.00208  (0.00230)
     | > decoder_diff_spec_loss: 0.48496  (0.49276)
     | > postnet_diff_spec_loss: 0.81570  (0.81321)
     | > decoder_ssim_loss: 0.39586  (0.31658)
     | > postnet_ssim_loss: 0.41185  (0.33131)
     | > loss: 3.05614  (3.48730)
     | > align_error: 0.98956  (0.98956)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.23795  (4.62186)
     | > current_lr: 0.00009 
     | > step_time: 3.93800  (3.95644)
     | > loader_time: 0.04440  (0.03648)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 274625[0m
     | > decoder_loss: 1.98646  (1.90312)
     | > postnet_loss: 1.62656  (1.61873)
     | > stopnet_loss: 1.17070  (1.59129)
     | > decoder_coarse_loss: 1.89103  (1.82524)
     | > decoder_ddc_loss: 0.00099  (0.00122)
     | > ga_loss: 0.00200  (0.00234)
     | > decoder_diff_spec_loss: 0.50469  (0.49313)
     | > postnet_diff_spec_loss: 0.80723  (0.81015)
     | > decoder_ssim_loss: 0.37877  (0.32525)
     | > postnet_ssim_loss: 0.39990  (0.34054)
     | > loss: 3.07963  (3.43233)
     | > align_error: 0.99126  (0.98918)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.54549  (4.33735)
     | > current_lr: 0.00009 
     | > step_time: 3.78900  (3.70980)
     | > loader_time: 0.04670  (0.03842)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 274650[0m
     | > decoder_loss: 1.90368  (1.89900)
     | > postnet_loss: 1.65640  (1.61992)
     | > stopnet_loss: 1.19405  (1.58632)
     | > decoder_coarse_loss: 1.80932  (1.82517)
     | > decoder_ddc_loss: 0.00129  (0.00125)
     | > ga_loss: 0.00225  (0.00235)
     | > decoder_diff_spec_loss: 0.49706  (0.49016)
     | > postnet_diff_spec_loss: 0.82697  (0.80906)
     | > decoder_ssim_loss: 0.38202  (0.32646)
     | > postnet_ssim_loss: 0.39257  (0.34176)
     | > loss: 3.07262  (3.42625)
     | > align_error: 0.98960  (0.98913)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.53680  (4.35211)
     | > current_lr: 0.00009 
     | > step_time: 3.61090  (3.68759)
     | > loader_time: 0.01830  (0.03779)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.66633 [0m(-0.52721)
     | > avg_decoder_loss:[92m 2.62943 [0m(-0.03166)
     | > avg_postnet_loss:[91m 2.39325 [0m(+0.15587)
     | > avg_stopnet_loss:[91m 1.32272 [0m(+0.00058)
     | > avg_decoder_coarse_loss:[91m 2.46846 [0m(+0.03366)
     | > avg_decoder_ddc_loss:[91m 0.00113 [0m(+0.00008)
     | > avg_ga_loss:[92m 0.00213 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.48126 [0m(+0.00186)
     | > avg_postnet_diff_spec_loss:[92m 0.82015 [0m(-0.00014)
     | > avg_decoder_ssim_loss:[92m 0.34050 [0m(-0.00084)
     | > avg_postnet_ssim_loss:[91m 0.35426 [0m(+0.00105)
     | > avg_loss:[91m 3.70546 [0m(+0.04055)
     | > avg_align_error:[92m 0.99048 [0m(-0.00013)


[4m[1m > EPOCH: 53/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:20:56) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 274675[0m
     | > decoder_loss: 1.89892  (1.96552)
     | > postnet_loss: 1.58599  (1.68493)
     | > stopnet_loss: 1.97218  (1.56012)
     | > decoder_coarse_loss: 1.80632  (1.88054)
     | > decoder_ddc_loss: 0.00109  (0.00130)
     | > ga_loss: 0.00275  (0.00247)
     | > decoder_diff_spec_loss: 0.51477  (0.50024)
     | > postnet_diff_spec_loss: 0.82178  (0.81546)
     | > decoder_ssim_loss: 0.26327  (0.32573)
     | > postnet_ssim_loss: 0.26955  (0.34243)
     | > loss: 3.77636  (3.45150)
     | > align_error: 0.98940  (0.98866)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.06362  (6.31345)
     | > current_lr: 0.00009 
     | > step_time: 3.59390  (3.94170)
     | > loader_time: 0.02120  (0.03853)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 274700[0m
     | > decoder_loss: 1.81910  (1.90530)
     | > postnet_loss: 1.42907  (1.62271)
     | > stopnet_loss: 1.29667  (1.59450)
     | > decoder_coarse_loss: 1.72665  (1.83980)
     | > decoder_ddc_loss: 0.00128  (0.00124)
     | > ga_loss: 0.00203  (0.00229)
     | > decoder_diff_spec_loss: 0.49237  (0.49420)
     | > postnet_diff_spec_loss: 0.78747  (0.81165)
     | > decoder_ssim_loss: 0.36733  (0.32546)
     | > postnet_ssim_loss: 0.38225  (0.34119)
     | > loss: 3.05821  (3.44135)
     | > align_error: 0.98875  (0.98907)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.22631  (4.81345)
     | > current_lr: 0.00009 
     | > step_time: 3.67070  (3.79205)
     | > loader_time: 0.01730  (0.03463)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 274725[0m
     | > decoder_loss: 1.94632  (1.88971)
     | > postnet_loss: 1.58564  (1.61304)
     | > stopnet_loss: 1.58720  (1.58699)
     | > decoder_coarse_loss: 1.88868  (1.82267)
     | > decoder_ddc_loss: 0.00259  (0.00126)
     | > ga_loss: 0.00396  (0.00234)
     | > decoder_diff_spec_loss: 0.49884  (0.49077)
     | > postnet_diff_spec_loss: 0.81288  (0.80879)
     | > decoder_ssim_loss: 0.38071  (0.32747)
     | > postnet_ssim_loss: 0.39466  (0.34339)
     | > loss: 3.48457  (3.42299)
     | > align_error: 0.98023  (0.98894)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 12.64937  (4.65405)
     | > current_lr: 0.00009 
     | > step_time: 1.97000  (3.64569)
     | > loader_time: 0.06680  (0.03533)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 274750[0m
     | > decoder_loss: 1.82319  (1.88695)
     | > postnet_loss: 1.60670  (1.60995)
     | > stopnet_loss: 1.47507  (1.59824)
     | > decoder_coarse_loss: 1.82041  (1.82014)
     | > decoder_ddc_loss: 0.00141  (0.00126)
     | > ga_loss: 0.00257  (0.00237)
     | > decoder_diff_spec_loss: 0.49165  (0.49079)
     | > postnet_diff_spec_loss: 0.82556  (0.80843)
     | > decoder_ssim_loss: 0.34269  (0.32462)
     | > postnet_ssim_loss: 0.35310  (0.34013)
     | > loss: 3.30410  (3.43067)
     | > align_error: 0.98826  (0.98890)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.84452  (4.68589)
     | > current_lr: 0.00009 
     | > step_time: 1.78190  (3.51862)
     | > loader_time: 0.01350  (0.03317)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.22931 [0m(+0.56298)
     | > avg_decoder_loss:[92m 2.59925 [0m(-0.03017)
     | > avg_postnet_loss:[92m 2.29398 [0m(-0.09927)
     | > avg_stopnet_loss:[92m 1.32181 [0m(-0.00091)
     | > avg_decoder_coarse_loss:[92m 2.42338 [0m(-0.04509)
     | > avg_decoder_ddc_loss:[92m 0.00110 [0m(-0.00003)
     | > avg_ga_loss:[91m 0.00213 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47758 [0m(-0.00368)
     | > avg_postnet_diff_spec_loss:[91m 0.82131 [0m(+0.00115)
     | > avg_decoder_ssim_loss:[92m 0.33995 [0m(-0.00056)
     | > avg_postnet_ssim_loss:[92m 0.35326 [0m(-0.00101)
     | > avg_loss:[92m 3.65989 [0m(-0.04557)
     | > avg_align_error:[91m 0.99053 [0m(+0.00005)


[4m[1m > EPOCH: 54/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:28:04) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 274775[0m
     | > decoder_loss: 1.77154  (1.90146)
     | > postnet_loss: 1.44833  (1.60738)
     | > stopnet_loss: 2.52421  (1.64734)
     | > decoder_coarse_loss: 1.72520  (1.82831)
     | > decoder_ddc_loss: 0.00083  (0.00117)
     | > ga_loss: 0.00193  (0.00229)
     | > decoder_diff_spec_loss: 0.46306  (0.49120)
     | > postnet_diff_spec_loss: 0.78221  (0.81206)
     | > decoder_ssim_loss: 0.20338  (0.31221)
     | > postnet_ssim_loss: 0.21252  (0.32709)
     | > loss: 4.18565  (3.47901)
     | > align_error: 0.99133  (0.98943)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.46871  (5.72194)
     | > current_lr: 0.00009 
     | > step_time: 4.98880  (3.84114)
     | > loader_time: 0.02840  (0.04330)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 274800[0m
     | > decoder_loss: 1.89398  (1.88271)
     | > postnet_loss: 1.59736  (1.59719)
     | > stopnet_loss: 1.52443  (1.58541)
     | > decoder_coarse_loss: 1.80763  (1.81466)
     | > decoder_ddc_loss: 0.00140  (0.00124)
     | > ga_loss: 0.00264  (0.00233)
     | > decoder_diff_spec_loss: 0.49797  (0.49131)
     | > postnet_diff_spec_loss: 0.81269  (0.80950)
     | > decoder_ssim_loss: 0.32336  (0.32295)
     | > postnet_ssim_loss: 0.33531  (0.33871)
     | > loss: 3.35504  (3.41163)
     | > align_error: 0.98778  (0.98902)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.54150  (4.79037)
     | > current_lr: 0.00009 
     | > step_time: 3.07840  (3.59486)
     | > loader_time: 0.03480  (0.04032)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 274825[0m
     | > decoder_loss: 1.71773  (1.88324)
     | > postnet_loss: 1.52278  (1.59968)
     | > stopnet_loss: 2.29024  (1.57705)
     | > decoder_coarse_loss: 1.69973  (1.81443)
     | > decoder_ddc_loss: 0.00082  (0.00125)
     | > ga_loss: 0.00235  (0.00233)
     | > decoder_diff_spec_loss: 0.45992  (0.48878)
     | > postnet_diff_spec_loss: 0.79612  (0.80817)
     | > decoder_ssim_loss: 0.22706  (0.32451)
     | > postnet_ssim_loss: 0.23502  (0.34044)
     | > loss: 3.96678  (3.40385)
     | > align_error: 0.99222  (0.98906)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.25708  (4.80597)
     | > current_lr: 0.00009 
     | > step_time: 4.14360  (3.62007)
     | > loader_time: 0.04820  (0.03980)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.92132 [0m(-0.30799)
     | > avg_decoder_loss:[91m 2.62524 [0m(+0.02598)
     | > avg_postnet_loss:[91m 2.42362 [0m(+0.12964)
     | > avg_stopnet_loss:[92m 1.31949 [0m(-0.00233)
     | > avg_decoder_coarse_loss:[91m 2.47252 [0m(+0.04914)
     | > avg_decoder_ddc_loss:[92m 0.00109 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00211 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.47897 [0m(+0.00139)
     | > avg_postnet_diff_spec_loss:[91m 0.82142 [0m(+0.00011)
     | > avg_decoder_ssim_loss:[92m 0.33936 [0m(-0.00059)
     | > avg_postnet_ssim_loss:[91m 0.35359 [0m(+0.00033)
     | > avg_loss:[91m 3.70898 [0m(+0.04909)
     | > avg_align_error:[92m 0.99045 [0m(-0.00007)


[4m[1m > EPOCH: 55/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:35:12) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 274850[0m
     | > decoder_loss: 2.10482  (1.96651)
     | > postnet_loss: 1.67179  (1.66045)
     | > stopnet_loss: 1.69033  (1.52473)
     | > decoder_coarse_loss: 2.02443  (1.87718)
     | > decoder_ddc_loss: 0.00118  (0.00129)
     | > ga_loss: 0.00235  (0.00242)
     | > decoder_diff_spec_loss: 0.55837  (0.50277)
     | > postnet_diff_spec_loss: 0.85219  (0.81437)
     | > decoder_ssim_loss: 0.31020  (0.33151)
     | > postnet_ssim_loss: 0.31564  (0.34849)
     | > loss: 3.66173  (3.41247)
     | > align_error: 0.98933  (0.98853)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.53623  (5.37560)
     | > current_lr: 0.00009 
     | > step_time: 3.60450  (3.89760)
     | > loader_time: 0.01440  (0.04146)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 274875[0m
     | > decoder_loss: 2.00342  (1.89877)
     | > postnet_loss: 1.67762  (1.60538)
     | > stopnet_loss: 1.69892  (1.59819)
     | > decoder_coarse_loss: 1.96616  (1.82874)
     | > decoder_ddc_loss: 0.00118  (0.00120)
     | > ga_loss: 0.00227  (0.00230)
     | > decoder_diff_spec_loss: 0.53844  (0.49472)
     | > postnet_diff_spec_loss: 0.83854  (0.81152)
     | > decoder_ssim_loss: 0.30228  (0.32348)
     | > postnet_ssim_loss: 0.31263  (0.33897)
     | > loss: 3.62033  (3.43538)
     | > align_error: 0.98912  (0.98913)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.42535  (4.34722)
     | > current_lr: 0.00009 
     | > step_time: 3.55670  (3.78458)
     | > loader_time: 0.02330  (0.03054)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 274900[0m
     | > decoder_loss: 1.76797  (1.88056)
     | > postnet_loss: 1.48861  (1.59331)
     | > stopnet_loss: 0.99375  (1.57593)
     | > decoder_coarse_loss: 1.68313  (1.81107)
     | > decoder_ddc_loss: 0.00154  (0.00122)
     | > ga_loss: 0.00243  (0.00231)
     | > decoder_diff_spec_loss: 0.46577  (0.49051)
     | > postnet_diff_spec_loss: 0.78899  (0.80797)
     | > decoder_ssim_loss: 0.44626  (0.32563)
     | > postnet_ssim_loss: 0.47182  (0.34173)
     | > loss: 2.78443  (3.40048)
     | > align_error: 0.98799  (0.98910)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.69647  (4.18405)
     | > current_lr: 0.00009 
     | > step_time: 3.15640  (3.66611)
     | > loader_time: 0.01690  (0.03248)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 274925[0m
     | > decoder_loss: 1.87882  (1.87919)
     | > postnet_loss: 1.51768  (1.59223)
     | > stopnet_loss: 1.87993  (1.59104)
     | > decoder_coarse_loss: 1.77919  (1.80758)
     | > decoder_ddc_loss: 0.00108  (0.00126)
     | > ga_loss: 0.00269  (0.00235)
     | > decoder_diff_spec_loss: 0.51105  (0.49036)
     | > postnet_diff_spec_loss: 0.81058  (0.80750)
     | > decoder_ssim_loss: 0.28659  (0.32345)
     | > postnet_ssim_loss: 0.29610  (0.33922)
     | > loss: 3.66367  (3.41300)
     | > align_error: 0.98892  (0.98887)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.94517  (4.39031)
     | > current_lr: 0.00009 
     | > step_time: 2.06420  (3.55805)
     | > loader_time: 0.01330  (0.03212)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.18057 [0m(+0.25925)
     | > avg_decoder_loss:[91m 2.64460 [0m(+0.01936)
     | > avg_postnet_loss:[92m 2.42158 [0m(-0.00204)
     | > avg_stopnet_loss:[91m 1.32214 [0m(+0.00265)
     | > avg_decoder_coarse_loss:[92m 2.38523 [0m(-0.08729)
     | > avg_decoder_ddc_loss:[92m 0.00107 [0m(-0.00003)
     | > avg_ga_loss:[91m 0.00211 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47782 [0m(-0.00115)
     | > avg_postnet_diff_spec_loss:[92m 0.82042 [0m(-0.00099)
     | > avg_decoder_ssim_loss:[92m 0.33887 [0m(-0.00049)
     | > avg_postnet_ssim_loss:[91m 0.35398 [0m(+0.00040)
     | > avg_loss:[92m 3.69360 [0m(-0.01538)
     | > avg_align_error:[91m 0.99049 [0m(+0.00003)


[4m[1m > EPOCH: 56/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:42:23) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 274950[0m
     | > decoder_loss: 1.76444  (1.88838)
     | > postnet_loss: 1.47138  (1.60617)
     | > stopnet_loss: 1.75598  (1.61405)
     | > decoder_coarse_loss: 1.72169  (1.81869)
     | > decoder_ddc_loss: 0.00082  (0.00117)
     | > ga_loss: 0.00216  (0.00229)
     | > decoder_diff_spec_loss: 0.47053  (0.49284)
     | > postnet_diff_spec_loss: 0.79589  (0.81290)
     | > decoder_ssim_loss: 0.27709  (0.31589)
     | > postnet_ssim_loss: 0.29703  (0.33194)
     | > loss: 3.46652  (3.44250)
     | > align_error: 0.99149  (0.98930)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.97017  (5.53129)
     | > current_lr: 0.00009 
     | > step_time: 4.01730  (3.95550)
     | > loader_time: 0.04170  (0.03780)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 274975[0m
     | > decoder_loss: 1.86399  (1.86760)
     | > postnet_loss: 1.61741  (1.58811)
     | > stopnet_loss: 1.39559  (1.59636)
     | > decoder_coarse_loss: 1.82845  (1.80227)
     | > decoder_ddc_loss: 0.00134  (0.00122)
     | > ga_loss: 0.00252  (0.00231)
     | > decoder_diff_spec_loss: 0.50788  (0.49030)
     | > postnet_diff_spec_loss: 0.82115  (0.80879)
     | > decoder_ssim_loss: 0.36549  (0.32171)
     | > postnet_ssim_loss: 0.37860  (0.33845)
     | > loss: 3.25428  (3.41252)
     | > align_error: 0.98830  (0.98900)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.19463  (4.77502)
     | > current_lr: 0.00009 
     | > step_time: 2.58010  (3.68447)
     | > loader_time: 0.01670  (0.03373)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 275000[0m
     | > decoder_loss: 1.90778  (1.87147)
     | > postnet_loss: 1.65958  (1.58887)
     | > stopnet_loss: 1.09880  (1.56869)
     | > decoder_coarse_loss: 1.83195  (1.80544)
     | > decoder_ddc_loss: 0.00101  (0.00123)
     | > ga_loss: 0.00167  (0.00232)
     | > decoder_diff_spec_loss: 0.46495  (0.48876)
     | > postnet_diff_spec_loss: 0.79181  (0.80753)
     | > decoder_ssim_loss: 0.39660  (0.32473)
     | > postnet_ssim_loss: 0.41638  (0.34138)
     | > loss: 2.97468  (3.38765)
     | > align_error: 0.99084  (0.98897)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.87916  (4.67698)
     | > current_lr: 0.00009 
     | > step_time: 4.12190  (3.63330)
     | > loader_time: 0.02330  (0.03483)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.13479 [0m(-0.04578)
     | > avg_decoder_loss:[92m 2.51179 [0m(-0.13281)
     | > avg_postnet_loss:[92m 2.33434 [0m(-0.08725)
     | > avg_stopnet_loss:[92m 1.31969 [0m(-0.00244)
     | > avg_decoder_coarse_loss:[92m 2.31942 [0m(-0.06581)
     | > avg_decoder_ddc_loss:[92m 0.00105 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00210 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47565 [0m(-0.00217)
     | > avg_postnet_diff_spec_loss:[92m 0.81919 [0m(-0.00123)
     | > avg_decoder_ssim_loss:[92m 0.33787 [0m(-0.00100)
     | > avg_postnet_ssim_loss:[92m 0.35303 [0m(-0.00095)
     | > avg_loss:[92m 3.61829 [0m(-0.07531)
     | > avg_align_error:[92m 0.99044 [0m(-0.00005)


[4m[1m > EPOCH: 57/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:49:35) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 275025[0m
     | > decoder_loss: 2.08421  (1.93566)
     | > postnet_loss: 1.77138  (1.64868)
     | > stopnet_loss: 1.28719  (1.48547)
     | > decoder_coarse_loss: 1.94207  (1.84457)
     | > decoder_ddc_loss: 0.00158  (0.00132)
     | > ga_loss: 0.00259  (0.00242)
     | > decoder_diff_spec_loss: 0.51739  (0.49092)
     | > postnet_diff_spec_loss: 0.83653  (0.80912)
     | > decoder_ssim_loss: 0.38142  (0.33277)
     | > postnet_ssim_loss: 0.39911  (0.35234)
     | > loss: 3.28358  (3.35141)
     | > align_error: 0.98719  (0.98842)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.13944  (6.98727)
     | > current_lr: 0.00009 
     | > step_time: 3.00120  (3.86266)
     | > loader_time: 0.01490  (0.03131)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 275050[0m
     | > decoder_loss: 1.85238  (1.86961)
     | > postnet_loss: 1.51143  (1.58369)
     | > stopnet_loss: 1.14226  (1.56846)
     | > decoder_coarse_loss: 1.76683  (1.81027)
     | > decoder_ddc_loss: 0.00145  (0.00124)
     | > ga_loss: 0.00200  (0.00227)
     | > decoder_diff_spec_loss: 0.49715  (0.49207)
     | > postnet_diff_spec_loss: 0.79878  (0.81011)
     | > decoder_ssim_loss: 0.38979  (0.32305)
     | > postnet_ssim_loss: 0.41220  (0.33959)
     | > loss: 2.95976  (3.38720)
     | > align_error: 0.98838  (0.98899)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.16278  (4.80045)
     | > current_lr: 0.00009 
     | > step_time: 3.28240  (3.75694)
     | > loader_time: 0.01840  (0.03787)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 275075[0m
     | > decoder_loss: 1.72412  (1.86034)
     | > postnet_loss: 1.41815  (1.57738)
     | > stopnet_loss: 1.16177  (1.56853)
     | > decoder_coarse_loss: 1.68704  (1.79815)
     | > decoder_ddc_loss: 0.00139  (0.00125)
     | > ga_loss: 0.00223  (0.00228)
     | > decoder_diff_spec_loss: 0.47184  (0.48957)
     | > postnet_diff_spec_loss: 0.78033  (0.80791)
     | > decoder_ssim_loss: 0.41000  (0.32262)
     | > postnet_ssim_loss: 0.42249  (0.33933)
     | > loss: 2.90179  (3.37907)
     | > align_error: 0.98911  (0.98899)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.41218  (4.59946)
     | > current_lr: 0.00009 
     | > step_time: 3.09060  (3.65975)
     | > loader_time: 0.05280  (0.03828)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 275100[0m
     | > decoder_loss: 1.95625  (1.85741)
     | > postnet_loss: 1.61550  (1.57354)
     | > stopnet_loss: 1.68069  (1.57535)
     | > decoder_coarse_loss: 1.85560  (1.79301)
     | > decoder_ddc_loss: 0.00173  (0.00128)
     | > ga_loss: 0.00285  (0.00232)
     | > decoder_diff_spec_loss: 0.53404  (0.48887)
     | > postnet_diff_spec_loss: 0.81864  (0.80703)
     | > decoder_ssim_loss: 0.31292  (0.32279)
     | > postnet_ssim_loss: 0.33067  (0.33945)
     | > loss: 3.55127  (3.38280)
     | > align_error: 0.98601  (0.98876)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.32930  (4.57296)
     | > current_lr: 0.00009 
     | > step_time: 1.74850  (3.54674)
     | > loader_time: 0.01460  (0.03434)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.06147 [0m(-0.07331)
     | > avg_decoder_loss:[91m 2.58535 [0m(+0.07356)
     | > avg_postnet_loss:[91m 2.37396 [0m(+0.03962)
     | > avg_stopnet_loss:[92m 1.31952 [0m(-0.00018)
     | > avg_decoder_coarse_loss:[92m 2.28644 [0m(-0.03298)
     | > avg_decoder_ddc_loss:[91m 0.00106 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00210 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47833 [0m(+0.00268)
     | > avg_postnet_diff_spec_loss:[91m 0.81949 [0m(+0.00030)
     | > avg_decoder_ssim_loss:[92m 0.33777 [0m(-0.00010)
     | > avg_postnet_ssim_loss:[92m 0.35303 [0m(-0.00000)
     | > avg_loss:[91m 3.63887 [0m(+0.02058)
     | > avg_align_error:[92m 0.99040 [0m(-0.00004)


[4m[1m > EPOCH: 58/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 16:56:41) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 275125[0m
     | > decoder_loss: 1.91519  (1.88188)
     | > postnet_loss: 1.60542  (1.58374)
     | > stopnet_loss: 1.15769  (1.59248)
     | > decoder_coarse_loss: 1.86008  (1.80875)
     | > decoder_ddc_loss: 0.00204  (0.00122)
     | > ga_loss: 0.00272  (0.00228)
     | > decoder_diff_spec_loss: 0.50196  (0.49542)
     | > postnet_diff_spec_loss: 0.82614  (0.81296)
     | > decoder_ssim_loss: 0.40293  (0.31683)
     | > postnet_ssim_loss: 0.41974  (0.33300)
     | > loss: 3.05465  (3.41231)
     | > align_error: 0.98446  (0.98904)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.12359  (4.97845)
     | > current_lr: 0.00009 
     | > step_time: 2.34880  (3.94130)
     | > loader_time: 0.05400  (0.03636)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 275150[0m
     | > decoder_loss: 1.92184  (1.85546)
     | > postnet_loss: 1.66353  (1.55884)
     | > stopnet_loss: 1.49330  (1.58301)
     | > decoder_coarse_loss: 1.87955  (1.78644)
     | > decoder_ddc_loss: 0.00144  (0.00124)
     | > ga_loss: 0.00248  (0.00229)
     | > decoder_diff_spec_loss: 0.49475  (0.49073)
     | > postnet_diff_spec_loss: 0.81953  (0.80770)
     | > decoder_ssim_loss: 0.31788  (0.31992)
     | > postnet_ssim_loss: 0.33458  (0.33686)
     | > loss: 3.36399  (3.38376)
     | > align_error: 0.98787  (0.98887)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.73045  (4.22589)
     | > current_lr: 0.00009 
     | > step_time: 3.44280  (3.72203)
     | > loader_time: 0.03870  (0.03478)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 275175[0m
     | > decoder_loss: 1.92278  (1.85738)
     | > postnet_loss: 1.66019  (1.56420)
     | > stopnet_loss: 1.63331  (1.56645)
     | > decoder_coarse_loss: 1.84067  (1.78942)
     | > decoder_ddc_loss: 0.00142  (0.00126)
     | > ga_loss: 0.00313  (0.00232)
     | > decoder_diff_spec_loss: 0.48468  (0.48885)
     | > postnet_diff_spec_loss: 0.81478  (0.80704)
     | > decoder_ssim_loss: 0.32096  (0.32271)
     | > postnet_ssim_loss: 0.33773  (0.33964)
     | > loss: 3.49478  (3.37065)
     | > align_error: 0.98743  (0.98880)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.59464  (4.32348)
     | > current_lr: 0.00009 
     | > step_time: 2.48930  (3.63203)
     | > loader_time: 0.02320  (0.03259)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.15201 [0m(+0.09054)
     | > avg_decoder_loss:[92m 2.43310 [0m(-0.15226)
     | > avg_postnet_loss:[92m 2.27772 [0m(-0.09624)
     | > avg_stopnet_loss:[92m 1.31858 [0m(-0.00094)
     | > avg_decoder_coarse_loss:[92m 2.25751 [0m(-0.02892)
     | > avg_decoder_ddc_loss:[92m 0.00098 [0m(-0.00008)
     | > avg_ga_loss:[91m 0.00210 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47644 [0m(-0.00189)
     | > avg_postnet_diff_spec_loss:[92m 0.81915 [0m(-0.00035)
     | > avg_decoder_ssim_loss:[92m 0.33677 [0m(-0.00100)
     | > avg_postnet_ssim_loss:[92m 0.35199 [0m(-0.00104)
     | > avg_loss:[92m 3.56749 [0m(-0.07138)
     | > avg_align_error:[92m 0.99036 [0m(-0.00004)


[4m[1m > EPOCH: 59/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:03:54) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 275200[0m
     | > decoder_loss: 2.14979  (1.89890)
     | > postnet_loss: 1.70062  (1.60080)
     | > stopnet_loss: 1.89784  (1.51012)
     | > decoder_coarse_loss: 2.05699  (1.82244)
     | > decoder_ddc_loss: 0.00074  (0.00123)
     | > ga_loss: 0.00193  (0.00240)
     | > decoder_diff_spec_loss: 0.55283  (0.49102)
     | > postnet_diff_spec_loss: 0.83924  (0.80575)
     | > decoder_ssim_loss: 0.25713  (0.32629)
     | > postnet_ssim_loss: 0.26641  (0.34498)
     | > loss: 3.86344  (3.34499)
     | > align_error: 0.99203  (0.98851)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.90010  (5.86908)
     | > current_lr: 0.00009 
     | > step_time: 4.37520  (4.12599)
     | > loader_time: 0.03910  (0.03296)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 275225[0m
     | > decoder_loss: 1.74308  (1.86452)
     | > postnet_loss: 1.42872  (1.56659)
     | > stopnet_loss: 1.92305  (1.59506)
     | > decoder_coarse_loss: 1.70811  (1.79856)
     | > decoder_ddc_loss: 0.00068  (0.00119)
     | > ga_loss: 0.00167  (0.00227)
     | > decoder_diff_spec_loss: 0.47187  (0.49137)
     | > postnet_diff_spec_loss: 0.79552  (0.81025)
     | > decoder_ssim_loss: 0.25243  (0.32015)
     | > postnet_ssim_loss: 0.26671  (0.33676)
     | > loss: 3.59817  (3.40377)
     | > align_error: 0.99235  (0.98898)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.98576  (4.32398)
     | > current_lr: 0.00009 
     | > step_time: 4.45630  (3.81458)
     | > loader_time: 0.04770  (0.03128)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 275250[0m
     | > decoder_loss: 2.12876  (1.85526)
     | > postnet_loss: 1.76356  (1.56210)
     | > stopnet_loss: 1.71853  (1.57877)
     | > decoder_coarse_loss: 2.05402  (1.78678)
     | > decoder_ddc_loss: 0.00093  (0.00120)
     | > ga_loss: 0.00174  (0.00228)
     | > decoder_diff_spec_loss: 0.54050  (0.48911)
     | > postnet_diff_spec_loss: 0.83419  (0.80786)
     | > decoder_ssim_loss: 0.28125  (0.32006)
     | > postnet_ssim_loss: 0.28651  (0.33713)
     | > loss: 3.69964  (3.38005)
     | > align_error: 0.99127  (0.98899)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.99411  (4.19185)
     | > current_lr: 0.00009 
     | > step_time: 4.73950  (3.72694)
     | > loader_time: 0.03090  (0.03272)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 275275[0m
     | > decoder_loss: 1.78731  (1.84831)
     | > postnet_loss: 1.45287  (1.55613)
     | > stopnet_loss: 1.55581  (1.57256)
     | > decoder_coarse_loss: 1.72235  (1.78138)
     | > decoder_ddc_loss: 0.00125  (0.00122)
     | > ga_loss: 0.00199  (0.00232)
     | > decoder_diff_spec_loss: 0.49329  (0.48778)
     | > postnet_diff_spec_loss: 0.78288  (0.80627)
     | > decoder_ssim_loss: 0.30021  (0.32194)
     | > postnet_ssim_loss: 0.31694  (0.33879)
     | > loss: 3.28005  (3.36958)
     | > align_error: 0.98779  (0.98881)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.67183  (4.35973)
     | > current_lr: 0.00009 
     | > step_time: 2.86690  (3.61887)
     | > loader_time: 0.02340  (0.03222)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.98404 [0m(-0.16797)
     | > avg_decoder_loss:[91m 2.48847 [0m(+0.05538)
     | > avg_postnet_loss:[92m 2.20775 [0m(-0.06997)
     | > avg_stopnet_loss:[91m 1.32070 [0m(+0.00212)
     | > avg_decoder_coarse_loss:[91m 2.25798 [0m(+0.00046)
     | > avg_decoder_ddc_loss:[91m 0.00105 [0m(+0.00007)
     | > avg_ga_loss:[92m 0.00208 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.47524 [0m(-0.00119)
     | > avg_postnet_diff_spec_loss:[92m 0.81910 [0m(-0.00005)
     | > avg_decoder_ssim_loss:[92m 0.33647 [0m(-0.00030)
     | > avg_postnet_ssim_loss:[92m 0.35171 [0m(-0.00028)
     | > avg_loss:[92m 3.56555 [0m(-0.00193)
     | > avg_align_error:[91m 0.99041 [0m(+0.00005)


[4m[1m > EPOCH: 60/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:11:01) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 275300[0m
     | > decoder_loss: 1.73821  (1.87551)
     | > postnet_loss: 1.41031  (1.57495)
     | > stopnet_loss: 1.98598  (1.59904)
     | > decoder_coarse_loss: 1.66881  (1.80161)
     | > decoder_ddc_loss: 0.00129  (0.00116)
     | > ga_loss: 0.00298  (0.00224)
     | > decoder_diff_spec_loss: 0.48924  (0.49222)
     | > postnet_diff_spec_loss: 0.79791  (0.81205)
     | > decoder_ssim_loss: 0.26296  (0.31169)
     | > postnet_ssim_loss: 0.27076  (0.32826)
     | > loss: 3.66077  (3.40961)
     | > align_error: 0.98771  (0.98925)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 10.27777  (5.90239)
     | > current_lr: 0.00009 
     | > step_time: 2.45960  (3.98297)
     | > loader_time: 0.01790  (0.04400)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 275325[0m
     | > decoder_loss: 1.70746  (1.84419)
     | > postnet_loss: 1.47319  (1.54349)
     | > stopnet_loss: 2.15386  (1.57390)
     | > decoder_coarse_loss: 1.63676  (1.77664)
     | > decoder_ddc_loss: 0.00087  (0.00122)
     | > ga_loss: 0.00229  (0.00227)
     | > decoder_diff_spec_loss: 0.48407  (0.48877)
     | > postnet_diff_spec_loss: 0.80257  (0.80700)
     | > decoder_ssim_loss: 0.23778  (0.31895)
     | > postnet_ssim_loss: 0.24968  (0.33640)
     | > loss: 3.81338  (3.36442)
     | > align_error: 0.99146  (0.98886)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.15746  (4.75528)
     | > current_lr: 0.00009 
     | > step_time: 4.07070  (3.70449)
     | > loader_time: 0.02770  (0.03994)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 275350[0m
     | > decoder_loss: 1.77594  (1.84782)
     | > postnet_loss: 1.52815  (1.55039)
     | > stopnet_loss: 1.58653  (1.55561)
     | > decoder_coarse_loss: 1.68989  (1.78205)
     | > decoder_ddc_loss: 0.00136  (0.00124)
     | > ga_loss: 0.00212  (0.00228)
     | > decoder_diff_spec_loss: 0.45430  (0.48759)
     | > postnet_diff_spec_loss: 0.78626  (0.80647)
     | > decoder_ssim_loss: 0.29827  (0.32180)
     | > postnet_ssim_loss: 0.31493  (0.33920)
     | > loss: 3.30940  (3.35116)
     | > align_error: 0.98761  (0.98878)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.40957  (4.66479)
     | > current_lr: 0.00009 
     | > step_time: 4.39510  (3.63660)
     | > loader_time: 0.02890  (0.03588)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.19268 [0m(+0.20864)
     | > avg_decoder_loss:[91m 2.49724 [0m(+0.00877)
     | > avg_postnet_loss:[92m 2.17895 [0m(-0.02880)
     | > avg_stopnet_loss:[92m 1.31957 [0m(-0.00113)
     | > avg_decoder_coarse_loss:[91m 2.27191 [0m(+0.01393)
     | > avg_decoder_ddc_loss:[92m 0.00099 [0m(-0.00006)
     | > avg_ga_loss:[91m 0.00208 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47628 [0m(+0.00104)
     | > avg_postnet_diff_spec_loss:[92m 0.81729 [0m(-0.00181)
     | > avg_decoder_ssim_loss:[92m 0.33593 [0m(-0.00054)
     | > avg_postnet_ssim_loss:[92m 0.35065 [0m(-0.00106)
     | > avg_loss:[92m 3.56230 [0m(-0.00325)
     | > avg_align_error:[91m 0.99045 [0m(+0.00004)


[4m[1m > EPOCH: 61/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:18:12) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 275375[0m
     | > decoder_loss: 1.84787  (1.83355)
     | > postnet_loss: 1.68079  (1.55830)
     | > stopnet_loss: 1.49567  (1.46608)
     | > decoder_coarse_loss: 1.81923  (1.77671)
     | > decoder_ddc_loss: 0.00115  (0.00136)
     | > ga_loss: 0.00214  (0.00242)
     | > decoder_diff_spec_loss: 0.49080  (0.48082)
     | > postnet_diff_spec_loss: 0.82672  (0.80012)
     | > decoder_ssim_loss: 0.31714  (0.33428)
     | > postnet_ssim_loss: 0.33426  (0.35508)
     | > loss: 3.33584  (3.26322)
     | > align_error: 0.98924  (0.98786)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.46869  (7.43579)
     | > current_lr: 0.00009 
     | > step_time: 3.72480  (4.03284)
     | > loader_time: 0.02310  (0.03625)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 275400[0m
     | > decoder_loss: 1.67346  (1.84741)
     | > postnet_loss: 1.39447  (1.54670)
     | > stopnet_loss: 1.43125  (1.57743)
     | > decoder_coarse_loss: 1.61451  (1.78799)
     | > decoder_ddc_loss: 0.00145  (0.00123)
     | > ga_loss: 0.00265  (0.00226)
     | > decoder_diff_spec_loss: 0.47324  (0.49038)
     | > postnet_diff_spec_loss: 0.78692  (0.81002)
     | > decoder_ssim_loss: 0.33200  (0.32098)
     | > postnet_ssim_loss: 0.34729  (0.33793)
     | > loss: 3.10035  (3.37439)
     | > align_error: 0.98723  (0.98881)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.03361  (4.65546)
     | > current_lr: 0.00009 
     | > step_time: 3.04740  (3.78589)
     | > loader_time: 0.01890  (0.03316)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 275425[0m
     | > decoder_loss: 1.77923  (1.83195)
     | > postnet_loss: 1.49065  (1.53462)
     | > stopnet_loss: 1.75992  (1.56910)
     | > decoder_coarse_loss: 1.71539  (1.77256)
     | > decoder_ddc_loss: 0.00096  (0.00121)
     | > ga_loss: 0.00221  (0.00226)
     | > decoder_diff_spec_loss: 0.45987  (0.48704)
     | > postnet_diff_spec_loss: 0.79359  (0.80656)
     | > decoder_ssim_loss: 0.27307  (0.31972)
     | > postnet_ssim_loss: 0.29245  (0.33721)
     | > loss: 3.47226  (3.35314)
     | > align_error: 0.99079  (0.98890)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.83288  (4.36565)
     | > current_lr: 0.00009 
     | > step_time: 4.30170  (3.66760)
     | > loader_time: 0.02390  (0.03481)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 275450[0m
     | > decoder_loss: 1.91630  (1.83210)
     | > postnet_loss: 1.59936  (1.53569)
     | > stopnet_loss: 2.04440  (1.56806)
     | > decoder_coarse_loss: 1.82805  (1.77143)
     | > decoder_ddc_loss: 0.00099  (0.00123)
     | > ga_loss: 0.00252  (0.00229)
     | > decoder_diff_spec_loss: 0.51410  (0.48642)
     | > postnet_diff_spec_loss: 0.81596  (0.80580)
     | > decoder_ssim_loss: 0.24210  (0.32114)
     | > postnet_ssim_loss: 0.24926  (0.33832)
     | > loss: 3.84854  (3.35257)
     | > align_error: 0.98899  (0.98875)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.37415  (4.41183)
     | > current_lr: 0.00009 
     | > step_time: 3.07190  (3.58301)
     | > loader_time: 0.01700  (0.03525)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.98536 [0m(-0.20732)
     | > avg_decoder_loss:[91m 2.50170 [0m(+0.00445)
     | > avg_postnet_loss:[91m 2.34372 [0m(+0.16477)
     | > avg_stopnet_loss:[92m 1.31853 [0m(-0.00104)
     | > avg_decoder_coarse_loss:[92m 2.26763 [0m(-0.00428)
     | > avg_decoder_ddc_loss:[92m 0.00097 [0m(-0.00003)
     | > avg_ga_loss:[92m 0.00208 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47456 [0m(-0.00172)
     | > avg_postnet_diff_spec_loss:[91m 0.81773 [0m(+0.00044)
     | > avg_decoder_ssim_loss:[92m 0.33566 [0m(-0.00028)
     | > avg_postnet_ssim_loss:[91m 0.35229 [0m(+0.00164)
     | > avg_loss:[91m 3.60249 [0m(+0.04020)
     | > avg_align_error:[91m 0.99055 [0m(+0.00010)


[4m[1m > EPOCH: 62/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:25:19) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 275475[0m
     | > decoder_loss: 1.67570  (1.85897)
     | > postnet_loss: 1.41512  (1.56099)
     | > stopnet_loss: 1.56254  (1.60255)
     | > decoder_coarse_loss: 1.65008  (1.80099)
     | > decoder_ddc_loss: 0.00090  (0.00112)
     | > ga_loss: 0.00186  (0.00219)
     | > decoder_diff_spec_loss: 0.45233  (0.49343)
     | > postnet_diff_spec_loss: 0.77536  (0.81199)
     | > decoder_ssim_loss: 0.30670  (0.31334)
     | > postnet_ssim_loss: 0.32348  (0.33034)
     | > loss: 3.22174  (3.40631)
     | > align_error: 0.99175  (0.98934)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.18061  (4.84632)
     | > current_lr: 0.00009 
     | > step_time: 3.60580  (3.96253)
     | > loader_time: 0.02420  (0.04734)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 275500[0m
     | > decoder_loss: 1.69165  (1.83502)
     | > postnet_loss: 1.41874  (1.52847)
     | > stopnet_loss: 1.44034  (1.57016)
     | > decoder_coarse_loss: 1.62184  (1.76958)
     | > decoder_ddc_loss: 0.00123  (0.00121)
     | > ga_loss: 0.00240  (0.00225)
     | > decoder_diff_spec_loss: 0.47078  (0.48968)
     | > postnet_diff_spec_loss: 0.78867  (0.80652)
     | > decoder_ssim_loss: 0.34481  (0.31997)
     | > postnet_ssim_loss: 0.36472  (0.33770)
     | > loss: 3.12796  (3.35347)
     | > align_error: 0.98800  (0.98878)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.74498  (4.47820)
     | > current_lr: 0.00009 
     | > step_time: 3.13390  (3.67195)
     | > loader_time: 0.06460  (0.03884)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 275525[0m
     | > decoder_loss: 1.66432  (1.83473)
     | > postnet_loss: 1.40974  (1.53419)
     | > stopnet_loss: 2.11214  (1.56164)
     | > decoder_coarse_loss: 1.61330  (1.77098)
     | > decoder_ddc_loss: 0.00086  (0.00122)
     | > ga_loss: 0.00189  (0.00227)
     | > decoder_diff_spec_loss: 0.43768  (0.48848)
     | > postnet_diff_spec_loss: 0.76663  (0.80616)
     | > decoder_ssim_loss: 0.23210  (0.32120)
     | > postnet_ssim_loss: 0.24354  (0.33888)
     | > loss: 3.71365  (3.34693)
     | > align_error: 0.99027  (0.98876)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.30688  (4.35797)
     | > current_lr: 0.00009 
     | > step_time: 4.63240  (3.61004)
     | > loader_time: 0.02290  (0.03671)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.37748 [0m(+0.39212)
     | > avg_decoder_loss:[91m 2.54747 [0m(+0.04577)
     | > avg_postnet_loss:[91m 2.35326 [0m(+0.00955)
     | > avg_stopnet_loss:[92m 1.31818 [0m(-0.00035)
     | > avg_decoder_coarse_loss:[91m 2.26975 [0m(+0.00212)
     | > avg_decoder_ddc_loss:[91m 0.00101 [0m(+0.00005)
     | > avg_ga_loss:[91m 0.00208 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47326 [0m(-0.00130)
     | > avg_postnet_diff_spec_loss:[92m 0.81674 [0m(-0.00099)
     | > avg_decoder_ssim_loss:[92m 0.33557 [0m(-0.00009)
     | > avg_postnet_ssim_loss:[91m 0.35266 [0m(+0.00037)
     | > avg_loss:[91m 3.61602 [0m(+0.01353)
     | > avg_align_error:[92m 0.99049 [0m(-0.00006)


[4m[1m > EPOCH: 63/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:32:25) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 275550[0m
     | > decoder_loss: 1.77602  (1.84688)
     | > postnet_loss: 1.36238  (1.51665)
     | > stopnet_loss: 1.22355  (1.40796)
     | > decoder_coarse_loss: 1.73721  (1.76547)
     | > decoder_ddc_loss: 0.00122  (0.00137)
     | > ga_loss: 0.00214  (0.00243)
     | > decoder_diff_spec_loss: 0.47982  (0.47859)
     | > postnet_diff_spec_loss: 0.76288  (0.79524)
     | > decoder_ssim_loss: 0.36823  (0.33735)
     | > postnet_ssim_loss: 0.40228  (0.35851)
     | > loss: 2.95674  (3.19514)
     | > align_error: 0.98957  (0.98759)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.02233  (7.88702)
     | > current_lr: 0.00008 
     | > step_time: 2.71260  (4.00822)
     | > loader_time: 0.05950  (0.04260)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 275575[0m
     | > decoder_loss: 1.77333  (1.84794)
     | > postnet_loss: 1.45975  (1.54698)
     | > stopnet_loss: 1.55693  (1.56170)
     | > decoder_coarse_loss: 1.71096  (1.78895)
     | > decoder_ddc_loss: 0.00119  (0.00121)
     | > ga_loss: 0.00239  (0.00223)
     | > decoder_diff_spec_loss: 0.46237  (0.49006)
     | > postnet_diff_spec_loss: 0.79301  (0.81009)
     | > decoder_ssim_loss: 0.30538  (0.31975)
     | > postnet_ssim_loss: 0.32159  (0.33732)
     | > loss: 3.27579  (3.35844)
     | > align_error: 0.98923  (0.98879)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.90718  (4.80270)
     | > current_lr: 0.00008 
     | > step_time: 3.69040  (3.70641)
     | > loader_time: 0.06160  (0.04201)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 275600[0m
     | > decoder_loss: 1.94149  (1.82983)
     | > postnet_loss: 1.56927  (1.53209)
     | > stopnet_loss: 1.35768  (1.55614)
     | > decoder_coarse_loss: 1.86197  (1.76901)
     | > decoder_ddc_loss: 0.00168  (0.00122)
     | > ga_loss: 0.00277  (0.00225)
     | > decoder_diff_spec_loss: 0.50787  (0.48718)
     | > postnet_diff_spec_loss: 0.82537  (0.80638)
     | > decoder_ssim_loss: 0.34984  (0.31966)
     | > postnet_ssim_loss: 0.36314  (0.33762)
     | > loss: 3.22671  (3.33815)
     | > align_error: 0.98522  (0.98878)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.41614  (4.43463)
     | > current_lr: 0.00008 
     | > step_time: 2.72040  (3.59736)
     | > loader_time: 0.05150  (0.03598)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 275625[0m
     | > decoder_loss: 1.64677  (1.82594)
     | > postnet_loss: 1.37291  (1.52843)
     | > stopnet_loss: 2.13182  (1.55385)
     | > decoder_coarse_loss: 1.57469  (1.76814)
     | > decoder_ddc_loss: 0.00113  (0.00124)
     | > ga_loss: 0.00235  (0.00228)
     | > decoder_diff_spec_loss: 0.44924  (0.48599)
     | > postnet_diff_spec_loss: 0.78253  (0.80519)
     | > decoder_ssim_loss: 0.24621  (0.32129)
     | > postnet_ssim_loss: 0.25915  (0.33900)
     | > loss: 3.72672  (3.33404)
     | > align_error: 0.98792  (0.98866)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.44648  (4.37657)
     | > current_lr: 0.00008 
     | > step_time: 3.28290  (3.52394)
     | > loader_time: 0.02250  (0.03585)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.10046 [0m(-0.27702)
     | > avg_decoder_loss:[92m 2.46001 [0m(-0.08745)
     | > avg_postnet_loss:[92m 2.31960 [0m(-0.03367)
     | > avg_stopnet_loss:[92m 1.31701 [0m(-0.00117)
     | > avg_decoder_coarse_loss:[92m 2.22774 [0m(-0.04201)
     | > avg_decoder_ddc_loss:[92m 0.00100 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00207 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47518 [0m(+0.00192)
     | > avg_postnet_diff_spec_loss:[92m 0.81669 [0m(-0.00004)
     | > avg_decoder_ssim_loss:[92m 0.33471 [0m(-0.00086)
     | > avg_postnet_ssim_loss:[92m 0.35214 [0m(-0.00053)
     | > avg_loss:[92m 3.57412 [0m(-0.04190)
     | > avg_align_error:[92m 0.99036 [0m(-0.00013)


[4m[1m > EPOCH: 64/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:39:37) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 275650[0m
     | > decoder_loss: 1.74443  (1.86262)
     | > postnet_loss: 1.63638  (1.56594)
     | > stopnet_loss: 1.65398  (1.58725)
     | > decoder_coarse_loss: 1.74224  (1.80213)
     | > decoder_ddc_loss: 0.00093  (0.00117)
     | > ga_loss: 0.00178  (0.00219)
     | > decoder_diff_spec_loss: 0.46507  (0.49371)
     | > postnet_diff_spec_loss: 0.81248  (0.81343)
     | > decoder_ssim_loss: 0.28544  (0.31302)
     | > postnet_ssim_loss: 0.30307  (0.33030)
     | > loss: 3.41037  (3.39379)
     | > align_error: 0.99086  (0.98903)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.46260  (5.37645)
     | > current_lr: 0.00008 
     | > step_time: 4.43140  (3.97330)
     | > loader_time: 0.03600  (0.03473)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 275675[0m
     | > decoder_loss: 1.95198  (1.82896)
     | > postnet_loss: 1.58285  (1.52443)
     | > stopnet_loss: 1.58618  (1.56314)
     | > decoder_coarse_loss: 1.85608  (1.76612)
     | > decoder_ddc_loss: 0.00113  (0.00123)
     | > ga_loss: 0.00197  (0.00223)
     | > decoder_diff_spec_loss: 0.50730  (0.48925)
     | > postnet_diff_spec_loss: 0.79669  (0.80629)
     | > decoder_ssim_loss: 0.29777  (0.31864)
     | > postnet_ssim_loss: 0.32135  (0.33662)
     | > loss: 3.42483  (3.34216)
     | > align_error: 0.98947  (0.98864)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.76519  (4.69101)
     | > current_lr: 0.00008 
     | > step_time: 4.23960  (3.68281)
     | > loader_time: 0.04720  (0.03841)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 275700[0m
     | > decoder_loss: 1.64624  (1.83059)
     | > postnet_loss: 1.32968  (1.52753)
     | > stopnet_loss: 1.14166  (1.54345)
     | > decoder_coarse_loss: 1.55477  (1.76615)
     | > decoder_ddc_loss: 0.00218  (0.00126)
     | > ga_loss: 0.00268  (0.00225)
     | > decoder_diff_spec_loss: 0.47324  (0.48839)
     | > postnet_diff_spec_loss: 0.78146  (0.80627)
     | > decoder_ssim_loss: 0.42930  (0.32181)
     | > postnet_ssim_loss: 0.45564  (0.33985)
     | > loss: 2.82320  (3.32514)
     | > align_error: 0.98342  (0.98858)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.92554  (4.37193)
     | > current_lr: 0.00008 
     | > step_time: 2.10970  (3.58852)
     | > loader_time: 0.03980  (0.03636)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.87832 [0m(-0.22214)
     | > avg_decoder_loss:[91m 2.49250 [0m(+0.03249)
     | > avg_postnet_loss:[91m 2.35274 [0m(+0.03315)
     | > avg_stopnet_loss:[92m 1.31590 [0m(-0.00111)
     | > avg_decoder_coarse_loss:[92m 2.20408 [0m(-0.02366)
     | > avg_decoder_ddc_loss:[91m 0.00105 [0m(+0.00005)
     | > avg_ga_loss:[92m 0.00206 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47410 [0m(-0.00108)
     | > avg_postnet_diff_spec_loss:[92m 0.81584 [0m(-0.00086)
     | > avg_decoder_ssim_loss:[92m 0.33445 [0m(-0.00027)
     | > avg_postnet_ssim_loss:[91m 0.35240 [0m(+0.00027)
     | > avg_loss:[91m 3.58301 [0m(+0.00888)
     | > avg_align_error:[91m 0.99037 [0m(+0.00001)


[4m[1m > EPOCH: 65/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:46:41) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 275725[0m
     | > decoder_loss: 1.78967  (1.83330)
     | > postnet_loss: 1.46113  (1.53278)
     | > stopnet_loss: 1.50090  (1.44972)
     | > decoder_coarse_loss: 1.69852  (1.74487)
     | > decoder_ddc_loss: 0.00142  (0.00144)
     | > ga_loss: 0.00248  (0.00247)
     | > decoder_diff_spec_loss: 0.44821  (0.47730)
     | > postnet_diff_spec_loss: 0.78792  (0.80105)
     | > decoder_ssim_loss: 0.31297  (0.32912)
     | > postnet_ssim_loss: 0.33165  (0.34861)
     | > loss: 3.22119  (3.22918)
     | > align_error: 0.98708  (0.98705)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.34787  (7.97600)
     | > current_lr: 0.00008 
     | > step_time: 3.85140  (3.98685)
     | > loader_time: 0.01370  (0.06979)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 275750[0m
     | > decoder_loss: 1.72231  (1.83548)
     | > postnet_loss: 1.47757  (1.53023)
     | > stopnet_loss: 1.58885  (1.55842)
     | > decoder_coarse_loss: 1.66513  (1.77594)
     | > decoder_ddc_loss: 0.00126  (0.00123)
     | > ga_loss: 0.00199  (0.00221)
     | > decoder_diff_spec_loss: 0.47205  (0.49032)
     | > postnet_diff_spec_loss: 0.79230  (0.81012)
     | > decoder_ssim_loss: 0.29714  (0.31945)
     | > postnet_ssim_loss: 0.30995  (0.33748)
     | > loss: 3.28321  (3.34454)
     | > align_error: 0.98811  (0.98873)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.83160  (4.90383)
     | > current_lr: 0.00008 
     | > step_time: 4.80840  (3.76307)
     | > loader_time: 0.02160  (0.03825)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 275775[0m
     | > decoder_loss: 1.64403  (1.81172)
     | > postnet_loss: 1.40003  (1.51375)
     | > stopnet_loss: 1.49424  (1.56056)
     | > decoder_coarse_loss: 1.59114  (1.75425)
     | > decoder_ddc_loss: 0.00098  (0.00122)
     | > ga_loss: 0.00203  (0.00222)
     | > decoder_diff_spec_loss: 0.45404  (0.48605)
     | > postnet_diff_spec_loss: 0.79229  (0.80545)
     | > decoder_ssim_loss: 0.29856  (0.31837)
     | > postnet_ssim_loss: 0.32014  (0.33666)
     | > loss: 3.12967  (3.32852)
     | > align_error: 0.99052  (0.98883)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.11337  (4.45975)
     | > current_lr: 0.00008 
     | > step_time: 3.76910  (3.67396)
     | > loader_time: 0.02270  (0.03897)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 275800[0m
     | > decoder_loss: 1.74821  (1.81512)
     | > postnet_loss: 1.43252  (1.51432)
     | > stopnet_loss: 1.46843  (1.54353)
     | > decoder_coarse_loss: 1.66935  (1.75591)
     | > decoder_ddc_loss: 0.00178  (0.00125)
     | > ga_loss: 0.00300  (0.00225)
     | > decoder_diff_spec_loss: 0.49131  (0.48594)
     | > postnet_diff_spec_loss: 0.80784  (0.80500)
     | > decoder_ssim_loss: 0.34173  (0.32160)
     | > postnet_ssim_loss: 0.35997  (0.33955)
     | > loss: 3.19661  (3.31445)
     | > align_error: 0.98548  (0.98865)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.22043  (4.47924)
     | > current_lr: 0.00008 
     | > step_time: 1.68140  (3.57361)
     | > loader_time: 0.01350  (0.03878)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.75054 [0m(-0.12778)
     | > avg_decoder_loss:[92m 2.42348 [0m(-0.06903)
     | > avg_postnet_loss:[92m 2.26839 [0m(-0.08435)
     | > avg_stopnet_loss:[91m 1.31773 [0m(+0.00184)
     | > avg_decoder_coarse_loss:[91m 2.20934 [0m(+0.00526)
     | > avg_decoder_ddc_loss:[92m 0.00101 [0m(-0.00004)
     | > avg_ga_loss:[92m 0.00205 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47475 [0m(+0.00065)
     | > avg_postnet_diff_spec_loss:[91m 0.81679 [0m(+0.00095)
     | > avg_decoder_ssim_loss:[92m 0.33388 [0m(-0.00057)
     | > avg_postnet_ssim_loss:[92m 0.35084 [0m(-0.00157)
     | > avg_loss:[92m 3.54760 [0m(-0.03540)
     | > avg_align_error:[92m 0.99034 [0m(-0.00003)


[4m[1m > EPOCH: 66/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 17:53:55) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 275825[0m
     | > decoder_loss: 1.75116  (1.85951)
     | > postnet_loss: 1.44753  (1.53746)
     | > stopnet_loss: 0.87087  (1.56832)
     | > decoder_coarse_loss: 1.70700  (1.78226)
     | > decoder_ddc_loss: 0.00137  (0.00122)
     | > ga_loss: 0.00164  (0.00221)
     | > decoder_diff_spec_loss: 0.46799  (0.49606)
     | > postnet_diff_spec_loss: 0.79304  (0.81282)
     | > decoder_ssim_loss: 0.43779  (0.31387)
     | > postnet_ssim_loss: 0.46610  (0.33120)
     | > loss: 2.64709  (3.36296)
     | > align_error: 0.98942  (0.98880)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.31559  (5.73843)
     | > current_lr: 0.00008 
     | > step_time: 4.84970  (3.93615)
     | > loader_time: 0.04210  (0.03811)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 275850[0m
     | > decoder_loss: 1.94214  (1.81350)
     | > postnet_loss: 1.51240  (1.50066)
     | > stopnet_loss: 1.94932  (1.55856)
     | > decoder_coarse_loss: 1.86718  (1.74672)
     | > decoder_ddc_loss: 0.00103  (0.00126)
     | > ga_loss: 0.00228  (0.00221)
     | > decoder_diff_spec_loss: 0.53695  (0.48786)
     | > postnet_diff_spec_loss: 0.81332  (0.80576)
     | > decoder_ssim_loss: 0.24463  (0.31837)
     | > postnet_ssim_loss: 0.25575  (0.33625)
     | > loss: 3.75408  (3.32220)
     | > align_error: 0.98869  (0.98855)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.89065  (4.72153)
     | > current_lr: 0.00008 
     | > step_time: 4.02350  (3.66278)
     | > loader_time: 0.02260  (0.03600)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 275875[0m
     | > decoder_loss: 1.73034  (1.82114)
     | > postnet_loss: 1.55793  (1.51083)
     | > stopnet_loss: 1.58128  (1.54305)
     | > decoder_coarse_loss: 1.66890  (1.75511)
     | > decoder_ddc_loss: 0.00109  (0.00125)
     | > ga_loss: 0.00214  (0.00223)
     | > decoder_diff_spec_loss: 0.47731  (0.48780)
     | > postnet_diff_spec_loss: 0.81810  (0.80585)
     | > decoder_ssim_loss: 0.29904  (0.31935)
     | > postnet_ssim_loss: 0.32063  (0.33737)
     | > loss: 3.31034  (3.31387)
     | > align_error: 0.98999  (0.98865)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.04669  (4.53516)
     | > current_lr: 0.00008 
     | > step_time: 3.63440  (3.58558)
     | > loader_time: 0.01940  (0.03605)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.84259 [0m(+0.09205)
     | > avg_decoder_loss:[91m 2.47192 [0m(+0.04844)
     | > avg_postnet_loss:[91m 2.36987 [0m(+0.10148)
     | > avg_stopnet_loss:[92m 1.31757 [0m(-0.00017)
     | > avg_decoder_coarse_loss:[91m 2.24486 [0m(+0.03551)
     | > avg_decoder_ddc_loss:[92m 0.00100 [0m(-0.00001)
     | > avg_ga_loss:[91m 0.00205 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47358 [0m(-0.00116)
     | > avg_postnet_diff_spec_loss:[92m 0.81578 [0m(-0.00101)
     | > avg_decoder_ssim_loss:[92m 0.33350 [0m(-0.00038)
     | > avg_postnet_ssim_loss:[91m 0.35168 [0m(+0.00085)
     | > avg_loss:[91m 3.59337 [0m(+0.04576)
     | > avg_align_error:[91m 0.99038 [0m(+0.00003)


[4m[1m > EPOCH: 67/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:01:03) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 275900[0m
     | > decoder_loss: 1.76219  (1.81675)
     | > postnet_loss: 1.43335  (1.54048)
     | > stopnet_loss: 1.40906  (1.45421)
     | > decoder_coarse_loss: 1.70625  (1.75328)
     | > decoder_ddc_loss: 0.00102  (0.00141)
     | > ga_loss: 0.00214  (0.00249)
     | > decoder_diff_spec_loss: 0.47114  (0.48637)
     | > postnet_diff_spec_loss: 0.77157  (0.80339)
     | > decoder_ssim_loss: 0.32805  (0.33310)
     | > postnet_ssim_loss: 0.35246  (0.35169)
     | > loss: 3.12625  (3.23828)
     | > align_error: 0.99091  (0.98698)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.67411  (7.25608)
     | > current_lr: 0.00008 
     | > step_time: 2.68900  (4.19680)
     | > loader_time: 0.17210  (0.07245)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 275925[0m
     | > decoder_loss: 1.83195  (1.82812)
     | > postnet_loss: 1.52457  (1.52458)
     | > stopnet_loss: 1.30761  (1.56066)
     | > decoder_coarse_loss: 1.78185  (1.77726)
     | > decoder_ddc_loss: 0.00132  (0.00123)
     | > ga_loss: 0.00237  (0.00220)
     | > decoder_diff_spec_loss: 0.48738  (0.49174)
     | > postnet_diff_spec_loss: 0.81887  (0.81031)
     | > decoder_ssim_loss: 0.34693  (0.31972)
     | > postnet_ssim_loss: 0.37526  (0.33774)
     | > loss: 3.11149  (3.34433)
     | > align_error: 0.98725  (0.98864)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.71339  (4.47989)
     | > current_lr: 0.00008 
     | > step_time: 3.10090  (3.74997)
     | > loader_time: 0.02360  (0.04058)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 275950[0m
     | > decoder_loss: 1.85006  (1.80639)
     | > postnet_loss: 1.48521  (1.50209)
     | > stopnet_loss: 1.88505  (1.55410)
     | > decoder_coarse_loss: 1.76919  (1.75082)
     | > decoder_ddc_loss: 0.00078  (0.00123)
     | > ga_loss: 0.00183  (0.00221)
     | > decoder_diff_spec_loss: 0.48788  (0.48633)
     | > postnet_diff_spec_loss: 0.79391  (0.80541)
     | > decoder_ssim_loss: 0.25360  (0.31810)
     | > postnet_ssim_loss: 0.27754  (0.33645)
     | > loss: 3.62372  (3.31684)
     | > align_error: 0.99146  (0.98868)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.66528  (4.10551)
     | > current_lr: 0.00008 
     | > step_time: 4.43610  (3.64711)
     | > loader_time: 0.02260  (0.03792)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 275975[0m
     | > decoder_loss: 1.77844  (1.80779)
     | > postnet_loss: 1.40188  (1.50003)
     | > stopnet_loss: 1.28438  (1.53457)
     | > decoder_coarse_loss: 1.71818  (1.75161)
     | > decoder_ddc_loss: 0.00109  (0.00125)
     | > ga_loss: 0.00205  (0.00223)
     | > decoder_diff_spec_loss: 0.46855  (0.48526)
     | > postnet_diff_spec_loss: 0.78079  (0.80436)
     | > decoder_ssim_loss: 0.34095  (0.32062)
     | > postnet_ssim_loss: 0.36100  (0.33867)
     | > loss: 3.00737  (3.29812)
     | > align_error: 0.99000  (0.98859)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.66084  (4.03397)
     | > current_lr: 0.00008 
     | > step_time: 3.54160  (3.56844)
     | > loader_time: 0.01730  (0.03733)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.90262 [0m(+0.06003)
     | > avg_decoder_loss:[92m 2.43798 [0m(-0.03394)
     | > avg_postnet_loss:[92m 2.18161 [0m(-0.18826)
     | > avg_stopnet_loss:[92m 1.31466 [0m(-0.00291)
     | > avg_decoder_coarse_loss:[92m 2.17043 [0m(-0.07443)
     | > avg_decoder_ddc_loss:[92m 0.00099 [0m(-0.00001)
     | > avg_ga_loss:[91m 0.00205 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47162 [0m(-0.00196)
     | > avg_postnet_diff_spec_loss:[92m 0.81526 [0m(-0.00051)
     | > avg_decoder_ssim_loss:[92m 0.33338 [0m(-0.00012)
     | > avg_postnet_ssim_loss:[92m 0.35022 [0m(-0.00146)
     | > avg_loss:[92m 3.51529 [0m(-0.07807)
     | > avg_align_error:[91m 0.99044 [0m(+0.00006)


[4m[1m > EPOCH: 68/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:08:07) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 276000[0m
     | > decoder_loss: 1.74518  (1.85366)
     | > postnet_loss: 1.48939  (1.52363)
     | > stopnet_loss: 1.78963  (1.60614)
     | > decoder_coarse_loss: 1.68112  (1.78622)
     | > decoder_ddc_loss: 0.00080  (0.00121)
     | > ga_loss: 0.00150  (0.00222)
     | > decoder_diff_spec_loss: 0.48296  (0.49683)
     | > postnet_diff_spec_loss: 0.81241  (0.81342)
     | > decoder_ssim_loss: 0.26921  (0.30552)
     | > postnet_ssim_loss: 0.29033  (0.32219)
     | > loss: 3.48998  (3.39292)
     | > align_error: 0.99089  (0.98868)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.28320  (4.86348)
     | > current_lr: 0.00008 
     | > step_time: 5.33590  (3.99813)
     | > loader_time: 0.06310  (0.04945)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 276025[0m
     | > decoder_loss: 1.63220  (1.80209)
     | > postnet_loss: 1.42341  (1.48648)
     | > stopnet_loss: 1.74235  (1.54891)
     | > decoder_coarse_loss: 1.59416  (1.73681)
     | > decoder_ddc_loss: 0.00156  (0.00126)
     | > ga_loss: 0.00278  (0.00221)
     | > decoder_diff_spec_loss: 0.44020  (0.48666)
     | > postnet_diff_spec_loss: 0.78935  (0.80512)
     | > decoder_ssim_loss: 0.28806  (0.31968)
     | > postnet_ssim_loss: 0.31695  (0.33791)
     | > loss: 3.37773  (3.30394)
     | > align_error: 0.98510  (0.98847)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.12035  (4.28813)
     | > current_lr: 0.00008 
     | > step_time: 2.57670  (3.72281)
     | > loader_time: 0.05100  (0.04556)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 276050[0m
     | > decoder_loss: 2.10830  (1.81226)
     | > postnet_loss: 1.68396  (1.49573)
     | > stopnet_loss: 1.42354  (1.53807)
     | > decoder_coarse_loss: 2.01042  (1.74919)
     | > decoder_ddc_loss: 0.00087  (0.00124)
     | > ga_loss: 0.00171  (0.00222)
     | > decoder_diff_spec_loss: 0.51512  (0.48780)
     | > postnet_diff_spec_loss: 0.81114  (0.80524)
     | > decoder_ssim_loss: 0.31137  (0.31907)
     | > postnet_ssim_loss: 0.32878  (0.33731)
     | > loss: 3.37457  (3.30115)
     | > align_error: 0.99143  (0.98855)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.39697  (4.17932)
     | > current_lr: 0.00008 
     | > step_time: 4.13180  (3.63450)
     | > loader_time: 0.02660  (0.04009)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.99436 [0m(+0.09174)
     | > avg_decoder_loss:[91m 2.49561 [0m(+0.05764)
     | > avg_postnet_loss:[91m 2.46669 [0m(+0.28508)
     | > avg_stopnet_loss:[91m 1.31796 [0m(+0.00330)
     | > avg_decoder_coarse_loss:[91m 2.22549 [0m(+0.05506)
     | > avg_decoder_ddc_loss:[91m 0.00099 [0m(+0.00000)
     | > avg_ga_loss:[92m 0.00204 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47271 [0m(+0.00109)
     | > avg_postnet_diff_spec_loss:[91m 0.81663 [0m(+0.00137)
     | > avg_decoder_ssim_loss:[91m 0.33347 [0m(+0.00010)
     | > avg_postnet_ssim_loss:[91m 0.35181 [0m(+0.00159)
     | > avg_loss:[91m 3.61902 [0m(+0.10373)
     | > avg_align_error:[91m 0.99054 [0m(+0.00010)


[4m[1m > EPOCH: 69/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:15:17) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 276075[0m
     | > decoder_loss: 1.82194  (1.84558)
     | > postnet_loss: 1.50415  (1.55551)
     | > stopnet_loss: 1.58298  (1.44973)
     | > decoder_coarse_loss: 1.76751  (1.78767)
     | > decoder_ddc_loss: 0.00140  (0.00155)
     | > ga_loss: 0.00250  (0.00259)
     | > decoder_diff_spec_loss: 0.48311  (0.49147)
     | > postnet_diff_spec_loss: 0.79430  (0.81380)
     | > decoder_ssim_loss: 0.30425  (0.33465)
     | > postnet_ssim_loss: 0.32250  (0.35092)
     | > loss: 3.34527  (3.25796)
     | > align_error: 0.98651  (0.98572)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 11.41379  (9.21134)
     | > current_lr: 0.00008 
     | > step_time: 4.80730  (4.77404)
     | > loader_time: 0.07300  (0.07680)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 276100[0m
     | > decoder_loss: 1.77563  (1.82765)
     | > postnet_loss: 1.45786  (1.50325)
     | > stopnet_loss: 0.87815  (1.55689)
     | > decoder_coarse_loss: 1.71139  (1.76673)
     | > decoder_ddc_loss: 0.00210  (0.00125)
     | > ga_loss: 0.00242  (0.00218)
     | > decoder_diff_spec_loss: 0.48848  (0.49098)
     | > postnet_diff_spec_loss: 0.79558  (0.80908)
     | > decoder_ssim_loss: 0.49077  (0.31823)
     | > postnet_ssim_loss: 0.52385  (0.33580)
     | > loss: 2.70167  (3.33103)
     | > align_error: 0.98541  (0.98859)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.41793  (5.30623)
     | > current_lr: 0.00008 
     | > step_time: 2.05300  (3.83765)
     | > loader_time: 0.01900  (0.04332)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 276125[0m
     | > decoder_loss: 1.87198  (1.80239)
     | > postnet_loss: 1.57125  (1.48582)
     | > stopnet_loss: 1.60147  (1.54012)
     | > decoder_coarse_loss: 1.84357  (1.73976)
     | > decoder_ddc_loss: 0.00117  (0.00125)
     | > ga_loss: 0.00202  (0.00220)
     | > decoder_diff_spec_loss: 0.48804  (0.48627)
     | > postnet_diff_spec_loss: 0.80377  (0.80473)
     | > decoder_ssim_loss: 0.30088  (0.31886)
     | > postnet_ssim_loss: 0.31323  (0.33693)
     | > loss: 3.41004  (3.29511)
     | > align_error: 0.98939  (0.98851)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.08823  (4.69184)
     | > current_lr: 0.00008 
     | > step_time: 4.81940  (3.68195)
     | > loader_time: 0.02700  (0.03689)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 276150[0m
     | > decoder_loss: 1.84501  (1.80454)
     | > postnet_loss: 1.55030  (1.48802)
     | > stopnet_loss: 1.28052  (1.53455)
     | > decoder_coarse_loss: 1.75911  (1.74183)
     | > decoder_ddc_loss: 0.00162  (0.00125)
     | > ga_loss: 0.00252  (0.00222)
     | > decoder_diff_spec_loss: 0.48472  (0.48497)
     | > postnet_diff_spec_loss: 0.80775  (0.80386)
     | > decoder_ssim_loss: 0.36942  (0.31977)
     | > postnet_ssim_loss: 0.38693  (0.33778)
     | > loss: 3.09431  (3.29117)
     | > align_error: 0.98554  (0.98850)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.03436  (4.63616)
     | > current_lr: 0.00008 
     | > step_time: 2.50100  (3.60689)
     | > loader_time: 0.01570  (0.03482)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.00760 [0m(+0.01325)
     | > avg_decoder_loss:[92m 2.43133 [0m(-0.06429)
     | > avg_postnet_loss:[92m 2.28959 [0m(-0.17711)
     | > avg_stopnet_loss:[92m 1.31402 [0m(-0.00393)
     | > avg_decoder_coarse_loss:[92m 2.17470 [0m(-0.05079)
     | > avg_decoder_ddc_loss:[91m 0.00101 [0m(+0.00003)
     | > avg_ga_loss:[92m 0.00204 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47418 [0m(+0.00146)
     | > avg_postnet_diff_spec_loss:[91m 0.81692 [0m(+0.00028)
     | > avg_decoder_ssim_loss:[92m 0.33257 [0m(-0.00090)
     | > avg_postnet_ssim_loss:[92m 0.35048 [0m(-0.00133)
     | > avg_loss:[92m 3.54192 [0m(-0.07710)
     | > avg_align_error:[92m 0.99048 [0m(-0.00006)


[4m[1m > EPOCH: 70/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:22:21) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 276175[0m
     | > decoder_loss: 1.73187  (1.85116)
     | > postnet_loss: 1.44537  (1.51436)
     | > stopnet_loss: 2.05963  (1.59699)
     | > decoder_coarse_loss: 1.69256  (1.78675)
     | > decoder_ddc_loss: 0.00082  (0.00120)
     | > ga_loss: 0.00179  (0.00226)
     | > decoder_diff_spec_loss: 0.49601  (0.49760)
     | > postnet_diff_spec_loss: 0.82185  (0.81319)
     | > decoder_ssim_loss: 0.24092  (0.30730)
     | > postnet_ssim_loss: 0.24401  (0.32409)
     | > loss: 3.73694  (3.38223)
     | > align_error: 0.99122  (0.98858)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.29354  (4.87877)
     | > current_lr: 0.00008 
     | > step_time: 4.64370  (3.92536)
     | > loader_time: 0.02260  (0.03267)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 276200[0m
     | > decoder_loss: 1.71470  (1.79637)
     | > postnet_loss: 1.34378  (1.47299)
     | > stopnet_loss: 1.90635  (1.53342)
     | > decoder_coarse_loss: 1.64444  (1.73972)
     | > decoder_ddc_loss: 0.00072  (0.00124)
     | > ga_loss: 0.00189  (0.00218)
     | > decoder_diff_spec_loss: 0.48016  (0.48731)
     | > postnet_diff_spec_loss: 0.78653  (0.80482)
     | > decoder_ssim_loss: 0.25311  (0.31974)
     | > postnet_ssim_loss: 0.27158  (0.33767)
     | > loss: 3.53954  (3.28429)
     | > align_error: 0.99213  (0.98856)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.96529  (4.10996)
     | > current_lr: 0.00008 
     | > step_time: 4.97640  (3.71864)
     | > loader_time: 0.02850  (0.03552)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 276225[0m
     | > decoder_loss: 1.92579  (1.80142)
     | > postnet_loss: 1.49242  (1.47795)
     | > stopnet_loss: 1.48787  (1.53826)
     | > decoder_coarse_loss: 1.84436  (1.74115)
     | > decoder_ddc_loss: 0.00133  (0.00126)
     | > ga_loss: 0.00236  (0.00222)
     | > decoder_diff_spec_loss: 0.51418  (0.48647)
     | > postnet_diff_spec_loss: 0.80270  (0.80445)
     | > decoder_ssim_loss: 0.32666  (0.31855)
     | > postnet_ssim_loss: 0.34769  (0.33684)
     | > loss: 3.31346  (3.29137)
     | > align_error: 0.98783  (0.98847)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.03411  (4.03465)
     | > current_lr: 0.00008 
     | > step_time: 3.13040  (3.59982)
     | > loader_time: 0.02310  (0.03367)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.28974 [0m(+0.28214)
     | > avg_decoder_loss:[92m 2.42669 [0m(-0.00464)
     | > avg_postnet_loss:[91m 2.43529 [0m(+0.14570)
     | > avg_stopnet_loss:[91m 1.31474 [0m(+0.00072)
     | > avg_decoder_coarse_loss:[92m 2.15467 [0m(-0.02003)
     | > avg_decoder_ddc_loss:[92m 0.00099 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00204 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47407 [0m(-0.00011)
     | > avg_postnet_diff_spec_loss:[92m 0.81627 [0m(-0.00065)
     | > avg_decoder_ssim_loss:[92m 0.33227 [0m(-0.00030)
     | > avg_postnet_ssim_loss:[91m 0.35193 [0m(+0.00145)
     | > avg_loss:[91m 3.57297 [0m(+0.03106)
     | > avg_align_error:[92m 0.99037 [0m(-0.00011)


[4m[1m > EPOCH: 71/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:29:25) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 276250[0m
     | > decoder_loss: 1.94487  (1.84684)
     | > postnet_loss: 1.67369  (1.53838)
     | > stopnet_loss: 1.40530  (1.42557)
     | > decoder_coarse_loss: 1.87917  (1.76077)
     | > decoder_ddc_loss: 0.00152  (0.00160)
     | > ga_loss: 0.00261  (0.00263)
     | > decoder_diff_spec_loss: 0.51214  (0.49548)
     | > postnet_diff_spec_loss: 0.84243  (0.82047)
     | > decoder_ssim_loss: 0.35237  (0.34855)
     | > postnet_ssim_loss: 0.36794  (0.36378)
     | > loss: 3.31189  (3.23270)
     | > align_error: 0.98565  (0.98520)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.34092  (6.48656)
     | > current_lr: 0.00008 
     | > step_time: 5.38860  (4.57777)
     | > loader_time: 0.16970  (0.09544)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 276275[0m
     | > decoder_loss: 1.97463  (1.81924)
     | > postnet_loss: 1.68378  (1.49054)
     | > stopnet_loss: 1.53513  (1.58532)
     | > decoder_coarse_loss: 1.92731  (1.75380)
     | > decoder_ddc_loss: 0.00110  (0.00120)
     | > ga_loss: 0.00211  (0.00216)
     | > decoder_diff_spec_loss: 0.51830  (0.49220)
     | > postnet_diff_spec_loss: 0.84075  (0.80913)
     | > decoder_ssim_loss: 0.30097  (0.31140)
     | > postnet_ssim_loss: 0.31705  (0.32834)
     | > loss: 3.43666  (3.34759)
     | > align_error: 0.98906  (0.98867)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.78166  (4.43353)
     | > current_lr: 0.00008 
     | > step_time: 4.26680  (3.85902)
     | > loader_time: 0.02030  (0.03799)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 276300[0m
     | > decoder_loss: 1.79105  (1.78845)
     | > postnet_loss: 1.51589  (1.46841)
     | > stopnet_loss: 1.81470  (1.53551)
     | > decoder_coarse_loss: 1.74654  (1.73027)
     | > decoder_ddc_loss: 0.00083  (0.00124)
     | > ga_loss: 0.00196  (0.00220)
     | > decoder_diff_spec_loss: 0.46998  (0.48590)
     | > postnet_diff_spec_loss: 0.81623  (0.80445)
     | > decoder_ssim_loss: 0.25512  (0.31833)
     | > postnet_ssim_loss: 0.27516  (0.33690)
     | > loss: 3.54219  (3.27998)
     | > align_error: 0.99116  (0.98846)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.15018  (4.10497)
     | > current_lr: 0.00008 
     | > step_time: 4.87660  (3.67883)
     | > loader_time: 0.04590  (0.03650)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 276325[0m
     | > decoder_loss: 1.93160  (1.79294)
     | > postnet_loss: 1.51769  (1.47289)
     | > stopnet_loss: 1.49796  (1.53448)
     | > decoder_coarse_loss: 1.88017  (1.73353)
     | > decoder_ddc_loss: 0.00171  (0.00125)
     | > ga_loss: 0.00259  (0.00220)
     | > decoder_diff_spec_loss: 0.50313  (0.48519)
     | > postnet_diff_spec_loss: 0.80961  (0.80365)
     | > decoder_ssim_loss: 0.33308  (0.31830)
     | > postnet_ssim_loss: 0.34860  (0.33675)
     | > loss: 3.34231  (3.28163)
     | > align_error: 0.98524  (0.98846)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.43672  (4.17757)
     | > current_lr: 0.00008 
     | > step_time: 2.55630  (3.65399)
     | > loader_time: 0.01850  (0.03334)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.71407 [0m(-0.57567)
     | > avg_decoder_loss:[91m 2.46469 [0m(+0.03800)
     | > avg_postnet_loss:[91m 2.62266 [0m(+0.18737)
     | > avg_stopnet_loss:[92m 1.31338 [0m(-0.00136)
     | > avg_decoder_coarse_loss:[91m 2.17724 [0m(+0.02257)
     | > avg_decoder_ddc_loss:[91m 0.00101 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00203 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47445 [0m(+0.00038)
     | > avg_postnet_diff_spec_loss:[91m 0.81667 [0m(+0.00040)
     | > avg_decoder_ssim_loss:[91m 0.33241 [0m(+0.00014)
     | > avg_postnet_ssim_loss:[91m 0.35316 [0m(+0.00123)
     | > avg_loss:[91m 3.63409 [0m(+0.06112)
     | > avg_align_error:[92m 0.99036 [0m(-0.00001)


[4m[1m > EPOCH: 72/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:36:30) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 276350[0m
     | > decoder_loss: 1.83706  (1.86013)
     | > postnet_loss: 1.39935  (1.51385)
     | > stopnet_loss: 1.56057  (1.56109)
     | > decoder_coarse_loss: 1.80103  (1.78721)
     | > decoder_ddc_loss: 0.00087  (0.00126)
     | > ga_loss: 0.00153  (0.00229)
     | > decoder_diff_spec_loss: 0.52235  (0.49855)
     | > postnet_diff_spec_loss: 0.80406  (0.81187)
     | > decoder_ssim_loss: 0.29633  (0.31153)
     | > postnet_ssim_loss: 0.31222  (0.32897)
     | > loss: 3.31153  (3.35087)
     | > align_error: 0.99141  (0.98825)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.94990  (5.38996)
     | > current_lr: 0.00008 
     | > step_time: 4.91750  (3.85731)
     | > loader_time: 0.06020  (0.04715)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 276375[0m
     | > decoder_loss: 1.67916  (1.79507)
     | > postnet_loss: 1.49866  (1.47072)
     | > stopnet_loss: 1.59140  (1.52257)
     | > decoder_coarse_loss: 1.65025  (1.73845)
     | > decoder_ddc_loss: 0.00200  (0.00128)
     | > ga_loss: 0.00295  (0.00218)
     | > decoder_diff_spec_loss: 0.44342  (0.48711)
     | > postnet_diff_spec_loss: 0.79077  (0.80492)
     | > decoder_ssim_loss: 0.32582  (0.32068)
     | > postnet_ssim_loss: 0.34797  (0.33884)
     | > loss: 3.29067  (3.27271)
     | > align_error: 0.98291  (0.98833)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 13.07998  (4.38842)
     | > current_lr: 0.00008 
     | > step_time: 2.13790  (3.74457)
     | > loader_time: 0.02500  (0.04264)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 276400[0m
     | > decoder_loss: 1.70736  (1.79076)
     | > postnet_loss: 1.47508  (1.47050)
     | > stopnet_loss: 1.78737  (1.53722)
     | > decoder_coarse_loss: 1.67614  (1.73565)
     | > decoder_ddc_loss: 0.00141  (0.00126)
     | > ga_loss: 0.00274  (0.00220)
     | > decoder_diff_spec_loss: 0.46255  (0.48565)
     | > postnet_diff_spec_loss: 0.80780  (0.80402)
     | > decoder_ssim_loss: 0.27731  (0.31751)
     | > postnet_ssim_loss: 0.29613  (0.33620)
     | > loss: 3.47699  (3.28363)
     | > align_error: 0.98752  (0.98838)
     | > amp_scaler: 65536.00000  (33792.00000)
     | > grad_norm: 5.16410  (4.32495)
     | > current_lr: 0.00008 
     | > step_time: 2.70520  (3.67584)
     | > loader_time: 0.02370  (0.03806)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.78240 [0m(+0.06833)
     | > avg_decoder_loss:[92m 2.36904 [0m(-0.09565)
     | > avg_postnet_loss:[92m 2.18040 [0m(-0.44225)
     | > avg_stopnet_loss:[92m 1.31135 [0m(-0.00204)
     | > avg_decoder_coarse_loss:[91m 2.19154 [0m(+0.01430)
     | > avg_decoder_ddc_loss:[92m 0.00098 [0m(-0.00003)
     | > avg_ga_loss:[91m 0.00203 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47792 [0m(+0.00346)
     | > avg_postnet_diff_spec_loss:[92m 0.81393 [0m(-0.00274)
     | > avg_decoder_ssim_loss:[92m 0.33179 [0m(-0.00062)
     | > avg_postnet_ssim_loss:[92m 0.34906 [0m(-0.00410)
     | > avg_loss:[92m 3.50018 [0m(-0.13391)
     | > avg_align_error:[91m 0.99041 [0m(+0.00005)


[4m[1m > EPOCH: 73/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:43:43) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 276425[0m
     | > decoder_loss: 1.73693  (1.73693)
     | > postnet_loss: 1.41765  (1.41765)
     | > stopnet_loss: 1.35898  (1.35898)
     | > decoder_coarse_loss: 1.65424  (1.65424)
     | > decoder_ddc_loss: 0.00161  (0.00161)
     | > ga_loss: 0.00264  (0.00264)
     | > decoder_diff_spec_loss: 0.47269  (0.47269)
     | > postnet_diff_spec_loss: 0.80072  (0.80072)
     | > decoder_ssim_loss: 0.34258  (0.34258)
     | > postnet_ssim_loss: 0.36004  (0.36004)
     | > loss: 3.06880  (3.06880)
     | > align_error: 0.98467  (0.98467)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.56591  (2.56591)
     | > current_lr: 0.00008 
     | > step_time: 3.19790  (3.19788)
     | > loader_time: 0.02420  (0.02424)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 276450[0m
     | > decoder_loss: 1.85693  (1.81394)
     | > postnet_loss: 1.50878  (1.48920)
     | > stopnet_loss: 1.90542  (1.58286)
     | > decoder_coarse_loss: 1.80857  (1.75142)
     | > decoder_ddc_loss: 0.00116  (0.00116)
     | > ga_loss: 0.00237  (0.00215)
     | > decoder_diff_spec_loss: 0.51878  (0.49049)
     | > postnet_diff_spec_loss: 0.82198  (0.80786)
     | > decoder_ssim_loss: 0.26576  (0.31113)
     | > postnet_ssim_loss: 0.27675  (0.32851)
     | > loss: 3.68193  (3.34205)
     | > align_error: 0.98702  (0.98869)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.35520  (4.02735)
     | > current_lr: 0.00008 
     | > step_time: 3.56310  (3.84754)
     | > loader_time: 0.02090  (0.03913)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 276475[0m
     | > decoder_loss: 1.66617  (1.78634)
     | > postnet_loss: 1.42314  (1.47184)
     | > stopnet_loss: 1.11394  (1.53082)
     | > decoder_coarse_loss: 1.60200  (1.72690)
     | > decoder_ddc_loss: 0.00158  (0.00122)
     | > ga_loss: 0.00250  (0.00219)
     | > decoder_diff_spec_loss: 0.44297  (0.48614)
     | > postnet_diff_spec_loss: 0.78944  (0.80423)
     | > decoder_ssim_loss: 0.37705  (0.31892)
     | > postnet_ssim_loss: 0.40238  (0.33820)
     | > loss: 2.80264  (3.27523)
     | > align_error: 0.98695  (0.98844)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.01611  (4.02810)
     | > current_lr: 0.00008 
     | > step_time: 2.98820  (3.60075)
     | > loader_time: 0.02100  (0.03675)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 276500[0m
     | > decoder_loss: 1.71907  (1.78724)
     | > postnet_loss: 1.39498  (1.47153)
     | > stopnet_loss: 1.60177  (1.53665)
     | > decoder_coarse_loss: 1.67050  (1.73015)
     | > decoder_ddc_loss: 0.00101  (0.00121)
     | > ga_loss: 0.00208  (0.00219)
     | > decoder_diff_spec_loss: 0.48200  (0.48435)
     | > postnet_diff_spec_loss: 0.80127  (0.80326)
     | > decoder_ssim_loss: 0.30041  (0.31759)
     | > postnet_ssim_loss: 0.31651  (0.33646)
     | > loss: 3.28362  (3.28057)
     | > align_error: 0.99100  (0.98852)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.15511  (4.02123)
     | > current_lr: 0.00008 
     | > step_time: 4.45660  (3.60014)
     | > loader_time: 0.01960  (0.03681)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.09971 [0m(+0.31731)
     | > avg_decoder_loss:[92m 2.34367 [0m(-0.02537)
     | > avg_postnet_loss:[91m 2.21536 [0m(+0.03496)
     | > avg_stopnet_loss:[91m 1.31410 [0m(+0.00275)
     | > avg_decoder_coarse_loss:[92m 2.11627 [0m(-0.07527)
     | > avg_decoder_ddc_loss:[91m 0.00100 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00202 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47385 [0m(-0.00407)
     | > avg_postnet_diff_spec_loss:[91m 0.81430 [0m(+0.00037)
     | > avg_decoder_ssim_loss:[92m 0.33109 [0m(-0.00071)
     | > avg_postnet_ssim_loss:[91m 0.35013 [0m(+0.00107)
     | > avg_loss:[92m 3.48563 [0m(-0.01455)
     | > avg_align_error:[92m 0.99040 [0m(-0.00000)


[4m[1m > EPOCH: 74/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:50:49) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 276525[0m
     | > decoder_loss: 1.94551  (1.84654)
     | > postnet_loss: 1.60492  (1.50945)
     | > stopnet_loss: 1.64617  (1.54846)
     | > decoder_coarse_loss: 1.89170  (1.78456)
     | > decoder_ddc_loss: 0.00161  (0.00126)
     | > ga_loss: 0.00287  (0.00233)
     | > decoder_diff_spec_loss: 0.51928  (0.49532)
     | > postnet_diff_spec_loss: 0.85446  (0.81209)
     | > decoder_ssim_loss: 0.30713  (0.31194)
     | > postnet_ssim_loss: 0.32409  (0.33007)
     | > loss: 3.52267  (3.33289)
     | > align_error: 0.98539  (0.98798)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 10.79757  (5.93404)
     | > current_lr: 0.00008 
     | > step_time: 2.03360  (3.69701)
     | > loader_time: 0.01710  (0.03628)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 276550[0m
     | > decoder_loss: 1.73938  (1.78901)
     | > postnet_loss: 1.36862  (1.46139)
     | > stopnet_loss: 1.21900  (1.51309)
     | > decoder_coarse_loss: 1.67332  (1.73740)
     | > decoder_ddc_loss: 0.00118  (0.00124)
     | > ga_loss: 0.00198  (0.00213)
     | > decoder_diff_spec_loss: 0.45476  (0.48726)
     | > postnet_diff_spec_loss: 0.77589  (0.80487)
     | > decoder_ssim_loss: 0.36074  (0.32003)
     | > postnet_ssim_loss: 0.37789  (0.33827)
     | > loss: 2.91683  (3.25862)
     | > align_error: 0.99006  (0.98847)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.13260  (4.22101)
     | > current_lr: 0.00008 
     | > step_time: 4.32110  (3.76162)
     | > loader_time: 0.02550  (0.03091)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 276575[0m
     | > decoder_loss: 1.96395  (1.78762)
     | > postnet_loss: 1.52407  (1.46281)
     | > stopnet_loss: 2.06032  (1.52515)
     | > decoder_coarse_loss: 1.91345  (1.73419)
     | > decoder_ddc_loss: 0.00096  (0.00124)
     | > ga_loss: 0.00249  (0.00218)
     | > decoder_diff_spec_loss: 0.55869  (0.48521)
     | > postnet_diff_spec_loss: 0.85893  (0.80362)
     | > decoder_ssim_loss: 0.24071  (0.31781)
     | > postnet_ssim_loss: 0.24835  (0.33656)
     | > loss: 3.90006  (3.26831)
     | > align_error: 0.98907  (0.98839)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.02060  (4.41414)
     | > current_lr: 0.00008 
     | > step_time: 4.32250  (3.62754)
     | > loader_time: 0.02610  (0.03557)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.86400 [0m(-0.23571)
     | > avg_decoder_loss:[91m 2.38558 [0m(+0.04191)
     | > avg_postnet_loss:[91m 2.39341 [0m(+0.17805)
     | > avg_stopnet_loss:[91m 1.31552 [0m(+0.00142)
     | > avg_decoder_coarse_loss:[92m 2.11603 [0m(-0.00024)
     | > avg_decoder_ddc_loss:[91m 0.00101 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00201 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47356 [0m(-0.00029)
     | > avg_postnet_diff_spec_loss:[91m 0.81618 [0m(+0.00188)
     | > avg_decoder_ssim_loss:[91m 0.33112 [0m(+0.00004)
     | > avg_postnet_ssim_loss:[91m 0.35173 [0m(+0.00160)
     | > avg_loss:[91m 3.54275 [0m(+0.05712)
     | > avg_align_error:[92m 0.99036 [0m(-0.00005)


[4m[1m > EPOCH: 75/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 18:57:55) [0m

[1m   --> STEP: 0/87 -- GLOBAL_STEP: 276600[0m
     | > decoder_loss: 1.72435  (1.72435)
     | > postnet_loss: 1.42014  (1.42014)
     | > stopnet_loss: 1.47753  (1.47753)
     | > decoder_coarse_loss: 1.69012  (1.69012)
     | > decoder_ddc_loss: 0.00161  (0.00161)
     | > ga_loss: 0.00275  (0.00275)
     | > decoder_diff_spec_loss: 0.47228  (0.47228)
     | > postnet_diff_spec_loss: 0.79946  (0.79946)
     | > decoder_ssim_loss: 0.32936  (0.32936)
     | > postnet_ssim_loss: 0.34585  (0.34585)
     | > loss: 3.18710  (3.18710)
     | > align_error: 0.98619  (0.98619)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.32922  (4.32922)
     | > current_lr: 0.00008 
     | > step_time: 4.43410  (4.43406)
     | > loader_time: 7.23250  (7.23249)


[1m   --> STEP: 25/87 -- GLOBAL_STEP: 276625[0m
     | > decoder_loss: 1.85406  (1.79735)
     | > postnet_loss: 1.52244  (1.46996)
     | > stopnet_loss: 1.09028  (1.56495)
     | > decoder_coarse_loss: 1.77508  (1.73153)
     | > decoder_ddc_loss: 0.00181  (0.00121)
     | > ga_loss: 0.00218  (0.00214)
     | > decoder_diff_spec_loss: 0.49315  (0.48830)
     | > postnet_diff_spec_loss: 0.81054  (0.80683)
     | > decoder_ssim_loss: 0.42161  (0.31210)
     | > postnet_ssim_loss: 0.45054  (0.33000)
     | > loss: 2.93348  (3.30996)
     | > align_error: 0.98609  (0.98858)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.56580  (5.23053)
     | > current_lr: 0.00008 
     | > step_time: 2.97720  (3.79974)
     | > loader_time: 0.03360  (0.03486)


[1m   --> STEP: 50/87 -- GLOBAL_STEP: 276650[0m
     | > decoder_loss: 1.65328  (1.77954)
     | > postnet_loss: 1.48035  (1.45826)
     | > stopnet_loss: 1.15111  (1.52590)
     | > decoder_coarse_loss: 1.60547  (1.71895)
     | > decoder_ddc_loss: 0.00151  (0.00125)
     | > ga_loss: 0.00228  (0.00217)
     | > decoder_diff_spec_loss: 0.45434  (0.48648)
     | > postnet_diff_spec_loss: 0.80142  (0.80355)
     | > decoder_ssim_loss: 0.39041  (0.31726)
     | > postnet_ssim_loss: 0.41397  (0.33610)
     | > loss: 2.86271  (3.26211)
     | > align_error: 0.98708  (0.98830)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.66141  (4.58821)
     | > current_lr: 0.00008 
     | > step_time: 2.63320  (3.63841)
     | > loader_time: 0.02440  (0.03746)


[1m   --> STEP: 75/87 -- GLOBAL_STEP: 276675[0m
     | > decoder_loss: 1.69746  (1.78058)
     | > postnet_loss: 1.40213  (1.46030)
     | > stopnet_loss: 1.38587  (1.52556)
     | > decoder_coarse_loss: 1.66374  (1.72126)
     | > decoder_ddc_loss: 0.00131  (0.00124)
     | > ga_loss: 0.00234  (0.00218)
     | > decoder_diff_spec_loss: 0.48727  (0.48397)
     | > postnet_diff_spec_loss: 0.80684  (0.80248)
     | > decoder_ssim_loss: 0.34356  (0.31737)
     | > postnet_ssim_loss: 0.36132  (0.33604)
     | > loss: 3.08850  (3.26227)
     | > align_error: 0.98817  (0.98834)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.58687  (4.44908)
     | > current_lr: 0.00008 
     | > step_time: 2.40150  (3.59571)
     | > loader_time: 0.02240  (0.03920)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.95069 [0m(+0.08669)
     | > avg_decoder_loss:[91m 2.40390 [0m(+0.01832)
     | > avg_postnet_loss:[92m 2.32611 [0m(-0.06730)
     | > avg_stopnet_loss:[92m 1.31312 [0m(-0.00239)
     | > avg_decoder_coarse_loss:[92m 2.10160 [0m(-0.01444)
     | > avg_decoder_ddc_loss:[92m 0.00097 [0m(-0.00004)
     | > avg_ga_loss:[92m 0.00201 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47157 [0m(-0.00199)
     | > avg_postnet_diff_spec_loss:[92m 0.81491 [0m(-0.00127)
     | > avg_decoder_ssim_loss:[91m 0.33115 [0m(+0.00003)
     | > avg_postnet_ssim_loss:[92m 0.35067 [0m(-0.00107)
     | > avg_loss:[92m 3.52338 [0m(-0.01936)
     | > avg_align_error:[91m 0.99051 [0m(+0.00015)


[4m[1m > EPOCH: 76/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:05:03) [0m

[1m   --> STEP: 12/87 -- GLOBAL_STEP: 276700[0m
     | > decoder_loss: 1.78557  (1.83420)
     | > postnet_loss: 1.46910  (1.49540)
     | > stopnet_loss: 1.92298  (1.53847)
     | > decoder_coarse_loss: 1.68870  (1.75455)
     | > decoder_ddc_loss: 0.00085  (0.00120)
     | > ga_loss: 0.00203  (0.00228)
     | > decoder_diff_spec_loss: 0.46691  (0.49282)
     | > postnet_diff_spec_loss: 0.80002  (0.80823)
     | > decoder_ssim_loss: 0.25464  (0.31213)
     | > postnet_ssim_loss: 0.26802  (0.33035)
     | > loss: 3.61657  (3.30708)
     | > align_error: 0.99077  (0.98832)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.01358  (5.92045)
     | > current_lr: 0.00008 
     | > step_time: 4.39200  (3.71395)
     | > loader_time: 0.02200  (0.03181)


[1m   --> STEP: 37/87 -- GLOBAL_STEP: 276725[0m
     | > decoder_loss: 1.69565  (1.78407)
     | > postnet_loss: 1.41129  (1.45686)
     | > stopnet_loss: 1.14156  (1.51992)
     | > decoder_coarse_loss: 1.63821  (1.71828)
     | > decoder_ddc_loss: 0.00154  (0.00122)
     | > ga_loss: 0.00224  (0.00214)
     | > decoder_diff_spec_loss: 0.47407  (0.48796)
     | > postnet_diff_spec_loss: 0.80338  (0.80509)
     | > decoder_ssim_loss: 0.38008  (0.31843)
     | > postnet_ssim_loss: 0.40694  (0.33684)
     | > loss: 2.85556  (3.25781)
     | > align_error: 0.98741  (0.98845)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.00743  (4.28321)
     | > current_lr: 0.00008 
     | > step_time: 2.39880  (3.70746)
     | > loader_time: 0.03830  (0.03432)


[1m   --> STEP: 62/87 -- GLOBAL_STEP: 276750[0m
     | > decoder_loss: 1.86120  (1.77777)
     | > postnet_loss: 1.55809  (1.45346)
     | > stopnet_loss: 1.36735  (1.51967)
     | > decoder_coarse_loss: 1.81391  (1.71470)
     | > decoder_ddc_loss: 0.00084  (0.00124)
     | > ga_loss: 0.00162  (0.00216)
     | > decoder_diff_spec_loss: 0.45600  (0.48341)
     | > postnet_diff_spec_loss: 0.78404  (0.80209)
     | > decoder_ssim_loss: 0.32406  (0.31848)
     | > postnet_ssim_loss: 0.35026  (0.33746)
     | > loss: 3.16254  (3.25264)
     | > align_error: 0.99104  (0.98835)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.65472  (4.35234)
     | > current_lr: 0.00008 
     | > step_time: 4.32060  (3.61219)
     | > loader_time: 0.02300  (0.03242)


[1m   --> STEP: 87/87 -- GLOBAL_STEP: 276775[0m
     | > decoder_loss: 1.25188  (1.76817)
     | > postnet_loss: 1.16962  (1.44593)
     | > stopnet_loss: 1.55007  (1.53897)
     | > decoder_coarse_loss: 1.31348  (1.70855)
     | > decoder_ddc_loss: 0.00281  (0.00126)
     | > ga_loss: 0.00309  (0.00220)
     | > decoder_diff_spec_loss: 0.37767  (0.48245)
     | > postnet_diff_spec_loss: 0.73487  (0.80117)
     | > decoder_ssim_loss: 0.37226  (0.31634)
     | > postnet_ssim_loss: 0.39830  (0.33477)
     | > loss: 2.97072  (3.26465)
     | > align_error: 0.97640  (0.98809)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 19.81631  (4.55450)
     | > current_lr: 0.00008 
     | > step_time: 0.87510  (3.46720)
     | > loader_time: 0.00650  (0.03217)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.78896 [0m(-0.16173)
     | > avg_decoder_loss:[91m 2.41267 [0m(+0.00877)
     | > avg_postnet_loss:[91m 2.60816 [0m(+0.28204)
     | > avg_stopnet_loss:[92m 1.31210 [0m(-0.00103)
     | > avg_decoder_coarse_loss:[91m 2.12113 [0m(+0.01954)
     | > avg_decoder_ddc_loss:[91m 0.00099 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00200 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47516 [0m(+0.00358)
     | > avg_postnet_diff_spec_loss:[91m 0.81609 [0m(+0.00118)
     | > avg_decoder_ssim_loss:[92m 0.33099 [0m(-0.00016)
     | > avg_postnet_ssim_loss:[91m 0.35234 [0m(+0.00168)
     | > avg_loss:[91m 3.60148 [0m(+0.07810)
     | > avg_align_error:[92m 0.99043 [0m(-0.00007)


[4m[1m > EPOCH: 77/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:12:07) [0m

[1m   --> STEP: 24/87 -- GLOBAL_STEP: 276800[0m
     | > decoder_loss: 1.86352  (1.78485)
     | > postnet_loss: 1.52962  (1.45363)
     | > stopnet_loss: 1.11625  (1.59185)
     | > decoder_coarse_loss: 1.83400  (1.73090)
     | > decoder_ddc_loss: 0.00121  (0.00118)
     | > ga_loss: 0.00194  (0.00211)
     | > decoder_diff_spec_loss: 0.47817  (0.48740)
     | > postnet_diff_spec_loss: 0.80873  (0.80594)
     | > decoder_ssim_loss: 0.38333  (0.30704)
     | > postnet_ssim_loss: 0.40377  (0.32448)
     | > loss: 2.95156  (3.32625)
     | > align_error: 0.98873  (0.98860)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.93405  (4.92138)
     | > current_lr: 0.00008 
     | > step_time: 4.28520  (3.88890)
     | > loader_time: 0.01980  (0.03765)


[1m   --> STEP: 49/87 -- GLOBAL_STEP: 276825[0m
     | > decoder_loss: 1.84213  (1.77192)
     | > postnet_loss: 1.42857  (1.44121)
     | > stopnet_loss: 1.14259  (1.53277)
     | > decoder_coarse_loss: 1.77111  (1.71608)
     | > decoder_ddc_loss: 0.00095  (0.00124)
     | > ga_loss: 0.00185  (0.00214)
     | > decoder_diff_spec_loss: 0.48733  (0.48569)
     | > postnet_diff_spec_loss: 0.79816  (0.80294)
     | > decoder_ssim_loss: 0.36385  (0.31508)
     | > postnet_ssim_loss: 0.39017  (0.33385)
     | > loss: 2.92239  (3.26047)
     | > align_error: 0.99084  (0.98823)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 10.10333  (4.30487)
     | > current_lr: 0.00008 
     | > step_time: 4.09010  (3.63872)
     | > loader_time: 0.02710  (0.03473)


[1m   --> STEP: 74/87 -- GLOBAL_STEP: 276850[0m
     | > decoder_loss: 1.75375  (1.77308)
     | > postnet_loss: 1.50274  (1.44799)
     | > stopnet_loss: 1.20983  (1.52716)
     | > decoder_coarse_loss: 1.69445  (1.71414)
     | > decoder_ddc_loss: 0.00124  (0.00125)
     | > ga_loss: 0.00203  (0.00215)
     | > decoder_diff_spec_loss: 0.48676  (0.48289)
     | > postnet_diff_spec_loss: 0.81886  (0.80195)
     | > decoder_ssim_loss: 0.36838  (0.31629)
     | > postnet_ssim_loss: 0.38548  (0.33512)
     | > loss: 2.97291  (3.25608)
     | > align_error: 0.98878  (0.98824)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.70633  (4.32715)
     | > current_lr: 0.00008 
     | > step_time: 3.59600  (3.57257)
     | > loader_time: 0.04420  (0.03352)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.88063 [0m(+0.09166)
     | > avg_decoder_loss:[92m 2.37988 [0m(-0.03279)
     | > avg_postnet_loss:[92m 2.30837 [0m(-0.29979)
     | > avg_stopnet_loss:[92m 1.30987 [0m(-0.00222)
     | > avg_decoder_coarse_loss:[91m 2.14515 [0m(+0.02402)
     | > avg_decoder_ddc_loss:[92m 0.00098 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00200 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47369 [0m(-0.00147)
     | > avg_postnet_diff_spec_loss:[92m 0.81489 [0m(-0.00121)
     | > avg_decoder_ssim_loss:[92m 0.33072 [0m(-0.00027)
     | > avg_postnet_ssim_loss:[92m 0.34991 [0m(-0.00243)
     | > avg_loss:[92m 3.52077 [0m(-0.08071)
     | > avg_align_error:[92m 0.99036 [0m(-0.00008)


[4m[1m > EPOCH: 78/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:19:17) [0m

[1m   --> STEP: 11/87 -- GLOBAL_STEP: 276875[0m
     | > decoder_loss: 1.82622  (1.83298)
     | > postnet_loss: 1.44526  (1.50498)
     | > stopnet_loss: 1.94005  (1.51192)
     | > decoder_coarse_loss: 1.71508  (1.76394)
     | > decoder_ddc_loss: 0.00109  (0.00125)
     | > ga_loss: 0.00251  (0.00227)
     | > decoder_diff_spec_loss: 0.50793  (0.49553)
     | > postnet_diff_spec_loss: 0.81462  (0.80871)
     | > decoder_ssim_loss: 0.25744  (0.31671)
     | > postnet_ssim_loss: 0.26598  (0.33556)
     | > loss: 3.66102  (3.28816)
     | > align_error: 0.98880  (0.98788)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.21290  (5.28465)
     | > current_lr: 0.00008 
     | > step_time: 3.78450  (3.82891)
     | > loader_time: 0.02060  (0.02849)


[1m   --> STEP: 36/87 -- GLOBAL_STEP: 276900[0m
     | > decoder_loss: 1.71025  (1.78418)
     | > postnet_loss: 1.32951  (1.45920)
     | > stopnet_loss: 1.25066  (1.52750)
     | > decoder_coarse_loss: 1.67403  (1.72137)
     | > decoder_ddc_loss: 0.00137  (0.00122)
     | > ga_loss: 0.00191  (0.00212)
     | > decoder_diff_spec_loss: 0.48266  (0.48811)
     | > postnet_diff_spec_loss: 0.78109  (0.80511)
     | > decoder_ssim_loss: 0.35649  (0.31616)
     | > postnet_ssim_loss: 0.37528  (0.33478)
     | > loss: 2.93788  (3.26563)
     | > align_error: 0.98791  (0.98834)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.60862  (4.16504)
     | > current_lr: 0.00008 
     | > step_time: 3.85150  (3.75304)
     | > loader_time: 0.02380  (0.03264)


[1m   --> STEP: 61/87 -- GLOBAL_STEP: 276925[0m
     | > decoder_loss: 1.80610  (1.77371)
     | > postnet_loss: 1.41696  (1.44900)
     | > stopnet_loss: 1.45415  (1.51670)
     | > decoder_coarse_loss: 1.73141  (1.70973)
     | > decoder_ddc_loss: 0.00288  (0.00127)
     | > ga_loss: 0.00349  (0.00215)
     | > decoder_diff_spec_loss: 0.49874  (0.48360)
     | > postnet_diff_spec_loss: 0.80361  (0.80217)
     | > decoder_ssim_loss: 0.36795  (0.31794)
     | > postnet_ssim_loss: 0.38447  (0.33706)
     | > loss: 3.22463  (3.24608)
     | > align_error: 0.97826  (0.98815)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 14.02076  (4.35942)
     | > current_lr: 0.00008 
     | > step_time: 2.15960  (3.61697)
     | > loader_time: 0.01890  (0.03476)


[1m   --> STEP: 86/87 -- GLOBAL_STEP: 276950[0m
     | > decoder_loss: 1.74482  (1.77202)
     | > postnet_loss: 1.47108  (1.44762)
     | > stopnet_loss: 1.47878  (1.53131)
     | > decoder_coarse_loss: 1.68968  (1.70906)
     | > decoder_ddc_loss: 0.00135  (0.00128)
     | > ga_loss: 0.00237  (0.00217)
     | > decoder_diff_spec_loss: 0.48239  (0.48347)
     | > postnet_diff_spec_loss: 0.81989  (0.80176)
     | > decoder_ssim_loss: 0.33253  (0.31524)
     | > postnet_ssim_loss: 0.34677  (0.33386)
     | > loss: 3.21275  (3.25825)
     | > align_error: 0.98756  (0.98805)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.25232  (4.37866)
     | > current_lr: 0.00008 
     | > step_time: 1.85710  (3.51782)
     | > loader_time: 0.01470  (0.03398)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.79524 [0m(-0.08539)
     | > avg_decoder_loss:[92m 2.33123 [0m(-0.04865)
     | > avg_postnet_loss:[92m 2.30726 [0m(-0.00111)
     | > avg_stopnet_loss:[92m 1.30869 [0m(-0.00118)
     | > avg_decoder_coarse_loss:[92m 2.08556 [0m(-0.05959)
     | > avg_decoder_ddc_loss:[91m 0.00101 [0m(+0.00003)
     | > avg_ga_loss:[91m 0.00200 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47179 [0m(-0.00190)
     | > avg_postnet_diff_spec_loss:[91m 0.81541 [0m(+0.00052)
     | > avg_decoder_ssim_loss:[92m 0.33019 [0m(-0.00053)
     | > avg_postnet_ssim_loss:[91m 0.34997 [0m(+0.00006)
     | > avg_loss:[92m 3.49179 [0m(-0.02898)
     | > avg_align_error:[92m 0.99023 [0m(-0.00013)


[4m[1m > EPOCH: 79/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:26:26) [0m

[1m   --> STEP: 23/87 -- GLOBAL_STEP: 276975[0m
     | > decoder_loss: 1.64926  (1.77515)
     | > postnet_loss: 1.27717  (1.44241)
     | > stopnet_loss: 2.47667  (1.59574)
     | > decoder_coarse_loss: 1.60792  (1.72519)
     | > decoder_ddc_loss: 0.00078  (0.00117)
     | > ga_loss: 0.00180  (0.00210)
     | > decoder_diff_spec_loss: 0.46685  (0.48715)
     | > postnet_diff_spec_loss: 0.77474  (0.80535)
     | > decoder_ssim_loss: 0.19741  (0.30330)
     | > postnet_ssim_loss: 0.20755  (0.32082)
     | > loss: 4.03109  (3.32136)
     | > align_error: 0.99070  (0.98859)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.82473  (4.91455)
     | > current_lr: 0.00008 
     | > step_time: 5.09330  (3.92039)
     | > loader_time: 0.02800  (0.02820)


[1m   --> STEP: 48/87 -- GLOBAL_STEP: 277000[0m
     | > decoder_loss: 1.78550  (1.76715)
     | > postnet_loss: 1.43591  (1.43614)
     | > stopnet_loss: 1.48430  (1.53018)
     | > decoder_coarse_loss: 1.68927  (1.71223)
     | > decoder_ddc_loss: 0.00144  (0.00126)
     | > ga_loss: 0.00240  (0.00213)
     | > decoder_diff_spec_loss: 0.48568  (0.48509)
     | > postnet_diff_spec_loss: 0.80789  (0.80264)
     | > decoder_ssim_loss: 0.31329  (0.31374)
     | > postnet_ssim_loss: 0.32925  (0.33242)
     | > loss: 3.20835  (3.25349)
     | > align_error: 0.98666  (0.98815)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.01428  (4.21084)
     | > current_lr: 0.00008 
     | > step_time: 3.68990  (3.69257)
     | > loader_time: 0.01870  (0.03149)


[1m   --> STEP: 73/87 -- GLOBAL_STEP: 277025[0m
     | > decoder_loss: 1.61983  (1.76906)
     | > postnet_loss: 1.40072  (1.44143)
     | > stopnet_loss: 2.24601  (1.51912)
     | > decoder_coarse_loss: 1.58903  (1.71330)
     | > decoder_ddc_loss: 0.00079  (0.00127)
     | > ga_loss: 0.00213  (0.00213)
     | > decoder_diff_spec_loss: 0.45285  (0.48208)
     | > postnet_diff_spec_loss: 0.78770  (0.80135)
     | > decoder_ssim_loss: 0.21956  (0.31520)
     | > postnet_ssim_loss: 0.23174  (0.33422)
     | > loss: 3.83222  (3.24425)
     | > align_error: 0.99159  (0.98817)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.41114  (4.28323)
     | > current_lr: 0.00008 
     | > step_time: 4.16200  (3.66007)
     | > loader_time: 0.02880  (0.03258)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.30609 [0m(+0.51085)
     | > avg_decoder_loss:[91m 2.37021 [0m(+0.03898)
     | > avg_postnet_loss:[92m 2.25450 [0m(-0.05276)
     | > avg_stopnet_loss:[91m 1.31062 [0m(+0.00193)
     | > avg_decoder_coarse_loss:[91m 2.13763 [0m(+0.05206)
     | > avg_decoder_ddc_loss:[91m 0.00102 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00198 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.47178 [0m(-0.00000)
     | > avg_postnet_diff_spec_loss:[92m 0.81461 [0m(-0.00079)
     | > avg_decoder_ssim_loss:[91m 0.33032 [0m(+0.00013)
     | > avg_postnet_ssim_loss:[92m 0.34938 [0m(-0.00059)
     | > avg_loss:[91m 3.50289 [0m(+0.01110)
     | > avg_align_error:[91m 0.99029 [0m(+0.00007)


[4m[1m > EPOCH: 80/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:33:37) [0m

[1m   --> STEP: 10/87 -- GLOBAL_STEP: 277050[0m
     | > decoder_loss: 1.94859  (1.83072)
     | > postnet_loss: 1.53756  (1.48668)
     | > stopnet_loss: 1.51870  (1.44856)
     | > decoder_coarse_loss: 1.89296  (1.77808)
     | > decoder_ddc_loss: 0.00114  (0.00129)
     | > ga_loss: 0.00214  (0.00220)
     | > decoder_diff_spec_loss: 0.54822  (0.49400)
     | > postnet_diff_spec_loss: 0.84577  (0.80778)
     | > decoder_ssim_loss: 0.30103  (0.32274)
     | > postnet_ssim_loss: 0.31008  (0.34181)
     | > loss: 3.37575  (3.22533)
     | > align_error: 0.98848  (0.98772)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.26607  (5.02542)
     | > current_lr: 0.00008 
     | > step_time: 3.21680  (3.68708)
     | > loader_time: 0.05430  (0.04374)


[1m   --> STEP: 35/87 -- GLOBAL_STEP: 277075[0m
     | > decoder_loss: 1.92757  (1.77710)
     | > postnet_loss: 1.52864  (1.44572)
     | > stopnet_loss: 1.59894  (1.53124)
     | > decoder_coarse_loss: 1.84940  (1.72103)
     | > decoder_ddc_loss: 0.00118  (0.00127)
     | > ga_loss: 0.00216  (0.00208)
     | > decoder_diff_spec_loss: 0.52907  (0.48649)
     | > postnet_diff_spec_loss: 0.83299  (0.80496)
     | > decoder_ssim_loss: 0.29500  (0.31465)
     | > postnet_ssim_loss: 0.30772  (0.33311)
     | > loss: 3.42762  (3.26273)
     | > align_error: 0.98828  (0.98822)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.14007  (4.11742)
     | > current_lr: 0.00008 
     | > step_time: 3.36860  (3.74423)
     | > loader_time: 0.01780  (0.03417)


[1m   --> STEP: 60/87 -- GLOBAL_STEP: 277100[0m
     | > decoder_loss: 1.63029  (1.76326)
     | > postnet_loss: 1.33654  (1.43380)
     | > stopnet_loss: 0.95034  (1.51103)
     | > decoder_coarse_loss: 1.60888  (1.70820)
     | > decoder_ddc_loss: 0.00145  (0.00127)
     | > ga_loss: 0.00227  (0.00210)
     | > decoder_diff_spec_loss: 0.46340  (0.48228)
     | > postnet_diff_spec_loss: 0.78102  (0.80147)
     | > decoder_ssim_loss: 0.43264  (0.31657)
     | > postnet_ssim_loss: 0.46197  (0.33572)
     | > loss: 2.64076  (3.23218)
     | > align_error: 0.98727  (0.98823)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.20361  (4.13071)
     | > current_lr: 0.00008 
     | > step_time: 3.00140  (3.64621)
     | > loader_time: 0.03900  (0.03446)


[1m   --> STEP: 85/87 -- GLOBAL_STEP: 277125[0m
     | > decoder_loss: 1.74743  (1.76501)
     | > postnet_loss: 1.38272  (1.43478)
     | > stopnet_loss: 1.72575  (1.52327)
     | > decoder_coarse_loss: 1.70390  (1.70736)
     | > decoder_ddc_loss: 0.00112  (0.00129)
     | > ga_loss: 0.00234  (0.00215)
     | > decoder_diff_spec_loss: 0.49007  (0.48221)
     | > postnet_diff_spec_loss: 0.80284  (0.80096)
     | > decoder_ssim_loss: 0.27701  (0.31448)
     | > postnet_ssim_loss: 0.29137  (0.33322)
     | > loss: 3.41155  (3.24384)
     | > align_error: 0.98805  (0.98804)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.55037  (4.25207)
     | > current_lr: 0.00007 
     | > step_time: 2.05630  (3.53188)
     | > loader_time: 0.01410  (0.03360)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.20376 [0m(-0.10234)
     | > avg_decoder_loss:[91m 2.43077 [0m(+0.06056)
     | > avg_postnet_loss:[91m 2.35293 [0m(+0.09843)
     | > avg_stopnet_loss:[92m 1.31017 [0m(-0.00045)
     | > avg_decoder_coarse_loss:[91m 2.15996 [0m(+0.02234)
     | > avg_decoder_ddc_loss:[92m 0.00098 [0m(-0.00004)
     | > avg_ga_loss:[91m 0.00199 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47106 [0m(-0.00072)
     | > avg_postnet_diff_spec_loss:[92m 0.81328 [0m(-0.00133)
     | > avg_decoder_ssim_loss:[92m 0.33016 [0m(-0.00016)
     | > avg_postnet_ssim_loss:[92m 0.34931 [0m(-0.00007)
     | > avg_loss:[91m 3.54724 [0m(+0.04435)
     | > avg_align_error:[92m 0.99027 [0m(-0.00002)


[4m[1m > EPOCH: 81/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:40:40) [0m

[1m   --> STEP: 22/87 -- GLOBAL_STEP: 277150[0m
     | > decoder_loss: 1.65478  (1.78268)
     | > postnet_loss: 1.30401  (1.45065)
     | > stopnet_loss: 1.69916  (1.54966)
     | > decoder_coarse_loss: 1.60417  (1.72301)
     | > decoder_ddc_loss: 0.00081  (0.00121)
     | > ga_loss: 0.00201  (0.00209)
     | > decoder_diff_spec_loss: 0.47334  (0.48643)
     | > postnet_diff_spec_loss: 0.78764  (0.80581)
     | > decoder_ssim_loss: 0.27069  (0.30760)
     | > postnet_ssim_loss: 0.29074  (0.32557)
     | > loss: 3.30574  (3.28088)
     | > align_error: 0.99067  (0.98837)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.83658  (5.60715)
     | > current_lr: 0.00007 
     | > step_time: 3.91990  (3.88288)
     | > loader_time: 0.04700  (0.03970)


[1m   --> STEP: 47/87 -- GLOBAL_STEP: 277175[0m
     | > decoder_loss: 1.79208  (1.76169)
     | > postnet_loss: 1.49258  (1.43295)
     | > stopnet_loss: 1.33959  (1.53389)
     | > decoder_coarse_loss: 1.72967  (1.70473)
     | > decoder_ddc_loss: 0.00136  (0.00128)
     | > ga_loss: 0.00227  (0.00211)
     | > decoder_diff_spec_loss: 0.50315  (0.48383)
     | > postnet_diff_spec_loss: 0.81288  (0.80201)
     | > decoder_ssim_loss: 0.35664  (0.31306)
     | > postnet_ssim_loss: 0.37119  (0.33217)
     | > loss: 3.11584  (3.25236)
     | > align_error: 0.98757  (0.98801)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.71523  (4.55977)
     | > current_lr: 0.00007 
     | > step_time: 2.53830  (3.65870)
     | > loader_time: 0.03360  (0.03456)


[1m   --> STEP: 72/87 -- GLOBAL_STEP: 277200[0m
     | > decoder_loss: 1.80323  (1.76714)
     | > postnet_loss: 1.54213  (1.43709)
     | > stopnet_loss: 1.08839  (1.51120)
     | > decoder_coarse_loss: 1.71910  (1.70901)
     | > decoder_ddc_loss: 0.00104  (0.00129)
     | > ga_loss: 0.00159  (0.00211)
     | > decoder_diff_spec_loss: 0.45756  (0.48168)
     | > postnet_diff_spec_loss: 0.78671  (0.80080)
     | > decoder_ssim_loss: 0.38550  (0.31585)
     | > postnet_ssim_loss: 0.41044  (0.33517)
     | > loss: 2.87275  (3.23377)
     | > align_error: 0.99021  (0.98798)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.84932  (4.57182)
     | > current_lr: 0.00007 
     | > step_time: 4.27170  (3.64529)
     | > loader_time: 0.01950  (0.03551)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.94422 [0m(-0.25953)
     | > avg_decoder_loss:[92m 2.38494 [0m(-0.04583)
     | > avg_postnet_loss:[92m 2.30664 [0m(-0.04629)
     | > avg_stopnet_loss:[92m 1.30813 [0m(-0.00203)
     | > avg_decoder_coarse_loss:[92m 2.09870 [0m(-0.06127)
     | > avg_decoder_ddc_loss:[91m 0.00100 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00198 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.46989 [0m(-0.00118)
     | > avg_postnet_diff_spec_loss:[91m 0.81336 [0m(+0.00008)
     | > avg_decoder_ssim_loss:[92m 0.32978 [0m(-0.00037)
     | > avg_postnet_ssim_loss:[91m 0.34962 [0m(+0.00031)
     | > avg_loss:[92m 3.50649 [0m(-0.04074)
     | > avg_align_error:[91m 0.99034 [0m(+0.00007)


[4m[1m > EPOCH: 82/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:47:47) [0m

[1m   --> STEP: 9/87 -- GLOBAL_STEP: 277225[0m
     | > decoder_loss: 1.91737  (1.80616)
     | > postnet_loss: 1.60529  (1.45624)
     | > stopnet_loss: 1.24149  (1.44093)
     | > decoder_coarse_loss: 1.85948  (1.73511)
     | > decoder_ddc_loss: 0.00152  (0.00130)
     | > ga_loss: 0.00231  (0.00221)
     | > decoder_diff_spec_loss: 0.50796  (0.48668)
     | > postnet_diff_spec_loss: 0.82978  (0.80259)
     | > decoder_ssim_loss: 0.36943  (0.32417)
     | > postnet_ssim_loss: 0.39096  (0.34476)
     | > loss: 3.12351  (3.19120)
     | > align_error: 0.98610  (0.98761)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.20519  (5.51636)
     | > current_lr: 0.00007 
     | > step_time: 2.46600  (3.85185)
     | > loader_time: 0.01560  (0.03950)


[1m   --> STEP: 34/87 -- GLOBAL_STEP: 277250[0m
     | > decoder_loss: 1.76663  (1.76301)
     | > postnet_loss: 1.37598  (1.42724)
     | > stopnet_loss: 1.08755  (1.51786)
     | > decoder_coarse_loss: 1.69484  (1.70037)
     | > decoder_ddc_loss: 0.00138  (0.00125)
     | > ga_loss: 0.00188  (0.00208)
     | > decoder_diff_spec_loss: 0.49254  (0.48505)
     | > postnet_diff_spec_loss: 0.79324  (0.80384)
     | > decoder_ssim_loss: 0.37991  (0.31457)
     | > postnet_ssim_loss: 0.40465  (0.33322)
     | > loss: 2.82422  (3.23538)
     | > align_error: 0.98774  (0.98815)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.86991  (4.05721)
     | > current_lr: 0.00007 
     | > step_time: 3.67900  (3.76831)
     | > loader_time: 0.02480  (0.03718)


[1m   --> STEP: 59/87 -- GLOBAL_STEP: 277275[0m
     | > decoder_loss: 1.63160  (1.75780)
     | > postnet_loss: 1.28287  (1.42380)
     | > stopnet_loss: 1.10185  (1.51583)
     | > decoder_coarse_loss: 1.56656  (1.69539)
     | > decoder_ddc_loss: 0.00146  (0.00125)
     | > ga_loss: 0.00202  (0.00209)
     | > decoder_diff_spec_loss: 0.46054  (0.48245)
     | > postnet_diff_spec_loss: 0.77632  (0.80134)
     | > decoder_ssim_loss: 0.40141  (0.31418)
     | > postnet_ssim_loss: 0.41722  (0.33301)
     | > loss: 2.74643  (3.22859)
     | > align_error: 0.98828  (0.98817)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.99158  (4.09132)
     | > current_lr: 0.00007 
     | > step_time: 2.60320  (3.64284)
     | > loader_time: 0.01900  (0.03771)


[1m   --> STEP: 84/87 -- GLOBAL_STEP: 277300[0m
     | > decoder_loss: 1.83367  (1.75832)
     | > postnet_loss: 1.45106  (1.42495)
     | > stopnet_loss: 1.60288  (1.52080)
     | > decoder_coarse_loss: 1.76038  (1.69626)
     | > decoder_ddc_loss: 0.00161  (0.00128)
     | > ga_loss: 0.00260  (0.00213)
     | > decoder_diff_spec_loss: 0.51979  (0.48193)
     | > postnet_diff_spec_loss: 0.81238  (0.80042)
     | > decoder_ssim_loss: 0.30521  (0.31453)
     | > postnet_ssim_loss: 0.32509  (0.33328)
     | > loss: 3.36818  (3.23419)
     | > align_error: 0.98546  (0.98794)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.30060  (4.28480)
     | > current_lr: 0.00007 
     | > step_time: 1.71210  (3.55155)
     | > loader_time: 0.02230  (0.03627)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.93301 [0m(-0.01122)
     | > avg_decoder_loss:[92m 2.30266 [0m(-0.08228)
     | > avg_postnet_loss:[91m 2.38255 [0m(+0.07591)
     | > avg_stopnet_loss:[91m 1.30853 [0m(+0.00039)
     | > avg_decoder_coarse_loss:[92m 2.07994 [0m(-0.01876)
     | > avg_decoder_ddc_loss:[91m 0.00101 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00197 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47326 [0m(+0.00337)
     | > avg_postnet_diff_spec_loss:[91m 0.81427 [0m(+0.00091)
     | > avg_decoder_ssim_loss:[92m 0.32923 [0m(-0.00055)
     | > avg_postnet_ssim_loss:[91m 0.35033 [0m(+0.00071)
     | > avg_loss:[92m 3.50168 [0m(-0.00481)
     | > avg_align_error:[92m 0.99019 [0m(-0.00016)


[4m[1m > EPOCH: 83/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 19:55:02) [0m

[1m   --> STEP: 21/87 -- GLOBAL_STEP: 277325[0m
     | > decoder_loss: 1.79355  (1.78058)
     | > postnet_loss: 1.45956  (1.45064)
     | > stopnet_loss: 1.11752  (1.54747)
     | > decoder_coarse_loss: 1.76163  (1.72952)
     | > decoder_ddc_loss: 0.00200  (0.00123)
     | > ga_loss: 0.00244  (0.00209)
     | > decoder_diff_spec_loss: 0.49905  (0.48812)
     | > postnet_diff_spec_loss: 0.81830  (0.80673)
     | > decoder_ssim_loss: 0.39134  (0.30893)
     | > postnet_ssim_loss: 0.41182  (0.32688)
     | > loss: 2.91403  (3.28109)
     | > align_error: 0.98353  (0.98822)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.71686  (4.79949)
     | > current_lr: 0.00007 
     | > step_time: 2.74920  (3.85531)
     | > loader_time: 0.01590  (0.04333)


[1m   --> STEP: 46/87 -- GLOBAL_STEP: 277350[0m
     | > decoder_loss: 1.82475  (1.75561)
     | > postnet_loss: 1.53709  (1.42315)
     | > stopnet_loss: 1.48624  (1.53811)
     | > decoder_coarse_loss: 1.80163  (1.70442)
     | > decoder_ddc_loss: 0.00150  (0.00126)
     | > ga_loss: 0.00220  (0.00210)
     | > decoder_diff_spec_loss: 0.49010  (0.48400)
     | > postnet_diff_spec_loss: 0.81272  (0.80103)
     | > decoder_ssim_loss: 0.31044  (0.31174)
     | > postnet_ssim_loss: 0.32851  (0.33087)
     | > loss: 3.27392  (3.25162)
     | > align_error: 0.98672  (0.98803)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.61717  (4.05145)
     | > current_lr: 0.00007 
     | > step_time: 3.46030  (3.63900)
     | > loader_time: 0.05420  (0.04109)


[1m   --> STEP: 71/87 -- GLOBAL_STEP: 277375[0m
     | > decoder_loss: 1.85372  (1.75869)
     | > postnet_loss: 1.53546  (1.42801)
     | > stopnet_loss: 1.53632  (1.51634)
     | > decoder_coarse_loss: 1.79885  (1.70539)
     | > decoder_ddc_loss: 0.00148  (0.00129)
     | > ga_loss: 0.00276  (0.00211)
     | > decoder_diff_spec_loss: 0.49095  (0.48257)
     | > postnet_diff_spec_loss: 0.80916  (0.80051)
     | > decoder_ssim_loss: 0.31419  (0.31456)
     | > postnet_ssim_loss: 0.33247  (0.33377)
     | > loss: 3.33419  (3.23310)
     | > align_error: 0.98618  (0.98788)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.80114  (4.22125)
     | > current_lr: 0.00007 
     | > step_time: 2.60340  (3.55515)
     | > loader_time: 0.01870  (0.03931)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.09482 [0m(+0.16182)
     | > avg_decoder_loss:[91m 2.35169 [0m(+0.04903)
     | > avg_postnet_loss:[92m 2.36094 [0m(-0.02161)
     | > avg_stopnet_loss:[91m 1.30920 [0m(+0.00068)
     | > avg_decoder_coarse_loss:[91m 2.11753 [0m(+0.03759)
     | > avg_decoder_ddc_loss:[91m 0.00103 [0m(+0.00002)
     | > avg_ga_loss:[91m 0.00198 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47248 [0m(-0.00078)
     | > avg_postnet_diff_spec_loss:[92m 0.81352 [0m(-0.00075)
     | > avg_decoder_ssim_loss:[91m 0.32944 [0m(+0.00021)
     | > avg_postnet_ssim_loss:[92m 0.34970 [0m(-0.00063)
     | > avg_loss:[91m 3.51820 [0m(+0.01651)
     | > avg_align_error:[91m 0.99030 [0m(+0.00012)


[4m[1m > EPOCH: 84/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:02:07) [0m

[1m   --> STEP: 8/87 -- GLOBAL_STEP: 277400[0m
     | > decoder_loss: 2.00972  (1.78969)
     | > postnet_loss: 1.54290  (1.44881)
     | > stopnet_loss: 1.86155  (1.46156)
     | > decoder_coarse_loss: 1.95947  (1.73038)
     | > decoder_ddc_loss: 0.00076  (0.00127)
     | > ga_loss: 0.00178  (0.00219)
     | > decoder_diff_spec_loss: 0.53833  (0.48505)
     | > postnet_diff_spec_loss: 0.83044  (0.79846)
     | > decoder_ssim_loss: 0.25060  (0.31818)
     | > postnet_ssim_loss: 0.26285  (0.33900)
     | > loss: 3.71924  (3.20021)
     | > align_error: 0.99142  (0.98772)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.57936  (6.95035)
     | > current_lr: 0.00007 
     | > step_time: 4.75640  (4.04886)
     | > loader_time: 0.02820  (0.03650)


[1m   --> STEP: 33/87 -- GLOBAL_STEP: 277425[0m
     | > decoder_loss: 1.66889  (1.75703)
     | > postnet_loss: 1.30930  (1.42614)
     | > stopnet_loss: 1.91403  (1.53607)
     | > decoder_coarse_loss: 1.59795  (1.70219)
     | > decoder_ddc_loss: 0.00070  (0.00123)
     | > ga_loss: 0.00159  (0.00208)
     | > decoder_diff_spec_loss: 0.46673  (0.48471)
     | > postnet_diff_spec_loss: 0.78839  (0.80338)
     | > decoder_ssim_loss: 0.24615  (0.31226)
     | > postnet_ssim_loss: 0.26298  (0.33075)
     | > loss: 3.50723  (3.25092)
     | > align_error: 0.99185  (0.98818)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.06119  (4.45427)
     | > current_lr: 0.00007 
     | > step_time: 4.58830  (3.81854)
     | > loader_time: 0.04530  (0.02995)


[1m   --> STEP: 58/87 -- GLOBAL_STEP: 277450[0m
     | > decoder_loss: 2.03068  (1.75761)
     | > postnet_loss: 1.61818  (1.42423)
     | > stopnet_loss: 1.66100  (1.52358)
     | > decoder_coarse_loss: 1.97124  (1.69843)
     | > decoder_ddc_loss: 0.00092  (0.00123)
     | > ga_loss: 0.00161  (0.00210)
     | > decoder_diff_spec_loss: 0.54128  (0.48240)
     | > postnet_diff_spec_loss: 0.82844  (0.80139)
     | > decoder_ssim_loss: 0.27493  (0.31230)
     | > postnet_ssim_loss: 0.28196  (0.33132)
     | > loss: 3.55597  (3.23629)
     | > align_error: 0.99054  (0.98821)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.86021  (4.52611)
     | > current_lr: 0.00007 
     | > step_time: 4.22660  (3.71951)
     | > loader_time: 0.02690  (0.03062)


[1m   --> STEP: 83/87 -- GLOBAL_STEP: 277475[0m
     | > decoder_loss: 1.69147  (1.75378)
     | > postnet_loss: 1.33930  (1.42237)
     | > stopnet_loss: 1.54728  (1.51838)
     | > decoder_coarse_loss: 1.61591  (1.69497)
     | > decoder_ddc_loss: 0.00121  (0.00126)
     | > ga_loss: 0.00188  (0.00213)
     | > decoder_diff_spec_loss: 0.48560  (0.48093)
     | > postnet_diff_spec_loss: 0.77720  (0.79984)
     | > decoder_ssim_loss: 0.29370  (0.31425)
     | > postnet_ssim_loss: 0.31123  (0.33308)
     | > loss: 3.18556  (3.22915)
     | > align_error: 0.98717  (0.98802)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.15490  (4.60087)
     | > current_lr: 0.00007 
     | > step_time: 2.93670  (3.60460)
     | > loader_time: 0.01860  (0.03146)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.02110 [0m(-0.07373)
     | > avg_decoder_loss:[92m 2.25360 [0m(-0.09809)
     | > avg_postnet_loss:[92m 2.05698 [0m(-0.30396)
     | > avg_stopnet_loss:[92m 1.30638 [0m(-0.00282)
     | > avg_decoder_coarse_loss:[92m 2.00891 [0m(-0.10862)
     | > avg_decoder_ddc_loss:[91m 0.00104 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00197 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47209 [0m(-0.00039)
     | > avg_postnet_diff_spec_loss:[92m 0.81164 [0m(-0.00189)
     | > avg_decoder_ssim_loss:[92m 0.32872 [0m(-0.00072)
     | > avg_postnet_ssim_loss:[92m 0.34700 [0m(-0.00270)
     | > avg_loss:[92m 3.38622 [0m(-0.13198)
     | > avg_align_error:[92m 0.99018 [0m(-0.00012)


[4m[1m > EPOCH: 85/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:09:15) [0m

[1m   --> STEP: 20/87 -- GLOBAL_STEP: 277500[0m
     | > decoder_loss: 1.67613  (1.76888)
     | > postnet_loss: 1.32032  (1.43952)
     | > stopnet_loss: 2.05847  (1.56691)
     | > decoder_coarse_loss: 1.60810  (1.71018)
     | > decoder_ddc_loss: 0.00137  (0.00119)
     | > ga_loss: 0.00264  (0.00206)
     | > decoder_diff_spec_loss: 0.48887  (0.48698)
     | > postnet_diff_spec_loss: 0.79402  (0.80559)
     | > decoder_ssim_loss: 0.25734  (0.30470)
     | > postnet_ssim_loss: 0.26595  (0.32220)
     | > loss: 3.67471  (3.28702)
     | > align_error: 0.98650  (0.98841)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 12.57078  (4.64150)
     | > current_lr: 0.00007 
     | > step_time: 2.34980  (3.94195)
     | > loader_time: 0.01690  (0.03732)


[1m   --> STEP: 45/87 -- GLOBAL_STEP: 277525[0m
     | > decoder_loss: 1.64004  (1.74169)
     | > postnet_loss: 1.34654  (1.41199)
     | > stopnet_loss: 2.07311  (1.53216)
     | > decoder_coarse_loss: 1.55051  (1.68573)
     | > decoder_ddc_loss: 0.00087  (0.00125)
     | > ga_loss: 0.00201  (0.00208)
     | > decoder_diff_spec_loss: 0.47308  (0.48311)
     | > postnet_diff_spec_loss: 0.79603  (0.80043)
     | > decoder_ssim_loss: 0.23201  (0.31145)
     | > postnet_ssim_loss: 0.24587  (0.33056)
     | > loss: 3.65442  (3.23412)
     | > align_error: 0.99053  (0.98800)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.42220  (3.95236)
     | > current_lr: 0.00007 
     | > step_time: 4.75520  (3.70177)
     | > loader_time: 0.02580  (0.03146)


[1m   --> STEP: 70/87 -- GLOBAL_STEP: 277550[0m
     | > decoder_loss: 1.70912  (1.74786)
     | > postnet_loss: 1.41283  (1.41642)
     | > stopnet_loss: 1.55767  (1.51019)
     | > decoder_coarse_loss: 1.64991  (1.69037)
     | > decoder_ddc_loss: 0.00132  (0.00127)
     | > ga_loss: 0.00191  (0.00210)
     | > decoder_diff_spec_loss: 0.44757  (0.48151)
     | > postnet_diff_spec_loss: 0.77974  (0.80005)
     | > decoder_ssim_loss: 0.29270  (0.31410)
     | > postnet_ssim_loss: 0.30915  (0.33334)
     | > loss: 3.21779  (3.21689)
     | > align_error: 0.98647  (0.98789)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 9.99281  (4.04917)
     | > current_lr: 0.00007 
     | > step_time: 4.56480  (3.62939)
     | > loader_time: 0.02990  (0.03112)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.02731 [0m(+0.00621)
     | > avg_decoder_loss:[91m 2.25841 [0m(+0.00481)
     | > avg_postnet_loss:[91m 2.09684 [0m(+0.03986)
     | > avg_stopnet_loss:[91m 1.30748 [0m(+0.00110)
     | > avg_decoder_coarse_loss:[91m 2.03577 [0m(+0.02686)
     | > avg_decoder_ddc_loss:[92m 0.00104 [0m(-0.00001)
     | > avg_ga_loss:[91m 0.00197 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47392 [0m(+0.00182)
     | > avg_postnet_diff_spec_loss:[91m 0.81244 [0m(+0.00080)
     | > avg_decoder_ssim_loss:[91m 0.32872 [0m(+0.00000)
     | > avg_postnet_ssim_loss:[91m 0.34792 [0m(+0.00092)
     | > avg_loss:[91m 3.40612 [0m(+0.01990)
     | > avg_align_error:[92m 0.99015 [0m(-0.00003)


[4m[1m > EPOCH: 86/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:16:23) [0m

[1m   --> STEP: 7/87 -- GLOBAL_STEP: 277575[0m
     | > decoder_loss: 1.76923  (1.74660)
     | > postnet_loss: 1.55187  (1.42354)
     | > stopnet_loss: 1.45790  (1.41031)
     | > decoder_coarse_loss: 1.71334  (1.67832)
     | > decoder_ddc_loss: 0.00120  (0.00137)
     | > ga_loss: 0.00199  (0.00223)
     | > decoder_diff_spec_loss: 0.48486  (0.47434)
     | > postnet_diff_spec_loss: 0.82042  (0.79378)
     | > decoder_ssim_loss: 0.31009  (0.32709)
     | > postnet_ssim_loss: 0.33029  (0.35045)
     | > loss: 3.21319  (3.12032)
     | > align_error: 0.98850  (0.98706)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.26805  (6.18739)
     | > current_lr: 0.00007 
     | > step_time: 4.02200  (3.89718)
     | > loader_time: 0.01430  (0.04914)


[1m   --> STEP: 32/87 -- GLOBAL_STEP: 277600[0m
     | > decoder_loss: 1.58131  (1.75165)
     | > postnet_loss: 1.29540  (1.42102)
     | > stopnet_loss: 1.42997  (1.52487)
     | > decoder_coarse_loss: 1.51964  (1.69690)
     | > decoder_ddc_loss: 0.00152  (0.00126)
     | > ga_loss: 0.00238  (0.00208)
     | > decoder_diff_spec_loss: 0.46219  (0.48387)
     | > postnet_diff_spec_loss: 0.77913  (0.80323)
     | > decoder_ssim_loss: 0.32349  (0.31368)
     | > postnet_ssim_loss: 0.34196  (0.33253)
     | > loss: 3.01804  (3.23632)
     | > align_error: 0.98604  (0.98791)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.92293  (4.29528)
     | > current_lr: 0.00007 
     | > step_time: 2.99100  (3.74928)
     | > loader_time: 0.01590  (0.03622)


[1m   --> STEP: 57/87 -- GLOBAL_STEP: 277625[0m
     | > decoder_loss: 1.66320  (1.74260)
     | > postnet_loss: 1.37392  (1.41114)
     | > stopnet_loss: 1.79775  (1.51822)
     | > decoder_coarse_loss: 1.61967  (1.68294)
     | > decoder_ddc_loss: 0.00096  (0.00125)
     | > ga_loss: 0.00200  (0.00207)
     | > decoder_diff_spec_loss: 0.45385  (0.48028)
     | > postnet_diff_spec_loss: 0.78805  (0.80033)
     | > decoder_ssim_loss: 0.26760  (0.31241)
     | > postnet_ssim_loss: 0.28898  (0.33192)
     | > loss: 3.42183  (3.21932)
     | > align_error: 0.98976  (0.98800)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.54398  (4.09248)
     | > current_lr: 0.00007 
     | > step_time: 4.54470  (3.64251)
     | > loader_time: 0.03830  (0.03564)


[1m   --> STEP: 82/87 -- GLOBAL_STEP: 277650[0m
     | > decoder_loss: 1.81077  (1.74647)
     | > postnet_loss: 1.45170  (1.41335)
     | > stopnet_loss: 2.03400  (1.51562)
     | > decoder_coarse_loss: 1.70509  (1.68568)
     | > decoder_ddc_loss: 0.00106  (0.00129)
     | > ga_loss: 0.00232  (0.00210)
     | > decoder_diff_spec_loss: 0.50289  (0.48007)
     | > postnet_diff_spec_loss: 0.80918  (0.79975)
     | > decoder_ssim_loss: 0.23701  (0.31398)
     | > postnet_ssim_loss: 0.24479  (0.33306)
     | > loss: 3.73621  (3.21954)
     | > align_error: 0.98835  (0.98786)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.20328  (4.19181)
     | > current_lr: 0.00007 
     | > step_time: 2.83020  (3.55890)
     | > loader_time: 0.01820  (0.03512)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.87219 [0m(-0.15511)
     | > avg_decoder_loss:[91m 2.28772 [0m(+0.02931)
     | > avg_postnet_loss:[91m 2.38521 [0m(+0.28837)
     | > avg_stopnet_loss:[92m 1.30595 [0m(-0.00153)
     | > avg_decoder_coarse_loss:[92m 2.02761 [0m(-0.00816)
     | > avg_decoder_ddc_loss:[91m 0.00105 [0m(+0.00002)
     | > avg_ga_loss:[92m 0.00196 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47220 [0m(-0.00171)
     | > avg_postnet_diff_spec_loss:[91m 0.81423 [0m(+0.00179)
     | > avg_decoder_ssim_loss:[92m 0.32855 [0m(-0.00017)
     | > avg_postnet_ssim_loss:[91m 0.34890 [0m(+0.00098)
     | > avg_loss:[91m 3.48214 [0m(+0.07602)
     | > avg_align_error:[92m 0.99012 [0m(-0.00003)


[4m[1m > EPOCH: 87/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:23:29) [0m

[1m   --> STEP: 19/87 -- GLOBAL_STEP: 277675[0m
     | > decoder_loss: 1.63408  (1.76846)
     | > postnet_loss: 1.31903  (1.43588)
     | > stopnet_loss: 1.50846  (1.53924)
     | > decoder_coarse_loss: 1.56437  (1.70292)
     | > decoder_ddc_loss: 0.00104  (0.00118)
     | > ga_loss: 0.00176  (0.00203)
     | > decoder_diff_spec_loss: 0.44463  (0.48615)
     | > postnet_diff_spec_loss: 0.76975  (0.80563)
     | > decoder_ssim_loss: 0.30055  (0.30668)
     | > postnet_ssim_loss: 0.31674  (0.32484)
     | > loss: 3.10483  (3.25731)
     | > align_error: 0.99076  (0.98851)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.34280  (4.66703)
     | > current_lr: 0.00007 
     | > step_time: 3.80720  (3.92733)
     | > loader_time: 0.02240  (0.04353)


[1m   --> STEP: 44/87 -- GLOBAL_STEP: 277700[0m
     | > decoder_loss: 1.59977  (1.74055)
     | > postnet_loss: 1.32318  (1.40624)
     | > stopnet_loss: 1.33153  (1.51665)
     | > decoder_coarse_loss: 1.53874  (1.68024)
     | > decoder_ddc_loss: 0.00129  (0.00127)
     | > ga_loss: 0.00215  (0.00207)
     | > decoder_diff_spec_loss: 0.46274  (0.48262)
     | > postnet_diff_spec_loss: 0.78399  (0.80030)
     | > decoder_ssim_loss: 0.33674  (0.31288)
     | > postnet_ssim_loss: 0.35846  (0.33208)
     | > loss: 2.94350  (3.21603)
     | > align_error: 0.98693  (0.98791)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.44085  (4.22557)
     | > current_lr: 0.00007 
     | > step_time: 2.51700  (3.67832)
     | > loader_time: 0.02160  (0.04237)


[1m   --> STEP: 69/87 -- GLOBAL_STEP: 277725[0m
     | > decoder_loss: 1.62098  (1.74416)
     | > postnet_loss: 1.33553  (1.41065)
     | > stopnet_loss: 2.08147  (1.50874)
     | > decoder_coarse_loss: 1.53324  (1.68437)
     | > decoder_ddc_loss: 0.00083  (0.00129)
     | > ga_loss: 0.00175  (0.00208)
     | > decoder_diff_spec_loss: 0.43583  (0.48155)
     | > postnet_diff_spec_loss: 0.75988  (0.80009)
     | > decoder_ssim_loss: 0.22720  (0.31406)
     | > postnet_ssim_loss: 0.23877  (0.33342)
     | > loss: 3.62829  (3.21155)
     | > align_error: 0.98988  (0.98790)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.52847  (4.13648)
     | > current_lr: 0.00007 
     | > step_time: 4.38010  (3.63684)
     | > loader_time: 0.05140  (0.03886)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.27153 [0m(+0.39934)
     | > avg_decoder_loss:[91m 2.31498 [0m(+0.02726)
     | > avg_postnet_loss:[92m 2.14552 [0m(-0.23968)
     | > avg_stopnet_loss:[92m 1.30516 [0m(-0.00080)
     | > avg_decoder_coarse_loss:[91m 2.08975 [0m(+0.06214)
     | > avg_decoder_ddc_loss:[92m 0.00104 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00195 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47501 [0m(+0.00281)
     | > avg_postnet_diff_spec_loss:[92m 0.81197 [0m(-0.00226)
     | > avg_decoder_ssim_loss:[91m 0.32857 [0m(+0.00002)
     | > avg_postnet_ssim_loss:[92m 0.34701 [0m(-0.00189)
     | > avg_loss:[92m 3.44338 [0m(-0.03875)
     | > avg_align_error:[91m 0.99014 [0m(+0.00002)


[4m[1m > EPOCH: 88/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:30:39) [0m

[1m   --> STEP: 6/87 -- GLOBAL_STEP: 277750[0m
     | > decoder_loss: 1.66894  (1.71744)
     | > postnet_loss: 1.22855  (1.38359)
     | > stopnet_loss: 1.17403  (1.38588)
     | > decoder_coarse_loss: 1.60213  (1.67078)
     | > decoder_ddc_loss: 0.00119  (0.00139)
     | > ga_loss: 0.00194  (0.00228)
     | > decoder_diff_spec_loss: 0.46962  (0.47503)
     | > postnet_diff_spec_loss: 0.75896  (0.78871)
     | > decoder_ssim_loss: 0.36142  (0.32929)
     | > postnet_ssim_loss: 0.39713  (0.35246)
     | > loss: 2.80571  (3.07693)
     | > align_error: 0.98879  (0.98661)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.05138  (5.10480)
     | > current_lr: 0.00007 
     | > step_time: 3.00580  (3.90437)
     | > loader_time: 0.01830  (0.04399)


[1m   --> STEP: 31/87 -- GLOBAL_STEP: 277775[0m
     | > decoder_loss: 1.68994  (1.75145)
     | > postnet_loss: 1.38086  (1.41782)
     | > stopnet_loss: 1.54718  (1.51843)
     | > decoder_coarse_loss: 1.66905  (1.69768)
     | > decoder_ddc_loss: 0.00129  (0.00125)
     | > ga_loss: 0.00211  (0.00205)
     | > decoder_diff_spec_loss: 0.45497  (0.48378)
     | > postnet_diff_spec_loss: 0.78980  (0.80391)
     | > decoder_ssim_loss: 0.29797  (0.31301)
     | > postnet_ssim_loss: 0.31900  (0.33185)
     | > loss: 3.20846  (3.22887)
     | > align_error: 0.98805  (0.98788)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.07919  (3.97469)
     | > current_lr: 0.00007 
     | > step_time: 3.77120  (3.76484)
     | > loader_time: 0.02000  (0.03762)


[1m   --> STEP: 56/87 -- GLOBAL_STEP: 277800[0m
     | > decoder_loss: 1.86350  (1.73960)
     | > postnet_loss: 1.47871  (1.40900)
     | > stopnet_loss: 1.31137  (1.50556)
     | > decoder_coarse_loss: 1.76298  (1.68281)
     | > decoder_ddc_loss: 0.00173  (0.00126)
     | > ga_loss: 0.00248  (0.00206)
     | > decoder_diff_spec_loss: 0.51004  (0.48048)
     | > postnet_diff_spec_loss: 0.81815  (0.80021)
     | > decoder_ssim_loss: 0.34348  (0.31279)
     | > postnet_ssim_loss: 0.35589  (0.33230)
     | > loss: 3.10737  (3.20550)
     | > align_error: 0.98360  (0.98789)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.73342  (4.00454)
     | > current_lr: 0.00007 
     | > step_time: 2.91860  (3.65806)
     | > loader_time: 0.06760  (0.03626)


[1m   --> STEP: 81/87 -- GLOBAL_STEP: 277825[0m
     | > decoder_loss: 1.55761  (1.73981)
     | > postnet_loss: 1.27592  (1.40924)
     | > stopnet_loss: 1.99290  (1.50151)
     | > decoder_coarse_loss: 1.49205  (1.68220)
     | > decoder_ddc_loss: 0.00117  (0.00128)
     | > ga_loss: 0.00216  (0.00209)
     | > decoder_diff_spec_loss: 0.44366  (0.47922)
     | > postnet_diff_spec_loss: 0.77912  (0.79911)
     | > decoder_ssim_loss: 0.24178  (0.31448)
     | > postnet_ssim_loss: 0.25647  (0.33374)
     | > loss: 3.51564  (3.20172)
     | > align_error: 0.98734  (0.98777)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.77483  (4.10017)
     | > current_lr: 0.00007 
     | > step_time: 3.49110  (3.59479)
     | > loader_time: 0.01540  (0.03353)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 5.16508 [0m(-0.10644)
     | > avg_decoder_loss:[92m 2.27689 [0m(-0.03809)
     | > avg_postnet_loss:[91m 2.16785 [0m(+0.02232)
     | > avg_stopnet_loss:[92m 1.30500 [0m(-0.00016)
     | > avg_decoder_coarse_loss:[92m 2.00957 [0m(-0.08018)
     | > avg_decoder_ddc_loss:[91m 0.00109 [0m(+0.00006)
     | > avg_ga_loss:[92m 0.00195 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[92m 0.47029 [0m(-0.00472)
     | > avg_postnet_diff_spec_loss:[91m 0.81312 [0m(+0.00116)
     | > avg_decoder_ssim_loss:[92m 0.32810 [0m(-0.00047)
     | > avg_postnet_ssim_loss:[91m 0.34773 [0m(+0.00073)
     | > avg_loss:[92m 3.41840 [0m(-0.02498)
     | > avg_align_error:[92m 0.99007 [0m(-0.00008)


[4m[1m > EPOCH: 89/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:37:54) [0m

[1m   --> STEP: 18/87 -- GLOBAL_STEP: 277850[0m
     | > decoder_loss: 1.67868  (1.77590)
     | > postnet_loss: 1.44890  (1.42607)
     | > stopnet_loss: 1.63727  (1.53449)
     | > decoder_coarse_loss: 1.59917  (1.70259)
     | > decoder_ddc_loss: 0.00097  (0.00123)
     | > ga_loss: 0.00165  (0.00201)
     | > decoder_diff_spec_loss: 0.45839  (0.48820)
     | > postnet_diff_spec_loss: 0.80508  (0.80686)
     | > decoder_ssim_loss: 0.28030  (0.30670)
     | > postnet_ssim_loss: 0.29740  (0.32453)
     | > loss: 3.28774  (3.25258)
     | > align_error: 0.99020  (0.98813)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.99532  (4.64680)
     | > current_lr: 0.00007 
     | > step_time: 4.69390  (3.90250)
     | > loader_time: 0.02280  (0.03000)


[1m   --> STEP: 43/87 -- GLOBAL_STEP: 277875[0m
     | > decoder_loss: 1.84377  (1.73910)
     | > postnet_loss: 1.41430  (1.39758)
     | > stopnet_loss: 1.57318  (1.52244)
     | > decoder_coarse_loss: 1.79675  (1.68043)
     | > decoder_ddc_loss: 0.00123  (0.00130)
     | > ga_loss: 0.00183  (0.00205)
     | > decoder_diff_spec_loss: 0.49913  (0.48218)
     | > postnet_diff_spec_loss: 0.79324  (0.80022)
     | > decoder_ssim_loss: 0.28952  (0.31188)
     | > postnet_ssim_loss: 0.31621  (0.33106)
     | > loss: 3.32087  (3.21864)
     | > align_error: 0.98869  (0.98771)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.79507  (4.10553)
     | > current_lr: 0.00007 
     | > step_time: 3.66460  (3.69001)
     | > loader_time: 0.01840  (0.02963)


[1m   --> STEP: 68/87 -- GLOBAL_STEP: 277900[0m
     | > decoder_loss: 1.55328  (1.74053)
     | > postnet_loss: 1.24083  (1.40345)
     | > stopnet_loss: 1.04706  (1.50198)
     | > decoder_coarse_loss: 1.47867  (1.68343)
     | > decoder_ddc_loss: 0.00206  (0.00131)
     | > ga_loss: 0.00240  (0.00207)
     | > decoder_diff_spec_loss: 0.46625  (0.48111)
     | > postnet_diff_spec_loss: 0.77681  (0.80031)
     | > decoder_ssim_loss: 0.42072  (0.31484)
     | > postnet_ssim_loss: 0.44791  (0.33441)
     | > loss: 2.65571  (3.20218)
     | > align_error: 0.98240  (0.98767)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.14942  (4.12361)
     | > current_lr: 0.00007 
     | > step_time: 2.33250  (3.63108)
     | > loader_time: 0.02360  (0.03101)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.94546 [0m(-0.21963)
     | > avg_decoder_loss:[92m 2.25012 [0m(-0.02677)
     | > avg_postnet_loss:[92m 2.16706 [0m(-0.00079)
     | > avg_stopnet_loss:[92m 1.30325 [0m(-0.00175)
     | > avg_decoder_coarse_loss:[92m 1.97895 [0m(-0.03062)
     | > avg_decoder_ddc_loss:[92m 0.00108 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00194 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47231 [0m(+0.00202)
     | > avg_postnet_diff_spec_loss:[91m 0.81335 [0m(+0.00023)
     | > avg_decoder_ssim_loss:[92m 0.32786 [0m(-0.00024)
     | > avg_postnet_ssim_loss:[92m 0.34765 [0m(-0.00008)
     | > avg_loss:[92m 3.40256 [0m(-0.01585)
     | > avg_align_error:[91m 0.99008 [0m(+0.00001)


[4m[1m > EPOCH: 90/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:45:02) [0m

[1m   --> STEP: 5/87 -- GLOBAL_STEP: 277925[0m
     | > decoder_loss: 1.70272  (1.73749)
     | > postnet_loss: 1.38611  (1.41776)
     | > stopnet_loss: 1.48774  (1.40883)
     | > decoder_coarse_loss: 1.63559  (1.67997)
     | > decoder_ddc_loss: 0.00149  (0.00145)
     | > ga_loss: 0.00223  (0.00230)
     | > decoder_diff_spec_loss: 0.44497  (0.47499)
     | > postnet_diff_spec_loss: 0.78212  (0.79474)
     | > decoder_ssim_loss: 0.30540  (0.32314)
     | > postnet_ssim_loss: 0.32738  (0.34375)
     | > loss: 3.14534  (3.11363)
     | > align_error: 0.98594  (0.98619)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.39733  (4.75342)
     | > current_lr: 0.00007 
     | > step_time: 3.93080  (4.09063)
     | > loader_time: 0.02390  (0.03987)


[1m   --> STEP: 30/87 -- GLOBAL_STEP: 277950[0m
     | > decoder_loss: 1.65153  (1.75143)
     | > postnet_loss: 1.35536  (1.41905)
     | > stopnet_loss: 1.52847  (1.51589)
     | > decoder_coarse_loss: 1.58233  (1.69224)
     | > decoder_ddc_loss: 0.00136  (0.00129)
     | > ga_loss: 0.00195  (0.00204)
     | > decoder_diff_spec_loss: 0.46453  (0.48521)
     | > postnet_diff_spec_loss: 0.78529  (0.80400)
     | > decoder_ssim_loss: 0.29118  (0.31311)
     | > postnet_ssim_loss: 0.30586  (0.33211)
     | > loss: 3.14760  (3.22571)
     | > align_error: 0.98700  (0.98777)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.61918  (3.97384)
     | > current_lr: 0.00007 
     | > step_time: 4.59390  (3.78387)
     | > loader_time: 0.02310  (0.03272)


[1m   --> STEP: 55/87 -- GLOBAL_STEP: 277975[0m
     | > decoder_loss: 1.59258  (1.73162)
     | > postnet_loss: 1.33739  (1.40205)
     | > stopnet_loss: 1.52575  (1.51050)
     | > decoder_coarse_loss: 1.52412  (1.67222)
     | > decoder_ddc_loss: 0.00104  (0.00128)
     | > ga_loss: 0.00185  (0.00204)
     | > decoder_diff_spec_loss: 0.44872  (0.47968)
     | > postnet_diff_spec_loss: 0.78759  (0.79954)
     | > decoder_ssim_loss: 0.29293  (0.31184)
     | > postnet_ssim_loss: 0.31733  (0.33162)
     | > loss: 3.11041  (3.20315)
     | > align_error: 0.98979  (0.98782)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.86496  (3.94306)
     | > current_lr: 0.00007 
     | > step_time: 3.99730  (3.65629)
     | > loader_time: 0.01900  (0.03312)


[1m   --> STEP: 80/87 -- GLOBAL_STEP: 278000[0m
     | > decoder_loss: 1.63990  (1.73633)
     | > postnet_loss: 1.31415  (1.40509)
     | > stopnet_loss: 1.47678  (1.49162)
     | > decoder_coarse_loss: 1.63057  (1.67743)
     | > decoder_ddc_loss: 0.00173  (0.00130)
     | > ga_loss: 0.00268  (0.00206)
     | > decoder_diff_spec_loss: 0.47923  (0.47972)
     | > postnet_diff_spec_loss: 0.80094  (0.79898)
     | > decoder_ssim_loss: 0.33323  (0.31499)
     | > postnet_ssim_loss: 0.35297  (0.33446)
     | > loss: 3.12837  (3.18902)
     | > align_error: 0.98423  (0.98767)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 8.58934  (4.10168)
     | > current_lr: 0.00007 
     | > step_time: 2.61770  (3.58001)
     | > loader_time: 0.01670  (0.03028)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.10648 [0m(+0.16102)
     | > avg_decoder_loss:[91m 2.27051 [0m(+0.02039)
     | > avg_postnet_loss:[91m 2.27378 [0m(+0.10671)
     | > avg_stopnet_loss:[91m 1.30497 [0m(+0.00173)
     | > avg_decoder_coarse_loss:[91m 2.03971 [0m(+0.06076)
     | > avg_decoder_ddc_loss:[91m 0.00109 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00193 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47264 [0m(+0.00033)
     | > avg_postnet_diff_spec_loss:[92m 0.81222 [0m(-0.00113)
     | > avg_decoder_ssim_loss:[91m 0.32794 [0m(+0.00008)
     | > avg_postnet_ssim_loss:[91m 0.34857 [0m(+0.00092)
     | > avg_loss:[91m 3.45126 [0m(+0.04870)
     | > avg_align_error:[92m 0.99001 [0m(-0.00007)


[4m[1m > EPOCH: 91/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:52:14) [0m

[1m   --> STEP: 17/87 -- GLOBAL_STEP: 278025[0m
     | > decoder_loss: 1.66579  (1.77193)
     | > postnet_loss: 1.34420  (1.43478)
     | > stopnet_loss: 0.85529  (1.51709)
     | > decoder_coarse_loss: 1.62331  (1.71306)
     | > decoder_ddc_loss: 0.00146  (0.00126)
     | > ga_loss: 0.00151  (0.00201)
     | > decoder_diff_spec_loss: 0.46369  (0.48886)
     | > postnet_diff_spec_loss: 0.78633  (0.80736)
     | > decoder_ssim_loss: 0.42995  (0.30769)
     | > postnet_ssim_loss: 0.45743  (0.32643)
     | > loss: 2.55588  (3.23997)
     | > align_error: 0.98871  (0.98790)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.08593  (4.35558)
     | > current_lr: 0.00007 
     | > step_time: 5.03990  (3.92046)
     | > loader_time: 0.04050  (0.03162)


[1m   --> STEP: 42/87 -- GLOBAL_STEP: 278050[0m
     | > decoder_loss: 1.89822  (1.73330)
     | > postnet_loss: 1.42768  (1.40039)
     | > stopnet_loss: 1.95843  (1.51094)
     | > decoder_coarse_loss: 1.79680  (1.67531)
     | > decoder_ddc_loss: 0.00110  (0.00133)
     | > ga_loss: 0.00207  (0.00203)
     | > decoder_diff_spec_loss: 0.52743  (0.48170)
     | > postnet_diff_spec_loss: 0.80589  (0.80012)
     | > decoder_ssim_loss: 0.23901  (0.31194)
     | > postnet_ssim_loss: 0.25205  (0.33123)
     | > loss: 3.70581  (3.20492)
     | > align_error: 0.98789  (0.98755)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.67516  (4.07048)
     | > current_lr: 0.00007 
     | > step_time: 3.72240  (3.70515)
     | > loader_time: 0.02250  (0.03574)


[1m   --> STEP: 67/87 -- GLOBAL_STEP: 278075[0m
     | > decoder_loss: 1.70863  (1.74045)
     | > postnet_loss: 1.44893  (1.40684)
     | > stopnet_loss: 1.57282  (1.49733)
     | > decoder_coarse_loss: 1.63698  (1.68090)
     | > decoder_ddc_loss: 0.00116  (0.00132)
     | > ga_loss: 0.00200  (0.00204)
     | > decoder_diff_spec_loss: 0.47579  (0.48169)
     | > postnet_diff_spec_loss: 0.81274  (0.80013)
     | > decoder_ssim_loss: 0.29422  (0.31298)
     | > postnet_ssim_loss: 0.31482  (0.33260)
     | > loss: 3.25615  (3.19678)
     | > align_error: 0.98889  (0.98764)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.88809  (4.02771)
     | > current_lr: 0.00007 
     | > step_time: 3.49350  (3.61311)
     | > loader_time: 0.06840  (0.03722)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.95914 [0m(-0.14733)
     | > avg_decoder_loss:[92m 2.20376 [0m(-0.06675)
     | > avg_postnet_loss:[92m 2.19327 [0m(-0.08051)
     | > avg_stopnet_loss:[92m 1.30448 [0m(-0.00050)
     | > avg_decoder_coarse_loss:[92m 1.99534 [0m(-0.04436)
     | > avg_decoder_ddc_loss:[92m 0.00108 [0m(-0.00001)
     | > avg_ga_loss:[92m 0.00192 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47364 [0m(+0.00100)
     | > avg_postnet_diff_spec_loss:[91m 0.81371 [0m(+0.00148)
     | > avg_decoder_ssim_loss:[92m 0.32756 [0m(-0.00038)
     | > avg_postnet_ssim_loss:[92m 0.34769 [0m(-0.00088)
     | > avg_loss:[92m 3.40311 [0m(-0.04815)
     | > avg_align_error:[92m 0.98982 [0m(-0.00019)


[4m[1m > EPOCH: 92/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 20:59:23) [0m

[1m   --> STEP: 4/87 -- GLOBAL_STEP: 278100[0m
     | > decoder_loss: 1.72073  (1.74745)
     | > postnet_loss: 1.32200  (1.42198)
     | > stopnet_loss: 1.41300  (1.41467)
     | > decoder_coarse_loss: 1.64455  (1.66589)
     | > decoder_ddc_loss: 0.00102  (0.00148)
     | > ga_loss: 0.00202  (0.00229)
     | > decoder_diff_spec_loss: 0.47322  (0.48142)
     | > postnet_diff_spec_loss: 0.76553  (0.79737)
     | > decoder_ssim_loss: 0.32435  (0.32713)
     | > postnet_ssim_loss: 0.34825  (0.34706)
     | > loss: 3.07301  (3.12357)
     | > align_error: 0.99023  (0.98593)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.91350  (4.98121)
     | > current_lr: 0.00007 
     | > step_time: 3.66870  (4.23337)
     | > loader_time: 0.13170  (0.08731)


[1m   --> STEP: 29/87 -- GLOBAL_STEP: 278125[0m
     | > decoder_loss: 1.75346  (1.74976)
     | > postnet_loss: 1.41853  (1.41523)
     | > stopnet_loss: 1.29589  (1.51330)
     | > decoder_coarse_loss: 1.68425  (1.68957)
     | > decoder_ddc_loss: 0.00157  (0.00132)
     | > ga_loss: 0.00220  (0.00202)
     | > decoder_diff_spec_loss: 0.48288  (0.48480)
     | > postnet_diff_spec_loss: 0.81107  (0.80423)
     | > decoder_ssim_loss: 0.33844  (0.31327)
     | > postnet_ssim_loss: 0.37014  (0.33268)
     | > loss: 3.02201  (3.22113)
     | > align_error: 0.98585  (0.98760)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.79560  (3.93066)
     | > current_lr: 0.00007 
     | > step_time: 3.39660  (3.73812)
     | > loader_time: 0.02270  (0.04652)


[1m   --> STEP: 54/87 -- GLOBAL_STEP: 278150[0m
     | > decoder_loss: 1.77459  (1.73170)
     | > postnet_loss: 1.37835  (1.40032)
     | > stopnet_loss: 1.79659  (1.50539)
     | > decoder_coarse_loss: 1.68913  (1.67050)
     | > decoder_ddc_loss: 0.00088  (0.00132)
     | > ga_loss: 0.00171  (0.00202)
     | > decoder_diff_spec_loss: 0.48564  (0.47963)
     | > postnet_diff_spec_loss: 0.78844  (0.79949)
     | > decoder_ssim_loss: 0.24956  (0.31175)
     | > postnet_ssim_loss: 0.27293  (0.33152)
     | > loss: 3.46502  (3.19707)
     | > align_error: 0.99070  (0.98758)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.04618  (4.00821)
     | > current_lr: 0.00007 
     | > step_time: 3.60070  (3.65030)
     | > loader_time: 0.02850  (0.04176)


[1m   --> STEP: 79/87 -- GLOBAL_STEP: 278175[0m
     | > decoder_loss: 1.70967  (1.73265)
     | > postnet_loss: 1.31992  (1.40179)
     | > stopnet_loss: 1.25755  (1.49220)
     | > decoder_coarse_loss: 1.67473  (1.67398)
     | > decoder_ddc_loss: 0.00119  (0.00134)
     | > ga_loss: 0.00190  (0.00204)
     | > decoder_diff_spec_loss: 0.45785  (0.47883)
     | > postnet_diff_spec_loss: 0.77511  (0.79869)
     | > decoder_ssim_loss: 0.33537  (0.31425)
     | > postnet_ssim_loss: 0.35647  (0.33392)
     | > loss: 2.92462  (3.18626)
     | > align_error: 0.98919  (0.98748)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.51234  (4.09935)
     | > current_lr: 0.00007 
     | > step_time: 3.52300  (3.56955)
     | > loader_time: 0.04250  (0.03949)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.90523 [0m(-0.05391)
     | > avg_decoder_loss:[91m 2.22662 [0m(+0.02286)
     | > avg_postnet_loss:[92m 2.14847 [0m(-0.04480)
     | > avg_stopnet_loss:[91m 1.30459 [0m(+0.00011)
     | > avg_decoder_coarse_loss:[91m 2.00903 [0m(+0.01368)
     | > avg_decoder_ddc_loss:[91m 0.00109 [0m(+0.00002)
     | > avg_ga_loss:[91m 0.00194 [0m(+0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.47220 [0m(-0.00145)
     | > avg_postnet_diff_spec_loss:[92m 0.81230 [0m(-0.00141)
     | > avg_decoder_ssim_loss:[92m 0.32749 [0m(-0.00007)
     | > avg_postnet_ssim_loss:[92m 0.34682 [0m(-0.00087)
     | > avg_loss:[92m 3.40029 [0m(-0.00282)
     | > avg_align_error:[92m 0.98972 [0m(-0.00010)


[4m[1m > EPOCH: 93/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:06:29) [0m

[1m   --> STEP: 16/87 -- GLOBAL_STEP: 278200[0m
     | > decoder_loss: 1.70089  (1.77618)
     | > postnet_loss: 1.39074  (1.42915)
     | > stopnet_loss: 1.66091  (1.55405)
     | > decoder_coarse_loss: 1.61442  (1.72247)
     | > decoder_ddc_loss: 0.00084  (0.00124)
     | > ga_loss: 0.00143  (0.00205)
     | > decoder_diff_spec_loss: 0.46979  (0.48998)
     | > postnet_diff_spec_loss: 0.80403  (0.80833)
     | > decoder_ssim_loss: 0.26259  (0.29940)
     | > postnet_ssim_loss: 0.28397  (0.31797)
     | > loss: 3.29990  (3.27546)
     | > align_error: 0.99053  (0.98782)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.44151  (5.08219)
     | > current_lr: 0.00007 
     | > step_time: 4.69970  (3.93321)
     | > loader_time: 0.02850  (0.03444)


[1m   --> STEP: 41/87 -- GLOBAL_STEP: 278225[0m
     | > decoder_loss: 1.59429  (1.72954)
     | > postnet_loss: 1.37983  (1.39528)
     | > stopnet_loss: 1.70746  (1.49695)
     | > decoder_coarse_loss: 1.50751  (1.66920)
     | > decoder_ddc_loss: 0.00168  (0.00132)
     | > ga_loss: 0.00260  (0.00203)
     | > decoder_diff_spec_loss: 0.43488  (0.47998)
     | > postnet_diff_spec_loss: 0.78492  (0.79987)
     | > decoder_ssim_loss: 0.28228  (0.31339)
     | > postnet_ssim_loss: 0.31207  (0.33312)
     | > loss: 3.29485  (3.18751)
     | > align_error: 0.98417  (0.98751)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 7.56070  (4.26816)
     | > current_lr: 0.00007 
     | > step_time: 2.29810  (3.72419)
     | > loader_time: 0.01890  (0.03933)


[1m   --> STEP: 66/87 -- GLOBAL_STEP: 278250[0m
     | > decoder_loss: 2.02997  (1.74510)
     | > postnet_loss: 1.52982  (1.40705)
     | > stopnet_loss: 1.43361  (1.49932)
     | > decoder_coarse_loss: 1.91919  (1.68018)
     | > decoder_ddc_loss: 0.00097  (0.00131)
     | > ga_loss: 0.00158  (0.00204)
     | > decoder_diff_spec_loss: 0.51478  (0.48083)
     | > postnet_diff_spec_loss: 0.80499  (0.80002)
     | > decoder_ssim_loss: 0.30630  (0.31290)
     | > postnet_ssim_loss: 0.32201  (0.33280)
     | > loss: 3.29852  (3.19957)
     | > align_error: 0.99077  (0.98758)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.75125  (4.35052)
     | > current_lr: 0.00007 
     | > step_time: 5.30970  (3.65189)
     | > loader_time: 0.02060  (0.03553)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.77486 [0m(-0.13037)
     | > avg_decoder_loss:[91m 2.27276 [0m(+0.04613)
     | > avg_postnet_loss:[91m 2.24319 [0m(+0.09473)
     | > avg_stopnet_loss:[92m 1.30352 [0m(-0.00106)
     | > avg_decoder_coarse_loss:[91m 2.03894 [0m(+0.02992)
     | > avg_decoder_ddc_loss:[92m 0.00109 [0m(-0.00000)
     | > avg_ga_loss:[92m 0.00192 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.47293 [0m(+0.00073)
     | > avg_postnet_diff_spec_loss:[92m 0.81227 [0m(-0.00003)
     | > avg_decoder_ssim_loss:[91m 0.32786 [0m(+0.00038)
     | > avg_postnet_ssim_loss:[91m 0.34760 [0m(+0.00077)
     | > avg_loss:[91m 3.44228 [0m(+0.04199)
     | > avg_align_error:[91m 0.98981 [0m(+0.00009)


[4m[1m > EPOCH: 94/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:13:38) [0m

[1m   --> STEP: 3/87 -- GLOBAL_STEP: 278275[0m
     | > decoder_loss: 1.71640  (1.75266)
     | > postnet_loss: 1.42122  (1.47170)
     | > stopnet_loss: 1.54365  (1.41289)
     | > decoder_coarse_loss: 1.64428  (1.67937)
     | > decoder_ddc_loss: 0.00161  (0.00169)
     | > ga_loss: 0.00221  (0.00237)
     | > decoder_diff_spec_loss: 0.48141  (0.48185)
     | > postnet_diff_spec_loss: 0.79195  (0.80998)
     | > decoder_ssim_loss: 0.29860  (0.32687)
     | > postnet_ssim_loss: 0.32021  (0.34735)
     | > loss: 3.22363  (3.14260)
     | > align_error: 0.98504  (0.98450)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.66683  (6.41983)
     | > current_lr: 0.00007 
     | > step_time: 4.67720  (4.33345)
     | > loader_time: 0.09200  (0.08795)


[1m   --> STEP: 28/87 -- GLOBAL_STEP: 278300[0m
     | > decoder_loss: 1.67671  (1.74777)
     | > postnet_loss: 1.33110  (1.41670)
     | > stopnet_loss: 0.80624  (1.51506)
     | > decoder_coarse_loss: 1.66708  (1.68961)
     | > decoder_ddc_loss: 0.00235  (0.00135)
     | > ga_loss: 0.00207  (0.00199)
     | > decoder_diff_spec_loss: 0.47878  (0.48439)
     | > postnet_diff_spec_loss: 0.78842  (0.80392)
     | > decoder_ssim_loss: 0.48009  (0.31213)
     | > postnet_ssim_loss: 0.51550  (0.33122)
     | > loss: 2.55158  (3.22178)
     | > align_error: 0.98374  (0.98747)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.59570  (4.15481)
     | > current_lr: 0.00007 
     | > step_time: 2.60660  (3.73430)
     | > loader_time: 0.01610  (0.04069)


[1m   --> STEP: 53/87 -- GLOBAL_STEP: 278325[0m
     | > decoder_loss: 1.82902  (1.73000)
     | > postnet_loss: 1.48516  (1.40016)
     | > stopnet_loss: 1.53238  (1.49581)
     | > decoder_coarse_loss: 1.75874  (1.66917)
     | > decoder_ddc_loss: 0.00128  (0.00136)
     | > ga_loss: 0.00186  (0.00201)
     | > decoder_diff_spec_loss: 0.48281  (0.47882)
     | > postnet_diff_spec_loss: 0.79804  (0.79945)
     | > decoder_ssim_loss: 0.29599  (0.31263)
     | > postnet_ssim_loss: 0.30900  (0.33238)
     | > loss: 3.28170  (3.18683)
     | > align_error: 0.98830  (0.98738)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.66737  (4.20522)
     | > current_lr: 0.00007 
     | > step_time: 4.16500  (3.64105)
     | > loader_time: 0.06100  (0.03566)


[1m   --> STEP: 78/87 -- GLOBAL_STEP: 278350[0m
     | > decoder_loss: 1.73396  (1.73466)
     | > postnet_loss: 1.46402  (1.40843)
     | > stopnet_loss: 1.21119  (1.49341)
     | > decoder_coarse_loss: 1.70289  (1.67298)
     | > decoder_ddc_loss: 0.00179  (0.00136)
     | > ga_loss: 0.00217  (0.00202)
     | > decoder_diff_spec_loss: 0.47527  (0.47847)
     | > postnet_diff_spec_loss: 0.80140  (0.79879)
     | > decoder_ssim_loss: 0.35947  (0.31367)
     | > postnet_ssim_loss: 0.38191  (0.33346)
     | > loss: 2.95223  (3.18898)
     | > align_error: 0.98422  (0.98739)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.03529  (4.32367)
     | > current_lr: 0.00007 
     | > step_time: 2.80620  (3.57957)
     | > loader_time: 0.01430  (0.03645)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.13680 [0m(+0.36193)
     | > avg_decoder_loss:[92m 2.20912 [0m(-0.06364)
     | > avg_postnet_loss:[92m 2.05716 [0m(-0.18603)
     | > avg_stopnet_loss:[91m 1.30362 [0m(+0.00009)
     | > avg_decoder_coarse_loss:[91m 2.07145 [0m(+0.03250)
     | > avg_decoder_ddc_loss:[91m 0.00110 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00190 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[91m 0.47385 [0m(+0.00092)
     | > avg_postnet_diff_spec_loss:[91m 0.81264 [0m(+0.00037)
     | > avg_decoder_ssim_loss:[92m 0.32752 [0m(-0.00035)
     | > avg_postnet_ssim_loss:[92m 0.34693 [0m(-0.00066)
     | > avg_loss:[92m 3.38808 [0m(-0.05420)
     | > avg_align_error:[92m 0.98969 [0m(-0.00012)


[4m[1m > EPOCH: 95/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:20:40) [0m

[1m   --> STEP: 15/87 -- GLOBAL_STEP: 278375[0m
     | > decoder_loss: 1.68261  (1.77714)
     | > postnet_loss: 1.40145  (1.43539)
     | > stopnet_loss: 2.07423  (1.56150)
     | > decoder_coarse_loss: 1.64052  (1.72224)
     | > decoder_ddc_loss: 0.00087  (0.00129)
     | > ga_loss: 0.00165  (0.00206)
     | > decoder_diff_spec_loss: 0.48280  (0.49108)
     | > postnet_diff_spec_loss: 0.82062  (0.80814)
     | > decoder_ssim_loss: 0.23669  (0.30190)
     | > postnet_ssim_loss: 0.24276  (0.32045)
     | > loss: 3.70956  (3.28620)
     | > align_error: 0.99058  (0.98754)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.13664  (5.14843)
     | > current_lr: 0.00007 
     | > step_time: 4.42350  (3.92621)
     | > loader_time: 0.06150  (0.04640)


[1m   --> STEP: 40/87 -- GLOBAL_STEP: 278400[0m
     | > decoder_loss: 1.67434  (1.72806)
     | > postnet_loss: 1.33407  (1.39690)
     | > stopnet_loss: 1.87062  (1.49947)
     | > decoder_coarse_loss: 1.58415  (1.67482)
     | > decoder_ddc_loss: 0.00075  (0.00133)
     | > ga_loss: 0.00176  (0.00199)
     | > decoder_diff_spec_loss: 0.46513  (0.48051)
     | > postnet_diff_spec_loss: 0.78455  (0.80017)
     | > decoder_ssim_loss: 0.24803  (0.31402)
     | > postnet_ssim_loss: 0.26864  (0.33369)
     | > loss: 3.46934  (3.19178)
     | > align_error: 0.99147  (0.98749)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.20147  (4.19883)
     | > current_lr: 0.00007 
     | > step_time: 4.82460  (3.76769)
     | > loader_time: 0.04640  (0.03713)


[1m   --> STEP: 65/87 -- GLOBAL_STEP: 278425[0m
     | > decoder_loss: 1.88412  (1.73835)
     | > postnet_loss: 1.40956  (1.40736)
     | > stopnet_loss: 1.45760  (1.50162)
     | > decoder_coarse_loss: 1.81098  (1.68082)
     | > decoder_ddc_loss: 0.00150  (0.00134)
     | > ga_loss: 0.00211  (0.00202)
     | > decoder_diff_spec_loss: 0.50580  (0.48013)
     | > postnet_diff_spec_loss: 0.79800  (0.79960)
     | > decoder_ssim_loss: 0.31991  (0.31274)
     | > postnet_ssim_loss: 0.34331  (0.33286)
     | > loss: 3.23644  (3.20001)
     | > align_error: 0.98665  (0.98739)
     | > amp_scaler: 65536.00000  (34280.36923)
     | > grad_norm: 6.77533  (4.48112)
     | > current_lr: 0.00007 
     | > step_time: 2.77840  (3.63164)
     | > loader_time: 0.05810  (0.03856)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.61391 [0m(-0.52289)
     | > avg_decoder_loss:[92m 2.10290 [0m(-0.10622)
     | > avg_postnet_loss:[92m 1.86815 [0m(-0.18900)
     | > avg_stopnet_loss:[92m 1.30220 [0m(-0.00142)
     | > avg_decoder_coarse_loss:[92m 1.95151 [0m(-0.11994)
     | > avg_decoder_ddc_loss:[92m 0.00108 [0m(-0.00002)
     | > avg_ga_loss:[92m 0.00189 [0m(-0.00001)
     | > avg_decoder_diff_spec_loss:[92m 0.47312 [0m(-0.00073)
     | > avg_postnet_diff_spec_loss:[92m 0.81069 [0m(-0.00195)
     | > avg_decoder_ssim_loss:[92m 0.32664 [0m(-0.00088)
     | > avg_postnet_ssim_loss:[92m 0.34436 [0m(-0.00258)
     | > avg_loss:[92m 3.28127 [0m(-0.10681)
     | > avg_align_error:[92m 0.98960 [0m(-0.00009)


[4m[1m > EPOCH: 96/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:27:47) [0m

[1m   --> STEP: 2/87 -- GLOBAL_STEP: 278450[0m
     | > decoder_loss: 1.90193  (1.77029)
     | > postnet_loss: 1.63137  (1.49172)
     | > stopnet_loss: 1.24375  (1.30100)
     | > decoder_coarse_loss: 1.80672  (1.69225)
     | > decoder_ddc_loss: 0.00162  (0.00170)
     | > ga_loss: 0.00247  (0.00244)
     | > decoder_diff_spec_loss: 0.50328  (0.48612)
     | > postnet_diff_spec_loss: 0.83783  (0.81616)
     | > decoder_ssim_loss: 0.34701  (0.34199)
     | > postnet_ssim_loss: 0.36305  (0.35933)
     | > loss: 3.10428  (3.05310)
     | > align_error: 0.98468  (0.98401)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.92114  (2.96168)
     | > current_lr: 0.00007 
     | > step_time: 3.67360  (4.01650)
     | > loader_time: 0.06530  (0.04152)


[1m   --> STEP: 27/87 -- GLOBAL_STEP: 278475[0m
     | > decoder_loss: 1.88002  (1.74606)
     | > postnet_loss: 1.55563  (1.40840)
     | > stopnet_loss: 1.52114  (1.54386)
     | > decoder_coarse_loss: 1.85439  (1.68949)
     | > decoder_ddc_loss: 0.00126  (0.00126)
     | > ga_loss: 0.00194  (0.00199)
     | > decoder_diff_spec_loss: 0.50619  (0.48473)
     | > postnet_diff_spec_loss: 0.83445  (0.80387)
     | > decoder_ssim_loss: 0.29403  (0.30564)
     | > postnet_ssim_loss: 0.31255  (0.32385)
     | > loss: 3.34048  (3.24463)
     | > align_error: 0.98803  (0.98763)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.85097  (3.82064)
     | > current_lr: 0.00007 
     | > step_time: 3.65800  (3.79778)
     | > loader_time: 0.01910  (0.04392)


[1m   --> STEP: 52/87 -- GLOBAL_STEP: 278500[0m
     | > decoder_loss: 1.80969  (1.72284)
     | > postnet_loss: 1.44024  (1.39276)
     | > stopnet_loss: 1.82068  (1.49777)
     | > decoder_coarse_loss: 1.69578  (1.66516)
     | > decoder_ddc_loss: 0.00086  (0.00131)
     | > ga_loss: 0.00182  (0.00201)
     | > decoder_diff_spec_loss: 0.46838  (0.47907)
     | > postnet_diff_spec_loss: 0.80942  (0.79942)
     | > decoder_ssim_loss: 0.25146  (0.31257)
     | > postnet_ssim_loss: 0.27115  (0.33269)
     | > loss: 3.51652  (3.18429)
     | > align_error: 0.99027  (0.98740)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.33253  (3.93034)
     | > current_lr: 0.00007 
     | > step_time: 5.22980  (3.67020)
     | > loader_time: 0.02360  (0.04033)


[1m   --> STEP: 77/87 -- GLOBAL_STEP: 278525[0m
     | > decoder_loss: 1.87590  (1.73085)
     | > postnet_loss: 1.49689  (1.40155)
     | > stopnet_loss: 1.41257  (1.49611)
     | > decoder_coarse_loss: 1.83521  (1.67600)
     | > decoder_ddc_loss: 0.00193  (0.00132)
     | > ga_loss: 0.00233  (0.00202)
     | > decoder_diff_spec_loss: 0.49425  (0.47854)
     | > postnet_diff_spec_loss: 0.80481  (0.79856)
     | > decoder_ssim_loss: 0.32667  (0.31268)
     | > postnet_ssim_loss: 0.34504  (0.33261)
     | > loss: 3.21940  (3.18924)
     | > align_error: 0.98341  (0.98741)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.65895  (4.09713)
     | > current_lr: 0.00007 
     | > step_time: 2.51980  (3.63041)
     | > loader_time: 0.05530  (0.03629)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.95944 [0m(+0.34553)
     | > avg_decoder_loss:[92m 2.08620 [0m(-0.01670)
     | > avg_postnet_loss:[92m 1.84482 [0m(-0.02333)
     | > avg_stopnet_loss:[92m 1.30156 [0m(-0.00063)
     | > avg_decoder_coarse_loss:[91m 2.00815 [0m(+0.05664)
     | > avg_decoder_ddc_loss:[91m 0.00111 [0m(+0.00003)
     | > avg_ga_loss:[91m 0.00189 [0m(+0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47374 [0m(+0.00061)
     | > avg_postnet_diff_spec_loss:[92m 0.81032 [0m(-0.00038)
     | > avg_decoder_ssim_loss:[92m 0.32647 [0m(-0.00016)
     | > avg_postnet_ssim_loss:[92m 0.34310 [0m(-0.00125)
     | > avg_loss:[91m 3.28451 [0m(+0.00324)
     | > avg_align_error:[91m 0.98964 [0m(+0.00004)


[4m[1m > EPOCH: 97/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:34:51) [0m

[1m   --> STEP: 14/87 -- GLOBAL_STEP: 278550[0m
     | > decoder_loss: 1.80471  (1.78072)
     | > postnet_loss: 1.32935  (1.42417)
     | > stopnet_loss: 1.50807  (1.51115)
     | > decoder_coarse_loss: 1.74916  (1.72888)
     | > decoder_ddc_loss: 0.00090  (0.00131)
     | > ga_loss: 0.00145  (0.00209)
     | > decoder_diff_spec_loss: 0.51580  (0.49164)
     | > postnet_diff_spec_loss: 0.80109  (0.80627)
     | > decoder_ssim_loss: 0.29251  (0.30624)
     | > postnet_ssim_loss: 0.30951  (0.32476)
     | > loss: 3.21607  (3.23759)
     | > align_error: 0.99093  (0.98727)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.99158  (4.38885)
     | > current_lr: 0.00007 
     | > step_time: 4.84540  (3.89664)
     | > loader_time: 0.02770  (0.04155)


[1m   --> STEP: 39/87 -- GLOBAL_STEP: 278575[0m
     | > decoder_loss: 1.62516  (1.72731)
     | > postnet_loss: 1.42390  (1.38848)
     | > stopnet_loss: 1.49817  (1.48772)
     | > decoder_coarse_loss: 1.59165  (1.67628)
     | > decoder_ddc_loss: 0.00186  (0.00131)
     | > ga_loss: 0.00267  (0.00200)
     | > decoder_diff_spec_loss: 0.43408  (0.47998)
     | > postnet_diff_spec_loss: 0.78786  (0.79995)
     | > decoder_ssim_loss: 0.32073  (0.31534)
     | > postnet_ssim_loss: 0.34377  (0.33459)
     | > loss: 3.14377  (3.17853)
     | > align_error: 0.98131  (0.98738)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 10.82439  (3.76498)
     | > current_lr: 0.00007 
     | > step_time: 2.06240  (3.66323)
     | > loader_time: 0.04270  (0.03493)


[1m   --> STEP: 64/87 -- GLOBAL_STEP: 278600[0m
     | > decoder_loss: 1.64776  (1.73000)
     | > postnet_loss: 1.41308  (1.39381)
     | > stopnet_loss: 1.72073  (1.49617)
     | > decoder_coarse_loss: 1.61030  (1.67727)
     | > decoder_ddc_loss: 0.00147  (0.00132)
     | > ga_loss: 0.00239  (0.00202)
     | > decoder_diff_spec_loss: 0.45296  (0.47901)
     | > postnet_diff_spec_loss: 0.80238  (0.79915)
     | > decoder_ssim_loss: 0.27254  (0.31228)
     | > postnet_ssim_loss: 0.29201  (0.33214)
     | > loss: 3.35578  (3.18751)
     | > align_error: 0.98590  (0.98736)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.84838  (3.84305)
     | > current_lr: 0.00007 
     | > step_time: 3.27430  (3.59023)
     | > loader_time: 0.02580  (0.03342)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 5.12350 [0m(+0.16406)
     | > avg_decoder_loss:[92m 2.05500 [0m(-0.03120)
     | > avg_postnet_loss:[91m 2.00182 [0m(+0.15700)
     | > avg_stopnet_loss:[91m 1.30400 [0m(+0.00244)
     | > avg_decoder_coarse_loss:[92m 1.91655 [0m(-0.09160)
     | > avg_decoder_ddc_loss:[92m 0.00110 [0m(-0.00001)
     | > avg_ga_loss:[91m 0.00190 [0m(+0.00001)
     | > avg_decoder_diff_spec_loss:[91m 0.47559 [0m(+0.00186)
     | > avg_postnet_diff_spec_loss:[91m 0.81141 [0m(+0.00109)
     | > avg_decoder_ssim_loss:[92m 0.32608 [0m(-0.00039)
     | > avg_postnet_ssim_loss:[91m 0.34498 [0m(+0.00188)
     | > avg_loss:[91m 3.29664 [0m(+0.01213)
     | > avg_align_error:[92m 0.98945 [0m(-0.00019)


[4m[1m > EPOCH: 98/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:42:04) [0m

[1m   --> STEP: 1/87 -- GLOBAL_STEP: 278625[0m
     | > decoder_loss: 1.64412  (1.64412)
     | > postnet_loss: 1.33970  (1.33970)
     | > stopnet_loss: 1.33712  (1.33712)
     | > decoder_coarse_loss: 1.57065  (1.57065)
     | > decoder_ddc_loss: 0.00194  (0.00194)
     | > ga_loss: 0.00237  (0.00237)
     | > decoder_diff_spec_loss: 0.47182  (0.47182)
     | > postnet_diff_spec_loss: 0.79059  (0.79059)
     | > decoder_ssim_loss: 0.33677  (0.33677)
     | > postnet_ssim_loss: 0.35404  (0.35404)
     | > loss: 2.97637  (2.97637)
     | > align_error: 0.98301  (0.98301)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 5.34483  (5.34483)
     | > current_lr: 0.00007 
     | > step_time: 4.86350  (4.86355)
     | > loader_time: 0.02430  (0.02426)


[1m   --> STEP: 26/87 -- GLOBAL_STEP: 278650[0m
     | > decoder_loss: 1.80246  (1.73327)
     | > postnet_loss: 1.43857  (1.39532)
     | > stopnet_loss: 1.79606  (1.53828)
     | > decoder_coarse_loss: 1.72087  (1.68056)
     | > decoder_ddc_loss: 0.00133  (0.00128)
     | > ga_loss: 0.00222  (0.00198)
     | > decoder_diff_spec_loss: 0.50865  (0.48389)
     | > postnet_diff_spec_loss: 0.81522  (0.80226)
     | > decoder_ssim_loss: 0.26064  (0.30563)
     | > postnet_ssim_loss: 0.27326  (0.32417)
     | > loss: 3.51242  (3.22980)
     | > align_error: 0.98574  (0.98764)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 2.20573  (4.38024)
     | > current_lr: 0.00007 
     | > step_time: 3.97250  (3.83416)
     | > loader_time: 0.02320  (0.03023)


[1m   --> STEP: 51/87 -- GLOBAL_STEP: 278675[0m
     | > decoder_loss: 1.63110  (1.71391)
     | > postnet_loss: 1.39629  (1.38071)
     | > stopnet_loss: 1.17757  (1.48712)
     | > decoder_coarse_loss: 1.57658  (1.65887)
     | > decoder_ddc_loss: 0.00174  (0.00134)
     | > ga_loss: 0.00220  (0.00200)
     | > decoder_diff_spec_loss: 0.43022  (0.47980)
     | > postnet_diff_spec_loss: 0.78550  (0.79871)
     | > decoder_ssim_loss: 0.36852  (0.31350)
     | > postnet_ssim_loss: 0.39789  (0.33358)
     | > loss: 2.83552  (3.16724)
     | > align_error: 0.98556  (0.98729)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 4.52331  (4.11437)
     | > current_lr: 0.00007 
     | > step_time: 3.07830  (3.64001)
     | > loader_time: 0.01720  (0.02757)


[1m   --> STEP: 76/87 -- GLOBAL_STEP: 278700[0m
     | > decoder_loss: 1.64605  (1.71895)
     | > postnet_loss: 1.30677  (1.38751)
     | > stopnet_loss: 1.51121  (1.49397)
     | > decoder_coarse_loss: 1.60097  (1.66205)
     | > decoder_ddc_loss: 0.00112  (0.00134)
     | > ga_loss: 0.00191  (0.00200)
     | > decoder_diff_spec_loss: 0.47853  (0.47824)
     | > postnet_diff_spec_loss: 0.79639  (0.79799)
     | > decoder_ssim_loss: 0.29493  (0.31220)
     | > postnet_ssim_loss: 0.31459  (0.33217)
     | > loss: 3.13061  (3.17656)
     | > align_error: 0.98977  (0.98731)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 3.09503  (4.13175)
     | > current_lr: 0.00007 
     | > step_time: 4.13160  (3.62672)
     | > loader_time: 0.06780  (0.03105)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[92m 4.63915 [0m(-0.48435)
     | > avg_decoder_loss:[92m 2.02888 [0m(-0.02612)
     | > avg_postnet_loss:[92m 1.93200 [0m(-0.06982)
     | > avg_stopnet_loss:[92m 1.30050 [0m(-0.00351)
     | > avg_decoder_coarse_loss:[92m 1.91271 [0m(-0.00383)
     | > avg_decoder_ddc_loss:[91m 0.00111 [0m(+0.00001)
     | > avg_ga_loss:[92m 0.00189 [0m(-0.00002)
     | > avg_decoder_diff_spec_loss:[92m 0.47395 [0m(-0.00164)
     | > avg_postnet_diff_spec_loss:[91m 0.81158 [0m(+0.00017)
     | > avg_decoder_ssim_loss:[92m 0.32561 [0m(-0.00047)
     | > avg_postnet_ssim_loss:[92m 0.34473 [0m(-0.00025)
     | > avg_loss:[92m 3.26757 [0m(-0.02907)
     | > avg_align_error:[92m 0.98940 [0m(-0.00005)


[4m[1m > EPOCH: 99/100[0m
 --> /mnt/aibb_data/development/atseng/VCproject/trained_models/tacotron-DDC/tecotronddc_libritts-December-10-2021_09+37AM-f92878cf

 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 5679
 | > Max length sequence: 721942.0
 | > Min length sequence: 7462.0
 | > Avg length sequence: 135172.60802958268
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 101
 | > Batch group size: 0.

[1m > TRAINING (2021-12-10 21:49:09) [0m

[1m   --> STEP: 13/87 -- GLOBAL_STEP: 278725[0m
     | > decoder_loss: 1.92907  (1.77279)
     | > postnet_loss: 1.53184  (1.42629)
     | > stopnet_loss: 1.66903  (1.51856)
     | > decoder_coarse_loss: 1.82281  (1.70592)
     | > decoder_ddc_loss: 0.00172  (0.00137)
     | > ga_loss: 0.00246  (0.00209)
     | > decoder_diff_spec_loss: 0.51835  (0.48922)
     | > postnet_diff_spec_loss: 0.84764  (0.80668)
     | > decoder_ssim_loss: 0.30098  (0.30673)
     | > postnet_ssim_loss: 0.32096  (0.32589)
     | > loss: 3.49970  (3.23776)
     | > align_error: 0.98364  (0.98669)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 11.90923  (4.79173)
     | > current_lr: 0.00007 
     | > step_time: 2.14270  (3.74107)
     | > loader_time: 0.02260  (0.03921)


[1m   --> STEP: 38/87 -- GLOBAL_STEP: 278750[0m
     | > decoder_loss: 1.68097  (1.71912)
     | > postnet_loss: 1.31744  (1.38074)
     | > stopnet_loss: 1.25260  (1.48369)
     | > decoder_coarse_loss: 1.63891  (1.66676)
     | > decoder_ddc_loss: 0.00121  (0.00133)
     | > ga_loss: 0.00181  (0.00195)
     | > decoder_diff_spec_loss: 0.45165  (0.48025)
     | > postnet_diff_spec_loss: 0.77366  (0.79989)
     | > decoder_ssim_loss: 0.35427  (0.31440)
     | > postnet_ssim_loss: 0.37408  (0.33426)
     | > loss: 2.90969  (3.16763)
     | > align_error: 0.98887  (0.98730)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 1.65636  (3.65147)
     | > current_lr: 0.00007 
     | > step_time: 4.41380  (3.77435)
     | > loader_time: 0.02240  (0.03898)


[1m   --> STEP: 63/87 -- GLOBAL_STEP: 278775[0m
     | > decoder_loss: 1.90203  (1.71697)
     | > postnet_loss: 1.49771  (1.38100)
     | > stopnet_loss: 2.04803  (1.49458)
     | > decoder_coarse_loss: 1.83515  (1.66077)
     | > decoder_ddc_loss: 0.00110  (0.00135)
     | > ga_loss: 0.00217  (0.00198)
     | > decoder_diff_spec_loss: 0.55134  (0.47862)
     | > postnet_diff_spec_loss: 0.85792  (0.79860)
     | > decoder_ssim_loss: 0.23704  (0.31215)
     | > postnet_ssim_loss: 0.24569  (0.33246)
     | > loss: 3.84087  (3.17496)
     | > align_error: 0.98779  (0.98714)
     | > amp_scaler: 32768.00000  (32768.00000)
     | > grad_norm: 6.59096  (4.07855)
     | > current_lr: 0.00007 
     | > step_time: 3.82490  (3.68725)
     | > loader_time: 0.02430  (0.03926)


 > DataLoader initialization
 | > Use phonemes: True
   | > phoneme language: en-us
 | > Number of instances : 57
 | > Max length sequence: 338182.0
 | > Min length sequence: 13462.0
 | > Avg length sequence: 131701.94736842104
 | > Num. instances discarded by max-min (max=440000, min=0) seq limits: 0
 | > Batch group size: 0.

[1m > EVALUATION [0m


  [1m--> EVAL PERFORMANCE[0m
     | > avg_loader_time:[91m 4.93830 [0m(+0.29915)
     | > avg_decoder_loss:[91m 2.04384 [0m(+0.01496)
     | > avg_postnet_loss:[91m 1.98491 [0m(+0.05291)
     | > avg_stopnet_loss:[92m 1.29994 [0m(-0.00055)
     | > avg_decoder_coarse_loss:[92m 1.91198 [0m(-0.00073)
     | > avg_decoder_ddc_loss:[91m 0.00111 [0m(+0.00000)
     | > avg_ga_loss:[92m 0.00188 [0m(-0.00000)
     | > avg_decoder_diff_spec_loss:[91m 0.47405 [0m(+0.00009)
     | > avg_postnet_diff_spec_loss:[91m 0.81187 [0m(+0.00029)
     | > avg_decoder_ssim_loss:[92m 0.32560 [0m(-0.00001)
     | > avg_postnet_ssim_loss:[91m 0.34478 [0m(+0.00005)
     | > avg_loss:[91m 3.28388 [0m(+0.01631)
     | > avg_align_error:[92m 0.98930 [0m(-0.00010)

